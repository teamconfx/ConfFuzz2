[
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testRecoveryV1",
        "failure": "java.io.FileNotFoundException",
        "errorMessage": "/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/task_200707121733_0001_m_000000/part-00000 (No such file or directory)",
        "stackTrace": [
            "java.base/java.io.FileInputStream.open0(Native Method)",
            "java.base/java.io.FileInputStream.open(FileInputStream.java:219)",
            "java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.slurp(TestFileOutputCommitter.java:570)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:184)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:121)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:161)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterV2",
        "failure": "java.io.FileNotFoundException",
        "errorMessage": "/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/part-00000 (No such file or directory)",
        "stackTrace": [
            "java.base/java.io.FileInputStream.open0(Native Method)",
            "java.base/java.io.FileInputStream.open(FileInputStream.java:219)",
            "java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.slurp(TestFileOutputCommitter.java:570)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:184)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:349)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterV1",
        "failure": "java.io.FileNotFoundException",
        "errorMessage": "/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/part-00000 (No such file or directory)",
        "stackTrace": [
            "java.base/java.io.FileInputStream.open0(Native Method)",
            "java.base/java.io.FileInputStream.open(FileInputStream.java:219)",
            "java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.slurp(TestFileOutputCommitter.java:570)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:184)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:349)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1(TestFileOutputCommitter.java:355)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV2",
        "failure": "java.io.FileNotFoundException",
        "errorMessage": "/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/part-00000 (No such file or directory)",
        "stackTrace": [
            "java.base/java.io.FileInputStream.open0(Native Method)",
            "java.base/java.io.FileInputStream.open(FileInputStream.java:219)",
            "java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.slurp(TestFileOutputCommitter.java:570)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:184)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:305)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:274)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testRecoveryV2",
        "failure": "java.io.FileNotFoundException",
        "errorMessage": "/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/part-00000 (No such file or directory)",
        "stackTrace": [
            "java.base/java.io.FileInputStream.open0(Native Method)",
            "java.base/java.io.FileInputStream.open(FileInputStream.java:219)",
            "java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.slurp(TestFileOutputCommitter.java:570)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:184)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:155)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV2(TestFileOutputCommitter.java:166)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager",
        "testMethod": "testDetermineCacheVisibilities",
        "failure": "java.io.FileNotFoundException",
        "errorMessage": "File file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/secondcachefile does not exist",
        "stackTrace": [
            "org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779)",
            "org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100)",
            "org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769)",
            "org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462)",
            "org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.getFileStatus(ClientDistributedCacheManager.java:325)",
            "org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.checkPermissionOfOther(ClientDistributedCacheManager.java:294)",
            "org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.isPublic(ClientDistributedCacheManager.java:258)",
            "org.apache.hadoop.mapreduce.filecache.ClientDistributedCacheManager.determineCacheVisibilities(ClientDistributedCacheManager.java:178)",
            "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.testDetermineCacheVisibilities(TestClientDistributedCacheManager.java:152)",
            "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.testDetermineCacheVisibilities$$CONFUZZ(TestClientDistributedCacheManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "fs.file.impl.disable.cache": "true"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-2",
        "testClass": "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager",
        "testMethod": "testDetermineTimestamps",
        "failure": "java.io.IOException",
        "errorMessage": "-443488098",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.createTempFile(TestClientDistributedCacheManager.java:254)",
            "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.setup(TestClientDistributedCacheManager.java:78)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1382379310"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-2",
        "testClass": "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager",
        "testMethod": "testDetermineCacheVisibilities",
        "failure": "java.io.IOException",
        "errorMessage": "-1358084722",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.createTempFile(TestClientDistributedCacheManager.java:254)",
            "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.setup(TestClientDistributedCacheManager.java:78)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "326320286"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testBinaryCredentialsWithScheme",
        "failure": "java.io.IOException",
        "errorMessage": "RM_HA_IDS property is not set for HA resource manager",
        "stackTrace": [
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getYarnConfWithRmHaId(YarnClientUtils.java:198)",
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getRmPrincipal(YarnClientUtils.java:99)",
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getRmPrincipal(YarnClientUtils.java:77)",
            "org.apache.hadoop.mapred.Master.getMasterPrincipal(Master.java:58)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.setup(TestTokenCache.java:54)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.resourcemanager.ha.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testObtainTokens",
        "failure": "java.io.IOException",
        "errorMessage": "RM_HA_IDS property is not set for HA resource manager",
        "stackTrace": [
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getYarnConfWithRmHaId(YarnClientUtils.java:198)",
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getRmPrincipal(YarnClientUtils.java:99)",
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getRmPrincipal(YarnClientUtils.java:77)",
            "org.apache.hadoop.mapred.Master.getMasterPrincipal(Master.java:58)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.setup(TestTokenCache.java:54)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.resourcemanager.ha.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testCleanUpTokenReferral",
        "failure": "java.io.IOException",
        "errorMessage": "RM_HA_IDS property is not set for HA resource manager",
        "stackTrace": [
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getYarnConfWithRmHaId(YarnClientUtils.java:198)",
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getRmPrincipal(YarnClientUtils.java:99)",
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getRmPrincipal(YarnClientUtils.java:77)",
            "org.apache.hadoop.mapred.Master.getMasterPrincipal(Master.java:58)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.setup(TestTokenCache.java:54)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.resourcemanager.ha.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testGetTokensForNamenodes",
        "failure": "java.io.IOException",
        "errorMessage": "RM_HA_IDS property is not set for HA resource manager",
        "stackTrace": [
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getYarnConfWithRmHaId(YarnClientUtils.java:198)",
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getRmPrincipal(YarnClientUtils.java:99)",
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getRmPrincipal(YarnClientUtils.java:77)",
            "org.apache.hadoop.mapred.Master.getMasterPrincipal(Master.java:58)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.setup(TestTokenCache.java:54)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.resourcemanager.ha.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testBinaryCredentialsWithoutScheme",
        "failure": "java.io.IOException",
        "errorMessage": "RM_HA_IDS property is not set for HA resource manager",
        "stackTrace": [
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getYarnConfWithRmHaId(YarnClientUtils.java:198)",
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getRmPrincipal(YarnClientUtils.java:99)",
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getRmPrincipal(YarnClientUtils.java:77)",
            "org.apache.hadoop.mapred.Master.getMasterPrincipal(Master.java:58)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.setup(TestTokenCache.java:54)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.resourcemanager.ha.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testSingleTokenFetch",
        "failure": "java.io.IOException",
        "errorMessage": "RM_HA_IDS property is not set for HA resource manager",
        "stackTrace": [
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getYarnConfWithRmHaId(YarnClientUtils.java:198)",
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getRmPrincipal(YarnClientUtils.java:99)",
            "org.apache.hadoop.yarn.client.util.YarnClientUtils.getRmPrincipal(YarnClientUtils.java:77)",
            "org.apache.hadoop.mapred.Master.getMasterPrincipal(Master.java:58)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.setup(TestTokenCache.java:54)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "yarn.resourcemanager.ha.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testObtainTokens",
        "failure": "java.io.IOException",
        "errorMessage": "Can't get Master Kerberos principal for use as renewer",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:134)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testObtainTokens(TestTokenCache.java:61)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testObtainTokens$$CONFUZZ(TestTokenCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.framework.name": "classic"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testSingleTokenFetch",
        "failure": "java.io.IOException",
        "errorMessage": "Can't get Master Kerberos principal for use as renewer",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:134)",
            "org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:102)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testSingleTokenFetch(TestTokenCache.java:175)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testSingleTokenFetch$$CONFUZZ(TestTokenCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.framework.name": "classic"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.split.TestJobSplitWriter",
        "testMethod": "testMaxBlockLocationsOldSplits",
        "failure": "java.io.IOException",
        "errorMessage": "Split metadata size exceeded 3. Aborting job job__0000",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.split.SplitMetaInfoReader.readSplitMetaInfo(SplitMetaInfoReader.java:53)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits(TestJobSplitWriter.java:77)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits$$CONFUZZ(TestJobSplitWriter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.split.metainfo.maxsize": "3"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.split.TestJobSplitWriter",
        "testMethod": "testMaxBlockLocationsNewSplits",
        "failure": "java.io.IOException",
        "errorMessage": "Split metadata size exceeded 21. Aborting job job__0000",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.split.SplitMetaInfoReader.readSplitMetaInfo(SplitMetaInfoReader.java:53)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsNewSplits(TestJobSplitWriter.java:53)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsNewSplits$$CONFUZZ(TestJobSplitWriter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.split.metainfo.maxsize": "21"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-42",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestShuffleScheduler",
        "testMethod": "TestSucceedAndFailedCopyMap",
        "failure": "java.lang.ArithmeticException",
        "errorMessage": "/ by zero",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.checkAndInformMRAppMaster(ShuffleSchedulerImpl.java:347)",
            "org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.copyFailed(ShuffleSchedulerImpl.java:308)",
            "org.apache.hadoop.mapreduce.task.reduce.TestShuffleScheduler.TestSucceedAndFailedCopyMap(TestShuffleScheduler.java:285)",
            "org.apache.hadoop.mapreduce.task.reduce.TestShuffleScheduler.TestSucceedAndFailedCopyMap$$CONFUZZ(TestShuffleScheduler.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.reduce.shuffle.notify.readerror": "false",
            "mapreduce.reduce.shuffle.maxfetchfailures": "0"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-52",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testFailAbortV2",
        "failure": "java.lang.ArrayIndexOutOfBoundsException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86)",
            "org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112)",
            "java.base/java.io.DataOutputStream.write(DataOutputStream.java:107)",
            "org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:71)",
            "org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:86)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:61)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:531)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV2(TestFileOutputCommitter.java:565)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.compression.codec.snappy.buffersize": "10",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.SnappyCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-52",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.ArrayIndexOutOfBoundsException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86)",
            "org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112)",
            "java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81)",
            "java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142)",
            "java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:182)",
            "java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:191)",
            "org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.close(WritableSerialization.java:103)",
            "org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:1397)",
            "org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306)",
            "org.apache.hadoop.mapred.MapFileOutputFormat$1.close(MapFileOutputFormat.java:80)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.writeMapFileOutput(TestFileOutputCommitter.java:85)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:382)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "io.compression.codec.snappy.buffersize": "31",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.SnappyCodec"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-52",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testFailAbortV1",
        "failure": "java.lang.ArrayIndexOutOfBoundsException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86)",
            "org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112)",
            "java.base/java.io.DataOutputStream.write(DataOutputStream.java:107)",
            "org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:71)",
            "org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:86)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:61)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:531)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV1(TestFileOutputCommitter.java:560)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.SnappyCodec",
            "io.compression.codec.snappy.buffersize": "5"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-52",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testRecoveryUpgradeV1V2",
        "failure": "java.lang.ArrayIndexOutOfBoundsException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86)",
            "org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112)",
            "java.base/java.io.DataOutputStream.write(DataOutputStream.java:107)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:78)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:93)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:114)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:162)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryUpgradeV1V2(TestFileOutputCommitter.java:219)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryUpgradeV1V2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.SnappyCodec",
            "io.compression.codec.snappy.buffersize": "24"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterV2TaskCleanupEnabled",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:223)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:315)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled(TestFileOutputCommitter.java:331)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testFailAbortV2",
        "failure": "java.lang.AssertionError",
        "errorMessage": "/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/_temporary/_attempt_200707121733_0001_m_000000_0/part-00000 does not exists",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:543)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV2(TestFileOutputCommitter.java:565)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testFailAbortV1",
        "failure": "java.lang.AssertionError",
        "errorMessage": "/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/_temporary/_attempt_200707121733_0001_m_000000_0/part-00000 does not exists",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:543)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV1(TestFileOutputCommitter.java:560)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testFailAbortV1",
        "failure": "java.lang.AssertionError",
        "errorMessage": "/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1/_temporary/attempt_200707121733_0001_m_000000_0/part-m-00000 does not exists",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:703)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1(TestFileOutputCommitter.java:720)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterV2TaskCleanupEnabled",
        "failure": "java.lang.AssertionError",
        "errorMessage": "job temp dir still exists",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertFalse(Assert.java:65)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:311)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled(TestFileOutputCommitter.java:331)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.fileoutputcommitter.cleanup.skipped": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-151",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV1",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Duplicate commit successful: wrong behavior for version 1.",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:311)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:269)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.fileoutputcommitter.cleanup.skipped": "true"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-151",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV1",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Duplicate commit success: wrong behavior for version 1.",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:376)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:336)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.fileoutputcommitter.cleanup.skipped": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestLineRecordReader",
        "testMethod": "testRecordSpanningMultipleSplitsCompressed",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Wrong number of records expected:<4> but was:<3>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.apache.hadoop.mapred.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:252)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed(TestLineRecordReader.java:279)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.input.linerecordreader.line.maxlength": "13018"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testRecordSpanningMultipleSplitsCompressed",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Wrong number of records expected:<4> but was:<3>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:197)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed(TestLineRecordReader.java:225)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.input.linerecordreader.line.maxlength": "29377"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testRecordSpanningMultipleSplits",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Wrong number of records expected:<4> but was:<14>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:197)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits(TestLineRecordReader.java:214)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.input.linerecordreader.line.maxlength": "10"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager",
        "testMethod": "testMemoryMerge",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Should be a memory merge",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testMemoryMerge(TestMergeManager.java:99)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testMemoryMerge$$CONFUZZ(TestMergeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.reduce.merge.memtomem.enabled": "true",
            "mapreduce.reduce.merge.memtomem.threshold": "1"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-140",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testBzipWithMultibyteDelimiter",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Unexpected number of records in split  expected:<60> but was:<61>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:114)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:646)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "52"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-140",
        "testClass": "org.apache.hadoop.mapred.TestLineRecordReader",
        "testMethod": "testBzipWithMultibyteDelimiter",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Unexpected number of records in split expected:<60> but was:<61>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:110)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:684)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "11"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobConf",
        "testMethod": "testNegativeValuesForMemoryParams",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<1024> but was:<269>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.mapred.TestJobConf.testNegativeValuesForMemoryParams(TestJobConf.java:299)",
            "org.apache.hadoop.mapred.TestJobConf.testNegativeValuesForMemoryParams$$CONFUZZ(TestJobConf.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapred.task.maxvmem": "282993279"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobConf",
        "testMethod": "testDeprecatedPropertyNameForTaskVmem",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<1024> but was:<0>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.mapred.TestJobConf.testDeprecatedPropertyNameForTaskVmem(TestJobConf.java:173)",
            "org.apache.hadoop.mapred.TestJobConf.testDeprecatedPropertyNameForTaskVmem$$CONFUZZ(TestJobConf.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapred.task.maxvmem": "32896"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobConf",
        "testMethod": "testDeprecatedPropertyNameForTaskVmem",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<1025> but was:<1024>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.mapred.TestJobConf.testDeprecatedPropertyNameForTaskVmem(TestJobConf.java:178)",
            "org.apache.hadoop.mapred.TestJobConf.testDeprecatedPropertyNameForTaskVmem$$CONFUZZ(TestJobConf.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapred.task.maxvmem": "1073775872"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobConf",
        "testMethod": "testJobConf",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<100000> but was:<0>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.mapred.TestJobConf.testJobConf(TestJobConf.java:146)",
            "org.apache.hadoop.mapred.TestJobConf.testJobConf$$CONFUZZ(TestJobConf.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapred.task.maxvmem": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobEndNotifier",
        "testMethod": "testLocalJobRunnerRetryCount",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<4> but was:<0>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.mapred.TestJobEndNotifier.testLocalJobRunnerRetryCount(TestJobEndNotifier.java:164)",
            "org.apache.hadoop.mapred.TestJobEndNotifier.testLocalJobRunnerRetryCount$$CONFUZZ(TestJobEndNotifier.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.request.header.size": "15"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterV2TaskCleanupEnabled",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:286)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled(TestFileOutputCommitter.java:331)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterV1",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1(TestFileOutputCommitter.java:355)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterV2",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:286)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:326)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV1",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV1(TestFileOutputCommitter.java:388)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testFailAbortV1",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:529)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV1(TestFileOutputCommitter.java:560)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testAbortV2",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testFailAbortV1",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:685)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1(TestFileOutputCommitter.java:720)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testFailAbortV2",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:685)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV2(TestFileOutputCommitter.java:725)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterV1",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:286)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV1(TestFileOutputCommitter.java:321)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV2",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:295)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:274)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testRecoveryV2",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:161)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV2(TestFileOutputCommitter.java:214)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testRecoveryV1",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:161)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:209)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV1",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:362)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:336)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterRepeatableV1",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterRepeatableV2",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV2",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testProgressDuringMerge",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterV2",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testAbortV2",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testRecoveryV2",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:109)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV2(TestFileOutputCommitter.java:166)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.ClassNotFoundException",
        "errorMessage": "net.jpountz.lz4.LZ4Factory",
        "stackTrace": [
            "java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)",
            "java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)",
            "java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)",
            "org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66)",
            "org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.Lz4Codec",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testProgressDuringMerge",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "SequenceFile doesn't work with GzipCodec without native-hadoop code!",
        "stackTrace": [
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.GzipCodec",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "SequenceFile doesn't work with GzipCodec without native-hadoop code!",
        "stackTrace": [
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.GzipCodec",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testProgressDuringMerge",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "SequenceFile doesn't work with GzipCodec without native-hadoop code!",
        "stackTrace": [
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.GzipCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testProgressDuringMerge",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "SequenceFile doesn't work with GzipCodec without native-hadoop code!",
        "stackTrace": [
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.type": "NONE",
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.GzipCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "SequenceFile doesn't work with GzipCodec without native-hadoop code!",
        "stackTrace": [
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK",
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.GzipCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "SequenceFile doesn't work with GzipCodec without native-hadoop code!",
        "stackTrace": [
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.GzipCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "SequenceFile doesn't work with GzipCodec without native-hadoop code!",
        "stackTrace": [
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.GzipCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "SequenceFile doesn't work with GzipCodec without native-hadoop code!",
        "stackTrace": [
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.GzipCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "SequenceFile doesn't work with GzipCodec without native-hadoop code!",
        "stackTrace": [
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.GzipCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "SequenceFile doesn't work with GzipCodec without native-hadoop code!",
        "stackTrace": [
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.GzipCodec"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-77",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestFetcher",
        "testMethod": "testInterruptOnDisk",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Minimum value of buffer size is 512.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.crypto.CryptoStreamUtils.checkBufferSize(CryptoStreamUtils.java:70)",
            "org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:104)",
            "org.apache.hadoop.fs.crypto.CryptoFSDataOutputStream.<init>(CryptoFSDataOutputStream.java:38)",
            "org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(CryptoUtils.java:141)",
            "org.apache.hadoop.mapreduce.security.IntermediateEncryptedStream.wrapIfNecessary(IntermediateEncryptedStream.java:46)",
            "org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<init>(OnDiskMapOutput.java:87)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptOnDisk(TestFetcher.java:645)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptOnDisk$$CONFUZZ(TestFetcher.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.encrypted-intermediate-data": "true",
            "mapreduce.job.encrypted-intermediate-data.buffer.kb": "632442548"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager",
        "testMethod": "testZeroShuffleMemoryLimitPercent",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value for mapreduce.reduce.shuffle.input.buffer.percent: -0.48889053",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:169)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testZeroShuffleMemoryLimitPercent(TestMergeManager.java:320)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testZeroShuffleMemoryLimitPercent$$CONFUZZ(TestMergeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.reduce.shuffle.input.buffer.percent": "-0.48889052867889404"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-77",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager",
        "testMethod": "testZeroShuffleMemoryLimitPercent",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Minimum value of buffer size is 512.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.crypto.CryptoStreamUtils.checkBufferSize(CryptoStreamUtils.java:70)",
            "org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:104)",
            "org.apache.hadoop.fs.crypto.CryptoFSDataOutputStream.<init>(CryptoFSDataOutputStream.java:38)",
            "org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(CryptoUtils.java:141)",
            "org.apache.hadoop.mapreduce.security.IntermediateEncryptedStream.wrapIfNecessary(IntermediateEncryptedStream.java:46)",
            "org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<init>(OnDiskMapOutput.java:87)",
            "org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.reserve(MergeManagerImpl.java:274)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.verifyReservedMapOutputType(TestMergeManager.java:309)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testZeroShuffleMemoryLimitPercent(TestMergeManager.java:323)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testZeroShuffleMemoryLimitPercent$$CONFUZZ(TestMergeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.encrypted-intermediate-data.buffer.kb": "1429102949",
            "mapreduce.job.encrypted-intermediate-data": "true"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-77",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestFetcher",
        "testMethod": "testCorruptedIFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Minimum value of buffer size is 512.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.crypto.CryptoStreamUtils.checkBufferSize(CryptoStreamUtils.java:70)",
            "org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:104)",
            "org.apache.hadoop.fs.crypto.CryptoFSDataOutputStream.<init>(CryptoFSDataOutputStream.java:38)",
            "org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(CryptoUtils.java:141)",
            "org.apache.hadoop.mapreduce.security.IntermediateEncryptedStream.wrapIfNecessary(IntermediateEncryptedStream.java:46)",
            "org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<init>(OnDiskMapOutput.java:87)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCorruptedIFile(TestFetcher.java:539)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCorruptedIFile$$CONFUZZ(TestFetcher.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.encrypted-intermediate-data.buffer.kb": "417711482",
            "mapreduce.job.encrypted-intermediate-data": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "SequenceFile doesn't work with GzipCodec without native-hadoop code!",
        "stackTrace": [
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.GzipCodec",
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "SequenceFile doesn't work with GzipCodec without native-hadoop code!",
        "stackTrace": [
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.GzipCodec",
            "mapreduce.output.fileoutputformat.compress.type": "NONE",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobEndNotifier",
        "testMethod": "testLocalJobRunnerUriSubstitution",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=1 < max=1 for QueuedThreadPool[qtp1299471046]@4d745ac6{STARTING,1<=0<=1,i=0,r=-1,q=0}[ReservedThreadExecutor@2262bc86{s=0/1,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.util.thread.ReservedThreadExecutor.doStart(ReservedThreadExecutor.java:163)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.util.thread.QueuedThreadPool.doStart(QueuedThreadPool.java:214)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.threads": "1"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobEndNotifier",
        "testMethod": "testLocalJobRunnerRetryCount",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=1 < max=1 for QueuedThreadPool[qtp1532904892]@5b5e45bc{STARTING,1<=0<=1,i=0,r=-1,q=0}[ReservedThreadExecutor@678b3746{s=0/1,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.util.thread.ReservedThreadExecutor.doStart(ReservedThreadExecutor.java:163)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.util.thread.QueuedThreadPool.doStart(QueuedThreadPool.java:214)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.threads": "1"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobEndNotifier",
        "testMethod": "testLocalJobRunnerUriSubstitution",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=302022658 < max=200 for QueuedThreadPool[qtp1629827491]@612531a3{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@1d5958d3{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "302022655"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobEndNotifier",
        "testMethod": "testNotificationTimeout",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=11551 < max=200 for QueuedThreadPool[qtp1602310266]@5f81507a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@37ab1b10{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "11548"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobEndNotifier",
        "testMethod": "testLocalJobRunnerRetryCount",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=515 < max=200 for QueuedThreadPool[qtp1706518410]@65b7678a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@1ecd09d5{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "512"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobEndNotifier",
        "testMethod": "testLocalJobRunnerUriSubstitution",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=931 < max=200 for QueuedThreadPool[qtp1553033411]@5c9168c3{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@62c1259f{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "929"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobEndNotifier",
        "testMethod": "testNotificationTimeout",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=59665411 < max=200 for QueuedThreadPool[qtp1257841023]@4af9217f{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@287c4e96{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "59665409"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestJobEndNotifier",
        "testMethod": "testLocalJobRunnerRetryCount",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=23868 < max=735 for QueuedThreadPool[qtp1109227776]@421d7900{STARTED,8<=8<=735,i=8,r=-1,q=0}[ReservedThreadExecutor@68feca3a{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "23866"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterV2TaskCleanupEnabled",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-577794076",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:286)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled(TestFileOutputCommitter.java:331)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1844675012"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testRecoveryV1",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1795044154",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:109)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:161)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "277769238"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV2",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1222646277",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1295806179"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestLineRecordReader",
        "testMethod": "testUncompressedInputWithLargeSplitSize",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-463171129",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapred.TestLineRecordReader.createInputFile(TestLineRecordReader.java:363)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputWithLargeSplitSize(TestLineRecordReader.java:377)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputWithLargeSplitSize$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1857410895"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterV1",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-312113122",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1(TestFileOutputCommitter.java:355)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1874195118"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV2",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-493513145",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "899602383"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV1",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1224424623",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV1(TestFileOutputCommitter.java:388)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1295608585"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testUncompressedInputCustomDelimiterPosValue",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-192715284",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.createInputFile(TestLineRecordReader.java:312)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue(TestLineRecordReader.java:417)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1410242956"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testBinaryCredentialsWithScheme",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-320815862",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331)",
            "org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:325)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentials(TestTokenCache.java:99)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithScheme(TestTokenCache.java:74)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithScheme$$CONFUZZ(TestTokenCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "918790970"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestLineRecordReader",
        "testMethod": "testUncompressedInputDefaultDelimiterPosValue",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1356002809",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapred.TestLineRecordReader.createInputFile(TestLineRecordReader.java:363)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue(TestLineRecordReader.java:607)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1758207375"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.split.TestJobSplitWriter",
        "testMethod": "testMaxBlockLocationsOldSplits",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1274735028",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:728)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.createFile(JobSplitWriter.java:102)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(JobSplitWriter.java:91)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits(TestJobSplitWriter.java:74)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits$$CONFUZZ(TestJobSplitWriter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1290018540"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.split.TestJobSplitWriter",
        "testMethod": "testMaxBlockLocationsNewSplits",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1386742863",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:728)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.createFile(JobSplitWriter.java:102)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(JobSplitWriter.java:78)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsNewSplits(TestJobSplitWriter.java:50)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsNewSplits$$CONFUZZ(TestJobSplitWriter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1277573225"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testGetTokensForNamenodes",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-739245495",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331)",
            "org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:325)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testGetTokensForNamenodes(TestTokenCache.java:205)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testGetTokensForNamenodes$$CONFUZZ(TestTokenCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1349517377"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testAbortV2",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1850573695",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "271599289"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testAbortV1",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-341189566",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:477)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1870964402"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testUncompressedInputContainingCRLF",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-506486317",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.createInputFile(TestLineRecordReader.java:312)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF(TestLineRecordReader.java:400)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "420942331"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV2",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1147077643",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:295)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:274)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "349765517"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestLineRecordReader",
        "testMethod": "testUncompressedInputContainingCRLF",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1465609958",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapred.TestLineRecordReader.createInputFile(TestLineRecordReader.java:363)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputContainingCRLF(TestLineRecordReader.java:467)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputContainingCRLF$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "791591626"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testUncompressedInputDefaultDelimiterPosValue",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-707224449",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.createInputFile(TestLineRecordReader.java:312)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue(TestLineRecordReader.java:559)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1353075271"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1097184774",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1309746346"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testRecoveryV1",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1682215051",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:109)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:161)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "file.bytes-per-checksum": "290305805"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV2",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1270647049",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "file.bytes-per-checksum": "336035583"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterV2",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-270995421",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "file.bytes-per-checksum": "1401545163"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterV1",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1637205394",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1(TestFileOutputCommitter.java:355)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "file.bytes-per-checksum": "295306878"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-2022686140",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK",
            "file.bytes-per-checksum": "252475684"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-2102121242",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "file.bytes-per-checksum": "720868150",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV2",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-210701491",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:295)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:274)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1885463077",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-694178464",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "400087648",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-50",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-609613437",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1363920939",
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-68",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager",
        "testMethod": "testLargeMemoryLimits",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:106)",
            "org.apache.hadoop.fs.crypto.CryptoFSDataOutputStream.<init>(CryptoFSDataOutputStream.java:38)",
            "org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(CryptoUtils.java:141)",
            "org.apache.hadoop.mapreduce.security.IntermediateEncryptedStream.wrapIfNecessary(IntermediateEncryptedStream.java:46)",
            "org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<init>(OnDiskMapOutput.java:87)",
            "org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.reserve(MergeManagerImpl.java:274)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.verifyReservedMapOutputType(TestMergeManager.java:309)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testLargeMemoryLimits(TestMergeManager.java:303)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testLargeMemoryLimits$$CONFUZZ(TestMergeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.encrypted-intermediate-data": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-68",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestFetcher",
        "testMethod": "testInterruptOnDisk",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:106)",
            "org.apache.hadoop.fs.crypto.CryptoFSDataOutputStream.<init>(CryptoFSDataOutputStream.java:38)",
            "org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(CryptoUtils.java:141)",
            "org.apache.hadoop.mapreduce.security.IntermediateEncryptedStream.wrapIfNecessary(IntermediateEncryptedStream.java:46)",
            "org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<init>(OnDiskMapOutput.java:87)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptOnDisk(TestFetcher.java:645)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptOnDisk$$CONFUZZ(TestFetcher.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.encrypted-intermediate-data": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-68",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager",
        "testMethod": "testZeroShuffleMemoryLimitPercent",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:106)",
            "org.apache.hadoop.fs.crypto.CryptoFSDataOutputStream.<init>(CryptoFSDataOutputStream.java:38)",
            "org.apache.hadoop.mapreduce.CryptoUtils.wrapIfNecessary(CryptoUtils.java:141)",
            "org.apache.hadoop.mapreduce.security.IntermediateEncryptedStream.wrapIfNecessary(IntermediateEncryptedStream.java:46)",
            "org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<init>(OnDiskMapOutput.java:87)",
            "org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.reserve(MergeManagerImpl.java:274)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.verifyReservedMapOutputType(TestMergeManager.java:309)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testZeroShuffleMemoryLimitPercent(TestMergeManager.java:323)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testZeroShuffleMemoryLimitPercent$$CONFUZZ(TestMergeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.encrypted-intermediate-data": "true"
        }
    },
    {
        "status": "TEST-BUG",
        "bugId": "Bug-165",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testBinaryCredentialsWithScheme",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentials(TestTokenCache.java:95)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithScheme(TestTokenCache.java:74)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithScheme$$CONFUZZ(TestTokenCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.framework.name": "classic"
        }
    },
    {
        "status": "TEST-BUG",
        "bugId": "Bug-165",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testGetTokensForNamenodes",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testGetTokensForNamenodes(TestTokenCache.java:202)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testGetTokensForNamenodes$$CONFUZZ(TestTokenCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.framework.name": "classic"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-69",
        "testClass": "org.apache.hadoop.mapreduce.TestJobResourceUploader",
        "testMethod": "testErasureCodingDisabled",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.JobResourceUploader.jobIDToAppId(JobResourceUploader.java:91)",
            "org.apache.hadoop.mapreduce.JobResourceUploader.initSharedCache(JobResourceUploader.java:79)",
            "org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:134)",
            "org.apache.hadoop.mapreduce.TestJobResourceUploader.testErasureCodingSetting(TestJobResourceUploader.java:442)",
            "org.apache.hadoop.mapreduce.TestJobResourceUploader.testErasureCodingDisabled(TestJobResourceUploader.java:380)",
            "org.apache.hadoop.mapreduce.TestJobResourceUploader.testErasureCodingDisabled$$CONFUZZ(TestJobResourceUploader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.sharedcache.mode": "archives",
            "mapreduce.framework.name": "yarn",
            "yarn.sharedcache.enabled": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-27",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testRecoveryV1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46)",
            "org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134)",
            "org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:109)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:161)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "io.file.buffer.size": "1510943493"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-27",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testFailAbortV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46)",
            "org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134)",
            "org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:529)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV2(TestFileOutputCommitter.java:565)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "io.file.buffer.size": "1627720800"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.lib.TestCombineFileRecordReader",
        "testMethod": "testInitNextRecordReader",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.util.LineReader.<init>(LineReader.java:142)",
            "org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37)",
            "org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.<init>(UncompressedSplitLineReader.java:46)",
            "org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:142)",
            "org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67)",
            "org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper.<init>(CombineFileRecordReaderWrapper.java:60)",
            "org.apache.hadoop.mapred.lib.TestCombineFileRecordReader$TextRecordReaderWrapper.<init>(TestCombineFileRecordReader.java:52)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.mapred.lib.CombineFileRecordReader.initNextRecordReader(CombineFileRecordReader.java:142)",
            "org.apache.hadoop.mapred.lib.CombineFileRecordReader.<init>(CombineFileRecordReader.java:117)",
            "org.apache.hadoop.mapred.lib.TestCombineFileRecordReader.testInitNextRecordReader(TestCombineFileRecordReader.java:77)",
            "org.apache.hadoop.mapred.lib.TestCombineFileRecordReader.testInitNextRecordReader$$CONFUZZ(TestCombineFileRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2038692353"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestIndexCache",
        "testMethod": "testRemoveMap",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapred.TestIndexCache.writeFile(TestIndexCache.java:320)",
            "org.apache.hadoop.mapred.TestIndexCache.testRemoveMap(TestIndexCache.java:218)",
            "org.apache.hadoop.mapred.TestIndexCache.testRemoveMap$$CONFUZZ(TestIndexCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2147417854"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testBzip2SplitEndsAtCRThenLF",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.util.LineReader.<init>(LineReader.java:142)",
            "org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37)",
            "org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader.<init>(CompressedSplitLineReader.java:122)",
            "org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:103)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:87)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testSplitRecords(TestLineRecordReader.java:65)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzip2SplitEndsAtCRThenLF(TestLineRecordReader.java:131)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzip2SplitEndsAtCRThenLF$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1591603506"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager",
        "testMethod": "testDetermineTimestamps",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:333)",
            "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.createTempFile(TestClientDistributedCacheManager.java:249)",
            "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.setup(TestClientDistributedCacheManager.java:78)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2146436014"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testProgressDuringMerge",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2130673407"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testBinaryCredentialsWithScheme",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331)",
            "org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:325)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentials(TestTokenCache.java:99)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithScheme(TestTokenCache.java:74)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithScheme$$CONFUZZ(TestTokenCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2123556607"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testAbortV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2120377958"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testConcurrentCommitTaskWithSubDirV1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            ""
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2139062398"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:285)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1864547432"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestIndexCache",
        "testMethod": "testInvalidReduceNumberOrLength",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapred.TestIndexCache.writeFile(TestIndexCache.java:320)",
            "org.apache.hadoop.mapred.TestIndexCache.testInvalidReduceNumberOrLength(TestIndexCache.java:169)",
            "org.apache.hadoop.mapred.TestIndexCache.testInvalidReduceNumberOrLength$$CONFUZZ(TestIndexCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2147483550"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.split.TestJobSplitWriter",
        "testMethod": "testMaxBlockLocationsOldSplits",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:728)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.writeJobSplitMetaInfo(JobSplitWriter.java:189)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(JobSplitWriter.java:95)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits(TestJobSplitWriter.java:74)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits$$CONFUZZ(TestJobSplitWriter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1869076490"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testAbortV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2067148020"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestIndexCache",
        "testMethod": "testCreateRace",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapred.TestIndexCache.writeFile(TestIndexCache.java:320)",
            "org.apache.hadoop.mapred.TestIndexCache.testCreateRace(TestIndexCache.java:262)",
            "org.apache.hadoop.mapred.TestIndexCache.testCreateRace$$CONFUZZ(TestIndexCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2078422113"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:285)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1223569515"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testBzip2SplitEndsAtCR",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.util.LineReader.<init>(LineReader.java:142)",
            "org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37)",
            "org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader.<init>(CompressedSplitLineReader.java:122)",
            "org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:103)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:87)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testSplitRecords(TestLineRecordReader.java:65)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzip2SplitEndsAtCR(TestLineRecordReader.java:123)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzip2SplitEndsAtCR$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1557765380"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testBinaryCredentialsWithoutScheme",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331)",
            "org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:325)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentials(TestTokenCache.java:99)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithoutScheme(TestTokenCache.java:68)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithoutScheme$$CONFUZZ(TestTokenCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2131239812"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestFetcher",
        "testMethod": "testCorruptedIFile",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209)",
            "org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56)",
            "org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275)",
            "org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCorruptedIFile(TestFetcher.java:588)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCorruptedIFile$$CONFUZZ(TestFetcher.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1847445678"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testRecoveryV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:438)",
            "org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)",
            "org.apache.hadoop.mapred.FileOutputCommitter.commitJob(FileOutputCommitter.java:136)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:154)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV2(TestFileOutputCommitter.java:166)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1530049726"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestLineRecordReader",
        "testMethod": "testBzip2SplitStartAtBlockMarker",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.util.LineReader.<init>(LineReader.java:142)",
            "org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37)",
            "org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader.<init>(CompressedSplitLineReader.java:122)",
            "org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:123)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:81)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecords(TestLineRecordReader.java:62)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testBzip2SplitStartAtBlockMarker(TestLineRecordReader.java:182)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testBzip2SplitStartAtBlockMarker$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1687382210"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestLineRecordReader",
        "testMethod": "testMultipleClose",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.util.LineReader.<init>(LineReader.java:142)",
            "org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37)",
            "org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader.<init>(CompressedSplitLineReader.java:122)",
            "org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:123)",
            "org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:96)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testMultipleClose(TestLineRecordReader.java:335)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testMultipleClose$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1894889483"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager",
        "testMethod": "testDetermineTimestamps",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:333)",
            "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.createTempFile(TestClientDistributedCacheManager.java:249)",
            "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.setup(TestClientDistributedCacheManager.java:78)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1964554009"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestLineRecordReader",
        "testMethod": "testUncompressedInputWithLargeSplitSize",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapred.TestLineRecordReader.createInputFile(TestLineRecordReader.java:363)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputWithLargeSplitSize(TestLineRecordReader.java:377)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputWithLargeSplitSize$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1510477730"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testProgressDuringMerge",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "2081851168"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:438)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter$CommitterWithFailedThenSucceed.commitJobInternal(TestFileOutputCommitter.java:860)",
            "org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:427)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "150918984"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:295)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:269)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1606509685"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testUncompressedInputCustomDelimiterPosValue",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.createInputFile(TestLineRecordReader.java:312)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue(TestLineRecordReader.java:417)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1985861671"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testUncompressedInputCustomDelimiterPosValue",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.createInputFile(TestLineRecordReader.java:312)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue(TestLineRecordReader.java:417)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "710482511"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestLineRecordReader",
        "testMethod": "testUncompressedInputCustomDelimiterPosValue",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapred.TestLineRecordReader.createInputFile(TestLineRecordReader.java:363)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue(TestLineRecordReader.java:484)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "217111000"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testAbortV1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "2110669750"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.split.TestJobSplitWriter",
        "testMethod": "testMaxBlockLocationsOldSplits",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:728)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.createFile(JobSplitWriter.java:102)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(JobSplitWriter.java:91)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits(TestJobSplitWriter.java:74)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits$$CONFUZZ(TestJobSplitWriter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "665441245"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testAbortV1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:477)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "235590617"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestLineRecordReader",
        "testMethod": "testUncompressedInputContainingCRLF",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapred.TestLineRecordReader.createInputFile(TestLineRecordReader.java:363)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputContainingCRLF(TestLineRecordReader.java:467)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputContainingCRLF$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "2145608438"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testUncompressedInputDefaultDelimiterPosValue",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.createInputFile(TestLineRecordReader.java:312)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue(TestLineRecordReader.java:559)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "2133575896"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.security.TestTokenCache",
        "testMethod": "testBinaryCredentialsWithoutScheme",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331)",
            "org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:325)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentials(TestTokenCache.java:99)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithoutScheme(TestTokenCache.java:68)",
            "org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithoutScheme$$CONFUZZ(TestTokenCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "621031299"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:438)",
            "org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:367)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:341)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "167159392"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterRepeatableV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "695819820"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-27",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46)",
            "org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134)",
            "org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "796477728",
            "file.stream-buffer-size": "394561934",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "649477926",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:286)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:326)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1365512653",
            "file.stream-buffer-size": "1401372841"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testAbortV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "795606604",
            "file.stream-buffer-size": "1343412531"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterRepeatableV1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "852326918",
            "file.stream-buffer-size": "1331628129"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV1(TestFileOutputCommitter.java:388)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.stream-buffer-size": "2071891629"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:285)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.stream-buffer-size": "1496541571"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testUncompressedInputContainingCRLF",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.createInputFile(TestLineRecordReader.java:312)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF(TestLineRecordReader.java:400)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputContainingCRLF$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.stream-buffer-size": "2130640638"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager",
        "testMethod": "testDetermineCacheVisibilities",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:333)",
            "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.createTempFile(TestClientDistributedCacheManager.java:249)",
            "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.setup(TestClientDistributedCacheManager.java:78)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.stream-buffer-size": "1339278575",
            "io.file.buffer.size": "1693839041"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.split.TestJobSplitWriter",
        "testMethod": "testMaxBlockLocationsNewSplits",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:728)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.createFile(JobSplitWriter.java:102)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(JobSplitWriter.java:78)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsNewSplits(TestJobSplitWriter.java:50)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsNewSplits$$CONFUZZ(TestJobSplitWriter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.stream-buffer-size": "418241280",
            "io.file.buffer.size": "1662691481"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-27",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testFailAbortV1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46)",
            "org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134)",
            "org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:685)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1(TestFileOutputCommitter.java:720)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1826478660",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapred.TestLineRecordReader",
        "testMethod": "testUncompressedInputContainingCRLF",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.mapred.TestLineRecordReader.createInputFile(TestLineRecordReader.java:363)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputContainingCRLF(TestLineRecordReader.java:467)",
            "org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputContainingCRLF$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "154525932",
            "file.stream-buffer-size": "1549476633"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testRecoveryV1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:161)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:209)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "2107284321",
            "io.file.buffer.size": "892717932"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterV2TaskCleanupEnabled",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:286)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled(TestFileOutputCommitter.java:331)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testFailAbortV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:685)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV2(TestFileOutputCommitter.java:725)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:286)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV1(TestFileOutputCommitter.java:321)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testRecoveryV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:161)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV2(TestFileOutputCommitter.java:214)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testRecoveryV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:161)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:209)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager",
        "testMethod": "testOnDiskMerger",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Invalid configuration: maxSingleShuffleLimit should be less than mergeThreshold maxSingleShuffleLimit: 2041701mergeThreshold: -1737840",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:215)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testOnDiskMerger(TestMergeManager.java:228)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testOnDiskMerger$$CONFUZZ(TestMergeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.reduce.shuffle.merge.percent": "-0.212793231010437"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager",
        "testMethod": "testZeroShuffleMemoryLimitPercent",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Invalid configuration: maxSingleShuffleLimit should be less than mergeThreshold maxSingleShuffleLimit: 0mergeThreshold: -128",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:215)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testZeroShuffleMemoryLimitPercent(TestMergeManager.java:320)",
            "org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testZeroShuffleMemoryLimitPercent$$CONFUZZ(TestMergeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.reduce.shuffle.merge.percent": "-0.31494325399398804"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV1(TestFileOutputCommitter.java:214)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testProgressDuringMerge",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:295)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:269)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testAbortV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testAbortV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testFailAbortV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:529)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV1(TestFileOutputCommitter.java:560)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testAbortV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testAbortV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:477)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testFailAbortV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:685)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1(TestFileOutputCommitter.java:720)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:295)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:274)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:362)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:341)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:362)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:336)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testRecoveryUpgradeV1V2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:161)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryUpgradeV1V2(TestFileOutputCommitter.java:219)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryUpgradeV1V2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterRepeatableV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterRepeatableV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testRecoveryV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131)",
            "org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:109)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV2(TestFileOutputCommitter.java:166)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testProgressDuringMerge",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testProgressDuringMerge",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress.type": "NONE"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress.type": "NONE"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.type": "NONE"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.type": "NONE"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "native zStandard library not available: this version of libhadoop was built without zstd support.",
        "stackTrace": [
            "org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65)",
            "org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.ZStandardCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterV2TaskCleanupEnabled",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:286)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled(TestFileOutputCommitter.java:331)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV1(TestFileOutputCommitter.java:388)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:295)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:269)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testAbortV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:477)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testFailAbortV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:685)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1(TestFileOutputCommitter.java:720)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:295)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:274)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testRecoveryV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:161)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:209)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:362)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:336)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testRecoveryUpgradeV1V2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:161)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryUpgradeV1V2(TestFileOutputCommitter.java:219)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryUpgradeV1V2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterRepeatableV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterRepeatableV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testRecoveryV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:109)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV2(TestFileOutputCommitter.java:166)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testRecoveryUpgradeV1V2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:109)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryUpgradeV1V2(TestFileOutputCommitter.java:171)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryUpgradeV1V2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testProgressDuringMerge",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:286)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:326)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithFailureV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testAbortV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testAbortV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testFailAbortV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:685)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV2(TestFileOutputCommitter.java:725)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:286)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV1(TestFileOutputCommitter.java:321)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testCommitterWithDuplicatedCommitV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113)",
            "org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:362)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:341)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testProgressDuringMerge",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress.type": "NONE",
            "mapreduce.output.fileoutputformat.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK",
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK",
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV2",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress.type": "NONE"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress.type": "NONE"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapred.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397)",
            "org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter",
        "testMethod": "testMapFileOutputCommitterV1",
        "failure": "java.lang.UnsupportedOperationException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150)",
            "org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168)",
            "org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306)",
            "org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194)",
            "org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569)",
            "org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278)",
            "org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131)",
            "org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577)",
            "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.output.fileoutputformat.compress.codec": "org.apache.hadoop.io.compress.PassthroughCodec",
            "mapreduce.output.fileoutputformat.compress": "true",
            "mapreduce.output.fileoutputformat.compress.type": "BLOCK"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-101",
        "testClass": "org.apache.hadoop.mapreduce.TestJobResourceUploaderWithSharedCache",
        "testMethod": "testSharedCacheArchivesAndLibjarsEnabled",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of -32001 is less than the required minimum of 1 for /tmp/hadoop-yarn/staging/files/second-input-file        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611)        at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.setReplication(FSDirAttrOp.java:135)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setReplication(FSNamesystem.java:2348)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setReplication(NameNodeRpcServer.java:851)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setReplication(ClientNamenodeProtocolServerSideTranslatorPB.java:540)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy30.setReplication(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setReplication(ClientNamenodeProtocolTranslatorPB.java:432)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy31.setReplication(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.setReplication(DFSClient.java:1490)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$12.doCall(DistributedFileSystem.java:737)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$12.doCall(DistributedFileSystem.java:734)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.setReplication(DistributedFileSystem.java:744)",
            "org.apache.hadoop.mapreduce.JobResourceUploader.copyRemoteFiles(JobResourceUploader.java:704)",
            "org.apache.hadoop.mapreduce.JobResourceUploader.uploadFiles(JobResourceUploader.java:258)",
            "org.apache.hadoop.mapreduce.JobResourceUploader.uploadResourcesInternal(JobResourceUploader.java:205)",
            "org.apache.hadoop.mapreduce.JobResourceUploader.uploadResources(JobResourceUploader.java:135)",
            "org.apache.hadoop.mapreduce.TestJobResourceUploaderWithSharedCache.uploadFilesToRemoteFS(TestJobResourceUploaderWithSharedCache.java:299)",
            "org.apache.hadoop.mapreduce.TestJobResourceUploaderWithSharedCache.testSharedCacheArchivesAndLibjarsEnabled(TestJobResourceUploaderWithSharedCache.java:204)",
            "org.apache.hadoop.mapreduce.TestJobResourceUploaderWithSharedCache.testSharedCacheArchivesAndLibjarsEnabled$$CONFUZZ(TestJobResourceUploaderWithSharedCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.client.submit.file.replication": "33587967"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC",
        "testMethod": "testMaxBlockLocationsNewSplitsWithErasureCoding",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 10 is less than the required minimum of 337 for /job.split        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611)        at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.setReplication(FSDirAttrOp.java:135)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setReplication(FSNamesystem.java:2348)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setReplication(NameNodeRpcServer.java:851)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setReplication(ClientNamenodeProtocolServerSideTranslatorPB.java:540)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy33.setReplication(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setReplication(ClientNamenodeProtocolTranslatorPB.java:432)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy34.setReplication(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.setReplication(DFSClient.java:1490)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$12.doCall(DistributedFileSystem.java:737)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$12.doCall(DistributedFileSystem.java:734)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.setReplication(DistributedFileSystem.java:744)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.createFile(JobSplitWriter.java:105)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(JobSplitWriter.java:78)",
            "org.apache.hadoop.mapreduce.split.JobSplitWriter.createSplitFiles(JobSplitWriter.java:72)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC.testMaxBlockLocationsNewSplitsWithErasureCoding(TestJobSplitWriterWithEC.java:99)",
            "org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC.testMaxBlockLocationsNewSplitsWithErasureCoding$$CONFUZZ(TestJobSplitWriterWithEC.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "337"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader",
        "testMethod": "testRecordSpanningMultipleSplits",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<...ne, which will surel[y span multiple splits,]> but was:<...ne, which will surel[]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:201)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits(TestLineRecordReader.java:214)",
            "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits$$CONFUZZ(TestLineRecordReader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.input.linerecordreader.line.maxlength": "63"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestFetcher",
        "testMethod": "testCopyFromHostWithRetryThenTimeout",
        "failure": "org.mockito.exceptions.verification.junit.ArgumentsAreDifferent",
        "errorMessage": "Argument(s) are different! Wanted:shuffleSchedulerImpl.copyFailed(    attempt_0_0001_m_000001_1,    localhost,    false,    false);-> at org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWithRetryThenTimeout(TestFetcher.java:476)Actual invocations have different arguments:shuffleSchedulerImpl.getMapsForHost(    localhost);-> at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:310)shuffleSchedulerImpl.hostFailed(    \"localhost\");-> at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:360)shuffleSchedulerImpl.copyFailed(    attempt_0_0001_m_000001_1,    localhost,    true,    false);-> at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:362)shuffleSchedulerImpl.putBackKnownMapOutput(    localhost,    attempt_0_0001_m_000002_1);-> at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:379)shuffleSchedulerImpl.putBackKnownMapOutput(    localhost,    attempt_0_0001_m_000001_1);-> at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:379)",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWithRetryThenTimeout(TestFetcher.java:476)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWithRetryThenTimeout$$CONFUZZ(TestFetcher.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.reduce.shuffle.fetch.retry.timeout-ms": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestFetcher",
        "testMethod": "testCopyFromHostWait",
        "failure": "org.mockito.exceptions.verification.NeverWantedButInvoked",
        "errorMessage": "counter.increment(1L);Never wanted here:-> at org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWait(TestFetcher.java:322)But invoked here:-> at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyMapOutput(Fetcher.java:585)",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWait(TestFetcher.java:322)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWait$$CONFUZZ(TestFetcher.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.encrypted-intermediate-data": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestFetcher",
        "testMethod": "testInterruptInMemory",
        "failure": "org.mockito.exceptions.verification.WantedButNotInvoked",
        "errorMessage": "Wanted but not invoked:inMemoryMapOutput.abort();-> at org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptInMemory(TestFetcher.java:636)Actually, there were zero interactions with this mock.",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptInMemory(TestFetcher.java:636)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptInMemory$$CONFUZZ(TestFetcher.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.encrypted-intermediate-data": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestFetcher",
        "testMethod": "testReduceOutOfDiskSpace",
        "failure": "org.mockito.exceptions.verification.WantedButNotInvoked",
        "errorMessage": "Wanted but not invoked:shuffleSchedulerImpl.reportLocalError(    <any java.io.IOException>);-> at org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testReduceOutOfDiskSpace(TestFetcher.java:155)However, there were exactly 5 interactions with this mock:shuffleSchedulerImpl.getMapsForHost(    localhost);-> at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:310)shuffleSchedulerImpl.hostFailed(\"localhost\");-> at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:360)shuffleSchedulerImpl.copyFailed(    attempt_0_0001_m_000001_1,    localhost,    true,    false);-> at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:362)shuffleSchedulerImpl.putBackKnownMapOutput(    localhost,    attempt_0_0001_m_000002_1);-> at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:379)shuffleSchedulerImpl.putBackKnownMapOutput(    localhost,    attempt_0_0001_m_000001_1);-> at org.apache.hadoop.mapreduce.task.reduce.Fetcher.copyFromHost(Fetcher.java:379)",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testReduceOutOfDiskSpace(TestFetcher.java:155)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testReduceOutOfDiskSpace$$CONFUZZ(TestFetcher.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.encrypted-intermediate-data": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.mapreduce.task.reduce.TestFetcher",
        "testMethod": "testCopyFromHostWithRetryUnreserve",
        "failure": "org.mockito.exceptions.verification.WantedButNotInvoked",
        "errorMessage": "Wanted but not invoked:inMemoryMapOutput.abort();-> at org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWithRetryUnreserve(TestFetcher.java:719)Actually, there were zero interactions with this mock.",
        "stackTrace": [
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWithRetryUnreserve(TestFetcher.java:719)",
            "org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWithRetryUnreserve$$CONFUZZ(TestFetcher.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "mapreduce.job.encrypted-intermediate-data": "true"
        }
    }
]
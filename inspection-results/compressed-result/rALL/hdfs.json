[
    {
        "status": "BUG",
        "bugId": [
            "Bug-87"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate",
        "testMethod": "testQuotaIssuesWhileCommitting",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "org.apache.hadoop.ipc.Server$Listener$Reader.<init>(Server.java:1267)",
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1242)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate.setUp(TestDiskspaceQuotaUpdate.java:76)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.connection-queue.size": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-188"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testMoveBlockFailure",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testMoveBlockFailure(TestFsDatasetImpl.java:1005)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testMoveBlockFailure$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "2139095042"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-189"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestPread",
        "testMethod": "testPreadLocalFS",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209)",
            "org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56)",
            "org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210)",
            "org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124)",
            "org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117)",
            "org.apache.hadoop.hdfs.TestPread.writeFile(TestPread.java:96)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS(TestPread.java:503)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS$$CONFUZZ(TestPread.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2081664379",
            "file.stream-buffer-size": "1398914017"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleDatanodes",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleDatanodes(TestSortLocatedBlock.java:197)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.stale.datanode.minimum.interval": "757603536"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testGetBlockLocationConsiderStorageType",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<IP-[2-4]> but was:<IP-[0-1]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderStorageType(TestDatanodeManager.java:733)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderStorageType$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.read.considerLoad": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-190"
        ],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.ScheduledThreadPoolExecutor.scheduleWithFixedDelay(ScheduledThreadPoolExecutor.java:671)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager.activate(DatanodeAdminManager.java:151)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.activate(DatanodeManager.java:451)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.activate(BlockManager.java:740)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startCommonServices(FSNamesystem.java:1278)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:870)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.initCluster(FSXAttrBaseTest.java:1377)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.init(FSXAttrBaseTest.java:109)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.decommission.interval.testing": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestMalformedURLs",
        "testMethod": "testTryStartingCluster",
        "failure": "java.io.EOFException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)",
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.client.idlethreshold": "0",
            "ipc.client.connection.idle-scan-interval.ms": "263",
            "ipc.client.connection.maxidletime": "2130640638"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultAclNewFileIntermediate",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<432> but was:<416>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.namenode.AclTestHelpers.assertPermission(AclTestHelpers.java:163)",
            "org.apache.hadoop.hdfs.server.namenode.AclTestHelpers.assertPermission(AclTestHelpers.java:147)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.assertPermission(FSAclBaseTest.java:1823)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testDefaultAclNewFileIntermediate(FSAclBaseTest.java:1130)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.testDefaultAclNewFileIntermediate$$CONFUZZ(TestFileContextAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.posix.acl.inheritance.enabled": "false"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFS",
        "testMethod": "testStoragePolicy",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Failed to set storage policy since dfs.storage.policy.enabled is set to false.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:739)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.setStoragePolicy(WebHdfsFileSystem.java:2006)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testStoragePolicy(TestWebHDFS.java:1640)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testStoragePolicy$$CONFUZZ(TestWebHDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.storage.policy.enabled": "false"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFS",
        "testMethod": "testWebHdfsAllowandDisallowSnapshots",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "7044",
            "ipc.maximum.response.length": "767"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot",
        "testMethod": "testDatanodeRestarts",
        "failure": "java.io.EOFException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)",
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.max.connections": "1"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-107"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestFileChecksum",
        "testMethod": "testStripedFileChecksumWithReconstructFail",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileChecksum.setup(TestFileChecksum.java:94)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "67141635",
            "dfs.datanode.handler.count": "1075364191"
        }
    },
    {
        "status": "Non-Reproducible",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestUpdateBlockTailing",
        "testMethod": "testStandbyAppendBlock",
        "failure": "org.apache.hadoop.hdfs.qjournal.client.QuorumException",
        "errorMessage": "Unable to check if JNs are ready for formatting. 1 successful responses:127.0.0.1:46595: false1 exceptions thrown:127.0.0.1:42335: Call From b3866d044c96/172.17.0.2 to localhost:42335 failed on socket timeout exception: java.net.SocketTimeoutException: 67 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:56114 remote=/127.0.0.1:42335]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:305)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.hasSomeData(QuorumJournalManager.java:282)",
            "org.apache.hadoop.hdfs.server.common.Storage.confirmFormat(Storage.java:1185)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.confirmFormat(FSImage.java:212)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1274)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.qjournal.MiniQJMHACluster.<init>(MiniQJMHACluster.java:129)",
            "org.apache.hadoop.hdfs.qjournal.MiniQJMHACluster.<init>(MiniQJMHACluster.java:38)",
            "org.apache.hadoop.hdfs.qjournal.MiniQJMHACluster$Builder.build(MiniQJMHACluster.java:68)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestUpdateBlockTailing.startUpCluster(TestUpdateBlockTailing.java:77)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1792",
            "ipc.client.rpc-timeout.ms": "67"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-194"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier",
        "testMethod": "testWhenStoragePolicySetToONESSD",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.setDataNodeStorageCapacities(MiniDFSCluster.java:1838)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.setDataNodeStorageCapacities(MiniDFSCluster.java:1817)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1797)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.startCluster(TestExternalStoragePolicySatisfier.java:211)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.createCluster(TestExternalStoragePolicySatisfier.java:194)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWhenStoragePolicySetToONESSD(TestExternalStoragePolicySatisfier.java:480)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWhenStoragePolicySetToONESSD$$CONFUZZ(TestExternalStoragePolicySatisfier.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "12623751"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testGetBlockLocationConsiderLoad",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<IP-[1-2]> but was:<IP-[0-1]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderLoad(TestDatanodeManager.java:581)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderLoad$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "net.topology.script.number.args": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-124"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testNodeUsageAfterDecommissioned",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.cleanupFile(AdminStatesBaseTest.java:459)",
            "org.apache.hadoop.hdfs.TestDecommission.nodeUsageVerification(TestDecommission.java:1575)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageAfterDecommissioned(TestDecommission.java:1498)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageAfterDecommissioned$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "4182576,457,884"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientRetries",
        "testMethod": "testClientDNProtocolTimeout",
        "failure": "org.apache.hadoop.security.AccessControlException",
        "errorMessage": "Client cannot authenticate via:[KERBEROS]",
        "stackTrace": [
            "org.apache.hadoop.security.SaslRpcClient.selectSaslClient(SaslRpcClient.java:179)",
            "org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:392)",
            "org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623)",
            "org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414)",
            "org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843)",
            "org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839)",
            "org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414)",
            "org.apache.hadoop.ipc.Client.getConnection(Client.java:1677)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1502)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy22.getReplicaVisibleLength(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolTranslatorPB.getReplicaVisibleLength(ClientDatanodeProtocolTranslatorPB.java:201)",
            "org.apache.hadoop.hdfs.TestDFSClientRetries.testClientDNProtocolTimeout(TestDFSClientRetries.java:894)",
            "org.apache.hadoop.hdfs.TestDFSClientRetries.testClientDNProtocolTimeout$$CONFUZZ(TestDFSClientRetries.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique",
        "testMethod": "testSingleThreaded",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Time out while waiting for journal node 0 to start.",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:262)",
            "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique.testSingleThreaded(TestEpochsAreUnique.java:55)",
            "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique.testSingleThreaded$$CONFUZZ(TestEpochsAreUnique.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "268470015"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-124"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testNodeUsageWhileDecommissioining",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.cleanupFile(AdminStatesBaseTest.java:459)",
            "org.apache.hadoop.hdfs.TestDecommission.nodeUsageVerification(TestDecommission.java:1575)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageWhileDecommissioining(TestDecommission.java:1510)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testNodeUsageWhileDecommissioining$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.17852377891540527"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-167"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs",
        "testMethod": "testNameEditsConfigsFailure",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure(TestNameEditsConfigs.java:450)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure$$CONFUZZ(TestNameEditsConfigs.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "1546,39198698,26"
        }
    },
    {
        "status": "Non-Reproducible",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestBatchIbr",
        "testMethod": "testIbr",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "File /dir/6753034785164449211_5 could only be written to 0 of the 1 minReplication nodes. There are 4 datanode(s) running and 4 node(s) are excluded in this operation.        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2315)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2960)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:904)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy29.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy32.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1088)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1915)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1717)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.overwrite.downstream.derived.qop": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat",
        "testMethod": "testBackwardsCompat",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.datanode.max.transfer.threads should not be less than 1.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:191)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat(TestDataXceiverBackwardsCompat.java:149)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat$$CONFUZZ(TestDataXceiverBackwardsCompat.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.transfer.threads": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-102"
        ],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testEncodedPathUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "timeouts can't be negative",
        "stackTrace": [
            "java.base/sun.net.www.protocol.http.HttpURLConnection.setReadTimeout(HttpURLConnection.java:3349)",
            "org.apache.hadoop.hdfs.web.SSLConnectionConfigurator.configure(SSLConnectionConfigurator.java:65)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:191)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:160)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:758)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:736)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:1767)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:377)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getAuthParameters(WebHdfsFileSystem.java:598)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toUrl(WebHdfsFileSystem.java:626)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl(TestWebHdfsUrl.java:83)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.socket.read-timeout": "6529429s",
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "Non-Reproducible",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestFileStatus",
        "testMethod": "testListStatusOnFile",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileStatus.testSetUp(TestFileStatus.java:70)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {}
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleAndSlowDatanodes",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<[4.4.4.4]> but was:<[3.3.3.3]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes(TestSortLocatedBlock.java:155)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.heartbeat.interval": "24111"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestParallelShortCircuitLegacyRead",
        "testMethod": "testParallelReadByteBuffer",
        "failure": "java.io.InterruptedIOException",
        "errorMessage": "No ack received after 6s and a timeout of 5s",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:931)",
            "org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:778)",
            "org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:888)",
            "org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "org.apache.hadoop.hdfs.client.impl.BlockReaderTestUtil.writeFile(BlockReaderTestUtil.java:131)",
            "org.apache.hadoop.hdfs.TestParallelReadUtil.runParallelRead(TestParallelReadUtil.java:326)",
            "org.apache.hadoop.hdfs.TestParallelReadUtil.runTestWorkload(TestParallelReadUtil.java:382)",
            "org.apache.hadoop.hdfs.TestParallelReadUtil.testParallelReadByteBuffer(TestParallelReadUtil.java:411)",
            "org.apache.hadoop.hdfs.TestParallelShortCircuitLegacyRead.testParallelReadByteBuffer$$CONFUZZ(TestParallelShortCircuitLegacyRead.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.socket.write.timeout": "767",
            "dfs.datanode.data.write.bandwidthPerSec": "4538"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot",
        "testMethod": "testOriginalAclEnforcedForSnapshotRootAfterRemoval",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected AccessControlException for user diana (auth:SIMPLE), path = /p5",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.assertDirPermissionDenied(TestAclWithSnapshot.java:857)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.testOriginalAclEnforcedForSnapshotRootAfterRemoval(TestAclWithSnapshot.java:298)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.testOriginalAclEnforcedForSnapshotRootAfterRemoval$$CONFUZZ(TestAclWithSnapshot.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.permissions.enabled": "false"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testCount",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "File has reached the limit on maximum number of blocks (dfs.namenode.fs-limits.max-blocks-per-file): 0 >= 0        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.validateAddBlock(FSDirWriteFileOp.java:186)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2948)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:904)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy30.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy31.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1088)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1915)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1717)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.max-blocks-per-file": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveDefaultAclStickyBit",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.disk.check.timeout - 0 (should be > 0)",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.<init>(StorageLocationChecker.java:98)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2818)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "0h"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-196"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testWhenSomeNodesAreNotGood",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.setUpBeforeClass(TestFavoredNodesEndToEnd.java:71)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "4631",
            "ipc.server.handler.queue.size": "304660495"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDistributedFileSystem",
        "testMethod": "testFileChecksum",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.fail(Assert.java:96)",
            "org.apache.hadoop.hdfs.TestDistributedFileSystem.testFileChecksum(TestDistributedFileSystem.java:1322)",
            "org.apache.hadoop.hdfs.TestDistributedFileSystem.testFileChecksum$$CONFUZZ(TestDistributedFileSystem.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.permissions.enabled": "false"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testGetBlockLocationConsiderLoad",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<IP-[1-3]> but was:<IP-[2-4]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderLoad(TestDatanodeManager.java:578)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderLoad$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.stale.datanode.minimum.interval": "928053426",
            "dfs.namenode.stale.datanode.interval": "13",
            "dfs.heartbeat.interval": "1922470578"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testHttpServer",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<200> but was:<431>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.DFSTestUtil.urlGetBytes(DFSTestUtil.java:1003)",
            "org.apache.hadoop.hdfs.DFSTestUtil.urlGet(DFSTestUtil.java:993)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.testHttpServer(TestJournalNode.java:318)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.testHttpServer$$CONFUZZ(TestJournalNode.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.request.header.size": "63"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport",
        "testMethod": "testDiffReportWithOpenFiles",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<2> but was:<1>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.DFSTestUtil.verifySnapshotDiffReport(DFSTestUtil.java:2511)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport.verifyDiffReport(TestSnapshotDiffReport.java:197)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport.testDiffReportWithOpenFiles(TestSnapshotDiffReport.java:1106)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport.testDiffReportWithOpenFiles$$CONFUZZ(TestSnapshotDiffReport.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.snapshot.skiplist.max.levels": "539008767"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testNodeUsageWhileDecommissioining",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.cleanupFile(AdminStatesBaseTest.java:459)",
            "org.apache.hadoop.hdfs.TestDecommission.nodeUsageVerification(TestDecommission.java:1575)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageWhileDecommissioining(TestDecommission.java:1510)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testNodeUsageWhileDecommissioining$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "2141261824"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-124"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testNodeUsageWhileDecommissioining",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.cleanupFile(AdminStatesBaseTest.java:459)",
            "org.apache.hadoop.hdfs.TestDecommission.nodeUsageVerification(TestDecommission.java:1575)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageWhileDecommissioining(TestDecommission.java:1510)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testNodeUsageWhileDecommissioining$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "687"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testGetBlockLocationConsiderLoadWithNodesOfSameDistance",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<2> but was:<4>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderLoadWithNodesOfSameDistance(TestDatanodeManager.java:669)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderLoadWithNodesOfSameDistance$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "net.topology.script.number.args": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-197"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testRemoteException",
        "failure": "java.lang.AssertionError",
        "errorMessage": "permission denied printed",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.hdfs.TestDFSShell$8.run(TestDFSShell.java:1948)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.TestDFSShell.testRemoteException(TestDFSShell.java:1935)",
            "org.apache.hadoop.hdfs.TestDFSShell.testRemoteException$$CONFUZZ(TestDFSShell.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "575"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-12"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade",
        "testMethod": "testDatanodeRollingUpgradeWithRollback",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.start(NameNodeRpcServer.java:579)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:880)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.startCluster(TestDataNodeRollingUpgrade.java:77)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback(TestDataNodeRollingUpgrade.java:263)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback$$CONFUZZ(TestDataNodeRollingUpgrade.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "237418903",
            "dfs.namenode.handler.count": "1214110464"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-198"
        ],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testOutOfSyncAtBeginningOfSegment2",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293)",
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215)",
            "org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel.createParallelExecutor(IPCLoggerChannel.java:283)",
            "org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel.<init>(IPCLoggerChannel.java:189)",
            "org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$1.createLogger(IPCLoggerChannel.java:161)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.createLoggers(QuorumJournalManager.java:424)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.createLoggers(QuorumJournalManager.java:199)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:147)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:121)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:251)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:245)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:449)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:421)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:245)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:112)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.qjournal.parallel-read.num-threads": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestMalformedURLs",
        "testMethod": "testTryStartingCluster",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskErrorException",
        "errorMessage": "Too many failed volumes - current valid volumes: 0, volumes configured: 2, volumes failed: 2, volume failures tolerated: 0",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:233)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestMalformedURLs.testTryStartingCluster(TestMalformedURLs.java:49)",
            "org.apache.hadoop.hdfs.server.namenode.TestMalformedURLs.testTryStartingCluster$$CONFUZZ(TestMalformedURLs.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "73ms",
            "dfs.namenode.gc.time.monitor.enable": "false",
            "ipc.server.read.threadpool.size": "18674",
            "dfs.namenode.edits.asynclogging": "true",
            "dfs.bytes-per-checksum": "27806",
            "dfs.client.failover.sleep.base.millis": "1367352593",
            "dfs.permissions.superusergroup": "vcdqliqztzxwilpmogcrmezpgsftmhdculyvzhiotcxfmidvdhnprllmtkdvrxuezfonqbnxmgroup",
            "dfs.datanode.fsdatasetasyncdisk.max.threads.per.volume": "3074"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testReaderWhileAnotherWrites",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting 3ms for a quorum of nodes to respond.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:138)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectStreamingInputStreams(QuorumJournalManager.java:619)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:535)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.selectInputStreams(QuorumJournalManager.java:510)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testReaderWhileAnotherWrites(TestQuorumJournalManager.java:174)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testReaderWhileAnotherWrites$$CONFUZZ(TestQuorumJournalManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.qjournal.select-input-streams.timeout.ms": "3"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-167"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs",
        "testMethod": "testNameEditsConfigsFailure",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure(TestNameEditsConfigs.java:450)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure$$CONFUZZ(TestNameEditsConfigs.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "153358982h"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testCrashBetweenSyncLogAndPersistPaxosData",
        "failure": "org.apache.hadoop.hdfs.qjournal.client.QuorumException",
        "errorMessage": "Got too many exceptions to achieve quorum size 2/3. 1 successful responses:127.0.0.1:41623: null [success]2 exceptions thrown:127.0.0.1:35317: Call From 596a60c918df/172.17.0.2 to localhost:35317 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused127.0.0.1:38681: Image transfer servlet at http://localhost:39195/getJournal?jid=test-journal&segmentTxId=1&storageInfo=-66%3A12345%3A0%3Amycluster&inProgressOk=true failed with status code 401Response message:Authentication required        at org.apache.hadoop.hdfs.server.common.Util.doGetUrl(Util.java:168)        at org.apache.hadoop.hdfs.server.namenode.TransferFsImage.doGetUrl(TransferFsImage.java:441)        at org.apache.hadoop.hdfs.qjournal.server.Journal$1.run(Journal.java:1007)        at org.apache.hadoop.hdfs.qjournal.server.Journal$1.run(Journal.java:997)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.security.SecurityUtil.doAsUser(SecurityUtil.java:536)        at org.apache.hadoop.security.SecurityUtil.doAsLoginUser(SecurityUtil.java:517)        at org.apache.hadoop.hdfs.qjournal.server.Journal.syncLog(Journal.java:996)        at org.apache.hadoop.hdfs.qjournal.server.Journal.acceptRecovery(Journal.java:935)        at org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.acceptRecovery(JournalNodeRpcServer.java:257)        at org.apache.hadoop.hdfs.qjournal.protocolPB.QJournalProtocolServerSideTranslatorPB.acceptRecovery(QJournalProtocolServerSideTranslatorPB.java:268)        at org.apache.hadoop.hdfs.qjournal.protocol.QJournalProtocolProtos$QJournalProtocolService$2.callBlockingMethod(QJournalProtocolProtos.java:31940)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:305)",
            "org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:143)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.recoverUnclosedSegment(QuorumJournalManager.java:395)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.recoverUnfinalizedSegments(QuorumJournalManager.java:497)",
            "org.apache.hadoop.hdfs.qjournal.QJMTestUtil.recoverAndReturnLastTxn(QJMTestUtil.java:164)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testCrashBetweenSyncLogAndPersistPaxosData(TestQuorumJournalManager.java:857)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testCrashBetweenSyncLogAndPersistPaxosData$$CONFUZZ(TestQuorumJournalManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.simple.anonymous.allowed": "false"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testInProgressRecovery",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Expected to find txid 2, but no more streams available to read from",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.hdfs.qjournal.QJMTestUtil.verifyEdits(QJMTestUtil.java:132)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testInProgressRecovery(TestQuorumJournalManager.java:974)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testInProgressRecovery$$CONFUZZ(TestQuorumJournalManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.ha.tail-edits.qjm.rpc.max-txns": "1"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations",
        "testMethod": "testGetBlockLocationsRacingWithDelete",
        "failure": "java.io.IOException",
        "errorMessage": "Unexpected configuration parameters: dfs.namenode.maintenance.replication.min = 1 > dfs.replication = 0",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:580)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.setupFileSystem(TestGetBlockLocations.java:135)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.testGetBlockLocationsRacingWithDelete(TestGetBlockLocations.java:65)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.testGetBlockLocationsRacingWithDelete$$CONFUZZ(TestGetBlockLocations.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.replication": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testChangeWritersLogsInSync",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting 3ms for a quorum of nodes to respond.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:138)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.createNewUniqueEpoch(QuorumJournalManager.java:233)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.recoverUnfinalizedSegments(QuorumJournalManager.java:478)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testChangeWritersLogsInSync(TestQuorumJournalManager.java:411)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testChangeWritersLogsInSync$$CONFUZZ(TestQuorumJournalManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.qjournal.get-journal-state.timeout.ms": "3"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testChangeWritersLogsInSync",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Time out while waiting for journal node 0 to start.",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:262)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:112)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "15"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-59"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleAndSlowDatanodes",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.Comparator.lambda$comparing$77a9974f$1(Comparator.java:469)",
            "java.base/java.util.TimSort.countRunAndMakeAscending(TimSort.java:355)",
            "java.base/java.util.TimSort.sort(TimSort.java:220)",
            "java.base/java.util.Arrays.sort(Arrays.java:1515)",
            "java.base/java.util.ArrayList.sort(ArrayList.java:1750)",
            "java.base/java.util.Collections.sort(Collections.java:179)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.lambda$createSecondaryNodeSorter$0(DatanodeManager.java:654)",
            "org.apache.hadoop.net.NetworkTopology.sortByDistance(NetworkTopology.java:983)",
            "org.apache.hadoop.net.NetworkTopology.sortByDistanceUsingNetworkLocation(NetworkTopology.java:946)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlock(DatanodeManager.java:637)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlocks(DatanodeManager.java:554)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes(TestSortLocatedBlock.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.stale.datanode.minimum.interval": "34561",
            "dfs.namenode.read.considerStorageType": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-124"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testNodeUsageAfterDecommissioned",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.cleanupFile(AdminStatesBaseTest.java:459)",
            "org.apache.hadoop.hdfs.TestDecommission.nodeUsageVerification(TestDecommission.java:1575)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageAfterDecommissioned(TestDecommission.java:1498)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageAfterDecommissioned$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "34559"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-10",
            "Bug-11"
        ],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testCrashAtBeginningOfSegment",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "627849093",
            "hadoop.http.selector.count": "1227789720"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testSelectViaRpcWithoutDurableTransactions",
        "failure": "org.mockito.exceptions.verification.junit.ArgumentsAreDifferent",
        "errorMessage": "Argument(s) are different! Wanted:iPCLoggerChannel.getJournaledEdits(    1L,    5000);-> at org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testSelectViaRpcWithoutDurableTransactions(TestQuorumJournalManager.java:1014)Actual invocations have different arguments:iPCLoggerChannel.format(    lv=-66;cid=mycluster;nsid=12345;c=0;bpid=my-bp,    false);-> at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.format(AsyncLoggerSet.java:321)iPCLoggerChannel.getProxy(    );-> at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$9.call(IPCLoggerChannel.java:519)iPCLoggerChannel.createProxy(    );-> at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel.getProxy(IPCLoggerChannel.java:224)iPCLoggerChannel.getJournalState(    );-> at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.getJournalState(AsyncLoggerSet.java:212)iPCLoggerChannel.getProxy(    );-> at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$5.call(IPCLoggerChannel.java:360)iPCLoggerChannel.newEpoch(    1L);-> at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.newEpoch(AsyncLoggerSet.java:231)iPCLoggerChannel.getProxy(    );-> at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$6.call(IPCLoggerChannel.java:373)iPCLoggerChannel.setEpoch(    1L);-> at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.setEpoch(AsyncLoggerSet.java:66)iPCLoggerChannel.startLogSegment(    1L,    -66);-> at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.startLogSegment(AsyncLoggerSet.java:240)iPCLoggerChannel.getProxy(    );-> at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$10.call(IPCLoggerChannel.java:531)iPCLoggerChannel.sendEdits(    1L,    1L,    3,    [(byte) 0x03, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x44, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x01, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x04, (byte) 0x74, (byte) 0x78, (byte) 0x20, (byte) 0x31, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x08, (byte) 0x74, (byte) 0x65, (byte) 0x73, (byte) 0x74, (byte) 0x75, (byte) 0x73, (byte) 0x65, (byte) 0x72, (byte) 0x09, (byte) 0x74, (byte) 0x65, (byte) 0x73, (byte) 0x74, (byte) 0x67, (byte) 0x72, (byte) 0x6F, (byte) 0x75, (byte) 0x70, (byte) 0x01, (byte) 0xFF, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x5E, (byte) 0xAF, (byte) 0xA6, (byte) 0xA0, (byte) 0x03, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x44, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x02, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x04, (byte) 0x74, (byte) 0x78, (byte) 0x20, (byte) 0x32, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x08, (byte) 0x74, (byte) 0x65, (byte) 0x73, (byte) 0x74, (byte) 0x75, (byte) 0x73, (byte) 0x65, (byte) 0x72, (byte) 0x09, (byte) 0x74, (byte) 0x65, (byte) 0x73, (byte) 0x74, (byte) 0x67, (byte) 0x72, (byte) 0x6F, (byte) 0x75, (byte) 0x70, (byte) 0x01, (byte) 0xFF, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0xBE, (byte) 0x64, (byte) 0xCB, (byte) 0x01, (byte) 0x03, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x44, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x03, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x04, (byte) 0x74, (byte) 0x78, (byte) 0x20, (byte) 0x33, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x08, (byte) 0x74, (byte) 0x65, (byte) 0x73, (byte) 0x74, (byte) 0x75, (byte) 0x73, (byte) 0x65, (byte) 0x72, (byte) 0x09, (byte) 0x74, (byte) 0x65, (byte) 0x73, (byte) 0x74, (byte) 0x67, (byte) 0x72, (byte) 0x6F, (byte) 0x75, (byte) 0x70, (byte) 0x01, (byte) 0xFF, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0xE1, (byte) 0xDD, (byte) 0xEF, (byte) 0x9E]);-> at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.sendEdits(AsyncLoggerSet.java:259)iPCLoggerChannel.isOutOfSync(    );-> at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel.throwIfOutOfSync(IPCLoggerChannel.java:462)iPCLoggerChannel.getProxy(    );-> at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:401)iPCLoggerChannel.setCommittedTxId(    3L);-> at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.setCommittedTxId(AsyncLoggerSet.java:77)iPCLoggerChannel.sendEdits(    1L,    4L,    1,    [(byte) 0x03, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x44, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x04, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x04, (byte) 0x74, (byte) 0x78, (byte) 0x20, (byte) 0x34, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x08, (byte) 0x74, (byte) 0x65, (byte) 0x73, (byte) 0x74, (byte) 0x75, (byte) 0x73, (byte) 0x65, (byte) 0x72, (byte) 0x09, (byte) 0x74, (byte) 0x65, (byte) 0x73, (byte) 0x74, (byte) 0x67, (byte) 0x72, (byte) 0x6F, (byte) 0x75, (byte) 0x70, (byte) 0x01, (byte) 0xFF, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0xA4, (byte) 0x83, (byte) 0x16, (byte) 0x02]);-> at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.sendEdits(AsyncLoggerSet.java:259)iPCLoggerChannel.setCommittedTxId(    4L);-> at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.setCommittedTxId(AsyncLoggerSet.java:77)iPCLoggerChannel.sendEdits(    1L,    5L,    1,    [(byte) 0x03, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x44, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x05, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x04, (byte) 0x74, (byte) 0x78, (byte) 0x20, (byte) 0x35, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x08, (byte) 0x74, (byte) 0x65, (byte) 0x73, (byte) 0x74, (byte) 0x75, (byte) 0x73, (byte) 0x65, (byte) 0x72, (byte) 0x09, (byte) 0x74, (byte) 0x65, (byte) 0x73, (byte) 0x74, (byte) 0x67, (byte) 0x72, (byte) 0x6F, (byte) 0x75, (byte) 0x70, (byte) 0x01, (byte) 0xFF, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0x00, (byte) 0xFB, (byte) 0x3A, (byte) 0x32, (byte) 0x9D]);-> at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.sendEdits(AsyncLoggerSet.java:259)iPCLoggerChannel.isOutOfSync(    );-> at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel.throwIfOutOfSync(IPCLoggerChannel.java:462)iPCLoggerChannel.getProxy(    );-> at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$7.call(IPCLoggerChannel.java:401)iPCLoggerChannel.getJournaledEdits(    1L,    18208);-> at org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.getJournaledEdits(AsyncLoggerSet.java:272)iPCLoggerChannel.getProxy(    );-> at org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannel$13.call(IPCLoggerChannel.java:578)",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testSelectViaRpcWithoutDurableTransactions(TestQuorumJournalManager.java:1014)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testSelectViaRpcWithoutDurableTransactions$$CONFUZZ(TestQuorumJournalManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.ha.tail-edits.qjm.rpc.max-txns": "18208"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA",
        "testMethod": "testRollbackWithNfs",
        "failure": "org.apache.hadoop.hdfs.server.common.HttpGetFailedException",
        "errorMessage": "Image transfer servlet at http://localhost:39083/imagetransfer?getimage=1&txid=3&storageInfo=-66:378155989:1690653392623:testClusterID&bootstrapstandby=true failed with status code 401Response message:Authentication required",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Util.doGetUrl(Util.java:168)",
            "org.apache.hadoop.hdfs.server.namenode.TransferFsImage.doGetUrl(TransferFsImage.java:441)",
            "org.apache.hadoop.hdfs.server.namenode.TransferFsImage.getFileClient(TransferFsImage.java:436)",
            "org.apache.hadoop.hdfs.server.namenode.TransferFsImage.downloadImageToStorage(TransferFsImage.java:123)",
            "org.apache.hadoop.hdfs.server.namenode.ha.BootstrapStandby.downloadImage(BootstrapStandby.java:357)",
            "org.apache.hadoop.hdfs.server.namenode.ha.BootstrapStandby.doRun(BootstrapStandby.java:239)",
            "org.apache.hadoop.hdfs.server.namenode.ha.BootstrapStandby.access$000(BootstrapStandby.java:82)",
            "org.apache.hadoop.hdfs.server.namenode.ha.BootstrapStandby$1.run(BootstrapStandby.java:125)",
            "org.apache.hadoop.hdfs.server.namenode.ha.BootstrapStandby$1.run(BootstrapStandby.java:121)",
            "org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503)",
            "org.apache.hadoop.hdfs.server.namenode.ha.BootstrapStandby.run(BootstrapStandby.java:121)",
            "org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:81)",
            "org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:95)",
            "org.apache.hadoop.hdfs.server.namenode.ha.BootstrapStandby.run(BootstrapStandby.java:544)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA.testRollbackWithNfs(TestDFSUpgradeWithHA.java:589)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestDFSUpgradeWithHA.testRollbackWithNfs$$CONFUZZ(TestDFSUpgradeWithHA.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.simple.anonymous.allowed": "false"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-33"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommissionFederation",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.runDatanodeDaemon(DataNode.java:2686)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1789)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:369)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommissionFederation(TestDecommission.java:243)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommissionFederation$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "21090",
            "dfs.datanode.handler.count": "1610711359"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDFSMkdirs",
        "testMethod": "testMkdirRpcNonCanonicalPath",
        "failure": "org.apache.hadoop.hdfs.server.namenode.SafeModeException",
        "errorMessage": "Cannot create directory //test1. Name node is in safe mode.Resources are low on NN. Please add or free up more resourcesthen turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use \"hdfs dfsadmin -safemode leave\" to turn safe mode off. NamenodeHostName:localhost",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3404)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1159)",
            "org.apache.hadoop.hdfs.TestDFSMkdirs.testMkdirRpcNonCanonicalPath(TestDFSMkdirs.java:144)",
            "org.apache.hadoop.hdfs.TestDFSMkdirs.testMkdirRpcNonCanonicalPath$$CONFUZZ(TestDFSMkdirs.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "7268"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestTrashWithSecureEncryptionZones",
        "testMethod": "testTrashExpunge",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.reencrypt.throttle.limit.handler.ratio is not positive.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler.<init>(ReencryptionHandler.java:215)",
            "org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager.<init>(EncryptionZoneManager.java:250)",
            "org.apache.hadoop.hdfs.server.namenode.FSDirectory.<init>(FSDirectory.java:411)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:977)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestTrashWithSecureEncryptionZones.init(TestTrashWithSecureEncryptionZones.java:214)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.reencrypt.throttle.limit.handler.ratio": "0.0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testEnterSafeModeInANNShouldNotThrowNPE",
        "failure": "java.io.IOException",
        "errorMessage": "Op 24 has size 17, but maxOpSize = 7",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$LengthPrefixedReader.decodeOpFrame(FSEditLogOp.java:5253)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$LengthPrefixedReader.decodeOp(FSEditLogOp.java:5198)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$Reader.readOp(FSEditLogOp.java:5071)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream.nextOpImpl(EditLogFileInputStream.java:229)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream.nextOp(EditLogFileInputStream.java:276)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)",
            "org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.nextOp(RedundantEditLogInputStream.java:201)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:915)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:762)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:339)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNode(MiniDFSCluster.java:2246)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNode(MiniDFSCluster.java:2227)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.restartActive(TestHASafeMode.java:252)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testEnterSafeModeInANNShouldNotThrowNPE(TestHASafeMode.java:198)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testEnterSafeModeInANNShouldNotThrowNPE$$CONFUZZ(TestHASafeMode.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.max.op.size": "7"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens",
        "testMethod": "testSaveNamespace",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Could not renew or cancel the token",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens.testSaveNamespace(TestCheckPointForSecurityTokens.java:125)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens.testSaveNamespace$$CONFUZZ(TestCheckPointForSecurityTokens.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.delegation.token.max-lifetime": "1056"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport",
        "testMethod": "testDiffReportWithOpenFiles",
        "failure": "java.io.IOException",
        "errorMessage": "Unable to close file because the last block BP-217263406-172.17.0.2-1690651587942:blk_1073741826_1002 does not have enough number of replicas.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:969)",
            "org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:909)",
            "org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:892)",
            "org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:489)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport.createFile(TestSnapshotDiffReport.java:1032)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport.testDiffReportWithOpenFiles(TestSnapshotDiffReport.java:1068)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport.testDiffReportWithOpenFiles$$CONFUZZ(TestSnapshotDiffReport.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.block.write.locateFollowingBlock.initial.delay.ms": "3",
            "dfs.blockreport.incremental.intervalMsec": "1025"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testRemoveAclEntriesMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Permission denied. user=super is not the owner of inode=/p5/bruce/file",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:739)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.removeAclEntries(WebHdfsFileSystem.java:1307)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testRemoveAclEntriesMustBeOwnerOrSuper(FSAclBaseTest.java:1347)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testRemoveAclEntriesMustBeOwnerOrSuper$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.permissions.superusergroup": "zndvtvcahnksnoaasttdnnomjipjrrffuivqjcsioiomxpadfleltwpknnbqluhqbaakixoqcvqxgroup"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS",
        "testMethod": "testBasicOperations",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "java.util.concurrent.ExecutionException: java.net.SocketTimeoutException: Read timed out        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.warmUpEncryptedKeys(KMSClientProvider.java:953)        at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.warmUpEncryptedKeys(LoadBalancingKMSClientProvider.java:295)        at org.apache.hadoop.crypto.key.KeyProviderCryptoExtension.warmUpEncryptedKeys(KeyProviderCryptoExtension.java:493)        at org.apache.hadoop.hdfs.server.namenode.FSDirEncryptionZoneOp.ensureKeyIsInitialized(FSDirEncryptionZoneOp.java:138)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.createEncryptionZone(FSNamesystem.java:7779)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.createEncryptionZone(NameNodeRpcServer.java:2202)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.createEncryptionZone(ClientNamenodeProtocolServerSideTranslatorPB.java:1587)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)Caused by: java.util.concurrent.ExecutionException: java.net.SocketTimeoutException: Read timed out        at org.apache.hadoop.thirdparty.com.google.common.util.concurrent.AbstractFuture.getDoneValue(AbstractFuture.java:566)        at org.apache.hadoop.thirdparty.com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:527)        at org.apache.hadoop.thirdparty.com.google.common.util.concurrent.AbstractFuture$TrustedFuture.get(AbstractFuture.java:104)        at org.apache.hadoop.thirdparty.com.google.common.util.concurrent.Uninterruptibles.getUninterruptibly(Uninterruptibles.java:240)        at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.getAndRecordStats(LocalCache.java:2313)        at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2279)        at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.lockedGetOrLoad(LocalCache.java:2155)        at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2045)        at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.get(LocalCache.java:3962)        at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3985)        at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4946)        at org.apache.hadoop.crypto.key.kms.ValueQueue.initializeQueuesForKeys(ValueQueue.java:276)        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.warmUpEncryptedKeys(KMSClientProvider.java:951)        ... 17 moreCaused by: java.net.SocketTimeoutException: Read timed out        at java.base/java.net.SocketInputStream.socketRead0(Native Method)        at java.base/java.net.SocketInputStream.socketRead(SocketInputStream.java:115)        at java.base/java.net.SocketInputStream.read(SocketInputStream.java:168)        at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)        at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)        at java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:292)        at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:351)        at java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:787)        at java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:722)        at java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1615)        at java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1520)        at java.base/java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:527)        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:564)        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.call(KMSClientProvider.java:540)        at org.apache.hadoop.crypto.key.kms.KMSClientProvider.access$200(KMSClientProvider.java:97)        at org.apache.hadoop.crypto.key.kms.KMSClientProvider$EncryptedQueueRefiller.fillQueueForKey(KMSClientProvider.java:155)        at org.apache.hadoop.crypto.key.kms.ValueQueue$1.load(ValueQueue.java:249)        at org.apache.hadoop.crypto.key.kms.ValueQueue$1.load(ValueQueue.java:243)        at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$LoadingValueReference.loadFuture(LocalCache.java:3529)        at org.apache.hadoop.thirdparty.com.google.common.cache.LocalCache$Segment.loadSync(LocalCache.java:2278)        ... 24 more",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy79.createEncryptionZone(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.createEncryptionZone(ClientNamenodeProtocolTranslatorPB.java:1606)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy80.createEncryptionZone(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.createEncryptionZone(DFSClient.java:2782)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$53.doCall(DistributedFileSystem.java:2720)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$53.doCall(DistributedFileSystem.java:2717)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.createEncryptionZone(DistributedFileSystem.java:2737)",
            "org.apache.hadoop.hdfs.client.HdfsAdmin.createEncryptionZone(HdfsAdmin.java:325)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.testBasicOperations(TestEncryptionZones.java:446)",
            "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.testBasicOperations$$CONFUZZ(TestEncryptionZonesWithKMS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.kms.encrypted.key.cache.expiry": "1008",
            "hadoop.kms.cache.enable": "false"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-123"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA",
        "testMethod": "testHarUriWithHaUriWithNoPort",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort(TestHarFileSystemWithHA.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort$$CONFUZZ(TestHarFileSystemWithHA.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-205"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor",
        "testMethod": "testDecommissionStatusAfterDNRestart",
        "failure": "java.lang.ArrayIndexOutOfBoundsException",
        "errorMessage": "Index 1 out of bounds for length 1",
        "stackTrace": [
            "org.apache.hadoop.hdfs.util.HostsFileWriter.initOutOfServiceHosts(HostsFileWriter.java:110)",
            "org.apache.hadoop.hdfs.util.HostsFileWriter.initExcludeHosts(HostsFileWriter.java:87)",
            "org.apache.hadoop.hdfs.util.HostsFileWriter.initExcludeHost(HostsFileWriter.java:82)",
            "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.testDecommissionStatusAfterDNRestart(TestDecommissioningStatus.java:463)",
            "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor.testDecommissionStatusAfterDNRestart$$CONFUZZ(TestDecommissioningStatusWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.hosts.provider.classname": "org.apache.hadoop.hdfs.server.blockmanagement.CombinedHostFileManager"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Checked if block was replicated after decommission, tried 21 times.",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:414)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:184)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.data.transfer.bandwidthPerSec": "35"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testComplexFailoverIntoSafemode",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Bad safemode status: 'Safe mode is ON. The reported blocks 5 has reached the threshold 0.9990 of total blocks 5. The minimum number of live datanodes is not required. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.'",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.assertSafeMode(TestHASafeMode.java:514)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testComplexFailoverIntoSafemode(TestHASafeMode.java:563)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testComplexFailoverIntoSafemode$$CONFUZZ(TestHASafeMode.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.ha.tail-edits.in-progress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDatanodeConfig",
        "testMethod": "testDataDirectories",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Data-node should startup.",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.hdfs.TestDatanodeConfig.testDataDirectories(TestDatanodeConfig.java:109)",
            "org.apache.hadoop.hdfs.TestDatanodeConfig.testDataDirectories$$CONFUZZ(TestDatanodeConfig.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "1853214028"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission2",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 4 is less than the required minimum of 9096 for /user/root/testDecommission2.dat, clientName=127.0.0.1        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy35.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.writeFile(AdminStatesBaseTest.java:136)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.writeFile(AdminStatesBaseTest.java:129)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.writeFile(AdminStatesBaseTest.java:124)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission2(TestDecommission.java:212)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission2$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.replication.max": "12072",
            "dfs.namenode.replication.min": "9096"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-206"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testBlocksRemovedWhileInSafeModeEditsArriveFirst",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "timeout can't be negative",
        "stackTrace": [
            "java.base/sun.nio.ch.SocketAdaptor.setSoTimeout(SocketAdaptor.java:338)",
            "org.apache.hadoop.hdfs.DataStreamer.createSocketForPipeline(DataStreamer.java:256)",
            "org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1774)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1728)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.socket-timeout": "2147483646"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-124"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testNodeUsageAfterDecommissioned",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.cleanupFile(AdminStatesBaseTest.java:459)",
            "org.apache.hadoop.hdfs.TestDecommission.nodeUsageVerification(TestDecommission.java:1575)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageAfterDecommissioned(TestDecommission.java:1498)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageAfterDecommissioned$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "044897756s"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade",
        "testMethod": "testDatanodeRollingUpgradeWithRollback",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.deleteAndEnsureInTrash(TestDataNodeRollingUpgrade.java:141)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback(TestDataNodeRollingUpgrade.java:274)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback$$CONFUZZ(TestDataNodeRollingUpgrade.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.heartbeat.interval": "1949799550"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-1"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testAppend",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestHDFSFileSystemContract.setUp(TestHDFSFileSystemContract.java:46)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "611881599",
            "ipc.server.read.threadpool.size": "1124040447"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleAndSlowDatanodes",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<[5.5.5.5]> but was:<[3.3.3.3]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes(TestSortLocatedBlock.java:153)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.stale.datanode.minimum.interval": "2202",
            "dfs.heartbeat.interval": "501"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsckReplicaDetails",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckReplicaDetails(TestFsck.java:959)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckReplicaDetails$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blockreport.initialDelay": "944"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "255",
            "dfs.permissions.superusergroup": "twvwarwwnedrdkduojshmvppbazyrprfawszwflzrbnrvrormovqvxltqxshdeuqomnolpstasdpzxsnktrgfbgroup"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-124"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testNodeUsageWhileDecommissioining",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.cleanupFile(AdminStatesBaseTest.java:459)",
            "org.apache.hadoop.hdfs.TestDecommission.nodeUsageVerification(TestDecommission.java:1575)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageWhileDecommissioining(TestDecommission.java:1510)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testNodeUsageWhileDecommissioining$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "225"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-125"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testUnreachableObserverWithMultiple",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "No reads!",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider$NameNodeAnswer$ClientProtocolAnswer.answer(TestObserverReadProxyProvider.java:404)",
            "org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:39)",
            "org.mockito.internal.handler.MockHandlerImpl.handle(MockHandlerImpl.java:96)",
            "org.mockito.internal.handler.NullResultGuardian.handle(NullResultGuardian.java:29)",
            "org.mockito.internal.handler.InvocationNotifierHandler.handle(InvocationNotifierHandler.java:35)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:61)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:49)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor$DispatcherDefaultingToRealMethod.interceptAbstract(MockMethodInterceptor.java:126)",
            "org.apache.hadoop.hdfs.protocol.ClientProtocol$MockitoMock$830028894.checkAccess(Unknown Source)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider$ObserverReadInvocationHandler.invoke(ObserverReadProxyProvider.java:519)",
            "com.sun.proxy.$Proxy36.checkAccess(Unknown Source)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.doRead(TestObserverReadProxyProvider.java:345)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.doRead(TestObserverReadProxyProvider.java:328)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testUnreachableObserverWithMultiple(TestObserverReadProxyProvider.java:212)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testUnreachableObserverWithMultiple$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.random.order": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testGetTrashRoots",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Minimum value of buffer size is 512.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.crypto.CryptoStreamUtils.checkBufferSize(CryptoStreamUtils.java:70)",
            "org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:104)",
            "org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:134)",
            "org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:128)",
            "org.apache.hadoop.hdfs.DFSClient.createWrappedOutputStream(DFSClient.java:1009)",
            "org.apache.hadoop.hdfs.DFSClient.createWrappedOutputStream(DFSClient.java:983)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.safelyCreateWrappedOutputStream(DistributedFileSystem.java:721)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.access$300(DistributedFileSystem.java:147)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:559)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.testGetTrashRoots(TestEncryptionZones.java:1910)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.testGetTrashRoots$$CONFUZZ(TestEncryptionZones.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.crypto.buffer.size": "469"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testSelectViaRpcTwoDeadJNs",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "numLevels must be at least 1",
        "stackTrace": [
            "org.apache.hadoop.ipc.CallQueueManager.parseNumLevels(CallQueueManager.java:355)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:78)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.<init>(JournalNodeRpcServer.java:101)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:242)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.0.scheduler.priority.levels": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-124"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testNodeUsageWhileDecommissioining",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.cleanupFile(AdminStatesBaseTest.java:459)",
            "org.apache.hadoop.hdfs.TestDecommission.nodeUsageVerification(TestDecommission.java:1575)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageWhileDecommissioining(TestDecommission.java:1510)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testNodeUsageWhileDecommissioining$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "26861"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-188"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testMoveBlockFailure",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testMoveBlockFailure(TestFsDatasetImpl.java:1005)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testMoveBlockFailure$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "135",
            "dfs.datanode.handler.count": "272664331"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-210"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testRename",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.lambda$testClientRetryWithFailover$2(TestRetryCacheWithHA.java:1346)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:449)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:421)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testClientRetryWithFailover(TestRetryCacheWithHA.java:1344)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testRename(TestRetryCacheWithHA.java:1190)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testRename$$CONFUZZ(TestRetryCacheWithHA.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.enable.retrycache": "false"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testPurgeLogs",
        "failure": "org.apache.hadoop.hdfs.qjournal.client.QuorumException",
        "errorMessage": "Got too many exceptions to achieve quorum size 2/3. 3 exceptions thrown:127.0.0.1:38047: RPC response exceeds maximum data length127.0.0.1:42241: RPC response exceeds maximum data length127.0.0.1:35805: RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:305)",
            "org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:143)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.createNewUniqueEpoch(QuorumJournalManager.java:233)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.recoverUnfinalizedSegments(QuorumJournalManager.java:478)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:118)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "33"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-211"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestAppendDifferentChecksum",
        "testMethod": "testAlgoSwitchRandomized",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Buffer size <= 0",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:73)",
            "org.apache.hadoop.hdfs.DataStreamer.createBlockOutputStream(DataStreamer.java:1785)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1728)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestAppendDifferentChecksum",
        "testMethod": "testAlgoSwitchRandomized",
        "failure": "java.io.InterruptedIOException",
        "errorMessage": "No ack received after 0s and a timeout of 0s",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DataStreamer.waitForAckedSeqno(DataStreamer.java:931)",
            "org.apache.hadoop.hdfs.DFSOutputStream.flushInternal(DFSOutputStream.java:778)",
            "org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:888)",
            "org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "org.apache.hadoop.hdfs.TestAppendDifferentChecksum.testAlgoSwitchRandomized(TestAppendDifferentChecksum.java:125)",
            "org.apache.hadoop.hdfs.TestAppendDifferentChecksum.testAlgoSwitchRandomized$$CONFUZZ(TestAppendDifferentChecksum.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.socket.write.timeout": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testListEncryptionZonesWithSnapshots",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.reencrypt.sleep.interval is not positive.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler.<init>(ReencryptionHandler.java:199)",
            "org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager.<init>(EncryptionZoneManager.java:250)",
            "org.apache.hadoop.hdfs.server.namenode.FSDirectory.<init>(FSDirectory.java:411)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:977)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.reencrypt.sleep.interval": "0s"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testProvidedVolumeImpl",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "configured value 32831for dfs.datanode.cache.revocation.polling.ms is too high.  It must not be more than half of the value of dfs.datanode.cache.revocation.timeout.ms.  Reconfigure this to 7007",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.<init>(FsDatasetCache.java:174)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:375)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.setUp(TestProvidedImpl.java:342)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "32831",
            "dfs.datanode.cache.revocation.timeout.ms": "14015"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDisableConnCache",
        "testMethod": "testDisableCache",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "The maximum path component name limit of testConnCache.dat in directory / is exceeded: limit=1 length=17        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1258)        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1360)        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addINode(FSDirectory.java:1184)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.addFile(FSDirWriteFileOp.java:579)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:398)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2703)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy29.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy30.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.client.impl.BlockReaderTestUtil.writeFile(BlockReaderTestUtil.java:127)",
            "org.apache.hadoop.hdfs.TestDisableConnCache.testDisableCache(TestDisableConnCache.java:54)",
            "org.apache.hadoop.hdfs.TestDisableConnCache.testDisableCache$$CONFUZZ(TestDisableConnCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.max-component-length": "1"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-123"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA",
        "testMethod": "testHarUriWithHaUriWithNoPort",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort(TestHarFileSystemWithHA.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort$$CONFUZZ(TestHarFileSystemWithHA.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "503"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForXAttr",
        "testMethod": "testWebImageViewerForGetXAttrsWithOutParameters",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForXAttr.createOriginalFSImage(TestOfflineImageViewerForXAttr.java:75)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.fsdatasetasyncdisk.max.threads.per.volume": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot",
        "testMethod": "testDatanodeRestarts",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<5> but was:<0>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot.testDatanodeRestarts(TestStandbyIsHot.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot.testDatanodeRestarts$$CONFUZZ(TestStandbyIsHot.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.heartbeat.recheck-interval": "7"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade",
        "testMethod": "testDatanodeRollingUpgradeWithRollback",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.deleteAndEnsureInTrash(TestDataNodeRollingUpgrade.java:141)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback(TestDataNodeRollingUpgrade.java:274)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback$$CONFUZZ(TestDataNodeRollingUpgrade.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.redundancy.interval.seconds": "260145153"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-125"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testUnreachableObserverWithMultiple",
        "failure": "java.io.IOException",
        "errorMessage": "Unavailable",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider$NameNodeAnswer$ClientProtocolAnswer.answer(TestObserverReadProxyProvider.java:370)",
            "org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:39)",
            "org.mockito.internal.handler.MockHandlerImpl.handle(MockHandlerImpl.java:96)",
            "org.mockito.internal.handler.NullResultGuardian.handle(NullResultGuardian.java:29)",
            "org.mockito.internal.handler.InvocationNotifierHandler.handle(InvocationNotifierHandler.java:35)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:61)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:49)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor$DispatcherDefaultingToRealMethod.interceptAbstract(MockMethodInterceptor.java:126)",
            "org.apache.hadoop.hdfs.protocol.ClientProtocol$MockitoMock$1295320945.checkAccess(Unknown Source)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider$ObserverReadInvocationHandler.invoke(ObserverReadProxyProvider.java:519)",
            "com.sun.proxy.$Proxy36.checkAccess(Unknown Source)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.doRead(TestObserverReadProxyProvider.java:345)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.doRead(TestObserverReadProxyProvider.java:328)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testUnreachableObserverWithMultiple(TestObserverReadProxyProvider.java:212)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testUnreachableObserverWithMultiple$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.random.order": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestStartup",
        "testMethod": "testChkpointStartup1",
        "failure": "java.lang.AssertionError",
        "errorMessage": "java.io.IOException: Running in secure mode, but config doesn't have a keytab        at org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)        at org.apache.hadoop.hdfs.server.namenode.NameNode.loginAsNameNodeUser(NameNode.java:719)        at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:738)        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)        at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)        at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)        at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)        at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)        at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)        at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)        at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)        at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)        at org.apache.hadoop.hdfs.server.namenode.TestStartup.createCheckPoint(TestStartup.java:151)        at org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1(TestStartup.java:348)        at org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1$$CONFUZZ(TestStartup.java)        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.base/java.lang.reflect.Method.invoke(Method.java:566)        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)        at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)        at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)        at edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)        at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)        at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)        at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)        at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)        at org.junit.runners.ParentRunner.run(ParentRunner.java:413)        at org.junit.runner.JUnitCore.run(JUnitCore.java:137)        at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)        at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.createCheckPoint(TestStartup.java:173)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1(TestStartup.java:348)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1$$CONFUZZ(TestStartup.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-1"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultAclNewFileWithMode",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "537974527",
            "ipc.server.read.threadpool.size": "1124797696"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testLoadingDfsUsedForVolumes",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<1024> but was:<18>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testLoadingDfsUsedForVolumes(TestFsDatasetImpl.java:684)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testLoadingDfsUsedForVolumes$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "fs.getspaceused.jitterMillis": "2130640638",
            "fs.local.block.size": "229119",
            "fs.getspaceused.classname": "org.apache.hadoop.fs.WindowsGetSpaceUsed"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-125"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testUnreachableObserverWithMultiple",
        "failure": "java.io.IOException",
        "errorMessage": "Unavailable",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider$NameNodeAnswer$ClientProtocolAnswer.answer(TestObserverReadProxyProvider.java:370)",
            "org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:39)",
            "org.mockito.internal.handler.MockHandlerImpl.handle(MockHandlerImpl.java:96)",
            "org.mockito.internal.handler.NullResultGuardian.handle(NullResultGuardian.java:29)",
            "org.mockito.internal.handler.InvocationNotifierHandler.handle(InvocationNotifierHandler.java:35)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:61)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:49)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor$DispatcherDefaultingToRealMethod.interceptAbstract(MockMethodInterceptor.java:126)",
            "org.apache.hadoop.hdfs.protocol.ClientProtocol$MockitoMock$436683570.checkAccess(Unknown Source)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider$ObserverReadInvocationHandler.invoke(ObserverReadProxyProvider.java:519)",
            "com.sun.proxy.$Proxy36.checkAccess(Unknown Source)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.doRead(TestObserverReadProxyProvider.java:345)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.doRead(TestObserverReadProxyProvider.java:328)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testUnreachableObserverWithMultiple(TestObserverReadProxyProvider.java:212)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testUnreachableObserverWithMultiple$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.random.order": "true",
            "dfs.client.failover.connection.retries.on.timeouts": "767"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientRetries",
        "testMethod": "testClientDNProtocolTimeout",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Protocol interface org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol is not known.",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy22.getReplicaVisibleLength(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolTranslatorPB.getReplicaVisibleLength(ClientDatanodeProtocolTranslatorPB.java:201)",
            "org.apache.hadoop.hdfs.TestDFSClientRetries.testClientDNProtocolTimeout(TestDFSClientRetries.java:894)",
            "org.apache.hadoop.hdfs.TestDFSClientRetries.testClientDNProtocolTimeout$$CONFUZZ(TestDFSClientRetries.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authorization": "true"
        }
    },
    {
        "status": "Non-Reproducible",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestStartup",
        "testMethod": "testChkpointStartup1",
        "failure": "java.lang.AssertionError",
        "errorMessage": "java.io.IOException: Unexpected configuration parameters: dfs.namenode.replication.min = 5888 > dfs.replication.max = 105        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:532)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)        at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)        at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)        at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)        at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)        at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)        at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)        at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)        at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)        at org.apache.hadoop.hdfs.server.namenode.TestStartup.createCheckPoint(TestStartup.java:151)        at org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1(TestStartup.java:348)        at org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1$$CONFUZZ(TestStartup.java)        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.base/java.lang.reflect.Method.invoke(Method.java:566)        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)        at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)        at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)        at edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)        at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)        at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)        at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)        at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)        at org.junit.runners.ParentRunner.run(ParentRunner.java:413)        at org.junit.runner.JUnitCore.run(JUnitCore.java:137)        at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)        at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.createCheckPoint(TestStartup.java:173)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1(TestStartup.java:348)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1$$CONFUZZ(TestStartup.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "2ms"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testSetAndClearSpaceQuotaPathIsFile",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Expected: is (a string containing \"setSpaceQuota\" and a string containing \"/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ag53Cfj888/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file\" and a string containing \"Is not a directory\")     but: a string containing \"/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/ag53Cfj888/TestQuota/testSetAndClearSpaceQuotaPathIsFile/path-is-file\" was \"setSpaceQuota: RPC response exceeds maximum data length\"",
        "stackTrace": [
            "org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)",
            "org.junit.Assert.assertThat(Assert.java:964)",
            "org.junit.Assert.assertThat(Assert.java:930)",
            "org.apache.hadoop.hdfs.TestQuota.testSetAndClearSpaceQuotaPathIsFileInternal(TestQuota.java:1511)",
            "org.apache.hadoop.hdfs.TestQuota.testSetAndClearSpaceQuotaPathIsFile(TestQuota.java:1480)",
            "org.apache.hadoop.hdfs.TestQuota.testSetAndClearSpaceQuotaPathIsFile$$CONFUZZ(TestQuota.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "695"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor",
        "testMethod": "testDecommissionWithMissingBlock",
        "failure": "java.io.IOException",
        "errorMessage": "Failed: the number of failed blocks = 4 > the number of parity blocks = 3",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:410)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.handleStreamerFailure(DFSStripedOutputStream.java:435)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.handleCurrentStreamerFailure(DFSStripedOutputStream.java:427)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.writeChunk(DFSStripedOutputStream.java:571)",
            "org.apache.hadoop.fs.FSOutputSummer.writeChecksumChunks(FSOutputSummer.java:218)",
            "org.apache.hadoop.fs.FSOutputSummer.write1(FSOutputSummer.java:126)",
            "org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:112)",
            "org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62)",
            "java.base/java.io.DataOutputStream.write(DataOutputStream.java:107)",
            "org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:96)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:903)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:924)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.writeStripedFile(TestDecommissionWithStriped.java:570)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testDecommissionWithMissingBlock(TestDecommissionWithStriped.java:844)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor.testDecommissionWithMissingBlock$$CONFUZZ(TestDecommissionWithStripedBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.socket-timeout": "939",
            "dfs.client-write-packet-size": "10096",
            "dfs.datanode.data.write.bandwidthPerSec": "767"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testBasicOperations",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.fsdatasetcache.max.threads.per.volume": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testSkipAclEnforcementSuper",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected AccessControlException for user diana (auth:SIMPLE), path = /p15/bruce/file",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.AclTestHelpers.assertFilePermissionDenied(AclTestHelpers.java:120)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testSkipAclEnforcementSuper(FSAclBaseTest.java:1315)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testSkipAclEnforcementSuper$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.permissions.enabled": "false"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier",
        "testMethod": "testWithKeytabs",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Failed to set storage policy since dfs.storage.policy.enabled is set to false.        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkStoragePolicyEnabled(FSNamesystem.java:2375)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setStoragePolicy(FSNamesystem.java:2395)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setStoragePolicy(NameNodeRpcServer.java:868)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setStoragePolicy(ClientNamenodeProtocolServerSideTranslatorPB.java:1765)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.setStoragePolicy(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setStoragePolicy(ClientNamenodeProtocolTranslatorPB.java:1805)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.setStoragePolicy(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.setStoragePolicy(DFSClient.java:1511)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$13.doCall(DistributedFileSystem.java:762)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$13.doCall(DistributedFileSystem.java:759)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.setStoragePolicy(DistributedFileSystem.java:771)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWhenStoragePolicySetToALLSSD(TestExternalStoragePolicySatisfier.java:455)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier$1.run(TestExternalStoragePolicySatisfier.java:311)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier$1.run(TestExternalStoragePolicySatisfier.java:307)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWithKeytabs(TestExternalStoragePolicySatisfier.java:307)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWithKeytabs$$CONFUZZ(TestExternalStoragePolicySatisfier.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.storage.policy.enabled": "false"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-8"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestPread",
        "testMethod": "testPreadLocalFS",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209)",
            "org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56)",
            "org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210)",
            "org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124)",
            "org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117)",
            "org.apache.hadoop.hdfs.TestPread.writeFile(TestPread.java:96)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS(TestPread.java:503)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS$$CONFUZZ(TestPread.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.stream-buffer-size": "2130640638"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testDefaultAclRenamedDir",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "The maximum path component name limit of p23 in directory / is exceeded: limit=2 length=3",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:739)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.mkdirs(WebHdfsFileSystem.java:1142)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:750)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testDefaultAclRenamedDir(FSAclBaseTest.java:1268)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testDefaultAclRenamedDir$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.max-component-length": "2"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testDefaultAclRenamedDir",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.directoryscan.interval": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testGetBlockLocations",
        "failure": "org.apache.hadoop.hdfs.server.blockmanagement.UnresolvedTopologyException",
        "errorMessage": "Unresolved topology mapping for host null",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.resolveNetworkLocation(DatanodeManager.java:1030)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.registerDatanode(DatanodeManager.java:1250)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocations(TestDatanodeManager.java:485)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocations$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.reject-unresolved-dn-topology-mapping": "true",
            "net.topology.script.number.args": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-123"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA",
        "testMethod": "testHarUriWithHaUriWithNoPort",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort(TestHarFileSystemWithHA.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort$$CONFUZZ(TestHarFileSystemWithHA.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "2534"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure",
        "testMethod": "testIdempotentCloseWithFailedStreams",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "The policy name RS-6-3-64k does not exist        at org.apache.hadoop.hdfs.server.namenode.ErasureCodingPolicyManager.enablePolicy(ErasureCodingPolicyManager.java:433)        at org.apache.hadoop.hdfs.server.namenode.FSDirErasureCodingOp.enableErasureCodingPolicy(FSDirErasureCodingOp.java:285)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.enableErasureCodingPolicy(FSNamesystem.java:8070)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.enableErasureCodingPolicy(NameNodeRpcServer.java:2559)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.enableErasureCodingPolicy(ClientNamenodeProtocolServerSideTranslatorPB.java:1916)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy30.enableErasureCodingPolicy(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.enableErasureCodingPolicy(ClientNamenodeProtocolTranslatorPB.java:1910)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.enableErasureCodingPolicy(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.enableErasureCodingPolicy(DFSClient.java:2993)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.enableErasureCodingPolicy(DistributedFileSystem.java:3228)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailureBase.setup(TestDFSStripedOutputStreamWithFailureBase.java:214)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams(TestDFSStripedOutputStreamWithFailure.java:165)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testIdempotentCloseWithFailedStreams$$CONFUZZ(TestDFSStripedOutputStreamWithFailure.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.ec.policies.max.cellsize": "767"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-197"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testSetXAttrPermission",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Permission denied printed",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.hdfs.TestDFSShell$11.run(TestDFSShell.java:3066)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.TestDFSShell.testSetXAttrPermission(TestDFSShell.java:3059)",
            "org.apache.hadoop.hdfs.TestDFSShell.testSetXAttrPermission$$CONFUZZ(TestDFSShell.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "767"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testCrashAtBeginningOfSegment",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting 3ms for a quorum of nodes to respond.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:138)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.createNewUniqueEpoch(QuorumJournalManager.java:244)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.recoverUnfinalizedSegments(QuorumJournalManager.java:478)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testCrashAtBeginningOfSegment(TestQuorumJournalManager.java:297)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testCrashAtBeginningOfSegment$$CONFUZZ(TestQuorumJournalManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.qjournal.new-epoch.timeout.ms": "3"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testCrashAtBeginningOfSegment",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting 2ms for a quorum of nodes to respond.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.AsyncLoggerSet.waitForWriteQuorum(AsyncLoggerSet.java:138)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.startLogSegment(QuorumJournalManager.java:436)",
            "org.apache.hadoop.hdfs.qjournal.QJMTestUtil.writeSegment(QJMTestUtil.java:84)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testCrashAtBeginningOfSegment(TestQuorumJournalManager.java:300)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testCrashAtBeginningOfSegment$$CONFUZZ(TestQuorumJournalManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.qjournal.start-segment.timeout.ms": "2"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens",
        "testMethod": "testSaveNamespace",
        "failure": "java.lang.AssertionError",
        "errorMessage": "In-progress log EditLogFile(file=/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000005,first=0000000000000000005,last=0000000000000000007,inProgress=true,hasCorruptHeader=false) should have 5 transactions expected:<5> but was:<3>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens.testSaveNamespace(TestCheckPointForSecurityTokens.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens.testSaveNamespace$$CONFUZZ(TestCheckPointForSecurityTokens.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edit.log.autoroll.multiplier.threshold": "-0.4923848509788513"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages",
        "testMethod": "testChangedStorageId",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /root/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages.testChangedStorageId(TestPendingCorruptDnMessages.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages.testChangedStorageId$$CONFUZZ(TestPendingCorruptDnMessages.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.enable": "false",
            "dfs.replication.max": "23191",
            "dfs.namenode.top.enabled": "false",
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestCrcCorruption",
        "testMethod": "testCrcCorruption",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestCrcCorruption.thistest(TestCrcCorruption.java:161)",
            "org.apache.hadoop.hdfs.TestCrcCorruption.testCrcCorruption(TestCrcCorruption.java:233)",
            "org.apache.hadoop.hdfs.TestCrcCorruption.testCrcCorruption$$CONFUZZ(TestCrcCorruption.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.read.shortcircuit": "true",
            "fs.trash.interval": "26960"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-6"
        ],
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testMultipartUploadEmptyPart",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.enable": "false",
            "dfs.replication.max": "20897",
            "dfs.namenode.blockreport.queue.size": "866272653"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-59"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleAndSlowDatanodes",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.Comparator.lambda$comparing$77a9974f$1(Comparator.java:469)",
            "java.base/java.util.TimSort.countRunAndMakeAscending(TimSort.java:355)",
            "java.base/java.util.TimSort.sort(TimSort.java:220)",
            "java.base/java.util.Arrays.sort(Arrays.java:1515)",
            "java.base/java.util.ArrayList.sort(ArrayList.java:1750)",
            "java.base/java.util.Collections.sort(Collections.java:179)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.lambda$createSecondaryNodeSorter$0(DatanodeManager.java:654)",
            "org.apache.hadoop.net.NetworkTopology.sortByDistance(NetworkTopology.java:983)",
            "org.apache.hadoop.net.NetworkTopology.sortByDistanceUsingNetworkLocation(NetworkTopology.java:946)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlock(DatanodeManager.java:637)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlocks(DatanodeManager.java:554)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes(TestSortLocatedBlock.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.stale.datanode.minimum.interval": "999",
            "dfs.namenode.read.considerStorageType": "true",
            "dfs.heartbeat.interval": "351"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testGetBlockLocationConsiderLoad",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<IP-[1-3]> but was:<IP-[2-4]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderLoad(TestDatanodeManager.java:578)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderLoad$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.stale.datanode.interval": "17",
            "dfs.heartbeat.interval": "0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testObserverToActive",
        "failure": "java.net.UnknownHostException",
        "errorMessage": "namenode0.test: Name or service not known",
        "stackTrace": [
            "java.base/java.net.Inet4AddressImpl.lookupAllHostAddr(Native Method)",
            "java.base/java.net.InetAddress$PlatformNameService.lookupAllHostAddr(InetAddress.java:930)",
            "java.base/java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1543)",
            "java.base/java.net.InetAddress$NameServiceAddresses.get(InetAddress.java:848)",
            "java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)",
            "java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)",
            "java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)",
            "org.apache.hadoop.net.DNSDomainNameResolver.getAllByDomainName(DNSDomainNameResolver.java:33)",
            "org.apache.hadoop.net.DNSDomainNameResolver.getAllResolvedHostnameByDomainName(DNSDomainNameResolver.java:49)",
            "org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider.getResolvedHostsIfNecessary(AbstractNNFailoverProxyProvider.java:240)",
            "org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider.getProxyAddresses(AbstractNNFailoverProxyProvider.java:183)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:51)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:45)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider.<init>(ObserverReadProxyProvider.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider$2.<init>(TestObserverReadProxyProvider.java:116)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.setupProxyProvider(TestObserverReadProxyProvider.java:106)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testObserverToActive(TestObserverReadProxyProvider.java:219)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testObserverToActive$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.resolve-needed.testcluster": "true",
            "hadoop.security.token.service.use_ip": "false"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-124"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testNodeUsageWhileDecommissioining",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.cleanupFile(AdminStatesBaseTest.java:459)",
            "org.apache.hadoop.hdfs.TestDecommission.nodeUsageVerification(TestDecommission.java:1575)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageWhileDecommissioining(TestDecommission.java:1510)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testNodeUsageWhileDecommissioining$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "318226274"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-12"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart",
        "testMethod": "testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart.testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister(TestFileLengthOnClusterRestart.java:43)",
            "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart.testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister$$CONFUZZ(TestFileLengthOnClusterRestart.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "699407230",
            "dfs.namenode.blockreport.queue.size": "454756540"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes",
        "testMethod": "testFullBlockReportAfterRemovingVolumes",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes.testFullBlockReportAfterRemovingVolumes(TestDataNodeHotSwapVolumes.java:1100)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes.testFullBlockReportAfterRemovingVolumes$$CONFUZZ(TestDataNodeHotSwapVolumes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "fs.trash.interval": "788",
            "dfs.client.domain.socket.data.traffic": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestStartup",
        "testMethod": "testChkpointStartup1",
        "failure": "java.lang.AssertionError",
        "errorMessage": "java.io.IOException: The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem        at org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)        at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)        at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)        at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)        at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)        at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)        at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)        at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)        at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)        at org.apache.hadoop.hdfs.server.namenode.TestStartup.createCheckPoint(TestStartup.java:151)        at org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1(TestStartup.java:348)        at org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1$$CONFUZZ(TestStartup.java)        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.base/java.lang.reflect.Method.invoke(Method.java:566)        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)        at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)        at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)        at edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)        at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)        at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)        at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)        at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)        at org.junit.runners.ParentRunner.run(ParentRunner.java:413)        at org.junit.runner.JUnitCore.run(JUnitCore.java:137)        at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)        at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.createCheckPoint(TestStartup.java:173)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1(TestStartup.java:348)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1$$CONFUZZ(TestStartup.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "35"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-167"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs",
        "testMethod": "testNameEditsConfigsFailure",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure(TestNameEditsConfigs.java:450)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure$$CONFUZZ(TestNameEditsConfigs.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "1645801136"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-124"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testNodeUsageAfterDecommissioned",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.cleanupFile(AdminStatesBaseTest.java:459)",
            "org.apache.hadoop.hdfs.TestDecommission.nodeUsageVerification(TestDecommission.java:1575)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageAfterDecommissioned(TestDecommission.java:1498)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageAfterDecommissioned$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.read.shortcircuit": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-171"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestPread",
        "testMethod": "testPreadLocalFS",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209)",
            "org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56)",
            "org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210)",
            "org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124)",
            "org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117)",
            "org.apache.hadoop.hdfs.TestPread.writeFile(TestPread.java:96)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS(TestPread.java:503)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS$$CONFUZZ(TestPread.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "2146036837"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-6"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testDecommissionWithBusyNode",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.stream-buffer-size": "945834638",
            "dfs.namenode.blockreport.queue.size": "467568147",
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1065849381"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-170"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA",
        "testMethod": "testMultipleExistingUsers",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93)",
            "org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)",
            "org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:114)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:456)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:447)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:447)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.copyNameDirs(MiniDFSCluster.java:1326)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1121)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA.setUpNameNode(TestGetGroupsWithHA.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1885408251",
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1032060624"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testAppend",
        "failure": "org.apache.hadoop.hdfs.server.namenode.NameNodeFormatException",
        "errorMessage": "NameNode format aborted as reformat is disabled for this cluster.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1267)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestHDFSFileSystemContract.setUp(TestHDFSFileSystemContract.java:46)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/LYG6doDKLM/name-0-1,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/LYG6doDKLM/name-0-2",
            "dfs.reformat.disabled": "true"
        }
    },
    {
        "status": "Non-Reproducible",
        "bugId": [],
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename",
        "testMethod": "testRenameNewFileSameDir",
        "failure": "java.io.IOException",
        "errorMessage": "Failed to save in any storage directories while saving namespace.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.FSImage.saveFSImageInAllDirs(FSImage.java:1243)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.saveFSImageInAllDirs(FSImage.java:1200)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.format(FSImage.java:191)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1278)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename.createCluster(TestHDFSContractRename.java:33)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "778928574",
            "dfs.image.compress": "true",
            "io.file.buffer.size": "2052039959"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-175"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestPread",
        "testMethod": "testPreadLocalFS",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210)",
            "org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124)",
            "org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117)",
            "org.apache.hadoop.hdfs.TestPread.writeFile(TestPread.java:96)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS(TestPread.java:503)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS$$CONFUZZ(TestPread.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1623667365"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestUpdateBlockTailing",
        "testMethod": "testStandbyAppendNewBlock",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Time out while waiting for journal node 0 to start.",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:262)",
            "org.apache.hadoop.hdfs.qjournal.MiniQJMHACluster.<init>(MiniQJMHACluster.java:117)",
            "org.apache.hadoop.hdfs.qjournal.MiniQJMHACluster.<init>(MiniQJMHACluster.java:38)",
            "org.apache.hadoop.hdfs.qjournal.MiniQJMHACluster$Builder.build(MiniQJMHACluster.java:68)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestUpdateBlockTailing.startUpCluster(TestUpdateBlockTailing.java:77)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.client.rpc-timeout.ms": "654",
            "ipc.server.read.threadpool.size": "3632"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testGetBlockLocationConsiderLoadWithNodesOfSameDistance",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<2> but was:<1>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderLoadWithNodesOfSameDistance(TestDatanodeManager.java:669)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderLoadWithNodesOfSameDistance$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.heartbeat.interval": "615442863",
            "dfs.namenode.stale.datanode.minimum.interval": "1404710177",
            "dfs.namenode.stale.datanode.interval": "40"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testGetBlockLocationConsiderStorageTypeAndLoad",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<IP-[1-3]> but was:<IP-[2-4]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderStorageTypeAndLoad(TestDatanodeManager.java:818)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderStorageTypeAndLoad$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.stale.datanode.interval": "131",
            "dfs.heartbeat.interval": "1355466193",
            "dfs.namenode.stale.datanode.minimum.interval": "581603761",
            "dfs.namenode.heartbeat.recheck-interval": "17944",
            "dfs.namenode.write.stale.datanode.ratio": "0.9f",
            "dfs.datanode.fileio.profiling.sampling.percentage": "8787"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-214"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestValidateConfigurationSettings",
        "testMethod": "testThatMatchingRPCandHttpPortsThrowException",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.TestValidateConfigurationSettings.testThatMatchingRPCandHttpPortsThrowException(TestValidateConfigurationSettings.java:70)",
            "org.apache.hadoop.hdfs.server.namenode.TestValidateConfigurationSettings.testThatMatchingRPCandHttpPortsThrowException$$CONFUZZ(TestValidateConfigurationSettings.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.replication": "9793",
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "54ms",
            "dfs.replication.max": "16354",
            "dfs.namenode.gc.time.monitor.observation.window.ms": "11414395d"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testGetBlockLocationConsiderStorageTypeAndLoad",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<IP-[0-1]> but was:<IP-[2-4]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderStorageTypeAndLoad(TestDatanodeManager.java:839)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderStorageTypeAndLoad$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.avoid.read.slow.datanode": "false",
            "hadoop.security.groups.cache.secs": "270",
            "dfs.hosts": "",
            "dfs.use.dfs.network.topology": "true",
            "dfs.namenode.hosts.provider.classname": "org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager",
            "dfs.namenode.max.full.block.report.leases": "1909070122",
            "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]",
            "net.topology.node.switch.mapping.impl": "org.apache.hadoop.net.ScriptBasedMapping",
            "dfs.namenode.reject-unresolved-dn-topology-mapping": "false",
            "dfs.namenode.stale.datanode.minimum.interval": "112247541",
            "dfs.hosts.exclude": "",
            "hadoop.kerberos.min.seconds.before.relogin": "570",
            "net.topology.script.number.args": "699",
            "ssl.client.stores.reload.interval": "738455503",
            "dfs.namenode.datanode.registration.ip-hostname-check": "true",
            "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback",
            "hadoop.ssl.keystores.factory.class": "org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory",
            "dfs.namenode.stale.datanode.interval": "146",
            "hadoop.security.groups.cache.warn.after.ms": "586",
            "hadoop.ssl.client.conf": "ssl-client.xml",
            "dfs.namenode.max.slowpeer.collect.nodes": "575",
            "hadoop.security.groups.cache.background.reload": "true",
            "dfs.datanode.outliers.report.interval": "6h",
            "hadoop.user.group.static.mapping.overrides": "dr.who=;",
            "dfs.datanode.ipc.address": "0.0.0.0:9867",
            "hadoop.ssl.hostname.verifier": "STRICT",
            "dfs.datanode.https.address": "0.0.0.0:9865",
            "dfs.net.topology.impl": "org.apache.hadoop.hdfs.net.DFSNetworkTopology",
            "dfs.namenode.enable.log.stale.datanode": "false",
            "hadoop.security.dns.log-slow-lookups.enabled": "true",
            "dfs.datanode.fileio.profiling.sampling.percentage": "768378785",
            "dfs.datanode.address": "0.0.0.0:9866",
            "dfs.namenode.heartbeat.recheck-interval": "918",
            "dfs.namenode.write.stale.datanode.ratio": "1.0f",
            "io.file.buffer.size": "536",
            "dfs.namenode.full.block.report.lease.length.ms": "1194498755",
            "dfs.heartbeat.interval": "1632918848",
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1835325989"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-12"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsLimits",
        "testMethod": "testMaxComponentLength",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsLimits.getMockNamesystem(TestFsLimits.java:57)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsLimits.lazyInitFSDirectory(TestFsLimits.java:296)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsLimits.mkdirs(TestFsLimits.java:251)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsLimits.testMaxComponentLength(TestFsLimits.java:88)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsLimits.testMaxComponentLength$$CONFUZZ(TestFsLimits.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.heartbeat.recheck-interval": "50587368",
            "dfs.namenode.safemode.extension": "874",
            "dfs.namenode.delegation.key.update-interval": "1438845953",
            "dfs.namenode.redundancy.interval.seconds": "806",
            "dfs.namenode.fs-limits.max-xattr-size": "34",
            "dfs.datanode.http.address": "0.0.0.0:9864",
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1604071531",
            "dfs.lock.suppress.warning.interval": "322363734s",
            "dfs.namenode.maintenance.replication.min": "1283365615",
            "dfs.namenode.fs-limits.max-blocks-per-file": "4962"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testBasicOperations",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.reencrypt.throttle.limit.updater.ratio is not positive.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.ReencryptionUpdater.<init>(ReencryptionUpdater.java:231)",
            "org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler.<init>(ReencryptionHandler.java:246)",
            "org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager.<init>(EncryptionZoneManager.java:250)",
            "org.apache.hadoop.hdfs.server.namenode.FSDirectory.<init>(FSDirectory.java:411)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:977)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.reencrypt.throttle.limit.updater.ratio": "0.00"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-123"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA",
        "testMethod": "testHarUriWithHaUriWithNoPort",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort(TestHarFileSystemWithHA.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort$$CONFUZZ(TestHarFileSystemWithHA.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.read.shortcircuit": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-171"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestPread",
        "testMethod": "testPreadLocalFS",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209)",
            "org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56)",
            "org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210)",
            "org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124)",
            "org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117)",
            "org.apache.hadoop.hdfs.TestPread.writeFile(TestPread.java:96)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS(TestPread.java:503)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS$$CONFUZZ(TestPread.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.stream-buffer-size": "1686491479",
            "file.bytes-per-checksum": "1107160090"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleDatanodes",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleDatanodes(TestSortLocatedBlock.java:197)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.heartbeat.interval": "151",
            "dfs.namenode.stale.datanode.minimum.interval": "720"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testCrashBetweenSyncLogAndPersistPaxosData",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=1569269103 < max=1466230894 for QueuedThreadPool[qtp945370867]@385936f3{STARTED,8<=8<=1466230894,i=8,r=-1,q=0}[ReservedThreadExecutor@5722c149{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.edit.log.transfer.bandwidthPerSec": "487",
            "dfs.ha.tail-edits.qjm.rpc.max-txns": "30346",
            "ipc.0.backoff.enable": "false",
            "ipc.server.read.threadpool.size": "9305",
            "ipc.client.connect.max.retries.on.timeouts": "1979084840",
            "hadoop.ssl.keystores.factory.class": "org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory",
            "dfs.qjm.operations.timeout": "6137s",
            "ipc.client.connection.idle-scan-interval.ms": "768567183",
            "dfs.namenode.edits.noeditlogchannelflush": "true",
            "hadoop.http.selector.count": "1569259701",
            "rpc.metrics.timeunit": "SECONDS",
            "hadoop.http.authentication.token.validity": "566155384"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-12"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystem",
        "testMethod": "testHAStateInNamespaceInfo",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystem.testHAStateInNamespaceInfo(TestFSNamesystem.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystem.testHAStateInNamespaceInfo$$CONFUZZ(TestFSNamesystem.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.read.considerLoad": "false",
            "dfs.lock.suppress.warning.interval": "59s",
            "dfs.use.dfs.network.topology": "false",
            "dfs.namenode.maintenance.replication.min": "683850693",
            "dfs.namenode.resource.check.interval": "15789",
            "dfs.datanode.peer.stats.enabled": "false",
            "dfs.namenode.fs-limits.max-blocks-per-file": "19814",
            "dfs.block.invalidate.limit": "318",
            "dfs.namenode.hosts.provider.classname": "org.apache.hadoop.hdfs.server.blockmanagement.CombinedHostFileManager",
            "dfs.replication": "583",
            "dfs.namenode.snapshot.skiplist.max.levels": "287831635",
            "dfs.client.block.write.replace-datanode-on-failure.enable": "true",
            "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]",
            "hadoop.caller.context.max.size": "1239761330",
            "dfs.namenode.audit.log.async": "false",
            "dfs.namenode.top.windows.minutes": "556,4723323,538836",
            "dfs.namenode.write-lock-reporting-threshold-ms": "308",
            "dfs.namenode.avoid.read.stale.datanode": "true",
            "dfs.namenode.startup": "REGULAR",
            "dfs.storage.policy.enabled": "false",
            "dfs.storage.policy.permissions.superuser-only": "false",
            "dfs.namenode.list.cache.pools.num.responses": "1213990387",
            "ssl.client.truststore.location": "",
            "dfs.namenode.lease-recheck-interval-ms": "14481",
            "dfs.namenode.ec.userdefined.policy.allowed": "false",
            "dfs.checksum.type": "CRC32C",
            "dfs.namenode.stale.datanode.minimum.interval": "973",
            "dfs.namenode.ec.policies.max.cellsize": "10502",
            "ssl.client.truststore.type": "jks",
            "hadoop.security.groups.cache.background.reload.threads": "32",
            "dfs.hosts.exclude": "",
            "dfs.namenode.replication.min": "181",
            "dfs.content-summary.sleep-microsec": "5889",
            "dfs.provided.storage.id": "DS-PROVIDED",
            "dfs.namenode.acls.enabled": "true",
            "net.topology.script.number.args": "23251",
            "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback",
            "dfs.namenode.fslock.fair": "false",
            "dfs.permissions.enabled": "false",
            "hadoop.ssl.keystores.factory.class": "org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory",
            "dfs.permissions.ContentSummary.subAccess": "false",
            "hadoop.security.groups.cache.warn.after.ms": "10980",
            "dfs.namenode.stale.datanode.interval": "324",
            "dfs.namenode.lazypersist.file.scrub.interval.sec": "805",
            "hadoop.security.auth_to_local.mechanism": "MIT",
            "dfs.namenode.blockreport.max.lock.hold.time": "22600",
            "dfs.namenode.provided.enabled": "true",
            "dfs.namenode.safemode.min.datanodes": "856362901",
            "hadoop.ssl.enabled.protocols": "TLSv1.2",
            "dfs.namenode.snapshot.skip.capture.accesstime-only-change": "false",
            "dfs.replication.max": "687",
            "dfs.namenode.read-lock-reporting-threshold-ms": "1933823618",
            "fs.trash.interval": "1493",
            "dfs.datanode.https.address": "0.0.0.0:9865",
            "dfs.ha.standby.checkpoints": "false",
            "dfs.block.placement.ec.classname": "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant",
            "dfs.namenode.replqueue.threshold-pct": "0.26422828435897827",
            "dfs.namenode.enable.log.stale.datanode": "true",
            "dfs.block.access.token.enable": "false",
            "dfs.blocksize": "143",
            "hadoop.security.dns.log-slow-lookups.enabled": "false",
            "dfs.datanode.fileio.profiling.sampling.percentage": "14971",
            "dfs.namenode.edekcacheloader.initial.delay.ms": "560",
            "dfs.ls.limit": "883719821",
            "dfs.namenode.write.stale.datanode.ratio": "1.0f",
            "dfs.encrypt.data.transfer": "false",
            "io.file.buffer.size": "32252",
            "dfs.namenode.max-lock-hold-to-release-lease-ms": "29883",
            "dfs.corruptfilesreturned.max": "14300",
            "dfs.namenode.xattrs.enabled": "false",
            "dfs.client-write-packet-size": "3288",
            "dfs.namenode.checkpoint.txns": "31348",
            "dfs.namenode.corrupt.block.delete.immediately.enabled": "false",
            "dfs.protected.subdirectories.enable": "true",
            "dfs.namenode.list.openfiles.num.responses": "157",
            "dfs.namenode.safemode.threshold-pct": "0.26803940534591675",
            "dfs.hosts": "",
            "dfs.namenode.block-placement-policy.default.prefer-local-node": "false",
            "dfs.namenode.replication.max-streams": "190",
            "dfs.namenode.caching.enabled": "true",
            "dfs.namenode.quota.init-threads": "521",
            "hadoop.security.key.provider.path": "",
            "dfs.namenode.file.close.num-committed-allowed": "75",
            "dfs.quota.by.storage.type.enabled": "false",
            "dfs.namenode.reconstruction.pending.timeout-sec": "31030",
            "dfs.namenode.replication.work.multiplier.per.iteration": "12765",
            "dfs.namenode.lock.detailed-metrics.enabled": "false",
            "dfs.namenode.delegation.token.renew-interval": "649",
            "dfs.namenode.retrycache.heap.percent": "0.9f",
            "hadoop.security.dns.log-slow-lookups.threshold.ms": "358",
            "dfs.namenode.reject-unresolved-dn-topology-mapping": "true",
            "hadoop.security.authentication": "kerberos",
            "dfs.namenode.max-corrupt-file-blocks-returned": "1968657862",
            "dfs.namenode.replication.max-streams-hard-limit": "11883",
            "dfs.namenode.top.num.users": "202",
            "hadoop.security.token.service.use_ip": "false",
            "hadoop.kerberos.min.seconds.before.relogin": "1657223448",
            "dfs.namenode.edekcacheloader.interval.ms": "16430",
            "ssl.client.stores.reload.interval": "495639355",
            "dfs.namenode.fs-limits.max-xattrs-per-inode": "5345",
            "dfs.namenode.edit.log.autoroll.multiplier.threshold": "-0.33380961418151855",
            "dfs.namenode.edit.log.autoroll.check.interval.ms": "593080665",
            "dfs.namenode.top.window.num.buckets": "23535",
            "dfs.namenode.max-num-blocks-to-log": "302",
            "dfs.namenode.retrycache.expirytime.millis": "1112412301",
            "dfs.namenode.snapshot.max.limit": "821",
            "hadoop.ssl.client.conf": "ssl-client.xml",
            "dfs.namenode.max.slowpeer.collect.nodes": "4599",
            "dfs.content-summary.limit": "762412041",
            "dfs.namenode.fs-limits.max-component-length": "4437",
            "dfs.namenode.enable.retrycache": "false",
            "hadoop.security.groups.cache.background.reload": "false",
            "dfs.namenode.posix.acl.inheritance.enabled": "false",
            "dfs.datanode.outliers.report.interval": "10504h",
            "hadoop.user.group.static.mapping.overrides": "dr.who=;",
            "dfs.datanode.ipc.address": "0.0.0.0:9867",
            "dfs.bytes-per-checksum": "6085",
            "dfs.namenode.max.objects": "2127861269",
            "dfs.namenode.read.considerStorageType": "false",
            "dfs.namenode.path.based.cache.retry.interval.ms": "788370123",
            "dfs.block.misreplication.processing.limit": "29612",
            "dfs.client.block.write.replace-datanode-on-failure.policy": "NEVER",
            "hadoop.ssl.hostname.verifier": "STRICT",
            "dfs.storage.policy.satisfier.mode": "external",
            "dfs.namenode.tolerate.heartbeat.multiplier": "13571",
            "hadoop.security.groups.negative-cache.secs": "292",
            "hadoop.caller.context.enabled": "false",
            "dfs.namenode.audit.log.token.tracking.id": "false",
            "ssl.client.keystore.type": "jks",
            "dfs.permissions.superusergroup": "mpfwqgsflobicqxgruzlxouslgbklpbllreqvtebqxdootcftfbvzakokobkoljxnnloyfcidpevmgroup",
            "dfs.namenode.path.based.cache.refresh.interval.ms": "23203",
            "dfs.namenode.safemode.replication.min": "308130438",
            "dfs.namenode.fs-limits.max-directory-items": "4423431",
            "dfs.namenode.snapshot.skiplist.interval": "21171",
            "dfs.namenode.safemode.extension": "678",
            "dfs.namenode.full.block.report.lease.length.ms": "24465",
            "dfs.heartbeat.interval": "496",
            "dfs.namenode.delegation.token.always-use": "false",
            "dfs.namenode.redundancy.interval.seconds": "621",
            "dfs.namenode.list.reencryption.status.num.responses": "411616124",
            "dfs.datanode.http.address": "0.0.0.0:9864",
            "dfs.permissions.allow.owner.set.quota": "false",
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1585230118"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-125"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testUnreachableObserverWithMultiple",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<namenode[2].test:8020> but was:<namenode[3].test:8020>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.assertHandledBy(TestObserverReadProxyProvider.java:336)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testUnreachableObserverWithMultiple(TestObserverReadProxyProvider.java:193)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testUnreachableObserverWithMultiple$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.random.order": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-11"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestDFSMkdirs",
        "testMethod": "testMkdirRpcNonCanonicalPath",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:152)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSMkdirs.testMkdirRpcNonCanonicalPath(TestDFSMkdirs.java:138)",
            "org.apache.hadoop.hdfs.TestDFSMkdirs.testMkdirRpcNonCanonicalPath$$CONFUZZ(TestDFSMkdirs.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1120636424",
            "hadoop.http.selector.count": "732159788"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testGetBlockLocationConsiderStorageTypeAndLoad",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<IP-[0-1]> but was:<IP-[2-4]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderStorageTypeAndLoad(TestDatanodeManager.java:823)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testGetBlockLocationConsiderStorageTypeAndLoad$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.stale.datanode.interval": "98",
            "dfs.heartbeat.interval": "1991920600",
            "dfs.block.invalidate.limit": "390133698",
            "dfs.namenode.stale.datanode.minimum.interval": "1916456597"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-29"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testListEncryptionZonesWithSnapshots",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler$ReencryptionBatch.<init>(ReencryptionHandler.java:488)",
            "org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler.<init>(ReencryptionHandler.java:248)",
            "org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager.<init>(EncryptionZoneManager.java:250)",
            "org.apache.hadoop.hdfs.server.namenode.FSDirectory.<init>(FSDirectory.java:411)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:977)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.reencrypt.batch.size": "1262602843",
            "dfs.namenode.blockreport.queue.size": "1329170972"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-167"
        ],
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs",
        "testMethod": "testNameEditsConfigsFailure",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure(TestNameEditsConfigs.java:450)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure$$CONFUZZ(TestNameEditsConfigs.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "383819019"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testgoodScript",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Expected: is \"IP-4\"     but: was \"IP-2\"",
        "stackTrace": [
            "org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)",
            "org.junit.Assert.assertThat(Assert.java:964)",
            "org.junit.Assert.assertThat(Assert.java:930)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.HelperFunction(TestDatanodeManager.java:443)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testgoodScript(TestDatanodeManager.java:322)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testgoodScript$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.avoid.read.stale.datanode": "true",
            "dfs.namenode.stale.datanode.minimum.interval": "170992440",
            "dfs.namenode.stale.datanode.interval": "5",
            "dfs.heartbeat.interval": "2134810349"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-189"
        ],
        "testClass": "org.apache.hadoop.hdfs.TestPread",
        "testMethod": "testPreadLocalFS",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209)",
            "org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56)",
            "org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210)",
            "org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124)",
            "org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117)",
            "org.apache.hadoop.hdfs.TestPread.writeFile(TestPread.java:96)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS(TestPread.java:503)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS$$CONFUZZ(TestPread.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1616848183",
            "io.file.buffer.size": "1587007752"
        }
    }
]
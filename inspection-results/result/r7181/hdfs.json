[
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDataTransferProtocol",
        "testMethod": "testDataTransferProtocol",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol(TestDataTransferProtocol.java:346)",
            "org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol$$CONFUZZ(TestDataTransferProtocol.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "34559"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "the minimum size of a bucket is 1 ms",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:229)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "402778112"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testBlocksAddedBeforeStandbyRestart",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "1023"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testFileChecksumAfterDecommission",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "10849"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testDecommissionWithBusyNode",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "the minimum size of a bucket is 1 ms",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:229)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "648644906"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "16814"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "the minimum size of a bucket is 1 ms",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:229)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "97265467"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestLeaseRecovery",
        "testMethod": "testLeaseRecoveryAndAppendWithViewDFS",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppend(TestLeaseRecovery.java:309)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS(TestLeaseRecovery.java:304)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS$$CONFUZZ(TestLeaseRecovery.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testBlockAllocationAdjustsUsageConservatively",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestQuota.restartCluster(TestQuota.java:122)",
            "org.apache.hadoop.hdfs.TestQuota.setUpClass(TestQuota.java:107)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "713"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot",
        "testMethod": "testOpenFileWritingAcrossSnapDeletion",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "the minimum size of a bucket is 1 ms",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:229)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot.setup(TestOpenFilesWithSnapshot.java:70)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "1333911552"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testUMaskDefaultAclNewFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "28882"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:95)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "27676"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "615"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "the minimum size of a bucket is 1 ms",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:229)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "971104680"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testCompleteEmptyUploadID",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "649"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testFavoredNodesEndToEndForAppend",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "the minimum size of a bucket is 1 ms",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:229)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.setUpBeforeClass(TestFavoredNodesEndToEnd.java:71)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "67110152"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement",
        "testMethod": "testInvalidateBlock",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "the minimum size of a bucket is 1 ms",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:229)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock(TestStandbyBlockManagement.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock$$CONFUZZ(TestStandbyBlockManagement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "491263"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement",
        "testMethod": "testInvalidateBlock",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock(TestStandbyBlockManagement.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock$$CONFUZZ(TestStandbyBlockManagement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDataTransferProtocol",
        "testMethod": "testDataTransferProtocol",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 191619180000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol(TestDataTransferProtocol.java:346)",
            "org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol$$CONFUZZ(TestDataTransferProtocol.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "3193653,42695,9152757"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 343391700000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "865,4,5723195"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testBlocksAddedBeforeStandbyRestart",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 20763840000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "346064,28,2"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testFileSmallerThanOneStripe",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 1326372240000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "22106204,5476,9"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testFileChecksumAfterDecommission",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 54426000000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "3,4856,907100"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testDecommissionWithBusyNode",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 35350320000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "78,589172,44"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 2313480000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:369)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:184)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "38558,5787868,153"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestLeaseRecovery",
        "testMethod": "testLeaseRecoveryAndAppendWithViewDFS",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 87284040000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppend(TestLeaseRecovery.java:309)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS(TestLeaseRecovery.java:304)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS$$CONFUZZ(TestLeaseRecovery.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "1454734,7263243,6"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testWriteReadAndDeleteHalfABlock",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 38020560000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestHDFSFileSystemContract.setUp(TestHDFSFileSystemContract.java:46)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "54,633676,993"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testBlockAllocationAdjustsUsageConservatively",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 218599860000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestQuota.restartCluster(TestQuota.java:122)",
            "org.apache.hadoop.hdfs.TestQuota.setUpClass(TestQuota.java:107)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "3,3361,3643331"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory",
        "testMethod": "testReleaseOnFileDeletion",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 2331979020000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.LazyPersistTestCase.startUpCluster(LazyPersistTestCase.java:348)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.LazyPersistTestCase$ClusterWithRamDiskBuilder.build(LazyPersistTestCase.java:447)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory.testReleaseOnFileDeletion(TestLazyPersistLockedMemory.java:87)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory.testReleaseOnFileDeletion$$CONFUZZ(TestLazyPersistLockedMemory.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "38866317,91444,5"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractOpen",
        "testMethod": "testFsIsEncrypted",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 3198537240000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractOpen.createCluster(TestHDFSContractOpen.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "20,961,53308954"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testAbortUnknownUpload",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 217721580000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "3628693,37184873,747"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testUMaskDefaultAclNewFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 20893740000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "1,2,348229"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testStat",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 3302679660000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "55044661,6,14155"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 564570360000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:95)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "9409506,1370,27404"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 30404040000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "57,506734,985472"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 327194940000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "5,1330,5453249"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement",
        "testMethod": "testInvalidateBlock",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 5757137040000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock(TestStandbyBlockManagement.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock$$CONFUZZ(TestStandbyBlockManagement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "95952284,871,48"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsckReplicaDetails",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Out of range: 2468820000",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:205)",
            "org.apache.hadoop.thirdparty.com.google.common.primitives.Ints.checkedCast(Ints.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.top.TopConf.<init>(TopConf.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:982)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckReplicaDetails(TestFsck.java:945)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckReplicaDetails$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "41147,5463,96983518"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDataTransferProtocol",
        "testMethod": "testDataTransferProtocol",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol(TestDataTransferProtocol.java:346)",
            "org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol$$CONFUZZ(TestDataTransferProtocol.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testBlocksAddedBeforeStandbyRestart",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testFileSmallerThanOneStripe",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:369)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:184)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestLeaseRecovery",
        "testMethod": "testLeaseRecoveryAndAppendWithViewDFS",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppend(TestLeaseRecovery.java:309)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS(TestLeaseRecovery.java:304)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS$$CONFUZZ(TestLeaseRecovery.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.permission.TestStickyBit",
        "testMethod": "testMovingFiles",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.permission.TestStickyBit.initCluster(TestStickyBit.java:79)",
            "org.apache.hadoop.fs.permission.TestStickyBit.init(TestStickyBit.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testWriteReadAndDeleteHalfABlock",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestHDFSFileSystemContract.setUp(TestHDFSFileSystemContract.java:46)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testBlockAllocationAdjustsUsageConservatively",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestQuota.restartCluster(TestQuota.java:122)",
            "org.apache.hadoop.hdfs.TestQuota.setUpClass(TestQuota.java:107)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory",
        "testMethod": "testReleaseOnFileDeletion",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.LazyPersistTestCase.startUpCluster(LazyPersistTestCase.java:348)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.LazyPersistTestCase$ClusterWithRamDiskBuilder.build(LazyPersistTestCase.java:447)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory.testReleaseOnFileDeletion(TestLazyPersistLockedMemory.java:87)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory.testReleaseOnFileDeletion$$CONFUZZ(TestLazyPersistLockedMemory.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot",
        "testMethod": "testOpenFileWritingAcrossSnapDeletion",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot.setup(TestOpenFilesWithSnapshot.java:70)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractOpen",
        "testMethod": "testFsIsEncrypted",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractOpen.createCluster(TestHDFSContractOpen.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFS",
        "testMethod": "testECPolicyCommands",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testECPolicyCommands(TestWebHDFS.java:1695)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testECPolicyCommands$$CONFUZZ(TestWebHDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testRemoveXAttr",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.setup(TestRetryCacheWithHA.java:149)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.viewfs.TestViewFsLinkFallback",
        "testMethod": "testMkdirShouldCreateParentDirInFallbackWhenMountDirExist",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.viewfs.TestViewFsLinkFallback.clusterSetupAtBeginning(TestViewFsLinkFallback.java:79)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS",
        "testMethod": "testBasicOperationsRootDir",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.setup(TestEncryptionZonesWithKMS.java:64)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testUMaskDefaultAclNewFile",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testStat",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntries",
        "failure": "java.io.IOException",
        "errorMessage": "The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.support.allow.format": "false"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournal",
        "failure": "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal#testStatisticsForErasureCodingRead",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "1125603642"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournalCommonDirAcrossNameSpace",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "1544764540"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testReaderWhileAnotherWrites",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "1775512936"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeRespectsBindHostKeys",
        "testMethod": "testRpcBindHostKey",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeRespectsBindHostKeys.testRpcBindHostKey(TestJournalNodeRespectsBindHostKeys.java:95)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeRespectsBindHostKeys.testRpcBindHostKey$$CONFUZZ(TestJournalNodeRespectsBindHostKeys.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "1270444141"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testInProgressRecovery",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "1094878295"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame",
        "testMethod": "testNameNodeXFrameOptionsDisabled",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:152)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.createServerwithXFrame(TestNameNodeHttpServerXFrame.java:92)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.testNameNodeXFrameOptionsDisabled(TestNameNodeHttpServerXFrame.java:68)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.testNameNodeXFrameOptionsDisabled$$CONFUZZ(TestNameNodeHttpServerXFrame.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "2041938680"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.TestDFSMkdirs",
        "testMethod": "testMkdirRpcNonCanonicalPath",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:152)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSMkdirs.testMkdirRpcNonCanonicalPath(TestDFSMkdirs.java:138)",
            "org.apache.hadoop.hdfs.TestDFSMkdirs.testMkdirRpcNonCanonicalPath$$CONFUZZ(TestDFSMkdirs.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "1618743415"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.TestFileCreation",
        "testMethod": "testServerDefaultsWithMinimalCaching",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:152)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithMinimalCaching(TestFileCreation.java:251)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithMinimalCaching$$CONFUZZ(TestFileCreation.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "1350209443"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint",
        "testMethod": "testSecondaryPurgesEditLogs",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:152)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryPurgesEditLogs(TestCheckpoint.java:2264)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryPurgesEditLogs$$CONFUZZ(TestCheckpoint.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "1357095905"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique",
        "testMethod": "testSingleThreaded",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique.testSingleThreaded(TestEpochsAreUnique.java:54)",
            "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique.testSingleThreaded$$CONFUZZ(TestEpochsAreUnique.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "978934948"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore",
        "testMethod": "testStorageRestoreFailure",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:152)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testStorageRestoreFailure(TestStorageRestore.java:397)",
            "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testStorageRestoreFailure$$CONFUZZ(TestStorageRestore.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "2139094974"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testOutOfSyncAtBeginningOfSegment0",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "1622700348"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testChangeWritersLogsInSync",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "821118571"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-10",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournalNodeSyncwithFederationTypeIncorrectConfigWithNamenodeId",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "1972669416"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournal",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=769 < max=200 for QueuedThreadPool[qtp37316493]@239678d{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@63214338{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger",
        "testMethod": "testMetricsLoggerOnByDefault",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=29112 < max=200 for QueuedThreadPool[qtp1326993328]@4f184fb0{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6fd076ac{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger$TestNameNode.<init>(TestNameNodeMetricsLogger.java:138)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.makeNameNode(TestNameNodeMetricsLogger.java:118)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault(TestNameNodeMetricsLogger.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault$$CONFUZZ(TestNameNodeMetricsLogger.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "29110"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testReaderWhileAnotherWrites",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=769 < max=200 for QueuedThreadPool[qtp252854626]@f124162{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6aa4f45{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeRespectsBindHostKeys",
        "testMethod": "testRpcBindHostKey",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=769 < max=200 for QueuedThreadPool[qtp631292424]@25a0c208{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@41019f9d{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeRespectsBindHostKeys.testRpcBindHostKey(TestJournalNodeRespectsBindHostKeys.java:95)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeRespectsBindHostKeys.testRpcBindHostKey$$CONFUZZ(TestJournalNodeRespectsBindHostKeys.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame",
        "testMethod": "testNameNodeXFrameOptionsDisabled",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=31061 < max=7231 for QueuedThreadPool[qtp1147765156]@446981a4{STARTED,8<=8<=7231,i=8,r=-1,q=0}[ReservedThreadExecutor@67e21ea2{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.createServerwithXFrame(TestNameNodeHttpServerXFrame.java:92)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.testNameNodeXFrameOptionsDisabled(TestNameNodeHttpServerXFrame.java:68)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.testNameNodeXFrameOptionsDisabled$$CONFUZZ(TestNameNodeHttpServerXFrame.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "31059"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSMkdirs",
        "testMethod": "testMkdirRpcNonCanonicalPath",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=34307 < max=200 for QueuedThreadPool[qtp578763703]@227f3bb7{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@23d8de33{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSMkdirs.testMkdirRpcNonCanonicalPath(TestDFSMkdirs.java:138)",
            "org.apache.hadoop.hdfs.TestDFSMkdirs.testMkdirRpcNonCanonicalPath$$CONFUZZ(TestDFSMkdirs.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "34305"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournalNodeSyncerNotStartWhenSyncEnabledIncorrectURI",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=2082 < max=200 for QueuedThreadPool[qtp2038827813]@79860b25{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@4e0b9055{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "2080"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFS",
        "testMethod": "testWebHdfsAllowandDisallowSnapshots",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=10536 < max=200 for QueuedThreadPool[qtp862307347]@3365c413{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@5cf8a5c9{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testWebHdfsAllowandDisallowSnapshots(TestWebHDFS.java:531)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testWebHdfsAllowandDisallowSnapshots$$CONFUZZ(TestWebHDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "10534"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint",
        "testMethod": "testSecondaryPurgesEditLogs",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=559361 < max=200 for QueuedThreadPool[qtp1784383452]@6a5b87dc{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@24da3c3b{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryPurgesEditLogs(TestCheckpoint.java:2264)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryPurgesEditLogs$$CONFUZZ(TestCheckpoint.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "559359"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique",
        "testMethod": "testSingleThreaded",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=11255 < max=200 for QueuedThreadPool[qtp258647562]@f6aa60a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@26b85fcf{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique.testSingleThreaded(TestEpochsAreUnique.java:54)",
            "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique.testSingleThreaded$$CONFUZZ(TestEpochsAreUnique.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "11253"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFS",
        "testMethod": "testContentSummary",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=8238 < max=200 for QueuedThreadPool[qtp832371320]@319cfa78{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@407ed4ce{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testContentSummary(TestWebHDFS.java:992)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testContentSummary$$CONFUZZ(TestWebHDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "8236"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournalNodeStartupFailsCleanly",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=769 < max=200 for QueuedThreadPool[qtp1427796259]@551a7123{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@16ae647d{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean",
        "testMethod": "testNNDirectorySize",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=6084 < max=200 for QueuedThreadPool[qtp1205449517]@47d9b32d{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@2a7554df{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testNNDirectorySize(TestNameNodeMXBean.java:806)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testNNDirectorySize$$CONFUZZ(TestNameNodeMXBean.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "6082"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileCreation",
        "testMethod": "testServerDefaultsWithCaching",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=31184 < max=200 for QueuedThreadPool[qtp1486725930]@589da32a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@26669943{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithCaching(TestFileCreation.java:199)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithCaching$$CONFUZZ(TestFileCreation.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "31182"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testPurgeLogs",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=769 < max=200 for QueuedThreadPool[qtp429135896]@19941818{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@1a61a2c4{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testOutOfSyncAtBeginningOfSegment0",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=3804 < max=200 for QueuedThreadPool[qtp881048360]@3483bb28{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@113b0382{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "3802"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testChangeWritersLogsInSync",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=58753793 < max=200 for QueuedThreadPool[qtp449266841]@1ac74499{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@96b3034{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "58753791"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournalNodeSyncwithFederationTypeIncorrectConfigWithNamenodeId",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=4491425 < max=200 for QueuedThreadPool[qtp679279260]@287cfa9c{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@2ca307d3{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "4491423"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint",
        "testMethod": "testCheckpointTriggerOnTxnCount",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=31550 < max=200 for QueuedThreadPool[qtp277434670]@1089512e{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@3fd127e6{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testCheckpointTriggerOnTxnCount(TestCheckpoint.java:2176)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testCheckpointTriggerOnTxnCount$$CONFUZZ(TestCheckpoint.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "31548"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testSelectViaRpcAfterJNRestart",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=8788 < max=200 for QueuedThreadPool[qtp551484395]@20defbeb{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@56a70784{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.acceptor.count": "8786"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournal",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournalCommonDirAcrossNameSpace",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestLeaseRecovery",
        "testMethod": "testLeaseRecoveryAndAppendWithViewDFS",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppend(TestLeaseRecovery.java:309)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS(TestLeaseRecovery.java:304)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS$$CONFUZZ(TestLeaseRecovery.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testBlockAllocationAdjustsUsageConservatively",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestQuota.restartCluster(TestQuota.java:122)",
            "org.apache.hadoop.hdfs.TestQuota.setUpClass(TestQuota.java:107)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger",
        "testMethod": "testMetricsLoggerOnByDefault",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger$TestNameNode.<init>(TestNameNodeMetricsLogger.java:138)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.makeNameNode(TestNameNodeMetricsLogger.java:118)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault(TestNameNodeMetricsLogger.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault$$CONFUZZ(TestNameNodeMetricsLogger.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testUMaskDefaultAclNewFile",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:95)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testCompleteEmptyUploadID",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testFavoredNodesEndToEndForAppend",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.setUpBeforeClass(TestFavoredNodesEndToEnd.java:71)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace",
        "testMethod": "testSaveNamespaceWithRenamedLease",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease(TestSaveNamespace.java:622)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease$$CONFUZZ(TestSaveNamespace.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testInProgressRecovery",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testGetAclStatusRequiresTraverseOrSuper",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame",
        "testMethod": "testNameNodeXFrameOptionsDisabled",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.createServerwithXFrame(TestNameNodeHttpServerXFrame.java:92)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.testNameNodeXFrameOptionsDisabled(TestNameNodeHttpServerXFrame.java:68)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.testNameNodeXFrameOptionsDisabled$$CONFUZZ(TestNameNodeHttpServerXFrame.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesOnlyAccess",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMinimal",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testRootDirEZTrash",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "javax.servlet.ServletException",
        "errorMessage": "Keytab does not exist: /home/ctestfuzz/hadoop.keytab",
        "stackTrace": [
            "org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler.init(KerberosAuthenticationHandler.java:156)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.initializeAuthHandler(AuthenticationFilter.java:194)",
            "org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(AuthenticationFilter.java:180)",
            "org.apache.hadoop.security.authentication.server.ProxyUserAuthenticationFilter.init(ProxyUserAuthenticationFilter.java:57)",
            "org.eclipse.jetty.servlet.FilterHolder.initialize(FilterHolder.java:140)",
            "org.eclipse.jetty.servlet.ServletHandler.lambda$initialize$0(ServletHandler.java:731)",
            "java.base/java.util.Spliterators$ArraySpliterator.forEachRemaining(Spliterators.java:948)",
            "java.base/java.util.stream.Streams$ConcatSpliterator.forEachRemaining(Streams.java:734)",
            "java.base/java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:658)",
            "org.eclipse.jetty.servlet.ServletHandler.initialize(ServletHandler.java:755)",
            "org.eclipse.jetty.servlet.ServletContextHandler.startContext(ServletContextHandler.java:379)",
            "org.eclipse.jetty.server.handler.ContextHandler.doStart(ContextHandler.java:910)",
            "org.eclipse.jetty.servlet.ServletContextHandler.doStart(ServletContextHandler.java:288)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:117)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.server.Server.start(Server.java:423)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.handler.AbstractHandler.doStart(AbstractHandler.java:97)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:387)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.initCluster(FSXAttrBaseTest.java:1377)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.init(FSXAttrBaseTest.java:109)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.type": "kerberos"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournal",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.<init>(JournalNodeRpcServer.java:101)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:242)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "810024962"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testSelectViaRpcWithoutDurableTransactions",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.<init>(JournalNodeRpcServer.java:101)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:242)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "1505813083"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger",
        "testMethod": "testMetricsLoggerOnByDefault",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger$TestNameNode.<init>(TestNameNodeMetricsLogger.java:138)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.makeNameNode(TestNameNodeMetricsLogger.java:118)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault(TestNameNodeMetricsLogger.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault$$CONFUZZ(TestNameNodeMetricsLogger.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "302317823"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace",
        "testMethod": "testSaveNamespaceWithRenamedLease",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease(TestSaveNamespace.java:622)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease$$CONFUZZ(TestSaveNamespace.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "2130640638"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testInProgressRecovery",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.<init>(JournalNodeRpcServer.java:101)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:242)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "796950401"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultMinimalAclNewFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "304103406"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS",
        "testMethod": "testRead",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead(TestBlockTokenWithDFS.java:357)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead$$CONFUZZ(TestBlockTokenWithDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "270010914"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer",
        "testMethod": "testBalancer0Integrity",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:681)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:642)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:636)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.oneNodeTest(TestBalancer.java:953)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testBalancer0Internal(TestBalancer.java:1068)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Integrity(TestBalancerWithSaslDataTransfer.java:34)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Integrity$$CONFUZZ(TestBalancerWithSaslDataTransfer.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "355635013"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.server.balancer.TestBalancer",
        "testMethod": "testUnknownDatanodeSimple",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.generateBlocks(TestBalancer.java:302)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanode(TestBalancer.java:998)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanodeSimple(TestBalancer.java:973)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanodeSimple$$CONFUZZ(TestBalancer.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "240553541"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier",
        "testMethod": "testWithKeytabs",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.startCluster(TestExternalStoragePolicySatisfier.java:211)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.createCluster(TestExternalStoragePolicySatisfier.java:194)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWhenStoragePolicySetToALLSSD(TestExternalStoragePolicySatisfier.java:453)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier$1.run(TestExternalStoragePolicySatisfier.java:311)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier$1.run(TestExternalStoragePolicySatisfier.java:307)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWithKeytabs(TestExternalStoragePolicySatisfier.java:307)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWithKeytabs$$CONFUZZ(TestExternalStoragePolicySatisfier.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "2147450881"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSecureNameNode",
        "testMethod": "testNameNodeStatusMXBeanSecurityEnabled",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSecureNameNode.testNameNodeStatusMXBeanSecurityEnabled(TestSecureNameNode.java:139)",
            "org.apache.hadoop.hdfs.server.namenode.TestSecureNameNode.testNameNodeStatusMXBeanSecurityEnabled$$CONFUZZ(TestSecureNameNode.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "2139588510"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFS",
        "testMethod": "testWebHdfsAllowandDisallowSnapshots",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testWebHdfsAllowandDisallowSnapshots(TestWebHDFS.java:531)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testWebHdfsAllowandDisallowSnapshots$$CONFUZZ(TestWebHDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "270045216"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks",
        "testMethod": "testSkewedRack2",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.DFSTestUtil.setupCluster(DFSTestUtil.java:2491)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.setupCluster(TestErasureCodingMultipleRacks.java:96)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2(TestErasureCodingMultipleRacks.java:131)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2$$CONFUZZ(TestErasureCodingMultipleRacks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "1963431348"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclMustBeOwnerOrSuper",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "268477954"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournalNodeStartupFailsCleanly",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.<init>(JournalNodeRpcServer.java:101)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:242)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "672444961"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.TestGenericRefresh",
        "testMethod": "testMultipleRegistration",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.TestGenericRefresh.setUpBeforeClass(TestGenericRefresh.java:60)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "1073776671"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testPurgeLogs",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.<init>(JournalNodeRpcServer.java:101)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:242)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "0"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournalNodeSyncwithFederationTypeIncorrectConfigWithNamenodeId",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.<init>(JournalNodeRpcServer.java:101)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:242)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "1391752709"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testRemoveAclEntriesMustBeOwnerOrSuper",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "2140147454"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-90",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testHttpServer",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.<init>(JournalNodeRpcServer.java:101)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:242)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.handler.queue.size": "1709725541"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "2h"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:369)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:184)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "879314729ms"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testBlockAllocationAdjustsUsageConservatively",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestQuota.restartCluster(TestQuota.java:122)",
            "org.apache.hadoop.hdfs.TestQuota.setUpClass(TestQuota.java:107)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "5847m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory",
        "testMethod": "testReleaseOnFileDeletion",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.LazyPersistTestCase.startUpCluster(LazyPersistTestCase.java:348)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.LazyPersistTestCase$ClusterWithRamDiskBuilder.build(LazyPersistTestCase.java:447)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory.testReleaseOnFileDeletion(TestLazyPersistLockedMemory.java:87)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistLockedMemory.testReleaseOnFileDeletion$$CONFUZZ(TestLazyPersistLockedMemory.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "99s"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger",
        "testMethod": "testMetricsLoggerOnByDefault",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger$TestNameNode.<init>(TestNameNodeMetricsLogger.java:138)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.makeNameNode(TestNameNodeMetricsLogger.java:118)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault(TestNameNodeMetricsLogger.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault$$CONFUZZ(TestNameNodeMetricsLogger.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "530717570m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFS",
        "testMethod": "testECPolicyCommands",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testECPolicyCommands(TestWebHDFS.java:1695)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testECPolicyCommands$$CONFUZZ(TestWebHDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "343s"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS",
        "testMethod": "testBasicOperationsRootDir",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.setup(TestEncryptionZonesWithKMS.java:64)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "89577717d"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:95)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "6466320h"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testCompleteEmptyUploadID",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "1d"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement",
        "testMethod": "testInvalidateBlock",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock(TestStandbyBlockManagement.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock$$CONFUZZ(TestStandbyBlockManagement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "096m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.fs.permission.TestStickyBit",
        "testMethod": "testStickyBitRecursiveDeleteFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.permission.TestStickyBit.initCluster(TestStickyBit.java:79)",
            "org.apache.hadoop.fs.permission.TestStickyBit.init(TestStickyBit.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "127509s"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testSetXAttrCaseSensitivity",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "4329867m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace",
        "testMethod": "testSaveNamespaceWithRenamedLease",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease(TestSaveNamespace.java:622)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease$$CONFUZZ(TestSaveNamespace.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "430m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations",
        "testMethod": "testFedSingleNN",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testFedSingleNN(TestDataNodeMultipleRegistrations.java:151)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testFedSingleNN$$CONFUZZ(TestDataNodeMultipleRegistrations.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "76m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsck",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck(TestFsck.java:218)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "586632s"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate",
        "testMethod": "testUpdateQuotaForAppend",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate.setUp(TestDiskspaceQuotaUpdate.java:76)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "4m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks",
        "testMethod": "testWithReplicationFactorAsOne",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne(TestProcessCorruptBlocks.java:168)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne$$CONFUZZ(TestProcessCorruptBlocks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "9387m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl",
        "testMethod": "testSetAclCustomMask",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl.init(TestNameNodeAcl.java:32)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "452677557h"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testRootDirEZTrash",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "533m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.initCluster(FSXAttrBaseTest.java:1377)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.init(FSXAttrBaseTest.java:109)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "72196ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "9528"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:369)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:184)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "25272"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS",
        "testMethod": "testBasicOperationsRootDir",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.setup(TestEncryptionZonesWithKMS.java:64)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "2130640638"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement",
        "testMethod": "testInvalidateBlock",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock(TestStandbyBlockManagement.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock$$CONFUZZ(TestStandbyBlockManagement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "9764"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace",
        "testMethod": "testSaveNamespaceWithRenamedLease",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease(TestSaveNamespace.java:622)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease$$CONFUZZ(TestSaveNamespace.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "383"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate",
        "testMethod": "testUpdateQuotaForAppend",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate.setUp(TestDiskspaceQuotaUpdate.java:76)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks",
        "testMethod": "testWithReplicationFactorAsOne",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne(TestProcessCorruptBlocks.java:168)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne$$CONFUZZ(TestProcessCorruptBlocks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "1152"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor",
        "testMethod": "testFileSmallerThanOneStripe",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "26220"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestExtendedAcls",
        "testMethod": "testRestrictAtSubDir",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestExtendedAcls.setup(TestExtendedAcls.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "17618"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testRootDirEZTrash",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "1344496590"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testDefaultAclRenamedDir",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testListEncryptionZonesWithSnapshots",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "9127"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal",
        "testMethod": "testStatisticsForErasureCodingRead",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal.testStatisticsForErasureCodingRead(TestBlockReaderLocal.java:822)",
            "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal.testStatisticsForErasureCodingRead$$CONFUZZ(TestBlockReaderLocal.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "36927"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.balancer.TestBalancer",
        "testMethod": "testUnknownDatanodeSimple",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.generateBlocks(TestBalancer.java:302)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanode(TestBalancer.java:998)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanodeSimple(TestBalancer.java:973)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanodeSimple$$CONFUZZ(TestBalancer.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "383"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.shell.TestHdfsTextCommand",
        "testMethod": "testDisplayForAvroFiles",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.shell.TestHdfsTextCommand.setUp(TestHdfsTextCommand.java:55)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "22120"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus",
        "testMethod": "testListFilesEmptyDirectoryRecursive",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus.createCluster(TestHDFSContractGetFileStatus.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "2384"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testSetXAttrPermission",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "287"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testBlockReadZeroByteFile",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek.createCluster(TestHDFSContractSeek.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "939217313"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileAppend2",
        "testMethod": "testSimpleAppend2",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileAppend2.testSimpleAppend2(TestFileAppend2.java:233)",
            "org.apache.hadoop.hdfs.TestFileAppend2.testSimpleAppend2$$CONFUZZ(TestFileAppend2.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "7"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testRecommission",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testRecommission(TestDecommission.java:435)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testRecommission$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "27938"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "1070492031"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:369)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:184)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "67141635"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestLeaseRecovery",
        "testMethod": "testLeaseRecoveryAndAppendWithViewDFS",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppend(TestLeaseRecovery.java:309)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS(TestLeaseRecovery.java:304)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS$$CONFUZZ(TestLeaseRecovery.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "2523"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testBlockAllocationAdjustsUsageConservatively",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestQuota.restartCluster(TestQuota.java:122)",
            "org.apache.hadoop.hdfs.TestQuota.setUpClass(TestQuota.java:107)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "117473663"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testAbortUnknownUpload",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "2147450878"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testUMaskDefaultAclNewFile",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "1023"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntries",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "1133561855"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:95)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "318874465"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "24681"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement",
        "testMethod": "testInvalidateBlock",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock(TestStandbyBlockManagement.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock$$CONFUZZ(TestStandbyBlockManagement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "255"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.permission.TestStickyBit",
        "testMethod": "testStickyBitRecursiveDeleteFile",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.permission.TestStickyBit.initCluster(TestStickyBit.java:79)",
            "org.apache.hadoop.fs.permission.TestStickyBit.init(TestStickyBit.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "1073875025"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testSetXAttrCaseSensitivity",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "32262"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations",
        "testMethod": "testFedSingleNN",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testFedSingleNN(TestDataNodeMultipleRegistrations.java:151)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testFedSingleNN$$CONFUZZ(TestDataNodeMultipleRegistrations.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "1695349847"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate",
        "testMethod": "testUpdateQuotaForAppend",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate.setUp(TestDiskspaceQuotaUpdate.java:76)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "9"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testTransferAndNativeCopyMetrics",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testTransferAndNativeCopyMetrics(TestFsDatasetImpl.java:1274)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testTransferAndNativeCopyMetrics$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "18208"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestFailoverWithBlockTokensEnabled",
        "testMethod": "testFailoverAfterRegistration",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestFailoverWithBlockTokensEnabled.startCluster(TestFailoverWithBlockTokensEnabled.java:73)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "669"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testSetAclMinimal",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "256"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl",
        "testMethod": "testSetAclCustomMask",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl.init(TestNameNodeAcl.java:32)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "1882"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor",
        "testMethod": "testFileSmallerThanOneStripe",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "Cannot start datanode because the configured max locked memory size (dfs.datanode.max.locked.memory) is greater than zero and native code is not available.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1374)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.max.locked.memory": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 134217728 < 1073791040        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy30.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy31.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.reset(TestSnapshotPathINodes.java:76)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "1073791040"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 512 < 1509983487 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy31.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:106)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "1509983487"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 8 < 1003 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy31.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy34.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testOpenFileWhenNNAndClientCrashAfterAddBlock(TestHASafeMode.java:848)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testOpenFileWhenNNAndClientCrashAfterAddBlock$$CONFUZZ(TestHASafeMode.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "1003"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testFavoredNodesEndToEndForAppend",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 4096 < 10088 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy31.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:522)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$7.doCall(DistributedFileSystem.java:519)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:541)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.testFavoredNodesEndToEndForAppend(TestFavoredNodesEndToEnd.java:175)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.testFavoredNodesEndToEndForAppend$$CONFUZZ(TestFavoredNodesEndToEnd.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "10088"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement",
        "testMethod": "testInvalidateBlock",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 134217728 < 871418914 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy29.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy30.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:902)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:924)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock(TestStandbyBlockManagement.java:72)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock$$CONFUZZ(TestStandbyBlockManagement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "871418914"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 134217728 < 919502527 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy31.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest$20.run(FSXAttrBaseTest.java:1182)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.testRawXAttrs(FSXAttrBaseTest.java:1178)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr.testRawXAttrs$$CONFUZZ(TestFileContextXAttr.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "919502527"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.balancer.TestBalancer",
        "testMethod": "testUnknownDatanodeSimple",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 100 < 23302 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.createFile(TestBalancer.java:292)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.generateBlocks(TestBalancer.java:310)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanode(TestBalancer.java:998)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanodeSimple(TestBalancer.java:973)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanodeSimple$$CONFUZZ(TestBalancer.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "23302"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testRename2",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 1024 < 2130640638 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy33.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy34.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA$Rename2Op.prepare(TestRetryCacheWithHA.java:542)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testClientRetryWithFailover(TestRetryCacheWithHA.java:1303)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testRename2(TestRetryCacheWithHA.java:1197)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testRename2$$CONFUZZ(TestRetryCacheWithHA.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "2130640638"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor",
        "testMethod": "testDecommissionTwoNodes",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 4194304 < 1117987521 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy33.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy34.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:902)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:924)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.writeStripedFile(TestDecommissionWithStriped.java:570)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testDecommission(TestDecommissionWithStriped.java:463)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testDecommissionTwoNodes(TestDecommissionWithStriped.java:202)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor.testDecommissionTwoNodes$$CONFUZZ(TestDecommissionWithStripedBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "1117987521"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testBlockReadZeroByteFile",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 1024 < 24178 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636)",
            "org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "24178"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks",
        "testMethod": "testSkewedRack2",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 134217728 < 1065385984 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy34.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy35.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:902)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2(TestErasureCodingMultipleRacks.java:138)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2$$CONFUZZ(TestErasureCodingMultipleRacks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "1065385984"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testCreateSymlink",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 1024 < 22552 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy33.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy34.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA$CreateSymlinkOp.prepare(TestRetryCacheWithHA.java:678)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testClientRetryWithFailover(TestRetryCacheWithHA.java:1303)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testCreateSymlink(TestRetryCacheWithHA.java:1218)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testCreateSymlink$$CONFUZZ(TestRetryCacheWithHA.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "22552"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileAppend2",
        "testMethod": "testSimpleAppend2",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 1024 < 9232 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy29.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy30.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.hdfs.AppendTestUtil.createFile(AppendTestUtil.java:195)",
            "org.apache.hadoop.hdfs.TestFileAppend2.testSimpleAppend2(TestFileAppend2.java:239)",
            "org.apache.hadoop.hdfs.TestFileAppend2.testSimpleAppend2$$CONFUZZ(TestFileAppend2.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "9232"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamUpdatePipeline",
        "testMethod": "testDFSStripedOutputStreamUpdatePipeline",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 1048576 < 303136769 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy29.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamUpdatePipeline.testDFSStripedOutputStreamUpdatePipeline(TestDFSStripedOutputStreamUpdatePipeline.java:46)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamUpdatePipeline.testDFSStripedOutputStreamUpdatePipeline$$CONFUZZ(TestDFSStripedOutputStreamUpdatePipeline.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "303136769"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testDu",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 1024 < 229119 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy30.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy31.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.TestDFSShell.writeFile(TestDFSShell.java:139)",
            "org.apache.hadoop.hdfs.TestDFSShell.testDu(TestDFSShell.java:254)",
            "org.apache.hadoop.hdfs.TestDFSShell.testDu$$CONFUZZ(TestDFSShell.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "229119"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testErrOutPut",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 1024 < 37748863 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy30.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy31.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.TestDFSShell.testErrOutPut(TestDFSShell.java:714)",
            "org.apache.hadoop.hdfs.TestDFSShell.testErrOutPut$$CONFUZZ(TestDFSShell.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "37748863"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractCreate",
        "testMethod": "testCreatedFileIsEventuallyVisible",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 1024 < 13018 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreatedFileIsEventuallyVisible(AbstractContractCreateTest.java:268)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractCreate.testCreatedFileIsEventuallyVisible$$CONFUZZ(TestHDFSContractCreate.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "13018"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDisableConnCache",
        "testMethod": "testDisableCache",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 134217728 < 1664876574 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy29.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy30.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.client.impl.BlockReaderTestUtil.writeFile(BlockReaderTestUtil.java:127)",
            "org.apache.hadoop.hdfs.TestDisableConnCache.testDisableCache(TestDisableConnCache.java:54)",
            "org.apache.hadoop.hdfs.TestDisableConnCache.testDisableCache$$CONFUZZ(TestDisableConnCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "1664876574"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testReadFullyZeroBytebufferPastEOF",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 1024 < 713685152 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636)",
            "org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "713685152"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testRemoveAclEntriesMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Specified block size is less than configured minimum value (dfs.namenode.fs-limits.min-block-size): 134217728 < 269651711 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2661) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner$1.close(WebHdfsFileSystem.java:1043)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testRemoveAclEntriesMustBeOwnerOrSuper(FSAclBaseTest.java:1342)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testRemoveAclEntriesMustBeOwnerOrSuper$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.min-block-size": "269651711"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "167948301"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot",
        "testMethod": "testOpenFileWritingAcrossSnapDeletion",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot.setup(TestOpenFilesWithSnapshot.java:70)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "68342161"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks",
        "testMethod": "testWithReplicationFactorAsOne",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne(TestProcessCorruptBlocks.java:168)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne$$CONFUZZ(TestProcessCorruptBlocks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "1065445696"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl",
        "testMethod": "testSetAclCustomMask",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl.init(TestNameNodeAcl.java:32)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "75678286"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.initCluster(FSXAttrBaseTest.java:1377)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.init(FSXAttrBaseTest.java:109)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "543195167"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testGetTrashRoots",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "1886433716"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamUpdatePipeline",
        "testMethod": "testDFSStripedOutputStreamUpdatePipeline",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamUpdatePipeline.testDFSStripedOutputStreamUpdatePipeline(TestDFSStripedOutputStreamUpdatePipeline.java:37)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamUpdatePipeline.testDFSStripedOutputStreamUpdatePipeline$$CONFUZZ(TestDFSStripedOutputStreamUpdatePipeline.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "555778329"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints",
        "testMethod": "testCheckpointSucceedsWithLegacyOIVException",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints.setupCluster(TestStandbyCheckpoints.java:103)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "121865728"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure",
        "testMethod": "testAddBlockWhenNoSufficientParityNumOfNodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailureBase.setup(TestDFSStripedOutputStreamWithFailureBase.java:208)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testAddBlockWhenNoSufficientParityNumOfNodes(TestDFSStripedOutputStreamWithFailure.java:209)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testAddBlockWhenNoSufficientParityNumOfNodes$$CONFUZZ(TestDFSStripedOutputStreamWithFailure.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "941662623"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot",
        "testMethod": "testXAttrForSnapshotRootAfterRemove",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot.initCluster(TestXAttrWithSnapshot.java:401)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot.init(TestXAttrWithSnapshot.java:78)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "1668223262"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.TestFileStatus",
        "testMethod": "testListStatusOnFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileStatus.testSetUp(TestFileStatus.java:70)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "2130640638"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.TestMultipleNNPortQOP",
        "testMethod": "testAuxiliaryPortSendingQOP",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestMultipleNNPortQOP.testAuxiliaryPortSendingQOP(TestMultipleNNPortQOP.java:96)",
            "org.apache.hadoop.hdfs.TestMultipleNNPortQOP.testAuxiliaryPortSendingQOP$$CONFUZZ(TestMultipleNNPortQOP.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "67666687"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-107",
        "testClass": "org.apache.hadoop.hdfs.TestFileStatus",
        "testMethod": "testGetFileInfo",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initIpcServer(DataNode.java:1027)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1424)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileStatus.testSetUp(TestFileStatus.java:70)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "471622094"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskErrorException",
        "errorMessage": "Too many failed volumes - current valid volumes: 1, volumes configured: 2, volumes failed: 1, volume failures tolerated: 0",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:233)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "23784",
            "dfs.datanode.disk.check.timeout": "097ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "22342"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:369)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:184)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "21282"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "28924"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testBlockAllocationAdjustsUsageConservatively",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestQuota.restartCluster(TestQuota.java:122)",
            "org.apache.hadoop.hdfs.TestQuota.setUpClass(TestQuota.java:107)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "202963243"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot",
        "testMethod": "testOpenFileWritingAcrossSnapDeletion",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot.setup(TestOpenFilesWithSnapshot.java:70)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "7044"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractOpen",
        "testMethod": "testFsIsEncrypted",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractOpen.createCluster(TestHDFSContractOpen.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "1241549087"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testAbortUnknownUpload",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "1073774719"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:95)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testCompleteEmptyUploadID",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "4490751"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testFavoredNodesEndToEndForAppend",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.setUpBeforeClass(TestFavoredNodesEndToEnd.java:71)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "27886"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestSetTimes",
        "testMethod": "testGetBlockLocationsOnlyUsesReadLock",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock(TestSetTimes.java:300)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock$$CONFUZZ(TestSetTimes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "531"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testSetXAttrCaseSensitivity",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "21772"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace",
        "testMethod": "testSaveNamespaceWithRenamedLease",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease(TestSaveNamespace.java:622)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease$$CONFUZZ(TestSaveNamespace.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "396"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations",
        "testMethod": "testFedSingleNN",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testFedSingleNN(TestDataNodeMultipleRegistrations.java:151)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testFedSingleNN$$CONFUZZ(TestDataNodeMultipleRegistrations.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "8976"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsck",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck(TestFsck.java:218)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "2147467343"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate",
        "testMethod": "testUpdateQuotaForAppend",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate.setUp(TestDiskspaceQuotaUpdate.java:76)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "20658"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS",
        "testMethod": "testBasicOperations",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.setup(TestEncryptionZonesWithKMS.java:64)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "398983053"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport",
        "testMethod": "testDiffReportWithOpenFiles",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport.setUp(TestSnapshotDiffReport.java:102)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "655"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks",
        "testMethod": "testWithReplicationFactorAsOne",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne(TestProcessCorruptBlocks.java:168)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne$$CONFUZZ(TestProcessCorruptBlocks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "13278"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "559017483"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.fs.permission.TestStickyBit",
        "testMethod": "testMovingFiles",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.permission.TestStickyBit.initCluster(TestStickyBit.java:79)",
            "org.apache.hadoop.fs.permission.TestStickyBit.init(TestStickyBit.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "2130640638"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testBlockAllocationAdjustsUsageConservatively",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestQuota.restartCluster(TestQuota.java:122)",
            "org.apache.hadoop.hdfs.TestQuota.setUpClass(TestQuota.java:107)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "892913680"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testAbortUnknownUpload",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "1916526199"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints",
        "testMethod": "testBothNodesInStandbyState",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints.setupCluster(TestStandbyCheckpoints.java:103)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "993026064"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:95)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "1341362580"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "1288979149"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testCompleteEmptyUploadID",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "2130640638"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testFavoredNodesEndToEndForAppend",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.setUpBeforeClass(TestFavoredNodesEndToEnd.java:71)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "2147451392"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager",
        "testMethod": "testBasicReplication",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.setupMockCluster(TestBlockManager.java:170)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "1074003968"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsckReplicaDetails",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckReplicaDetails(TestFsck.java:945)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckReplicaDetails$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "403144447"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace",
        "testMethod": "testSaveNamespaceWithRenamedLease",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease(TestSaveNamespace.java:622)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease$$CONFUZZ(TestSaveNamespace.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "1114082606"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier",
        "testMethod": "testChooseInSameDatanodeWithONESSDShouldNotChooseIfNoSpace",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.startCluster(TestExternalStoragePolicySatisfier.java:211)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testChooseInSameDatanodeWithONESSDShouldNotChooseIfNoSpace(TestExternalStoragePolicySatisfier.java:1026)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testChooseInSameDatanodeWithONESSDShouldNotChooseIfNoSpace$$CONFUZZ(TestExternalStoragePolicySatisfier.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "505318108"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport",
        "testMethod": "testDiffReportWithOpenFiles",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport.setUp(TestSnapshotDiffReport.java:102)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "1265550653"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultMinimalAclNewFile",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "2139381039"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations",
        "testMethod": "testResolveReservedPath",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.setupFileSystem(TestGetBlockLocations.java:135)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.testResolveReservedPath(TestGetBlockLocations.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.testResolveReservedPath$$CONFUZZ(TestGetBlockLocations.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "1142889521"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor",
        "testMethod": "testFileSmallerThanOneStripe",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "545226495"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.initCluster(FSXAttrBaseTest.java:1377)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.init(FSXAttrBaseTest.java:109)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "2130640638"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.TestFileAppend3",
        "testMethod": "testTC1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileAppend3.setUp(TestFileAppend3.java:80)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "1948295937"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-6",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testDefaultAclRenamedDir",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "1561914766"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testNumVersionsCorrectAfterReregister",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.mockDatanodeManager(TestDatanodeManager.java:91)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testNumVersionsCorrectAfterReregister(TestDatanodeManager.java:119)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testNumVersionsCorrectAfterReregister$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestLeaseRecovery",
        "testMethod": "testLeaseRecoveryAndAppendWithViewDFS",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppend(TestLeaseRecovery.java:309)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS(TestLeaseRecovery.java:304)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS$$CONFUZZ(TestLeaseRecovery.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:95)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testFavoredNodesEndToEndForAppend",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.setUpBeforeClass(TestFavoredNodesEndToEnd.java:71)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager",
        "testMethod": "testBasicReplication",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.setupMockCluster(TestBlockManager.java:170)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsckReplicaDetails",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckReplicaDetails(TestFsck.java:945)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckReplicaDetails$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate",
        "testMethod": "testUpdateQuotaForAppend",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate.setUp(TestDiskspaceQuotaUpdate.java:76)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS",
        "testMethod": "testRead",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead(TestBlockTokenWithDFS.java:357)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead$$CONFUZZ(TestBlockTokenWithDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer",
        "testMethod": "testBalancer0Integrity",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:681)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:642)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:636)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.oneNodeTest(TestBalancer.java:953)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testBalancer0Internal(TestBalancer.java:1068)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Integrity(TestBalancerWithSaslDataTransfer.java:34)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Integrity$$CONFUZZ(TestBalancerWithSaslDataTransfer.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.00f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestUnsetAndChangeDirectoryEcPolicy",
        "testMethod": "testUnsetEcPolicyInEditLog",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestUnsetAndChangeDirectoryEcPolicy.setup(TestUnsetAndChangeDirectoryEcPolicy.java:75)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement",
        "testMethod": "testBlockMoveAcrossStorageInSameNode",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement.testBlockMoveAcrossStorageInSameNode(TestBlockReplacement.java:275)",
            "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement.testBlockMoveAcrossStorageInSameNode$$CONFUZZ(TestBlockReplacement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint",
        "testMethod": "testStorageAlreadyLockedErrorMessage",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testStorageAlreadyLockedErrorMessage(TestCheckpoint.java:859)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testStorageAlreadyLockedErrorMessage$$CONFUZZ(TestCheckpoint.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclMustBeOwnerOrSuper",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testgoodScript",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.mockDatanodeManager(TestDatanodeManager.java:91)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.HelperFunction(TestDatanodeManager.java:376)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testgoodScript(TestDatanodeManager.java:322)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testgoodScript$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.viewfs.TestViewFsLinkFallback",
        "testMethod": "testMkdirShouldFailWhenFallbackFSNotAvailable",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.viewfs.TestViewFsLinkFallback.clusterSetupAtBeginning(TestViewFsLinkFallback.java:79)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations",
        "testMethod": "testGetBlockLocationsRacingWithRename",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.setupFileSystem(TestGetBlockLocations.java:135)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.testGetBlockLocationsRacingWithRename(TestGetBlockLocations.java:98)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.testGetBlockLocationsRacingWithRename$$CONFUZZ(TestGetBlockLocations.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsLimits",
        "testMethod": "testParentDirectoryNameIsCorrect",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.write.stale.datanode.ratio = '0.0' is invalid. It should be a positive non-zero float value, not greater than 1.0f.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.<init>(DatanodeManager.java:361)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:479)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsLimits.getMockNamesystem(TestFsLimits.java:57)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsLimits.lazyInitFSDirectory(TestFsLimits.java:296)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsLimits.mkdirs(TestFsLimits.java:251)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsLimits.testParentDirectoryNameIsCorrect(TestFsLimits.java:185)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsLimits.testParentDirectoryNameIsCorrect$$CONFUZZ(TestFsLimits.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.write.stale.datanode.ratio": "0.0f"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "6403d"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testDecommissionWithBusyNode",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "0768h"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.TestLeaseRecovery",
        "testMethod": "testLeaseRecoveryAndAppendWithViewDFS",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppend(TestLeaseRecovery.java:309)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS(TestLeaseRecovery.java:304)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS$$CONFUZZ(TestLeaseRecovery.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "3597ms"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.TestLeaseRecovery",
        "testMethod": "testLeaseRecoveryAndAppendWithViewDFS",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppend(TestLeaseRecovery.java:309)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS(TestLeaseRecovery.java:304)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS$$CONFUZZ(TestLeaseRecovery.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "6403d"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot",
        "testMethod": "testOpenFileWritingAcrossSnapDeletion",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot.setup(TestOpenFilesWithSnapshot.java:70)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "480539416s"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger",
        "testMethod": "testMetricsLoggerOnByDefault",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger$TestNameNode.<init>(TestNameNodeMetricsLogger.java:138)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.makeNameNode(TestNameNodeMetricsLogger.java:118)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault(TestNameNodeMetricsLogger.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault$$CONFUZZ(TestNameNodeMetricsLogger.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "8318049h"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "71280175m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "7ms"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.fs.permission.TestStickyBit",
        "testMethod": "testStickyBitRecursiveDeleteFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.permission.TestStickyBit.initCluster(TestStickyBit.java:79)",
            "org.apache.hadoop.fs.permission.TestStickyBit.init(TestStickyBit.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "7673254m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.TestSetTimes",
        "testMethod": "testGetBlockLocationsOnlyUsesReadLock",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock(TestSetTimes.java:300)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock$$CONFUZZ(TestSetTimes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "037120653h"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testSetXAttrCaseSensitivity",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "1649d"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsck",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck(TestFsck.java:218)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "9047d"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier",
        "testMethod": "testChooseInSameDatanodeWithONESSDShouldNotChooseIfNoSpace",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.startCluster(TestExternalStoragePolicySatisfier.java:211)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testChooseInSameDatanodeWithONESSDShouldNotChooseIfNoSpace(TestExternalStoragePolicySatisfier.java:1026)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testChooseInSameDatanodeWithONESSDShouldNotChooseIfNoSpace$$CONFUZZ(TestExternalStoragePolicySatisfier.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "59360d"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate",
        "testMethod": "testUpdateQuotaForAppend",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate.setUp(TestDiskspaceQuotaUpdate.java:76)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "726d"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks",
        "testMethod": "testWithReplicationFactorAsOne",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne(TestProcessCorruptBlocks.java:168)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne$$CONFUZZ(TestProcessCorruptBlocks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "509013d"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultMinimalAclNewFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "097624d"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testSetAclMinimal",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "49855261m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl",
        "testMethod": "testSetAclCustomMask",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl.init(TestNameNodeAcl.java:32)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "434200415m"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesOnlyAccess",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:122)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "454ms"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-106",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMinimal",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "024d"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodes",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.setUp(TestSnapshotPathINodes.java:65)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1627054902"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testBlocksAddedBeforeStandbyRestart",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "816061141"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:369)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:184)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "754935474"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.TestLeaseRecovery",
        "testMethod": "testLeaseRecoveryAndAppendWithViewDFS",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppend(TestLeaseRecovery.java:309)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS(TestLeaseRecovery.java:304)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS$$CONFUZZ(TestLeaseRecovery.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1140883467"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testBlockAllocationAdjustsUsageConservatively",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestQuota.restartCluster(TestQuota.java:122)",
            "org.apache.hadoop.hdfs.TestQuota.setUpClass(TestQuota.java:107)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "598081440"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFS",
        "testMethod": "testECPolicyCommands",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testECPolicyCommands(TestWebHDFS.java:1695)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testECPolicyCommands$$CONFUZZ(TestWebHDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "2147248222"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS",
        "testMethod": "testBasicOperationsRootDir",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.setup(TestEncryptionZonesWithKMS.java:64)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "893437087"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testUMaskDefaultAclNewFile",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "698463708"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1174949630"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testFavoredNodesEndToEndForAppend",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.setUpBeforeClass(TestFavoredNodesEndToEnd.java:71)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "2130640638"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager",
        "testMethod": "testBasicReplication",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.setupMockCluster(TestBlockManager.java:170)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1138074722"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager",
        "testMethod": "testSafeModeIBR",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.setupMockCluster(TestBlockManager.java:170)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1900120839"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsckReplicaDetails",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckReplicaDetails(TestFsck.java:945)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckReplicaDetails$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "792773124"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.fs.permission.TestStickyBit",
        "testMethod": "testStickyBitRecursiveDeleteFile",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.permission.TestStickyBit.initCluster(TestStickyBit.java:79)",
            "org.apache.hadoop.fs.permission.TestStickyBit.init(TestStickyBit.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1535169838"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.TestSetTimes",
        "testMethod": "testGetBlockLocationsOnlyUsesReadLock",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock(TestSetTimes.java:300)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock$$CONFUZZ(TestSetTimes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1266697604"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsck",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck(TestFsck.java:218)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "797114892"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations",
        "testMethod": "testResolveReservedPath",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.setupFileSystem(TestGetBlockLocations.java:135)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.testResolveReservedPath(TestGetBlockLocations.java:56)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.testResolveReservedPath$$CONFUZZ(TestGetBlockLocations.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "2130640638"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesOnlyAccess",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "537434185"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMinimal",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "1081865820"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMinimal",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:484)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "274760193"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testBlocksAddedBeforeStandbyRestart",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testRemoveXAttr",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.setup(TestRetryCacheWithHA.java:149)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement",
        "testMethod": "testInvalidateBlock",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock(TestStandbyBlockManagement.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock$$CONFUZZ(TestStandbyBlockManagement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testRename",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.setup(TestRetryCacheWithHA.java:149)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA",
        "testMethod": "testMultipleNonExistingUsers",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA.setUpNameNode(TestGetGroupsWithHA.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testCreateSymlink",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.setup(TestRetryCacheWithHA.java:149)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints",
        "testMethod": "testCheckpointSucceedsWithLegacyOIVException",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints.setupCluster(TestStandbyCheckpoints.java:103)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean",
        "testMethod": "testNNDirectorySize",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testNNDirectorySize(TestNameNodeMXBean.java:806)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testNNDirectorySize$$CONFUZZ(TestNameNodeMXBean.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testEnterSafeModeInANNShouldNotThrowNPE",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints",
        "testMethod": "testStandbyAndObserverState",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints.setupCluster(TestStandbyCheckpoints.java:103)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testAddCachePool",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.setup(TestRetryCacheWithHA.java:149)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testBlocksAddedWhileStandbyIsDown",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot",
        "testMethod": "testDatanodeRestarts",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot.testDatanodeRestarts(TestStandbyIsHot.java:146)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot.testDatanodeRestarts$$CONFUZZ(TestStandbyIsHot.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover",
        "testMethod": "testPipelineRecoveryStress",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.HAStressTestHarness.startCluster(HAStressTestHarness.java:73)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testPipelineRecoveryStress(TestPipelinesFailover.java:465)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testPipelineRecoveryStress$$CONFUZZ(TestPipelinesFailover.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA",
        "testMethod": "testMultipleExistingUsers",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA.setUpNameNode(TestGetGroupsWithHA.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testComplexFailoverIntoSafemode",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.mover.TestMover",
        "testMethod": "testMoverCliWithFederationHA",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.mover.TestMover.testMoverCliWithFederationHA(TestMover.java:583)",
            "org.apache.hadoop.hdfs.server.mover.TestMover.testMoverCliWithFederationHA$$CONFUZZ(TestMover.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-4"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.viewfs.TestViewFsLinkFallback",
        "testMethod": "testMkdirShouldFailWhenFallbackFSNotAvailable",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.viewfs.TestViewFsLinkFallback.clusterSetupAtBeginning(TestViewFsLinkFallback.java:79)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-3,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-1-4"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations",
        "testMethod": "testClusterIdMismatch",
        "failure": "java.io.IOException",
        "errorMessage": "Cannot lock storage /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-3-1. The directory is already locked",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.lock(Storage.java:915)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:699)",
            "org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:642)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:387)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testClusterIdMismatch(TestDataNodeMultipleRegistrations.java:206)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testClusterIdMismatch$$CONFUZZ(TestDataNodeMultipleRegistrations.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir": "file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-3-1,file:/home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-3-2"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testSimpleProxyAuthParamsInUrl",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<[d[oas=test-proxy-user, op=GETFILESTATUS, user.name=test-user]]> but was:<[d[elegation=IwAPdGVzdC1wcm94eS11c2VyAACKAYlpWb1ligGJboAZZQEBFGd9M0RjnYu8jAIrTWNBv3bpxMqrEldFQkhERlMgZGVsZWdhdGlvbgsxMjcuMC4wLjE6MA, op=GETFILESTATUS]]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.checkQueryParams(TestWebHdfsUrl.java:372)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSimpleProxyAuthParamsInUrl(TestWebHdfsUrl.java:124)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSimpleProxyAuthParamsInUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testBatchedListingUrl",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<[[op=LISTSTATUS_BATCH, startafter=last, user.name=test-user]]> but was:<[[delegation=HQAJdGVzdC11c2VyAACKAYlpQtGIigGJbmktiAEBFHrP-hReL26V_jZaKbbG8HMOPwzmEldFQkhERlMgZGVsZWdhdGlvbgsxMjcuMC4wLjE6MA, op=LISTSTATUS_BATCH, startafter=last]]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.checkQueryParams(TestWebHdfsUrl.java:372)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testBatchedListingUrl(TestWebHdfsUrl.java:359)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testBatchedListingUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testSimpleProxyAuthParamsInUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.getWebHdfsFileSystem(TestWebHdfsUrl.java:391)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSimpleProxyAuthParamsInUrl(TestWebHdfsUrl.java:119)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSimpleProxyAuthParamsInUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true",
            "fs.webhdfs.impl.disable.cache": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testSecureProxyAuthParamsInUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.getWebHdfsFileSystem(TestWebHdfsUrl.java:391)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSecureProxyAuthParamsInUrl(TestWebHdfsUrl.java:238)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSecureProxyAuthParamsInUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true",
            "fs.webhdfs.impl.disable.cache": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testSimpleProxyAuthParamsInUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)",
            "org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)",
            "org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.getWebHdfsFileSystem(TestWebHdfsUrl.java:391)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSimpleProxyAuthParamsInUrl(TestWebHdfsUrl.java:119)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSimpleProxyAuthParamsInUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)",
            "org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)",
            "org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)",
            "org.apache.hadoop.hdfs.web.WebHdfsTestUtil.getWebHdfsFileSystem(WebHdfsTestUtil.java:63)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:464)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testSecureProxyAuthParamsInUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)",
            "org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)",
            "org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.getWebHdfsFileSystem(TestWebHdfsUrl.java:391)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSecureProxyAuthParamsInUrl(TestWebHdfsUrl.java:238)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSecureProxyAuthParamsInUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testSecureAuthParamsInUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)",
            "org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)",
            "org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.getWebHdfsFileSystem(TestWebHdfsUrl.java:391)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSecureAuthParamsInUrl(TestWebHdfsUrl.java:145)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSecureAuthParamsInUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testDefaultAclNewDirIntermediate",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)",
            "org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)",
            "org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)",
            "org.apache.hadoop.hdfs.web.WebHdfsTestUtil.getWebHdfsFileSystem(WebHdfsTestUtil.java:63)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.createFileSystem(TestWebHDFSAcl.java:55)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.createFileSystem(TestWebHDFSAcl.java:29)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.initFileSystems(FSAclBaseTest.java:1729)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.setUp(FSAclBaseTest.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsTokens",
        "testMethod": "testNoTokenForGetToken",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.spyWebhdfsInSecureSetup(TestWebHdfsTokens.java:185)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.checkNoTokenForOperation(TestWebHdfsTokens.java:230)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.testNoTokenForGetToken(TestWebHdfsTokens.java:214)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.testNoTokenForGetToken$$CONFUZZ(TestWebHdfsTokens.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)",
            "org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)",
            "org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)",
            "org.apache.hadoop.hdfs.web.WebHdfsTestUtil.getWebHdfsFileSystem(WebHdfsTestUtil.java:63)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSXAttr.createFileSystem(TestWebHDFSXAttr.java:34)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSXAttr.createFileSystem(TestWebHDFSXAttr.java:25)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.initFileSystem(FSXAttrBaseTest.java:1365)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.setUp(FSXAttrBaseTest.java:126)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testSetAclMustBeOwnerOrSuper",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)",
            "org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)",
            "org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)",
            "org.apache.hadoop.hdfs.web.WebHdfsTestUtil.getWebHdfsFileSystem(WebHdfsTestUtil.java:63)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.createFileSystem(TestWebHDFSAcl.java:55)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.createFileSystem(TestWebHDFSAcl.java:29)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.initFileSystems(FSAclBaseTest.java:1729)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.setUp(FSAclBaseTest.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsTokens",
        "testMethod": "testNoTokenForCancelToken",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.spyWebhdfsInSecureSetup(TestWebHdfsTokens.java:185)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.checkNoTokenForOperation(TestWebHdfsTokens.java:230)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.testNoTokenForCancelToken(TestWebHdfsTokens.java:226)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.testNoTokenForCancelToken$$CONFUZZ(TestWebHdfsTokens.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testBatchedListingUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)",
            "org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)",
            "org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.getWebHdfsFileSystem(TestWebHdfsUrl.java:391)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testBatchedListingUrl(TestWebHdfsUrl.java:352)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testBatchedListingUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testDefaultAclNewFileIntermediate",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)",
            "org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)",
            "org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)",
            "org.apache.hadoop.hdfs.web.WebHdfsTestUtil.getWebHdfsFileSystem(WebHdfsTestUtil.java:63)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.createFileSystem(TestWebHDFSAcl.java:55)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.createFileSystem(TestWebHDFSAcl.java:29)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.initFileSystems(FSAclBaseTest.java:1729)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.setUp(FSAclBaseTest.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-166",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testFileChecksumAfterDecommission",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1683401871",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:191)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.<init>(DFSStripedOutputStream.java:293)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:315)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:902)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:924)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.writeStripedFile(TestDecommissionWithStriped.java:570)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission(TestDecommissionWithStriped.java:432)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileChecksumAfterDecommission$$CONFUZZ(TestDecommissionWithStriped.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "1244611113"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-166",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus",
        "testMethod": "testListLocatedStatusFile",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1858696969",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:191)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636)",
            "org.apache.hadoop.fs.contract.ContractTestUtils.touch(ContractTestUtils.java:672)",
            "org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.touchf(AbstractContractGetFileStatusTest.java:466)",
            "org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.testListLocatedStatusFile(AbstractContractGetFileStatusTest.java:426)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus.testListLocatedStatusFile$$CONFUZZ(TestHDFSContractGetFileStatus.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "270696703"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-166",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testLsr",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1633372663",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:191)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.TestDFSShell.writeFile(TestDFSShell.java:139)",
            "org.apache.hadoop.hdfs.TestDFSShell.createTree(TestDFSShell.java:1225)",
            "org.apache.hadoop.hdfs.TestDFSShell.testLsr(TestDFSShell.java:2144)",
            "org.apache.hadoop.hdfs.TestDFSShell.testLsr$$CONFUZZ(TestDFSShell.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "295732737"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-166",
        "testClass": "org.apache.hadoop.hdfs.TestFileStatus",
        "testMethod": "testListStatusOnFile",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1945072282",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:191)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.TestFileStatus.testSetUp(TestFileStatus.java:75)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "261099446"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS",
        "testMethod": "testRestartAfterReencrypt",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestReencryption.setup(TestReencryption.java:129)",
            "org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS.setup(TestReencryptionWithKMS.java:60)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "32702"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testBlockAllocationAdjustsUsageConservatively",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestQuota.restartCluster(TestQuota.java:122)",
            "org.apache.hadoop.hdfs.TestQuota.setUpClass(TestQuota.java:107)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "9528"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testUMaskDefaultAclNewFile",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "24846"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:95)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "727222702"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testCompleteEmptyUploadID",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "169122132"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations",
        "testMethod": "testFedSingleNN",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testFedSingleNN(TestDataNodeMultipleRegistrations.java:151)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testFedSingleNN$$CONFUZZ(TestDataNodeMultipleRegistrations.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "41"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveDefaultAclOnlyAccess",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "5482"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testGetAclStatusRequiresTraverseOrSuper",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "28798"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl",
        "testMethod": "testSetAclCustomMask",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl.init(TestNameNodeAcl.java:32)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesOnlyAccess",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "1776091086"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testReadFullyZeroByteFile",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek.createCluster(TestHDFSContractSeek.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "149"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer",
        "testMethod": "testBalancer0Integrity",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:692)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:642)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:636)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.oneNodeTest(TestBalancer.java:953)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testBalancer0Internal(TestBalancer.java:1068)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Integrity(TestBalancerWithSaslDataTransfer.java:34)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Integrity$$CONFUZZ(TestBalancerWithSaslDataTransfer.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "7"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileCreation",
        "testMethod": "testConcurrentFileCreation",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileCreation.testConcurrentFileCreation(TestFileCreation.java:998)",
            "org.apache.hadoop.hdfs.TestFileCreation.testConcurrentFileCreation$$CONFUZZ(TestFileCreation.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "2130640638"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.mover.TestMover",
        "testMethod": "testMoverFailedRetryWithPinnedBlocks",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.mover.TestMover.testMoverFailedRetryWithPinnedBlocks(TestMover.java:1104)",
            "org.apache.hadoop.hdfs.server.mover.TestMover.testMoverFailedRetryWithPinnedBlocks$$CONFUZZ(TestMover.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "274726927"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand",
        "testMethod": "testRunMultipleCommandsUnderOneSetup",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand.setUp(TestDiskBalancerCommand.java:96)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "15"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestMaintenanceState",
        "testMethod": "testInvalidation",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestMaintenanceState.testInvalidation(TestMaintenanceState.java:935)",
            "org.apache.hadoop.hdfs.TestMaintenanceState.testInvalidation$$CONFUZZ(TestMaintenanceState.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "527"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus",
        "testMethod": "testListFilesNoDir",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus.createCluster(TestHDFSContractGetFileStatus.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "13565"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure",
        "testMethod": "testAddBlockWhenNoSufficientParityNumOfNodes",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailureBase.setup(TestDFSStripedOutputStreamWithFailureBase.java:208)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testAddBlockWhenNoSufficientParityNumOfNodes(TestDFSStripedOutputStreamWithFailure.java:209)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testAddBlockWhenNoSufficientParityNumOfNodes$$CONFUZZ(TestDFSStripedOutputStreamWithFailure.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "41984"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.permission.TestStickyBit",
        "testMethod": "testAclStickyBitPersistence",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.permission.TestStickyBit.initCluster(TestStickyBit.java:79)",
            "org.apache.hadoop.fs.permission.TestStickyBit.init(TestStickyBit.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "135"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testSetAclOnlyDefault",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "537014432"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testDecommissionWithBusyNode",
        "failure": "java.io.IOException",
        "errorMessage": "Failed: the number of failed blocks = 4 > the number of parity blocks = 3",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:410)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.handleStreamerFailure(DFSStripedOutputStream.java:435)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.flushAllInternals(DFSStripedOutputStream.java:1336)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1239)",
            "org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:904)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:924)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.writeStripedFile(TestDecommissionWithStriped.java:570)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testDecommissionWithBusyNode(TestDecommissionWithStriped.java:303)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testDecommissionWithBusyNode$$CONFUZZ(TestDecommissionWithStriped.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client-write-packet-size": "229282775",
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testDecommissionWithBusyNode",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 14980. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "14980"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 662008371. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:369)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:184)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "662008371"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 63. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "63"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 327188607. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:95)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "327188607"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 25242. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "25242"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 767. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testCompleteEmptyUploadID",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 767. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement",
        "testMethod": "testInvalidateBlock",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 1026. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock(TestStandbyBlockManagement.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock$$CONFUZZ(TestStandbyBlockManagement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "1026"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsckReplicaDetails",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 574. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckReplicaDetails(TestFsck.java:945)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckReplicaDetails$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "574"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testSetXAttrCaseSensitivity",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 4864. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "4864"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace",
        "testMethod": "testSaveNamespaceWithRenamedLease",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 20972286. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease(TestSaveNamespace.java:622)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease$$CONFUZZ(TestSaveNamespace.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "20972286"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsck",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 7020. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck(TestFsck.java:218)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "7020"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testGetAclStatusRequiresTraverseOrSuper",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 1737805558. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "1737805558"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testTransferAndNativeCopyMetrics",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 33287. Value configured is either less than maxVolumeFailureLimit or greater than to the number of configured volumes (1).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:331)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "33287"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testMoveBlockFailure",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 623098990. Value configured is either less than maxVolumeFailureLimit or greater than to the number of configured volumes (1).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:331)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "623098990"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks",
        "testMethod": "testWithReplicationFactorAsOne",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 1056931583. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne(TestProcessCorruptBlocks.java:168)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne$$CONFUZZ(TestProcessCorruptBlocks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "1056931583"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor",
        "testMethod": "testFileSmallerThanOneStripe",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 6639. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "6639"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestExtendedAcls",
        "testMethod": "testRestrictAtSubDir",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 31032. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestExtendedAcls.setup(TestExtendedAcls.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "31032"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testProvidedVolumeImpl",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 572528586. Value configured is either less than maxVolumeFailureLimit or greater than to the number of configured volumes (1).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:331)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.setUp(TestProvidedImpl.java:342)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "572528586"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS",
        "testMethod": "testRead",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.failed.volumes.tolerated - 2132039. Value configured is >= to the number of configured volumes (2).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:178)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead(TestBlockTokenWithDFS.java:357)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead$$CONFUZZ(TestBlockTokenWithDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.failed.volumes.tolerated": "2132039"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournalCommonDirAcrossNameSpace",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=27509 < max=200 for QueuedThreadPool[qtp565352670]@21b298de{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58211c07{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "27506"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testFormat",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=19343 < max=200 for QueuedThreadPool[qtp283430665]@10e4cf09{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@5a934ef9{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "19340"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeRespectsBindHostKeys",
        "testMethod": "testRpcBindHostKey",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=13021 < max=200 for QueuedThreadPool[qtp1239489703]@49e11ca7{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6b41df80{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeRespectsBindHostKeys.testRpcBindHostKey(TestJournalNodeRespectsBindHostKeys.java:95)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNodeRespectsBindHostKeys.testRpcBindHostKey$$CONFUZZ(TestJournalNodeRespectsBindHostKeys.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "13018"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame",
        "testMethod": "testNameNodeXFrameOptionsDisabled",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=13021 < max=200 for QueuedThreadPool[qtp1762556809]@690e7b89{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@49482761{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.createServerwithXFrame(TestNameNodeHttpServerXFrame.java:92)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.testNameNodeXFrameOptionsDisabled(TestNameNodeHttpServerXFrame.java:68)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.testNameNodeXFrameOptionsDisabled$$CONFUZZ(TestNameNodeHttpServerXFrame.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "13018"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileCreation",
        "testMethod": "testServerDefaultsWithMinimalCaching",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=165900 < max=200 for QueuedThreadPool[qtp2064702302]@7b10db5e{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@66699a8d{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithMinimalCaching(TestFileCreation.java:251)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithMinimalCaching$$CONFUZZ(TestFileCreation.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "165897"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA",
        "testMethod": "testMultipleNonExistingUsers",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=27465 < max=200 for QueuedThreadPool[qtp191871257]@b6fb919{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58419069{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA.setUpNameNode(TestGetGroupsWithHA.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "27462"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean",
        "testMethod": "testQueueLength",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=645 < max=200 for QueuedThreadPool[qtp1811519050]@6bf9964a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@57bbc4a9{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testQueueLength(TestNameNodeMXBean.java:774)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testQueueLength$$CONFUZZ(TestNameNodeMXBean.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "642"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint",
        "testMethod": "testSecondaryPurgesEditLogs",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=20147 < max=200 for QueuedThreadPool[qtp87701945]@53a39b9{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@4d04ce06{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryPurgesEditLogs(TestCheckpoint.java:2264)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryPurgesEditLogs$$CONFUZZ(TestCheckpoint.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "20144"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique",
        "testMethod": "testSingleThreaded",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=25319 < max=284 for QueuedThreadPool[qtp312559824]@12a148d0{STARTED,8<=8<=284,i=8,r=-1,q=0}[ReservedThreadExecutor@33f2ccd1{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique.testSingleThreaded(TestEpochsAreUnique.java:54)",
            "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique.testSingleThreaded$$CONFUZZ(TestEpochsAreUnique.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "25316"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournalNodeStartupFailsCleanly",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=2146309 < max=200 for QueuedThreadPool[qtp79341612]@4baa82c{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@463d48b2{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "2146306"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testPurgeLogs",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=270597890 < max=28371 for QueuedThreadPool[qtp760422553]@2d532099{STARTED,8<=8<=28371,i=8,r=-1,q=0}[ReservedThreadExecutor@289d98a{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "270597887"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testOutOfSyncAtBeginningOfSegment0",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=921 < max=200 for QueuedThreadPool[qtp1906742867]@71a69653{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@1dd53a93{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "918"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testChangeWritersLogsInSync",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=571 < max=200 for QueuedThreadPool[qtp1922360411]@7294e45b{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@6414b660{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "512"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint",
        "testMethod": "testCheckpointTriggerOnTxnCount",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=83885988 < max=200 for QueuedThreadPool[qtp1984741883]@764cc1fb{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@3056bd1d{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testCheckpointTriggerOnTxnCount(TestCheckpoint.java:2176)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testCheckpointTriggerOnTxnCount$$CONFUZZ(TestCheckpoint.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "83885985"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testCrashAtBeginningOfSegment",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=770 < max=200 for QueuedThreadPool[qtp45854145]@2bbadc1{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@34ded59f{s=0/2,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "767"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:369)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission(TestDecommission.java:184)",
            "org.apache.hadoop.hdfs.TestDecommission.testDecommission$$CONFUZZ(TestDecommission.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "2139792275"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testFavoredNodesEndToEndForAppend",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.setUpBeforeClass(TestFavoredNodesEndToEnd.java:71)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "327155587"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesOnlyAccess",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "729558051"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor",
        "testMethod": "testFileSmallerThanOneStripe",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "2147483646"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMinimal",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "2129065283"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testRootDirEZTrash",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "2147450998"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations",
        "testMethod": "testClusterIdMismatch",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testClusterIdMismatch(TestDataNodeMultipleRegistrations.java:206)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testClusterIdMismatch$$CONFUZZ(TestDataNodeMultipleRegistrations.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "598650527"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testDefaultAclRenamedDir",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "119570440"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.TestDFSMkdirs",
        "testMethod": "testMkdirRpcNonCanonicalPath",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSMkdirs.testMkdirRpcNonCanonicalPath(TestDFSMkdirs.java:138)",
            "org.apache.hadoop.hdfs.TestDFSMkdirs.testMkdirRpcNonCanonicalPath$$CONFUZZ(TestDFSMkdirs.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "1889386293"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMustBeOwnerOrSuper",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "1065353734"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.TestFileCreation",
        "testMethod": "testServerDefaultsWithMinimalCaching",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithMinimalCaching(TestFileCreation.java:251)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithMinimalCaching$$CONFUZZ(TestFileCreation.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "807444507"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement",
        "testMethod": "testBlockMoveAcrossStorageInSameNode",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement.testBlockMoveAcrossStorageInSameNode(TestBlockReplacement.java:275)",
            "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement.testBlockMoveAcrossStorageInSameNode$$CONFUZZ(TestBlockReplacement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "2130673407"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor",
        "testMethod": "testDecommissionDeadDN",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.createCluster(TestDecommissioningStatus.java:122)",
            "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor.setUp(TestDecommissioningStatusWithBackoffMonitor.java:68)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "1615393039"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testAddVolumeWithSameStorageUuid",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testAddVolumeWithSameStorageUuid(TestFsDatasetImpl.java:366)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testAddVolumeWithSameStorageUuid$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "2130640638"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testAddCachePool",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.setup(TestRetryCacheWithHA.java:149)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "33554495"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testReadFullySmallFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek.createCluster(TestHDFSContractSeek.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "126353663"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testSetAclMustBeOwnerOrSuper",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "1622354187"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testRemoveAclEntries",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "536911615"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart",
        "testMethod": "testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart.testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister(TestFileLengthOnClusterRestart.java:43)",
            "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart.testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister$$CONFUZZ(TestFileLengthOnClusterRestart.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "2130640638"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testReadFullyZeroBytebufferPastEOF",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168)",
            "org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3115)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek.createCluster(TestHDFSContractSeek.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "1273960567"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommission",
        "testMethod": "testDecommission",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "15"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsckReplicaDetails",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "188"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "1"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement",
        "testMethod": "testBlockMoveAcrossStorageInSameNode",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "7"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestProtectedDirectories",
        "testMethod": "testDelete",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "5"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testSetXAttrPermission",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "319"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks",
        "testMethod": "testSkewedRack2",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "1"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testGetTrashRoots",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "1"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestStoragePolicyPermissionSettings",
        "testMethod": "testStoragePolicyPermissionDisabled",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "767"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1987432512"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1073774335"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testFormat",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.<init>(JournalNodeRpcServer.java:101)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:242)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1373996960"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot",
        "testMethod": "testSnapshotMtime",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.setUp(TestSnapshot.java:122)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1073856767"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testBlocksRemovedWhileInSafeModeEditsArriveFirst",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1616523264"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestProtectedDirectories",
        "testMethod": "testDelete",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestProtectedDirectories.setupTestCase(TestProtectedDirectories.java:82)",
            "org.apache.hadoop.hdfs.server.namenode.TestProtectedDirectories.testDelete(TestProtectedDirectories.java:263)",
            "org.apache.hadoop.hdfs.server.namenode.TestProtectedDirectories.testDelete$$CONFUZZ(TestProtectedDirectories.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1322721054"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testJournalNodeSyncerNotStartWhenSyncEnabledIncorrectURI",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.<init>(JournalNodeRpcServer.java:101)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:242)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1073775501"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testBlockReadZeroByteFile",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek.createCluster(TestHDFSContractSeek.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "635474065"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.TestTrashWithSecureEncryptionZones",
        "testMethod": "testTrashExpunge",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestTrashWithSecureEncryptionZones.init(TestTrashWithSecureEncryptionZones.java:214)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "2130640638"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens",
        "testMethod": "testSaveNamespace",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens.testSaveNamespace(TestCheckPointForSecurityTokens.java:72)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens.testSaveNamespace$$CONFUZZ(TestCheckPointForSecurityTokens.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1086296492"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade",
        "testMethod": "testDatanodeRollingUpgradeWithRollback",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.startCluster(TestDataNodeRollingUpgrade.java:77)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback(TestDataNodeRollingUpgrade.java:263)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback$$CONFUZZ(TestDataNodeRollingUpgrade.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1090486015"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier",
        "testMethod": "testWhenStoragePolicySetToONESSD",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.startCluster(TestExternalStoragePolicySatisfier.java:211)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.createCluster(TestExternalStoragePolicySatisfier.java:194)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWhenStoragePolicySetToONESSD(TestExternalStoragePolicySatisfier.java:480)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWhenStoragePolicySetToONESSD$$CONFUZZ(TestExternalStoragePolicySatisfier.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1365555254"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testDuSnapshots",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "915826065"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot",
        "testMethod": "testDatanodeRestarts",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot.testDatanodeRestarts(TestStandbyIsHot.java:146)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot.testDatanodeRestarts$$CONFUZZ(TestStandbyIsHot.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1073710592"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.TestFileChecksum",
        "testMethod": "testStripedFileChecksumWithReconstructFail",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileChecksum.setup(TestFileChecksum.java:94)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "840992831"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testSetXAttrPermissionAsDifferentOwner",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "714257043"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesOnlyDefault",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1581940767"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.TestAppendDifferentChecksum",
        "testMethod": "testSwitchAlgorithms",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestAppendDifferentChecksum.setupCluster(TestAppendDifferentChecksum.java:54)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "1644225349"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold",
        "testMethod": "testCornerCaseUnderThreshold",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.startUpCluster(TestDnRespectsBlockReportSplitThreshold.java:71)",
            "org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.testCornerCaseUnderThreshold(TestDnRespectsBlockReportSplitThreshold.java:149)",
            "org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.testCornerCaseUnderThreshold$$CONFUZZ(TestDnRespectsBlockReportSplitThreshold.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "2147417854"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-1",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testHttpServer",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeRpcServer.<init>(JournalNodeRpcServer.java:101)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:242)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.read.threadpool.size": "673669547"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-12",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5243)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:613)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blockreport.queue.size": "273801683",
            "dfs.namenode.blocks.per.postponedblocks.rescan": "270041727"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.31234157).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.312341570854187"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.30858308).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:95)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.3085830807685852"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.117709756).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.11770975589752197"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testFavoredNodesEndToEndForAppend",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.1627298).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.setUpBeforeClass(TestFavoredNodesEndToEnd.java:71)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.16272979974746704"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations",
        "testMethod": "testFedSingleNN",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.0019607544).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testFedSingleNN(TestDataNodeMultipleRegistrations.java:151)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations.testFedSingleNN$$CONFUZZ(TestDataNodeMultipleRegistrations.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.00196075439453125"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport",
        "testMethod": "testDiffReportWithOpenFiles",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.4291439).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport.setUp(TestSnapshotDiffReport.java:102)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.42914390563964844"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultMinimalAclNewFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.17147708).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.1714770793914795"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestExtendedAcls",
        "testMethod": "testRestrictAtSubDir",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.47479856).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestExtendedAcls.setup(TestExtendedAcls.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.4747985601425171"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestUnsetAndChangeDirectoryEcPolicy",
        "testMethod": "testUnsetEcPolicyInEditLog",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.058646858).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestUnsetAndChangeDirectoryEcPolicy.setup(TestUnsetAndChangeDirectoryEcPolicy.java:75)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.05864685773849487"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus",
        "testMethod": "testListFilesEmptyDirectoryRecursive",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.2136625).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus.createCluster(TestHDFSContractGetFileStatus.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.2136625051498413"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSecureNameNode",
        "testMethod": "testNameNodeStatusMXBeanSecurityEnabled",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.4349718).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSecureNameNode.testNameNodeStatusMXBeanSecurityEnabled(TestSecureNameNode.java:139)",
            "org.apache.hadoop.hdfs.server.namenode.TestSecureNameNode.testNameNodeStatusMXBeanSecurityEnabled$$CONFUZZ(TestSecureNameNode.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.43497180938720703"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testSetXAttrPermission",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.40147108).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.4014710783958435"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand",
        "testMethod": "testRunMultipleCommandsUnderOneSetup",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.45886356).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand.setUp(TestDiskBalancerCommand.java:96)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.4588635563850403"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclMustBeOwnerOrSuper",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.2973495).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.2973495125770569"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testCreateSymlink",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.0013390183).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.setup(TestRetryCacheWithHA.java:149)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.0013390183448791504"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultAclNewSymlinkIntermediate",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.31718457).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.31718456745147705"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename",
        "testMethod": "testRenameDirIntoExistingDir",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.34569764).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename.createCluster(TestHDFSContractRename.java:33)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.34569764137268066"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions",
        "testMethod": "testTransitionActiveToStandby",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.23590344).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions.testTransitionActiveToStandby(TestHAStateTransitions.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions.testTransitionActiveToStandby$$CONFUZZ(TestHAStateTransitions.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.23590344190597534"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testDu",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.21874768).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.21874767541885376"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename",
        "testMethod": "testRenamePopulatesDirectoryAncestors",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.ec.reconstruction.xmits.weight, it can not be negative value (-0.45313215).",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:64)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename.createCluster(TestHDFSContractRename.java:33)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.xmits.weight": "-0.45313215255737305"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '16777487ms'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "16777487ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testRemoveXAttr",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '1229065983ms'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.setup(TestRetryCacheWithHA.java:149)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1229065983ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes",
        "testMethod": "testExcludedNodesForgiveness",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '1049615s'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness(TestDFSClientExcludedNodes.java:95)",
            "org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness$$CONFUZZ(TestDFSClientExcludedNodes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1049615s"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testFavoredNodesEndToEndForAppend",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '4198143ms'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.setUpBeforeClass(TestFavoredNodesEndToEnd.java:71)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "4198143ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks",
        "testMethod": "testWithReplicationFactorAsOne",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '6307937s'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne(TestProcessCorruptBlocks.java:168)",
            "org.apache.hadoop.hdfs.server.namenode.TestProcessCorruptBlocks.testWithReplicationFactorAsOne$$CONFUZZ(TestProcessCorruptBlocks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "6307937s"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesOnlyAccess",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '520027903s'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "520027903s"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '771727471s'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.initCluster(FSXAttrBaseTest.java:1377)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.init(FSXAttrBaseTest.java:109)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "771727471s"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultAclRenamedFile",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '65799ms'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "65799ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS",
        "testMethod": "testRead",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '2008219630ms'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead(TestBlockTokenWithDFS.java:357)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead$$CONFUZZ(TestBlockTokenWithDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "2008219630ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot",
        "testMethod": "testSnapshotMtime",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '16711423ms'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.setUp(TestSnapshot.java:122)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "16711423ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus",
        "testMethod": "testListFilesEmptyDirectoryRecursive",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '1176348675s'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus.createCluster(TestHDFSContractGetFileStatus.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1176348675s"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSecureNameNode",
        "testMethod": "testNameNodeStatusMXBeanSecurityEnabled",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '67112703ms'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSecureNameNode.testNameNodeStatusMXBeanSecurityEnabled(TestSecureNameNode.java:139)",
            "org.apache.hadoop.hdfs.server.namenode.TestSecureNameNode.testNameNodeStatusMXBeanSecurityEnabled$$CONFUZZ(TestSecureNameNode.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "67112703ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testSetXAttrPermission",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '1078198527s'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1078198527s"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache",
        "testMethod": "testRetryCacheRebuild",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '267477020s'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.setup(TestNamenodeRetryCache.java:104)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "267477020s"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileAppend2",
        "testMethod": "testSimpleAppend2",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '1091772768s'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileAppend2.testSimpleAppend2(TestFileAppend2.java:233)",
            "org.apache.hadoop.hdfs.TestFileAppend2.testSimpleAppend2$$CONFUZZ(TestFileAppend2.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1091772768s"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.tools.TestJMXGet",
        "testMethod": "testDataNode",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '1021835012s'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.tools.TestJMXGet.testDataNode(TestJMXGet.java:156)",
            "org.apache.hadoop.tools.TestJMXGet.testDataNode$$CONFUZZ(TestJMXGet.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1021835012s"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultAclNewSymlinkIntermediate",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '982783ms'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "982783ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints",
        "testMethod": "testCheckpointSucceedsWithLegacyOIVException",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '654245631ms'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints.setupCluster(TestStandbyCheckpoints.java:103)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "654245631ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS",
        "testMethod": "testRestartAfterReencryptAndCheckpoint",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '1035ms'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestReencryption.setup(TestReencryption.java:129)",
            "org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS.setup(TestReencryptionWithKMS.java:60)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1035ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testDu",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 's' in '1885354073ms'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1885354073ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestLeaseRecovery",
        "testMethod": "testLeaseRecoveryAndAppendWithViewDFS",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'h' in '728674995h'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppend(TestLeaseRecovery.java:309)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS(TestLeaseRecovery.java:304)",
            "org.apache.hadoop.hdfs.TestLeaseRecovery.testLeaseRecoveryAndAppendWithViewDFS$$CONFUZZ(TestLeaseRecovery.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "728674995h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testSetXAttrCaseSensitivity",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'h' in '538935327h'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "538935327h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl",
        "testMethod": "testSetAclCustomMask",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'h' in '33619711h'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl.init(TestNameNodeAcl.java:32)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "33619711h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestExtendedAcls",
        "testMethod": "testRestrictAtSubDir",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'h' in '1611669247h'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestExtendedAcls.setup(TestExtendedAcls.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1611669247h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testRootDirEZTrash",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'h' in '2144403713h'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "2144403713h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor",
        "testMethod": "testDecommissionTwoNodes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'h' in '1000227344h'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1000227344h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testGetTrashRoots",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'd' in '16843009d'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "16843009d"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testAddVolumeWithSameStorageUuid",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'h' in '538774791h'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testAddVolumeWithSameStorageUuid(TestFsDatasetImpl.java:366)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testAddVolumeWithSameStorageUuid$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "538774791h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.permission.TestStickyBit",
        "testMethod": "testAclStickyBitPersistence",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'h' in '702573833h'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.permission.TestStickyBit.initCluster(TestStickyBit.java:79)",
            "org.apache.hadoop.fs.permission.TestStickyBit.init(TestStickyBit.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "702573833h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testSetPermissionCannotSetAclBit",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'h' in '270010383h'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "270010383h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart",
        "testMethod": "testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'h' in '16843009h'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart.testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister(TestFileLengthOnClusterRestart.java:43)",
            "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart.testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister$$CONFUZZ(TestFileLengthOnClusterRestart.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "16843009h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testClusterStats",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'h' in '260312144h'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testClusterStats(TestDecommission.java:528)",
            "org.apache.hadoop.hdfs.TestDecommission.testClusterStats(TestDecommission.java:512)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testClusterStats$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "260312144h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testReadFullyZeroBytebufferPastEOF",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'h' in '1062982940h'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek.createCluster(TestHDFSContractSeek.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1062982940h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testFilePermissions",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'd' in '19235095d'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "19235095d"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.balancer.TestBalancer",
        "testMethod": "testUnknownDatanodeSimple",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'd' in '1470756669d'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.generateBlocks(TestBalancer.java:302)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanode(TestBalancer.java:998)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanodeSimple(TestBalancer.java:973)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanodeSimple$$CONFUZZ(TestBalancer.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1470756669d"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot",
        "testMethod": "testParentDirWithUCFileDeleteWithSnapShot",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'd' in '31d'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot.setup(TestOpenFilesWithSnapshot.java:70)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "31d"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks",
        "testMethod": "testSkewedRack2",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'd' in '2080374905d'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.DFSTestUtil.setupCluster(DFSTestUtil.java:2491)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.setupCluster(TestErasureCodingMultipleRacks.java:96)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2(TestErasureCodingMultipleRacks.java:131)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2$$CONFUZZ(TestErasureCodingMultipleRacks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "2080374905d"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testSeekPastEndOfFileThenReseekAndRead",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'd' in '2146435188d'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek.createCluster(TestHDFSContractSeek.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "2146435188d"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDatanodeConfig",
        "testMethod": "testDataDirectories",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'd' in '673185807d'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1594)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1875)",
            "org.apache.hadoop.hdfs.TestDatanodeConfig.testDataDirectories(TestDatanodeConfig.java:108)",
            "org.apache.hadoop.hdfs.TestDatanodeConfig.testDataDirectories$$CONFUZZ(TestDatanodeConfig.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "673185807d"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestPendingDataNodeMessages",
        "testMethod": "testPendingDataNodeMessagesWithEC",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'd' in '2013133753d'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestPendingDataNodeMessages.testPendingDataNodeMessagesWithEC(TestPendingDataNodeMessages.java:91)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestPendingDataNodeMessages.testPendingDataNodeMessagesWithEC$$CONFUZZ(TestPendingDataNodeMessages.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "2013133753d"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testPendingNodeButDecommissioned",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'd' in '1875607230d'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.initDataXceiver(DataNode.java:1159)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1411)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testPendingNodeButDecommissioned(TestDecommission.java:1355)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testPendingNodeButDecommissioned$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "1875607230d"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat",
        "testMethod": "testBackwardsCompat",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid size prefix 'd' in '16843009d'. Allowed prefixes are k, m, g, t, p, e(case insensitive)",
        "stackTrace": [
            "org.apache.hadoop.util.StringUtils$TraditionalBinaryPrefix.string2long(StringUtils.java:846)",
            "org.apache.hadoop.conf.Configuration.getLongBytes(Configuration.java:1664)",
            "org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.<init>(DataXceiverServer.java:200)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat(TestDataXceiverBackwardsCompat.java:149)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat$$CONFUZZ(TestDataXceiverBackwardsCompat.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.balance.bandwidthPerSec": "16843009d"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.setUp(TestSnapshotDeletion.java:101)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testStat",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "9"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestParallelRead",
        "testMethod": "testParallelReadMixed",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.client.impl.BlockReaderTestUtil.<init>(BlockReaderTestUtil.java:97)",
            "org.apache.hadoop.hdfs.TestParallelReadUtil.setupCluster(TestParallelReadUtil.java:71)",
            "org.apache.hadoop.hdfs.TestParallelRead.setupCluster(TestParallelRead.java:37)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.initCluster(FSXAttrBaseTest.java:1377)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.init(FSXAttrBaseTest.java:109)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "127"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMustBeOwnerOrSuper",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "746"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileAppend3",
        "testMethod": "testTC12",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileAppend3.setUp(TestFileAppend3.java:80)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "955"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions",
        "testMethod": "testTransitionActiveToStandby",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions.testTransitionActiveToStandby(TestHAStateTransitions.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions.testTransitionActiveToStandby$$CONFUZZ(TestHAStateTransitions.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForXAttr",
        "testMethod": "testWebImageViewerForListXAttrs",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForXAttr.createOriginalFSImage(TestOfflineImageViewerForXAttr.java:75)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "726"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade",
        "testMethod": "testDatanodeRollingUpgradeWithRollback",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.startCluster(TestDataNodeRollingUpgrade.java:77)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback(TestDataNodeRollingUpgrade.java:263)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback$$CONFUZZ(TestDataNodeRollingUpgrade.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "127"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testErrOutPut",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "31"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsTokens",
        "testMethod": "testLazyTokenFetchForWebhdfs",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.testLazyTokenFetchForWebhdfs(TestWebHdfsTokens.java:279)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.testLazyTokenFetchForWebhdfs$$CONFUZZ(TestWebHdfsTokens.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testSeekPastEndOfFileThenReseekAndRead",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek.createCluster(TestHDFSContractSeek.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "31"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemMBean",
        "testMethod": "testWithFSNamesystemWriteLock",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemMBean.testWithFSNamesystemWriteLock(TestFSNamesystemMBean.java:148)",
            "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemMBean.testWithFSNamesystemWriteLock$$CONFUZZ(TestFSNamesystemMBean.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "904"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testGetAclStatusRequiresTraverseOrSuper",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "260"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testPendingNodeButDecommissioned",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testPendingNodeButDecommissioned(TestDecommission.java:1355)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testPendingNodeButDecommissioned$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "256"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl",
        "testMethod": "testSetAclMinimal",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl.init(TestNameNodeAcl.java:32)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "767"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-104",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion",
        "testMethod": "testDeleteSnapshot1",
        "failure": "java.io.IOException",
        "errorMessage": "Tried to read 1 byte(s) past the limit at offset 8",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader$PositionTrackingInputStream.checkLimit(FSEditLogLoader.java:1352)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader$PositionTrackingInputStream.read(FSEditLogLoader.java:1359)",
            "java.base/java.io.DataInputStream.readByte(DataInputStream.java:270)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$LengthPrefixedReader.decodeOpFrame(FSEditLogOp.java:5237)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$LengthPrefixedReader.decodeOp(FSEditLogOp.java:5198)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$Reader.readOp(FSEditLogOp.java:5071)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream.nextOpImpl(EditLogFileInputStream.java:229)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream.nextOp(EditLogFileInputStream.java:276)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)",
            "org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.nextOp(RedundantEditLogInputStream.java:201)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:915)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:762)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:339)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loadNamesystem(NameNode.java:681)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:768)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNode(MiniDFSCluster.java:2246)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNodes(MiniDFSCluster.java:2201)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.testDeleteSnapshot1(TestSnapshotDeletion.java:606)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.testDeleteSnapshot1$$CONFUZZ(TestSnapshotDeletion.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.max.op.size": "0"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-104",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace",
        "testMethod": "testRTEWhileSavingSecondImage",
        "failure": "java.io.IOException",
        "errorMessage": "Tried to read 1 byte(s) past the limit at offset 12",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader$PositionTrackingInputStream.checkLimit(FSEditLogLoader.java:1352)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader$PositionTrackingInputStream.read(FSEditLogLoader.java:1359)",
            "java.base/java.io.DataInputStream.readInt(DataInputStream.java:395)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$LengthPrefixedReader.decodeOpFrame(FSEditLogOp.java:5251)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$LengthPrefixedReader.decodeOp(FSEditLogOp.java:5198)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogOp$Reader.readOp(FSEditLogOp.java:5071)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream.nextOpImpl(EditLogFileInputStream.java:229)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogFileInputStream.nextOp(EditLogFileInputStream.java:276)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)",
            "org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.nextOp(RedundantEditLogInputStream.java:201)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadEditRecords(FSEditLogLoader.java:243)",
            "org.apache.hadoop.hdfs.server.namenode.FSEditLogLoader.loadFSEdits(FSEditLogLoader.java:182)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.loadEdits(FSImage.java:915)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.loadFSImage(FSImage.java:762)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.recoverTransitionRead(FSImage.java:339)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFSImage(FSNamesystem.java:1201)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.loadFromDisk(FSNamesystem.java:779)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.saveNamespaceWithInjectedFault(TestSaveNamespace.java:240)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testRTEWhileSavingSecondImage(TestSaveNamespace.java:343)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testRTEWhileSavingSecondImage$$CONFUZZ(TestSaveNamespace.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.max.op.size": "4"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testWriteReadAndDeleteHalfABlock",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1543707946",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestHDFSFileSystemContract.setUp(TestHDFSFileSystemContract.java:46)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "945099495m"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testDecommissionTwoNodes",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1233502030",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:151)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "69869591h"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport",
        "testMethod": "testDiffReportWithOpenFiles",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-554856174",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDiffReport.setUp(TestSnapshotDiffReport.java:102)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "512239349h"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultMinimalAclNewFile",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-465623902",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "500432818h"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testRootDirEZTrash",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-669847294",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "5180814d"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandby",
        "testMethod": "testSharedEditsMissingLogs",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-957537406",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandby.setupCluster(TestBootstrapStandby.java:79)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "0690241d"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal",
        "testMethod": "testStatisticsForErasureCodingRead",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-938425396",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal.testStatisticsForErasureCodingRead(TestBlockReaderLocal.java:822)",
            "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal.testStatisticsForErasureCodingRead$$CONFUZZ(TestBlockReaderLocal.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "26818514d"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.TestFileCreation",
        "testMethod": "testServerDefaultsWithMinimalCaching",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-134909822",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithMinimalCaching(TestFileCreation.java:251)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithMinimalCaching$$CONFUZZ(TestFileCreation.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "116562775d"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus",
        "testMethod": "testListFilesEmptyDirectoryRecursive",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-697698046",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus.createCluster(TestHDFSContractGetFileStatus.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "705278d"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor",
        "testMethod": "testDecommissionDeadDN",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1239734466",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.createCluster(TestDecommissioningStatus.java:122)",
            "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor.setUp(TestDecommissioningStatusWithBackoffMonitor.java:68)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "29421981h"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks",
        "testMethod": "testSkewedRack2",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1996745470",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.DFSTestUtil.setupCluster(DFSTestUtil.java:2491)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.setupCluster(TestErasureCodingMultipleRacks.java:96)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2(TestErasureCodingMultipleRacks.java:131)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2$$CONFUZZ(TestErasureCodingMultipleRacks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "6595334d"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot",
        "testMethod": "testDatanodeRestarts",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-2004724170",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot.testDatanodeRestarts(TestStandbyIsHot.java:146)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot.testDatanodeRestarts$$CONFUZZ(TestStandbyIsHot.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "548767535m"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.TestFileAppend3",
        "testMethod": "testAppendToPartialChunk",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1429926471",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileAppend3.setUp(TestFileAppend3.java:80)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "85737628d"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testSetPermissionCannotSetAclBit",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1437028862",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "911044d"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot",
        "testMethod": "testUCFileDeleteWithSnapShot",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1430676510",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot.setup(TestOpenFilesWithSnapshot.java:70)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "9943414h"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemMBean",
        "testMethod": "testWithFSNamesystemWriteLock",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-789373182",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemMBean.testWithFSNamesystemWriteLock(TestFSNamesystemMBean.java:148)",
            "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemMBean.testWithFSNamesystemWriteLock$$CONFUZZ(TestFSNamesystemMBean.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "346434898d"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testBasicOperations",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1927040830",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "695255740h"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot",
        "testMethod": "testXAttrForSnapshotRootAfterChange",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-571275774",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot.initCluster(TestXAttrWithSnapshot.java:401)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot.init(TestXAttrWithSnapshot.java:78)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "625322132d"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.TestFileStatus",
        "testMethod": "testListStatusOnFile",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1574229726",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileStatus.testSetUp(TestFileStatus.java:70)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "403449370h"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-53",
        "testClass": "org.apache.hadoop.hdfs.TestFileAppend",
        "testMethod": "testAppend2Twice",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1243073590",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileAppend.testAppend2Twice(TestFileAppend.java:356)",
            "org.apache.hadoop.hdfs.TestFileAppend.testAppend2Twice$$CONFUZZ(TestFileAppend.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "970152358m"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testWriteReadAndDeleteHalfABlock",
        "failure": "org.junit.runners.model.TestTimedOutException",
        "errorMessage": "test timed out after 30000 milliseconds",
        "stackTrace": [
            "java.base@11.0.19/java.lang.Thread.sleep(Native Method)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.waitActive(MiniDFSCluster.java:2771)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.waitActive(MiniDFSCluster.java:2820)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1795)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "app//org.apache.hadoop.hdfs.TestHDFSFileSystemContract.setUp(TestHDFSFileSystemContract.java:46)",
            "java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566)",
            "app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "app//org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base@11.0.19/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.heartbeat.recheck-interval": "1693287612"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testWriteReadAndDeleteHalfABlock",
        "failure": "org.junit.runners.model.TestTimedOutException",
        "errorMessage": "test timed out after 30000 milliseconds",
        "stackTrace": [
            "java.base@11.0.19/java.lang.Thread.sleep(Native Method)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:973)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:909)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:892)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "app//org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "app//org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "app//org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(FileSystemContractBaseTest.java:932)",
            "app//org.apache.hadoop.fs.FileSystemContractBaseTest.writeReadAndDelete(FileSystemContractBaseTest.java:359)",
            "app//org.apache.hadoop.fs.FileSystemContractBaseTest.testWriteReadAndDeleteHalfABlock(FileSystemContractBaseTest.java:333)",
            "app//org.apache.hadoop.hdfs.TestHDFSFileSystemContract.testWriteReadAndDeleteHalfABlock$$CONFUZZ(TestHDFSFileSystemContract.java)",
            "java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566)",
            "app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base@11.0.19/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.block.write.locateFollowingBlock.initial.delay.ms": "343185681"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-110",
        "testClass": "org.apache.hadoop.hdfs.TestQuota",
        "testMethod": "testBlockAllocationAdjustsUsageConservatively",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "timeouts can't be negative",
        "stackTrace": [
            "java.base/sun.net.www.protocol.http.HttpURLConnection.setConnectTimeout(HttpURLConnection.java:3304)",
            "org.apache.hadoop.hdfs.web.SSLConnectionConfigurator.configure(SSLConnectionConfigurator.java:64)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:191)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:160)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:758)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:736)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getContentSummary(WebHdfsFileSystem.java:1886)",
            "org.apache.hadoop.hdfs.TestQuota.testBlockAllocationAdjustsUsageConservatively(TestQuota.java:1098)",
            "org.apache.hadoop.hdfs.TestQuota.testBlockAllocationAdjustsUsageConservatively$$CONFUZZ(TestQuota.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.socket.connect-timeout": "1809h"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-110",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntries",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "timeouts can't be negative",
        "stackTrace": [
            "java.base/sun.net.www.protocol.http.HttpURLConnection.setConnectTimeout(HttpURLConnection.java:3304)",
            "org.apache.hadoop.hdfs.web.SSLConnectionConfigurator.configure(SSLConnectionConfigurator.java:64)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:191)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:160)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:758)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:736)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.mkdirs(WebHdfsFileSystem.java:1142)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:750)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testModifyAclEntries(FSAclBaseTest.java:118)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testModifyAclEntries$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.socket.connect-timeout": "387222d"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-110",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testRemoveAclOnlyDefault",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "timeouts can't be negative",
        "stackTrace": [
            "java.base/sun.net.www.protocol.http.HttpURLConnection.setConnectTimeout(HttpURLConnection.java:3304)",
            "org.apache.hadoop.hdfs.web.SSLConnectionConfigurator.configure(SSLConnectionConfigurator.java:64)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:191)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:160)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:758)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:736)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.mkdirs(WebHdfsFileSystem.java:1142)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:750)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testRemoveAclOnlyDefault(FSAclBaseTest.java:624)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testRemoveAclOnlyDefault$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.socket.connect-timeout": "75772301d"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-110",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testRemoveAclEntriesMustBeOwnerOrSuper",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "timeouts can't be negative",
        "stackTrace": [
            "java.base/sun.net.www.protocol.http.HttpURLConnection.setConnectTimeout(HttpURLConnection.java:3304)",
            "org.apache.hadoop.hdfs.web.SSLConnectionConfigurator.configure(SSLConnectionConfigurator.java:64)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:191)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:160)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:758)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:736)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.mkdirs(WebHdfsFileSystem.java:1142)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testRemoveAclEntriesMustBeOwnerOrSuper(FSAclBaseTest.java:1340)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testRemoveAclEntriesMustBeOwnerOrSuper$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.socket.connect-timeout": "400223707h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger",
        "testMethod": "testMetricsLoggerOnByDefault",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.loginAsNameNodeUser(NameNode.java:719)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:738)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger$TestNameNode.<init>(TestNameNodeMetricsLogger.java:138)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.makeNameNode(TestNameNodeMetricsLogger.java:118)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault(TestNameNodeMetricsLogger.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMetricsLogger.testMetricsLoggerOnByDefault$$CONFUZZ(TestNameNodeMetricsLogger.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace",
        "testMethod": "testSaveNamespaceWithRenamedLease",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease(TestSaveNamespace.java:622)",
            "org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease$$CONFUZZ(TestSaveNamespace.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.tools.TestGetGroups",
        "testMethod": "testExistingInterleavedWithNonExistentUsers",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.tools.TestGetGroups.setUpNameNode(TestGetGroups.java:40)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileCreation",
        "testMethod": "testServerDefaultsWithMinimalCaching",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithMinimalCaching(TestFileCreation.java:251)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithMinimalCaching$$CONFUZZ(TestFileCreation.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsPathWithSemicolon",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsPathWithSemicolon(TestWebHdfsUrl.java:514)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsPathWithSemicolon$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache",
        "testMethod": "testRetryCacheRebuild",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.setup(TestNamenodeRetryCache.java:104)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testRecommission",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testRecommission(TestDecommission.java:435)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testRecommission$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS",
        "testMethod": "testReencryptionKMSACLs",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestReencryption.setup(TestReencryption.java:129)",
            "org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS.setup(TestReencryptionWithKMS.java:60)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFSImage",
        "testMethod": "testLoadMtimeAtime",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFSImage.testLoadMtimeAtime(TestFSImage.java:373)",
            "org.apache.hadoop.hdfs.server.namenode.TestFSImage.testLoadMtimeAtime$$CONFUZZ(TestFSImage.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS",
        "testMethod": "testRestartDuringReencrypt",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestReencryption.setup(TestReencryption.java:129)",
            "org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS.setup(TestReencryptionWithKMS.java:60)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testClusterStats",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testClusterStats(TestDecommission.java:528)",
            "org.apache.hadoop.hdfs.TestDecommission.testClusterStats(TestDecommission.java:512)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testClusterStats$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS",
        "testMethod": "testWarmupEDEKCacheOnStartup",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS.setup(TestEncryptionZonesWithKMS.java:64)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testAppend",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestHDFSFileSystemContract.setUp(TestHDFSFileSystemContract.java:46)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA",
        "testMethod": "testMultipleExistingUsers",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA.setUpNameNode(TestGetGroupsWithHA.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testCount",
        "failure": "java.io.IOException",
        "errorMessage": "Running in secure mode, but config doesn't have a keytab",
        "stackTrace": [
            "org.apache.hadoop.security.SecurityUtil.login(SecurityUtil.java:308)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1232)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testReaderWhileAnotherWrites",
        "failure": "org.apache.hadoop.hdfs.qjournal.client.QuorumException",
        "errorMessage": "Could not format one or more JournalNodes. 3 exceptions thrown:127.0.0.1:37513: Call From 04c076bd0267/172.17.0.2 to localhost:37513 failed on socket timeout exception: java.net.SocketTimeoutException: 31 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:33628 remote=/127.0.0.1:37513]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout127.0.0.1:39373: Call From 04c076bd0267/172.17.0.2 to localhost:39373 failed on socket timeout exception: java.net.SocketTimeoutException: 31 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:39670 remote=/127.0.0.1:39373]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout127.0.0.1:33647: Call From 04c076bd0267/172.17.0.2 to localhost:33647 failed on socket timeout exception: java.net.SocketTimeoutException: 31 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:42316 remote=/127.0.0.1:33647]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:305)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.format(QuorumJournalManager.java:264)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:117)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.client.rpc-timeout.ms": "31"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testChangeWritersLogsInSync",
        "failure": "org.apache.hadoop.hdfs.qjournal.client.QuorumException",
        "errorMessage": "Could not format one or more JournalNodes. 3 exceptions thrown:127.0.0.1:44583: Call From 9eb3ad918851/172.17.0.2 to localhost:44583 failed on socket timeout exception: java.net.SocketTimeoutException: 3 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:53922 remote=/127.0.0.1:44583]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout127.0.0.1:41391: Call From 9eb3ad918851/172.17.0.2 to localhost:41391 failed on socket timeout exception: java.net.SocketTimeoutException: 3 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:34756 remote=/127.0.0.1:41391]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout127.0.0.1:32795: Call From 9eb3ad918851/172.17.0.2 to localhost:32795 failed on socket timeout exception: java.net.SocketTimeoutException: 3 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/127.0.0.1:35254 remote=/127.0.0.1:32795]; For more details see:  http://wiki.apache.org/hadoop/SocketTimeout",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumException.create(QuorumException.java:81)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumCall.rethrowException(QuorumCall.java:305)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.format(QuorumJournalManager.java:264)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:117)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.client.rpc-timeout.ms": "3"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testReaderWhileAnotherWrites",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Time out while waiting for journal node 0 to start.",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:262)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:112)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.qjm.operations.timeout": "49933592h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testFormat",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Time out while waiting for journal node 0 to start.",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:262)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:112)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.qjm.operations.timeout": "59479316h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testReaderWhileAnotherWrites",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Attempted to use QJM output buffer capacity (524288) greater than the IPC max data length (ipc.maximum.data.length = 30166). This will cause journals to reject edits.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.setOutputBufferCapacity(QuorumJournalManager.java:457)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:194)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:121)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:251)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:245)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:449)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:421)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:245)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:112)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "30166"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testFormat",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Attempted to use QJM output buffer capacity (524288) greater than the IPC max data length (ipc.maximum.data.length = 515). This will cause journals to reject edits.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.setOutputBufferCapacity(QuorumJournalManager.java:457)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:194)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:121)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:251)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:245)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:449)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:421)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:245)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:112)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "515"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testInProgressRecovery",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Attempted to use QJM output buffer capacity (524288) greater than the IPC max data length (ipc.maximum.data.length = 8). This will cause journals to reject edits.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.setOutputBufferCapacity(QuorumJournalManager.java:457)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:194)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:121)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:251)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:245)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:449)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:421)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:245)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:112)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "8"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique",
        "testMethod": "testSingleThreaded",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Attempted to use QJM output buffer capacity (524288) greater than the IPC max data length (ipc.maximum.data.length = 23035). This will cause journals to reject edits.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.setOutputBufferCapacity(QuorumJournalManager.java:457)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:194)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:121)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:251)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:245)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:449)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:421)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:245)",
            "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique.testSingleThreaded(TestEpochsAreUnique.java:55)",
            "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique.testSingleThreaded$$CONFUZZ(TestEpochsAreUnique.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "23035"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testOutOfSyncAtBeginningOfSegment0",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Attempted to use QJM output buffer capacity (524288) greater than the IPC max data length (ipc.maximum.data.length = 6924). This will cause journals to reject edits.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.setOutputBufferCapacity(QuorumJournalManager.java:457)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:194)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:121)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:251)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:245)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:449)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:421)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:245)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:112)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "6924"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testChangeWritersLogsInSync",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Attempted to use QJM output buffer capacity (524288) greater than the IPC max data length (ipc.maximum.data.length = 66). This will cause journals to reject edits.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.setOutputBufferCapacity(QuorumJournalManager.java:457)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:194)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:121)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:251)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:245)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:449)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:421)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:245)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:112)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "66"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testSelectViaRpcTwoDeadJNs",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Attempted to use QJM output buffer capacity (524288) greater than the IPC max data length (ipc.maximum.data.length = 25962). This will cause journals to reject edits.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.setOutputBufferCapacity(QuorumJournalManager.java:457)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:194)",
            "org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager.<init>(QuorumJournalManager.java:121)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:251)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$1.get(MiniJournalCluster.java:245)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:449)",
            "org.apache.hadoop.test.GenericTestUtils.waitFor(GenericTestUtils.java:421)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.waitActive(MiniJournalCluster.java:245)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:112)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "25962"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testObserverToActive",
        "failure": "java.net.UnknownHostException",
        "errorMessage": "namenode0.test",
        "stackTrace": [
            "java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)",
            "java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)",
            "java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)",
            "java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)",
            "org.apache.hadoop.net.DNSDomainNameResolver.getAllByDomainName(DNSDomainNameResolver.java:33)",
            "org.apache.hadoop.net.DNSDomainNameResolver.getAllResolvedHostnameByDomainName(DNSDomainNameResolver.java:49)",
            "org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider.getResolvedHostsIfNecessary(AbstractNNFailoverProxyProvider.java:240)",
            "org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider.getProxyAddresses(AbstractNNFailoverProxyProvider.java:183)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:51)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:45)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider.<init>(ObserverReadProxyProvider.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider$2.<init>(TestObserverReadProxyProvider.java:116)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.setupProxyProvider(TestObserverReadProxyProvider.java:106)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testObserverToActive(TestObserverReadProxyProvider.java:219)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testObserverToActive$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.resolve-needed.testcluster": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testWithNonClientProxy",
        "failure": "java.net.UnknownHostException",
        "errorMessage": "namenode0.test",
        "stackTrace": [
            "java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)",
            "java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)",
            "java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)",
            "java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)",
            "org.apache.hadoop.net.DNSDomainNameResolver.getAllByDomainName(DNSDomainNameResolver.java:33)",
            "org.apache.hadoop.net.DNSDomainNameResolver.getAllResolvedHostnameByDomainName(DNSDomainNameResolver.java:49)",
            "org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider.getResolvedHostsIfNecessary(AbstractNNFailoverProxyProvider.java:240)",
            "org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider.getProxyAddresses(AbstractNNFailoverProxyProvider.java:183)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:51)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:45)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider.<init>(ObserverReadProxyProvider.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider$2.<init>(TestObserverReadProxyProvider.java:116)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.setupProxyProvider(TestObserverReadProxyProvider.java:106)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testWithNonClientProxy(TestObserverReadProxyProvider.java:130)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testWithNonClientProxy$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.resolve-needed.testcluster": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testReadOperationOnObserver",
        "failure": "java.net.UnknownHostException",
        "errorMessage": "namenode0.test",
        "stackTrace": [
            "java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)",
            "java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)",
            "java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)",
            "java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)",
            "org.apache.hadoop.net.DNSDomainNameResolver.getAllByDomainName(DNSDomainNameResolver.java:33)",
            "org.apache.hadoop.net.DNSDomainNameResolver.getAllResolvedHostnameByDomainName(DNSDomainNameResolver.java:49)",
            "org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider.getResolvedHostsIfNecessary(AbstractNNFailoverProxyProvider.java:240)",
            "org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider.getProxyAddresses(AbstractNNFailoverProxyProvider.java:183)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:51)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:45)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider.<init>(ObserverReadProxyProvider.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider$2.<init>(TestObserverReadProxyProvider.java:116)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.setupProxyProvider(TestObserverReadProxyProvider.java:106)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testReadOperationOnObserver(TestObserverReadProxyProvider.java:155)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testReadOperationOnObserver$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.resolve-needed.testcluster": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testUnreachableObserverWithMultiple",
        "failure": "java.net.UnknownHostException",
        "errorMessage": "namenode0.test",
        "stackTrace": [
            "java.base/java.net.InetAddress$CachedAddresses.get(InetAddress.java:797)",
            "java.base/java.net.InetAddress.getAllByName0(InetAddress.java:1533)",
            "java.base/java.net.InetAddress.getAllByName(InetAddress.java:1386)",
            "java.base/java.net.InetAddress.getAllByName(InetAddress.java:1307)",
            "org.apache.hadoop.net.DNSDomainNameResolver.getAllByDomainName(DNSDomainNameResolver.java:33)",
            "org.apache.hadoop.net.DNSDomainNameResolver.getAllResolvedHostnameByDomainName(DNSDomainNameResolver.java:49)",
            "org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider.getResolvedHostsIfNecessary(AbstractNNFailoverProxyProvider.java:240)",
            "org.apache.hadoop.hdfs.server.namenode.ha.AbstractNNFailoverProxyProvider.getProxyAddresses(AbstractNNFailoverProxyProvider.java:183)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:51)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider.<init>(ConfiguredFailoverProxyProvider.java:45)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider.<init>(ObserverReadProxyProvider.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider$2.<init>(TestObserverReadProxyProvider.java:116)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.setupProxyProvider(TestObserverReadProxyProvider.java:106)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testUnreachableObserverWithMultiple(TestObserverReadProxyProvider.java:187)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testUnreachableObserverWithMultiple$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.resolve-needed.testcluster": "true"
        }
    },
    {
        "status": "FLAKY",
        "bugId": "Bug-125",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testObserverToActive",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "No writes!",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider$NameNodeAnswer$ClientProtocolAnswer.answer(TestObserverReadProxyProvider.java:398)",
            "org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:39)",
            "org.mockito.internal.handler.MockHandlerImpl.handle(MockHandlerImpl.java:96)",
            "org.mockito.internal.handler.NullResultGuardian.handle(NullResultGuardian.java:29)",
            "org.mockito.internal.handler.InvocationNotifierHandler.handle(InvocationNotifierHandler.java:35)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:61)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:49)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor$DispatcherDefaultingToRealMethod.interceptAbstract(MockMethodInterceptor.java:126)",
            "org.apache.hadoop.hdfs.protocol.ClientProtocol$MockitoMock$494868196.reportBadBlocks(Unknown Source)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider$ObserverReadInvocationHandler.invoke(ObserverReadProxyProvider.java:519)",
            "com.sun.proxy.$Proxy36.reportBadBlocks(Unknown Source)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.doWrite(TestObserverReadProxyProvider.java:341)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.doWrite(TestObserverReadProxyProvider.java:332)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testObserverToActive(TestObserverReadProxyProvider.java:238)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testObserverToActive$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.random.order": "true"
        }
    },
    {
        "status": "FLAKY",
        "bugId": "Bug-125",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider",
        "testMethod": "testWriteOperationOnActive",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "No writes!",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider$NameNodeAnswer$ClientProtocolAnswer.answer(TestObserverReadProxyProvider.java:398)",
            "org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:39)",
            "org.mockito.internal.handler.MockHandlerImpl.handle(MockHandlerImpl.java:96)",
            "org.mockito.internal.handler.NullResultGuardian.handle(NullResultGuardian.java:29)",
            "org.mockito.internal.handler.InvocationNotifierHandler.handle(InvocationNotifierHandler.java:35)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:61)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:49)",
            "org.mockito.internal.creation.bytebuddy.MockMethodInterceptor$DispatcherDefaultingToRealMethod.interceptAbstract(MockMethodInterceptor.java:126)",
            "org.apache.hadoop.hdfs.protocol.ClientProtocol$MockitoMock$2060723153.reportBadBlocks(Unknown Source)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.hdfs.server.namenode.ha.ObserverReadProxyProvider$ObserverReadInvocationHandler.invoke(ObserverReadProxyProvider.java:519)",
            "com.sun.proxy.$Proxy36.reportBadBlocks(Unknown Source)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.doWrite(TestObserverReadProxyProvider.java:341)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.doWrite(TestObserverReadProxyProvider.java:332)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testWriteOperationOnActive(TestObserverReadProxyProvider.java:169)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestObserverReadProxyProvider.testWriteOperationOnActive$$CONFUZZ(TestObserverReadProxyProvider.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.client.failover.random.order": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints",
        "testMethod": "testBothNodesInStandbyState",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Expected non-empty /home/ctestfuzz/fuzz-hadoop/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000012",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil.assertNNHasCheckpoints(FSImageTestUtil.java:515)",
            "org.apache.hadoop.hdfs.server.namenode.ha.HATestUtil.waitForCheckpoint(HATestUtil.java:347)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints.testBothNodesInStandbyState(TestStandbyCheckpoints.java:245)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints.testBothNodesInStandbyState$$CONFUZZ(TestStandbyCheckpoints.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.ha.standby.checkpoints": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testUMaskDefaultAclNewFile",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=931) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testUMaskDefaultAclNewFile(FSAclBaseTest.java:934)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.testUMaskDefaultAclNewFile$$CONFUZZ(TestFileContextAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "931"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testStat",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=767) must divide block size (=1024).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.TestDFSShell.testStat(TestDFSShell.java:2063)",
            "org.apache.hadoop.hdfs.TestDFSShell.testStat$$CONFUZZ(TestDFSShell.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement",
        "testMethod": "testInvalidateBlock",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=886) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:902)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:924)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock(TestStandbyBlockManagement.java:72)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyBlockManagement.testInvalidateBlock$$CONFUZZ(TestStandbyBlockManagement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "886"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsck",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=13018) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFiles(DFSTestUtil.java:411)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFiles(DFSTestUtil.java:368)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck(TestFsck.java:221)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "13018"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate",
        "testMethod": "testUpdateQuotaForAppend",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=23156) must divide block size (=1024).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate.testUpdateQuotaForAppend(TestDiskspaceQuotaUpdate.java:143)",
            "org.apache.hadoop.hdfs.server.namenode.TestDiskspaceQuotaUpdate.testUpdateQuotaForAppend$$CONFUZZ(TestDiskspaceQuotaUpdate.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "23156"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultMinimalAclNewFile",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=20653) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testDefaultMinimalAclNewFile(FSAclBaseTest.java:981)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.testDefaultMinimalAclNewFile$$CONFUZZ(TestFileContextAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "20653"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=767) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest$20.run(FSXAttrBaseTest.java:1182)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.testRawXAttrs(FSXAttrBaseTest.java:1178)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr.testRawXAttrs$$CONFUZZ(TestFileContextXAttr.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testPut",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=696) must divide block size (=1024).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:418)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391)",
            "org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2482)",
            "org.apache.hadoop.hdfs.TestDFSShell.testPut(TestDFSShell.java:598)",
            "org.apache.hadoop.hdfs.TestDFSShell.testPut$$CONFUZZ(TestDFSShell.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "696"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename",
        "testMethod": "testRenameNewFileSameDir",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=3) must divide block size (=1048576).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183)",
            "org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152)",
            "org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameNewFileSameDir(AbstractContractRenameTest.java:43)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename.testRenameNewFileSameDir$$CONFUZZ(TestHDFSContractRename.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "3"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=899) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testRemoveAclEntriesMustBeOwnerOrSuper(FSAclBaseTest.java:1342)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.testRemoveAclEntriesMustBeOwnerOrSuper$$CONFUZZ(TestFileContextAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "899"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.shell.TestHdfsTextCommand",
        "testMethod": "testDisplayForAvroFiles",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=27868) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.fs.shell.TestHdfsTextCommand.createAvroFile(TestHdfsTextCommand.java:115)",
            "org.apache.hadoop.fs.shell.TestHdfsTextCommand.testDisplayForAvroFiles(TestHdfsTextCommand.java:78)",
            "org.apache.hadoop.fs.shell.TestHdfsTextCommand.testDisplayForAvroFiles$$CONFUZZ(TestHdfsTextCommand.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "27868"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveDefaultAclMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=959) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testRemoveDefaultAclMustBeOwnerOrSuper(FSAclBaseTest.java:1358)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.testRemoveDefaultAclMustBeOwnerOrSuper$$CONFUZZ(TestFileContextAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "959"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestMaintenanceState",
        "testMethod": "testInvalidation",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=9382) must divide block size (=8192).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.writeFile(AdminStatesBaseTest.java:136)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.writeFile(AdminStatesBaseTest.java:129)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.writeFile(AdminStatesBaseTest.java:124)",
            "org.apache.hadoop.hdfs.TestMaintenanceState.testInvalidation(TestMaintenanceState.java:943)",
            "org.apache.hadoop.hdfs.TestMaintenanceState.testInvalidation$$CONFUZZ(TestMaintenanceState.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "9382"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testGetTrashRoots",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=15374) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.testGetTrashRoots(TestEncryptionZones.java:1910)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.testGetTrashRoots$$CONFUZZ(TestEncryptionZones.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "15374"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages",
        "testMethod": "testChangedStorageId",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=7) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages.testChangedStorageId(TestPendingCorruptDnMessages.java:66)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestPendingCorruptDnMessages.testChangedStorageId$$CONFUZZ(TestPendingCorruptDnMessages.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "7"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus",
        "testMethod": "testListLocatedStatusFile",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=6746) must divide block size (=1024).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636)",
            "org.apache.hadoop.fs.contract.ContractTestUtils.touch(ContractTestUtils.java:672)",
            "org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.touchf(AbstractContractGetFileStatusTest.java:466)",
            "org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.testListLocatedStatusFile(AbstractContractGetFileStatusTest.java:426)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus.testListLocatedStatusFile$$CONFUZZ(TestHDFSContractGetFileStatus.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "6746"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testDu",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=32468) must divide block size (=1024).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.TestDFSShell.writeFile(TestDFSShell.java:139)",
            "org.apache.hadoop.hdfs.TestDFSShell.testDu(TestDFSShell.java:254)",
            "org.apache.hadoop.hdfs.TestDFSShell.testDu$$CONFUZZ(TestDFSShell.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "32468"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestLease",
        "testMethod": "testFactory",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid checksum type: userOpt=null, default=CRC32C:0, effective=null",
        "stackTrace": [
            "org.apache.hadoop.hdfs.client.impl.DfsClientConf.createChecksum(DfsClientConf.java:395)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1273)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1155)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1134)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1105)",
            "org.apache.hadoop.hdfs.TestLease.createFsOut(TestLease.java:398)",
            "org.apache.hadoop.hdfs.TestLease.testFactory(TestLease.java:380)",
            "org.apache.hadoop.hdfs.TestLease.testFactory$$CONFUZZ(TestLease.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestLease",
        "testMethod": "testFactory",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=562) must divide block size (=1024).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1155)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1134)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1105)",
            "org.apache.hadoop.hdfs.TestLease.createFsOut(TestLease.java:398)",
            "org.apache.hadoop.hdfs.TestLease.testFactory(TestLease.java:380)",
            "org.apache.hadoop.hdfs.TestLease.testFactory$$CONFUZZ(TestLease.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "562"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager",
        "testMethod": "testNeededReconstructionWhileAppending",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=16875551) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testNeededReconstructionWhileAppending(TestBlockManager.java:469)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testNeededReconstructionWhileAppending$$CONFUZZ(TestBlockManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "16875551"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testUMaskDefaultAclNewFile",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "520060671"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testGetAclStatusRequiresTraverseOrSuper",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "117407487"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl",
        "testMethod": "testSetAclCustomMask",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl.init(TestNameNodeAcl.java:32)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "2130047"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesOnlyAccess",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "1506520789"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMinimal",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "1725273842"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.TestExtendedAcls",
        "testMethod": "testRestrictAtSubDir",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestExtendedAcls.setup(TestExtendedAcls.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "6340607"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS",
        "testMethod": "testRead",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead(TestBlockTokenWithDFS.java:357)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead$$CONFUZZ(TestBlockTokenWithDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "16809984"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testDefaultAclRenamedDir",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "279089807"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer",
        "testMethod": "testBalancer0Integrity",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:681)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:642)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:636)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.oneNodeTest(TestBalancer.java:953)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testBalancer0Internal(TestBalancer.java:1068)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Integrity(TestBalancerWithSaslDataTransfer.java:34)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Integrity$$CONFUZZ(TestBalancerWithSaslDataTransfer.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "12172699"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testSetAclOnlyAccess",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "34619423"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testBlockReadZeroByteFile",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek.createCluster(TestHDFSContractSeek.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "33685382"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand",
        "testMethod": "testRunMultipleCommandsUnderOneSetup",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand.setUp(TestDiskBalancerCommand.java:96)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "943205422"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks",
        "testMethod": "testSkewedRack2",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.DFSTestUtil.setupCluster(DFSTestUtil.java:2491)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.setupCluster(TestErasureCodingMultipleRacks.java:96)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2(TestErasureCodingMultipleRacks.java:131)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2$$CONFUZZ(TestErasureCodingMultipleRacks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "169198600"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamUpdatePipeline",
        "testMethod": "testDFSStripedOutputStreamUpdatePipeline",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamUpdatePipeline.testDFSStripedOutputStreamUpdatePipeline(TestDFSStripedOutputStreamUpdatePipeline.java:37)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamUpdatePipeline.testDFSStripedOutputStreamUpdatePipeline$$CONFUZZ(TestDFSStripedOutputStreamUpdatePipeline.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "1340013650"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultAclNewSymlinkIntermediate",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "2130640638"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean",
        "testMethod": "testNNDirectorySize",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testNNDirectorySize(TestNameNodeMXBean.java:838)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testNNDirectorySize$$CONFUZZ(TestNameNodeMXBean.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "269648128"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename",
        "testMethod": "testRenamePopulatesDirectoryAncestors",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename.createCluster(TestHDFSContractRename.java:33)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "873500719"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testErrOutPut",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "4294656"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.TestAppendSnapshotTruncate",
        "testMethod": "testAST",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestAppendSnapshotTruncate.startUp(TestAppendSnapshotTruncate.java:94)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "1337101663"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-103",
        "testClass": "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure",
        "testMethod": "testAddBlockWhenNoSufficientParityNumOfNodes",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Test resulted in an unexpected exit",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2115)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2102)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(MiniDFSCluster.java:2095)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:979)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailureBase.setup(TestDFSStripedOutputStreamWithFailureBase.java:208)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testAddBlockWhenNoSufficientParityNumOfNodes(TestDFSStripedOutputStreamWithFailure.java:209)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure.testAddBlockWhenNoSufficientParityNumOfNodes$$CONFUZZ(TestDFSStripedOutputStreamWithFailure.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "86028946"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "java.net.BindException",
        "errorMessage": "Address already in use",
        "stackTrace": [
            "java.base/sun.nio.ch.Net.bind0(Native Method)",
            "java.base/sun.nio.ch.Net.bind(Net.java:459)",
            "java.base/sun.nio.ch.Net.bind(Net.java:448)",
            "java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)",
            "java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)",
            "org.apache.hadoop.ipc.Server.bind(Server.java:631)",
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1233)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNode(MiniDFSCluster.java:2246)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNode(MiniDFSCluster.java:2227)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testOpenFileWhenNNAndClientCrashAfterAddBlock(TestHASafeMode.java:840)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testOpenFileWhenNNAndClientCrashAfterAddBlock$$CONFUZZ(TestHASafeMode.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.reuseaddr": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart",
        "testMethod": "testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister",
        "failure": "java.net.BindException",
        "errorMessage": "Address already in use",
        "stackTrace": [
            "java.base/sun.nio.ch.Net.bind0(Native Method)",
            "java.base/sun.nio.ch.Net.bind(Net.java:459)",
            "java.base/sun.nio.ch.Net.bind(Net.java:448)",
            "java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)",
            "java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)",
            "org.apache.hadoop.ipc.Server.bind(Server.java:631)",
            "org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1233)",
            "org.apache.hadoop.ipc.Server.<init>(Server.java:3127)",
            "org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371)",
            "org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.<init>(NameNodeRpcServer.java:466)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createRpcServer(NameNode.java:865)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:771)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNode(MiniDFSCluster.java:2246)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.restartNameNode(MiniDFSCluster.java:2211)",
            "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart.testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister(TestFileLengthOnClusterRestart.java:53)",
            "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart.testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister$$CONFUZZ(TestFileLengthOnClusterRestart.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.server.reuseaddr": "false"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-73",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testOpenFileWhenNNAndClientCrashAfterAddBlock",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSUtil.getBindAddress(DFSUtil.java:1191)",
            "org.apache.hadoop.hdfs.server.aliasmap.InMemoryLevelDBAliasMapServer.start(InMemoryLevelDBAliasMapServer.java:82)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startAliasMapServerIfNecessary(NameNode.java:809)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:769)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.provided.aliasmap.inmemory.enabled": "true",
            "dfs.namenode.provided.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsBackwardCompatibleSpecialCharacterFile",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskErrorException",
        "errorMessage": "Too many failed volumes - current valid volumes: 0, volumes configured: 2, volumes failed: 2, volume failures tolerated: 0",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:233)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile(TestWebHdfsUrl.java:460)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsBackwardCompatibleSpecialCharacterFile$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "4ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testFavoredNodesEndToEndForAppend",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskErrorException",
        "errorMessage": "Too many failed volumes - current valid volumes: 1, volumes configured: 2, volumes failed: 1, volume failures tolerated: 0",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:233)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.setUpBeforeClass(TestFavoredNodesEndToEnd.java:71)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "79ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.balancer.TestBalancer",
        "testMethod": "testUnknownDatanodeSimple",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskErrorException",
        "errorMessage": "Too many failed volumes - current valid volumes: 0, volumes configured: 1, volumes failed: 1, volume failures tolerated: 0",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:233)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.generateBlocks(TestBalancer.java:302)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanode(TestBalancer.java:998)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanodeSimple(TestBalancer.java:973)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.testUnknownDatanodeSimple$$CONFUZZ(TestBalancer.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "7ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier",
        "testMethod": "testWhenStoragePolicySetToONESSD",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskErrorException",
        "errorMessage": "Too many failed volumes - current valid volumes: 1, volumes configured: 2, volumes failed: 1, volume failures tolerated: 0",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:233)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.startCluster(TestExternalStoragePolicySatisfier.java:211)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.createCluster(TestExternalStoragePolicySatisfier.java:194)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWhenStoragePolicySetToONESSD(TestExternalStoragePolicySatisfier.java:480)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWhenStoragePolicySetToONESSD$$CONFUZZ(TestExternalStoragePolicySatisfier.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "35ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesOnlyDefault",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskErrorException",
        "errorMessage": "Too many failed volumes - current valid volumes: 0, volumes configured: 2, volumes failed: 2, volume failures tolerated: 0",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:233)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "011ms"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-28",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testCompleteEmptyUploadID",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.start(NameNodeRpcServer.java:579)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:880)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.createCluster(TestHDFSContractMultipartUploader.java:42)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "1077903103"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-28",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot",
        "testMethod": "testParentDirWithUCFileDeleteWithSnapShot",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.start(NameNodeRpcServer.java:579)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:880)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot.setup(TestOpenFilesWithSnapshot.java:70)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "1693442557"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-28",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testDeadNodeCountAfterNamenodeRestart",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.start(NameNodeRpcServer.java:579)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:880)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testDeadNodeCountAfterNamenodeRestart(TestDecommission.java:1184)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testDeadNodeCountAfterNamenodeRestart$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "1423279098"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-28",
        "testClass": "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamUpdatePipeline",
        "testMethod": "testDFSStripedOutputStreamUpdatePipeline",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.start(NameNodeRpcServer.java:579)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:880)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamUpdatePipeline.testDFSStripedOutputStreamUpdatePipeline(TestDFSStripedOutputStreamUpdatePipeline.java:37)",
            "org.apache.hadoop.hdfs.TestDFSStripedOutputStreamUpdatePipeline.testDFSStripedOutputStreamUpdatePipeline$$CONFUZZ(TestDFSStripedOutputStreamUpdatePipeline.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "1260054753"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-28",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testAddVolumeWithSameStorageUuid",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.start(NameNodeRpcServer.java:579)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:880)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testAddVolumeWithSameStorageUuid(TestFsDatasetImpl.java:366)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testAddVolumeWithSameStorageUuid$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "571574015"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-28",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean",
        "testMethod": "testNNDirectorySize",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.start(NameNodeRpcServer.java:579)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:880)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testNNDirectorySize(TestNameNodeMXBean.java:806)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testNNDirectorySize$$CONFUZZ(TestNameNodeMXBean.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "663781388"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-28",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore",
        "testMethod": "testStorageRestoreFailure",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.start(NameNodeRpcServer.java:579)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:880)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testStorageRestoreFailure(TestStorageRestore.java:397)",
            "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testStorageRestoreFailure$$CONFUZZ(TestStorageRestore.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "1117565892"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-65",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager",
        "testMethod": "testBasicReplication",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.getInServiceXceiverAverageByStorageType(BlockPlacementPolicyDefault.java:1044)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.getInServiceXceiverAverage(BlockPlacementPolicyDefault.java:1023)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.excludeNodeByLoad(BlockPlacementPolicyDefault.java:1000)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.isGoodDatanode(BlockPlacementPolicyDefault.java:1086)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:855)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:774)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:566)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:478)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:350)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:170)",
            "org.apache.hadoop.hdfs.server.blockmanagement.ReplicationWork.chooseTargets(ReplicationWork.java:51)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:2031)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.scheduleSingleReplication(TestBlockManager.java:641)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.doBasicTest(TestBlockManager.java:230)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testBasicReplication(TestBlockManager.java:221)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testBasicReplication$$CONFUZZ(TestBlockManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.redundancy.considerLoadByStorageType": "true"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-65",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager",
        "testMethod": "testOneOfTwoRacksDecommissioned",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.getInServiceXceiverAverageByStorageType(BlockPlacementPolicyDefault.java:1044)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.getInServiceXceiverAverage(BlockPlacementPolicyDefault.java:1023)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.excludeNodeByLoad(BlockPlacementPolicyDefault.java:1000)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.isGoodDatanode(BlockPlacementPolicyDefault.java:1086)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:855)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRemoteRack(BlockPlacementPolicyDefault.java:782)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTargetInOrder(BlockPlacementPolicyDefault.java:557)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:478)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:350)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:170)",
            "org.apache.hadoop.hdfs.server.blockmanagement.ReplicationWork.chooseTargets(ReplicationWork.java:51)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:2031)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.scheduleSingleReplication(TestBlockManager.java:641)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.doTestOneOfTwoRacksDecommissioned(TestBlockManager.java:364)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testOneOfTwoRacksDecommissioned(TestBlockManager.java:351)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testOneOfTwoRacksDecommissioned$$CONFUZZ(TestBlockManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.redundancy.considerLoadByStorageType": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager",
        "testMethod": "testSafeModeIBR",
        "failure": "org.apache.hadoop.hdfs.server.blockmanagement.UnresolvedTopologyException",
        "errorMessage": "Unresolved topology mapping for host host",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.resolveNetworkLocation(DatanodeManager.java:1030)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.registerDatanode(DatanodeManager.java:1250)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testSafeModeIBR(TestBlockManager.java:912)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testSafeModeIBR$$CONFUZZ(TestBlockManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.reject-unresolved-dn-topology-mapping": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager",
        "testMethod": "testgoodScript",
        "failure": "org.apache.hadoop.hdfs.server.blockmanagement.UnresolvedTopologyException",
        "errorMessage": "Unresolved topology mapping for host null",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.resolveNetworkLocation(DatanodeManager.java:1030)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.registerDatanode(DatanodeManager.java:1250)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.HelperFunction(TestDatanodeManager.java:407)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testgoodScript(TestDatanodeManager.java:322)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestDatanodeManager.testgoodScript$$CONFUZZ(TestDatanodeManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.reject-unresolved-dn-topology-mapping": "true"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-105",
        "testClass": "org.apache.hadoop.fs.permission.TestStickyBit",
        "testMethod": "testStickyBitRecursiveDeleteFile",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.start(NameNodeRpcServer.java:579)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:880)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.permission.TestStickyBit.initCluster(TestStickyBit.java:79)",
            "org.apache.hadoop.fs.permission.TestStickyBit.init(TestStickyBit.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.handler.count": "639821933",
            "ipc.server.handler.queue.size": "2141282303"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestSetTimes",
        "testMethod": "testGetBlockLocationsOnlyUsesReadLock",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Cannot create directory /. Name node is in safe mode.The reported blocks 0 has reached the threshold 0.9990 of total blocks 0. The number of live datanodes 0 needs an additional 1081223 live datanodes to reach the minimum number 1081223.Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3404)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1159)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:740)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy26.mkdirs(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:674)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy27.mkdirs(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2507)",
            "org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2483)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1485)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1482)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1499)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1474)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:456)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock(TestSetTimes.java:305)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock$$CONFUZZ(TestSetTimes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "1081223"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean",
        "testMethod": "testNNDirectorySize",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /. Name node is in safe mode.The reported blocks 0 has reached the threshold 0.9990 of total blocks 0. The number of live datanodes 0 needs an additional 821 live datanodes to reach the minimum number 821.Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1568) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3404) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1159) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:740) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)Caused by: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot create directory /. Name node is in safe mode.The reported blocks 0 has reached the threshold 0.9990 of total blocks 0. The number of live datanodes 0 needs an additional 821 live datanodes to reach the minimum number 821.Safe mode will be turned off automatically once the thresholds have been reached. NamenodeHostName:localhost at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564) ... 14 more",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy26.mkdirs(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:674)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy28.mkdirs(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2507)",
            "org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2483)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1485)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1482)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1499)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1474)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:456)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testNNDirectorySize(TestNameNodeMXBean.java:824)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeMXBean.testNNDirectorySize$$CONFUZZ(TestNameNodeMXBean.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.min.datanodes": "821"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestSetTimes",
        "testMethod": "testGetBlockLocationsOnlyUsesReadLock",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=26592) must divide block size (=912).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock(TestSetTimes.java:305)",
            "org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock$$CONFUZZ(TestSetTimes.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "912"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMinimal",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=512) must divide block size (=767).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testRemoveAclEntriesMinimal(FSAclBaseTest.java:368)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.testRemoveAclEntriesMinimal$$CONFUZZ(TestFileContextAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestExtendedAcls",
        "testMethod": "testRestrictAtSubDir",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=512) must divide block size (=531104006).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.TestExtendedAcls.testRestrictAtSubDir(TestExtendedAcls.java:365)",
            "org.apache.hadoop.hdfs.TestExtendedAcls.testRestrictAtSubDir$$CONFUZZ(TestExtendedAcls.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "531104006"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testRootDirEZTrash",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=512) must divide block size (=538053634).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.testRootDirEZTrash(TestEncryptionZones.java:1865)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.testRootDirEZTrash$$CONFUZZ(TestEncryptionZones.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "538053634"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSOutputStream",
        "testMethod": "testComputePacketChunkSize",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=512) must divide block size (=26887).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.TestDFSOutputStream.testComputePacketChunkSize(TestDFSOutputStream.java:130)",
            "org.apache.hadoop.hdfs.TestDFSOutputStream.testComputePacketChunkSize$$CONFUZZ(TestDFSOutputStream.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "26887"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testSetAclOnlyAccess",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=7) must divide block size (=543801866).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testSetAclOnlyAccess(FSAclBaseTest.java:671)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.testSetAclOnlyAccess$$CONFUZZ(TestFileContextAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "543801866"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=512) must divide block size (=601161730).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testRemoveAclMustBeOwnerOrSuper(FSAclBaseTest.java:1372)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.testRemoveAclMustBeOwnerOrSuper$$CONFUZZ(TestFileContextAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "601161730"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestParallelShortCircuitLegacyRead",
        "testMethod": "testParallelReadByteBuffer",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=662720255) must divide block size (=767).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.client.impl.BlockReaderTestUtil.writeFile(BlockReaderTestUtil.java:127)",
            "org.apache.hadoop.hdfs.TestParallelReadUtil.runParallelRead(TestParallelReadUtil.java:326)",
            "org.apache.hadoop.hdfs.TestParallelReadUtil.runTestWorkload(TestParallelReadUtil.java:382)",
            "org.apache.hadoop.hdfs.TestParallelReadUtil.testParallelReadByteBuffer(TestParallelReadUtil.java:411)",
            "org.apache.hadoop.hdfs.TestParallelShortCircuitLegacyRead.testParallelReadByteBuffer$$CONFUZZ(TestParallelShortCircuitLegacyRead.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDisableConnCache",
        "testMethod": "testDisableCache",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=512) must divide block size (=13018).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.client.impl.BlockReaderTestUtil.writeFile(BlockReaderTestUtil.java:127)",
            "org.apache.hadoop.hdfs.TestDisableConnCache.testDisableCache(TestDisableConnCache.java:54)",
            "org.apache.hadoop.hdfs.TestDisableConnCache.testDisableCache$$CONFUZZ(TestDisableConnCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "13018"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testSetAclMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=512) must divide block size (=13018).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testSetAclMustBeOwnerOrSuper(FSAclBaseTest.java:1386)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.testSetAclMustBeOwnerOrSuper$$CONFUZZ(TestFileContextAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "13018"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl",
        "testMethod": "testSetAclMinimal",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=512) must divide block size (=767).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:223)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testSetAclMinimal(FSAclBaseTest.java:708)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeAcl.testSetAclMinimal$$CONFUZZ(TestNameNodeAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsck",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 3 is less than the required minimum of 29 for /srcdat/seven/four/4824355616721279605, clientName=127.0.0.1        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy31.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFiles(DFSTestUtil.java:411)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFiles(DFSTestUtil.java:368)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck(TestFsck.java:221)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "29"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testWriteReadAndDeleteOneBlock",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 1 is less than the required minimum of 33 for /user/ctestfuzz/FileSystemContractBaseTest/writeReadAndDelete/file, clientName=127.0.0.1 at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(FileSystemContractBaseTest.java:927)",
            "org.apache.hadoop.fs.FileSystemContractBaseTest.writeReadAndDelete(FileSystemContractBaseTest.java:359)",
            "org.apache.hadoop.fs.FileSystemContractBaseTest.testWriteReadAndDeleteOneBlock(FileSystemContractBaseTest.java:338)",
            "org.apache.hadoop.hdfs.TestHDFSFileSystemContract.testWriteReadAndDeleteOneBlock$$CONFUZZ(TestHDFSFileSystemContract.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "33"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand",
        "testMethod": "testRunMultipleCommandsUnderOneSetup",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 1 is less than the required minimum of 215 for /ac85d5e9-7acc-46d0-a976-5389c5aedaae, clientName=127.0.0.1 at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.balancer.TestBalancer.createFile(TestBalancer.java:292)",
            "org.apache.hadoop.hdfs.server.diskbalancer.DiskBalancerTestUtil.newImbalancedCluster(DiskBalancerTestUtil.java:326)",
            "org.apache.hadoop.hdfs.server.diskbalancer.DiskBalancerTestUtil.newImbalancedCluster(DiskBalancerTestUtil.java:281)",
            "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand.testRunMultipleCommandsUnderOneSetup(TestDiskBalancerCommand.java:171)",
            "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand.testRunMultipleCommandsUnderOneSetup$$CONFUZZ(TestDiskBalancerCommand.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "215"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testWebHdfsPathWithSemicolon",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 1 is less than the required minimum of 8 for /a;b, clientName=127.0.0.1 at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner$1.close(WebHdfsFileSystem.java:1043)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsPathWithSemicolon(TestWebHdfsUrl.java:524)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testWebHdfsPathWithSemicolon$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "8"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader",
        "testMethod": "testMultipartUploadEmptyPart",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 2 is less than the required minimum of 403 for /testtestMultipartUpload_multipart_8549bef0-4ad8-4d79-8df1-77c1ee837220/1.part, clientName=127.0.0.1 at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$10.doCall(DistributedFileSystem.java:662)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$10.doCall(DistributedFileSystem.java:659)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.createNonRecursive(DistributedFileSystem.java:680)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.access$500(DistributedFileSystem.java:147)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$HdfsDataOutputStreamBuilder.build(DistributedFileSystem.java:3557)",
            "org.apache.hadoop.fs.impl.FileSystemMultipartUploader.innerPutPart(FileSystemMultipartUploader.java:144)",
            "org.apache.hadoop.fs.impl.FileSystemMultipartUploader.lambda$putPart$1(FileSystemMultipartUploader.java:119)",
            "org.apache.hadoop.fs.impl.FutureIOSupport.eval(FutureIOSupport.java:199)",
            "org.apache.hadoop.fs.impl.FileSystemMultipartUploader.putPart(FileSystemMultipartUploader.java:119)",
            "org.apache.hadoop.fs.contract.AbstractContractMultipartUploaderTest.testMultipartUploadEmptyPart(AbstractContractMultipartUploaderTest.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractMultipartUploader.testMultipartUploadEmptyPart$$CONFUZZ(TestHDFSContractMultipartUploader.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "403"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testReadFullySmallFile",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 2 is less than the required minimum of 25 for /test/seekfile.txt, clientName=127.0.0.1 at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636)",
            "org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "25"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot",
        "testMethod": "testDatanodeRestarts",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 1 is less than the required minimum of 443 for /testStandbyIsHot, clientName=127.0.0.1 at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy29.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy30.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot.testDatanodeRestarts(TestStandbyIsHot.java:154)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyIsHot.testDatanodeRestarts$$CONFUZZ(TestStandbyIsHot.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "443"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 1 is less than the required minimum of 68 for /foo/bar, clientName=127.0.0.1 at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy31.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest$20.run(FSXAttrBaseTest.java:1182)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.testRawXAttrs(FSXAttrBaseTest.java:1178)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSXAttr.testRawXAttrs$$CONFUZZ(TestWebHDFSXAttr.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "68"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS",
        "testMethod": "testRestartDuringReencrypt",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 1 is less than the required minimum of 290 for /zones/zone/dir2/f, clientName=127.0.0.1 at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy79.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy80.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.TestReencryption.testRestartDuringReencrypt(TestReencryption.java:473)",
            "org.apache.hadoop.hdfs.server.namenode.TestReencryptionWithKMS.testRestartDuringReencrypt$$CONFUZZ(TestReencryptionWithKMS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "290"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testClusterStats",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Requested replication factor of 1 is less than the required minimum of 140 for /user/ctestfuzz/testClusterStats.dat, clientName=127.0.0.1 at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.verifyReplication(BlockManager.java:1611) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2679) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:494)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.writeFile(AdminStatesBaseTest.java:136)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.writeFile(AdminStatesBaseTest.java:129)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.writeFile(AdminStatesBaseTest.java:124)",
            "org.apache.hadoop.hdfs.TestDecommission.testClusterStats(TestDecommission.java:533)",
            "org.apache.hadoop.hdfs.TestDecommission.testClusterStats(TestDecommission.java:512)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testClusterStats$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "140"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsck",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck(TestFsck.java:245)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.extension.testing": "13018"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFsck",
        "testMethod": "testFsck",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Expected getfileinfo event not found in audit log",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.verifyAuditLogs(TestFsck.java:281)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck(TestFsck.java:228)",
            "org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck$$CONFUZZ(TestFsck.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.audit.log.token.tracking.id": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.tools.TestDFSHAAdmin",
        "testMethod": "testTransitionToStandby",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<0> but was:<-1>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:120)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.tools.TestDFSHAAdmin.testTransitionToStandby(TestDFSHAAdmin.java:283)",
            "org.apache.hadoop.hdfs.tools.TestDFSHAAdmin.testTransitionToStandby$$CONFUZZ(TestDFSHAAdmin.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.ha.automatic-failover.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.tools.TestDFSHAAdmin",
        "testMethod": "testFencingConfigPerNameNode",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<0> but was:<-1>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:120)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.tools.TestDFSHAAdmin.testFencingConfigPerNameNode(TestDFSHAAdmin.java:414)",
            "org.apache.hadoop.hdfs.tools.TestDFSHAAdmin.testFencingConfigPerNameNode$$CONFUZZ(TestDFSHAAdmin.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.ha.automatic-failover.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.tools.TestDFSHAAdmin",
        "testMethod": "testFailoverWithNoFencerConfigured",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<-1> but was:<0>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:120)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.tools.TestDFSHAAdmin.testFailoverWithNoFencerConfigured(TestDFSHAAdmin.java:296)",
            "org.apache.hadoop.hdfs.tools.TestDFSHAAdmin.testFailoverWithNoFencerConfigured$$CONFUZZ(TestDFSHAAdmin.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.ha.automatic-failover.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testGetAclStatusRequiresTraverseOrSuper",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=512) must divide block size (=767).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner$1.close(WebHdfsFileSystem.java:1043)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testGetAclStatusRequiresTraverseOrSuper(FSAclBaseTest.java:1405)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testGetAclStatusRequiresTraverseOrSuper$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsTokens",
        "testMethod": "testLazyTokenFetchForWebhdfs",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=512) must divide block size (=1028).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner$1.close(WebHdfsFileSystem.java:1043)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.validateLazyTokenFetch(TestWebHdfsTokens.java:391)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.testLazyTokenFetchForWebhdfs(TestWebHdfsTokens.java:288)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsTokens.testLazyTokenFetchForWebhdfs$$CONFUZZ(TestWebHdfsTokens.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "1028"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testDefaultAclNewFileIntermediate",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=512) must divide block size (=483).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner$1.close(WebHdfsFileSystem.java:1043)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testDefaultAclNewFileIntermediate(FSAclBaseTest.java:1110)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testDefaultAclNewFileIntermediate$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blocksize": "483"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testTransferAndNativeCopyMetrics",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "configured value 171437102for dfs.datanode.cache.revocation.polling.ms is too high.  It must not be more than half of the value of dfs.datanode.cache.revocation.timeout.ms.  Reconfigure this to 450000",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.<init>(FsDatasetCache.java:174)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:375)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "171437102"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testMoveBlockFailure",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "configured value 1610743870for dfs.datanode.cache.revocation.polling.ms is too high.  It must not be more than half of the value of dfs.datanode.cache.revocation.timeout.ms.  Reconfigure this to 450000",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.<init>(FsDatasetCache.java:174)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:375)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "1610743870"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testDeletingBlocks",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "configured value 134250503for dfs.datanode.cache.revocation.polling.ms is too high.  It must not be more than half of the value of dfs.datanode.cache.revocation.timeout.ms.  Reconfigure this to 450000",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.<init>(FsDatasetCache.java:174)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:375)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "134250503"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testProvidedVolumeImpl",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "configured value 273728136for dfs.datanode.cache.revocation.polling.ms is too high.  It must not be more than half of the value of dfs.datanode.cache.revocation.timeout.ms.  Reconfigure this to 450000",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.<init>(FsDatasetCache.java:174)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:375)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.setUp(TestProvidedImpl.java:342)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "273728136"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testScannerWithProvidedVolumes",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "configured value 211029891for dfs.datanode.cache.revocation.polling.ms is too high.  It must not be more than half of the value of dfs.datanode.cache.revocation.timeout.ms.  Reconfigure this to 9507",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.<init>(FsDatasetCache.java:174)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:375)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.setUp(TestProvidedImpl.java:342)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "211029891"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testMoveBlockFailure",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Exception while testing testMoveBlockFailure",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testMoveBlockFailure(TestFsDatasetImpl.java:1003)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testMoveBlockFailure$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "899"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-31",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testTransferAndNativeCopyMetrics",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293)",
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.initializeCacheExecutor(FsVolumeImpl.java:213)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.<init>(FsVolumeImpl.java:184)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder.build(FsVolumeImplBuilder.java:93)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.addVolume(FsDatasetImpl.java:486)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:371)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.fsdatasetcache.max.threads.per.volume": "0"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-31",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testProvidedVolumeImpl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293)",
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.initializeCacheExecutor(FsVolumeImpl.java:213)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.<init>(FsVolumeImpl.java:184)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder.build(FsVolumeImplBuilder.java:93)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.addVolume(FsDatasetImpl.java:486)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:371)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.setUp(TestProvidedImpl.java:342)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.fsdatasetcache.max.threads.per.volume": "0"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-31",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testRemoveOneVolume",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293)",
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.initializeCacheExecutor(FsVolumeImpl.java:213)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.<init>(FsVolumeImpl.java:184)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder.build(FsVolumeImplBuilder.java:93)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.addVolume(FsDatasetImpl.java:486)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:371)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.fsdatasetcache.max.threads.per.volume": "0"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-31",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testProvidedBlockRead",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293)",
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.initializeCacheExecutor(FsVolumeImpl.java:213)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.<init>(FsVolumeImpl.java:184)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder.build(FsVolumeImplBuilder.java:93)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.addVolume(FsDatasetImpl.java:486)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:371)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.setUp(TestProvidedImpl.java:342)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.fsdatasetcache.max.threads.per.volume": "0"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-31",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testScannerWithProvidedVolumes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293)",
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.initializeCacheExecutor(FsVolumeImpl.java:213)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImpl.<init>(FsVolumeImpl.java:184)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeImplBuilder.build(FsVolumeImplBuilder.java:93)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.addVolume(FsDatasetImpl.java:486)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:371)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.setUp(TestProvidedImpl.java:342)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.fsdatasetcache.max.threads.per.volume": "0"
        }
    },
    {
        "status": "TEST-BUG",
        "bugId": "Bug-126",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testMoveBlockFailure",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testMoveBlockFailure(TestFsDatasetImpl.java:1005)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testMoveBlockFailure$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.quota.init-threads": "1468568631"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-11",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame",
        "testMethod": "testNameNodeXFrameOptionsDisabled",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:152)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.createServerwithXFrame(TestNameNodeHttpServerXFrame.java:92)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.testNameNodeXFrameOptionsDisabled(TestNameNodeHttpServerXFrame.java:68)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServerXFrame.testNameNodeXFrameOptionsDisabled$$CONFUZZ(TestNameNodeHttpServerXFrame.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "841301670"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-11",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestProtectedDirectories",
        "testMethod": "testDelete",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:152)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestProtectedDirectories.setupTestCase(TestProtectedDirectories.java:82)",
            "org.apache.hadoop.hdfs.server.namenode.TestProtectedDirectories.testDelete(TestProtectedDirectories.java:263)",
            "org.apache.hadoop.hdfs.server.namenode.TestProtectedDirectories.testDelete$$CONFUZZ(TestProtectedDirectories.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "1496861504"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-11",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA",
        "testMethod": "testMultipleNonExistingUsers",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:152)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA.setUpNameNode(TestGetGroupsWithHA.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "1199695380"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-11",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique",
        "testMethod": "testSingleThreaded",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique.testSingleThreaded(TestEpochsAreUnique.java:54)",
            "org.apache.hadoop.hdfs.qjournal.client.TestEpochsAreUnique.testSingleThreaded$$CONFUZZ(TestEpochsAreUnique.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "1955666221"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-11",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testSelectThreadCounts",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "2139127811"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-11",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testSelectViaRpcAfterJNRestart",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "1524245515"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-11",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testHttpServer",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "1818231329"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-11",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testSelectViaRpcTwoDeadJNs",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99)",
            "org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600)",
            "org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216)",
            "org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114)",
            "org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534)",
            "org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:81)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.selector.count": "807987199"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-102",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesOnlyAccess",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "timeouts can't be negative",
        "stackTrace": [
            "java.base/sun.net.www.protocol.http.HttpURLConnection.setReadTimeout(HttpURLConnection.java:3349)",
            "org.apache.hadoop.hdfs.web.SSLConnectionConfigurator.configure(SSLConnectionConfigurator.java:65)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:191)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:160)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:758)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:717)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.create(WebHdfsFileSystem.java:1521)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testModifyAclEntriesOnlyAccess(FSAclBaseTest.java:152)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testModifyAclEntriesOnlyAccess$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.socket.read-timeout": "377895d"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-102",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testSetAclOnlyDefault",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "timeouts can't be negative",
        "stackTrace": [
            "java.base/sun.net.www.protocol.http.HttpURLConnection.setReadTimeout(HttpURLConnection.java:3349)",
            "org.apache.hadoop.hdfs.web.SSLConnectionConfigurator.configure(SSLConnectionConfigurator.java:65)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:191)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.openConnection(URLConnectionFactory.java:160)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:758)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:736)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.mkdirs(WebHdfsFileSystem.java:1142)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:750)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testSetAclOnlyDefault(FSAclBaseTest.java:690)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testSetAclOnlyDefault$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.webhdfs.socket.read-timeout": "981h"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-156",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor",
        "testMethod": "testFileSmallerThanOneStripe",
        "failure": "java.io.IOException",
        "errorMessage": "Failed: the number of failed blocks = 4 > the number of parity blocks = 3",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.checkStreamers(DFSStripedOutputStream.java:410)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.handleStreamerFailure(DFSStripedOutputStream.java:435)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.handleCurrentStreamerFailure(DFSStripedOutputStream.java:427)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.writeParity(DFSStripedOutputStream.java:1186)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.writeParityCells(DFSStripedOutputStream.java:1142)",
            "org.apache.hadoop.hdfs.DFSStripedOutputStream.closeImpl(DFSStripedOutputStream.java:1234)",
            "org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:904)",
            "org.apache.hadoop.hdfs.DFSTestUtil.writeFile(DFSTestUtil.java:924)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.writeStripedFile(TestDecommissionWithStriped.java:570)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testDecommission(TestDecommissionWithStriped.java:463)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.testFileSmallerThanOneStripe(TestDecommissionWithStriped.java:196)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor.testFileSmallerThanOneStripe$$CONFUZZ(TestDecommissionWithStripedBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-156",
        "testClass": "org.apache.hadoop.hdfs.TestFileAppend3",
        "testMethod": "testAppendToPartialChunk",
        "failure": "java.io.IOException",
        "errorMessage": "Could not get block locations. Source file \"/partialChunk/foo1\" - Aborting...block==null",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1525)",
            "org.apache.hadoop.hdfs.DataStreamer.processDatanodeOrExternalError(DataStreamer.java:1305)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:668)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-2",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStripedBackoffMonitor",
        "testMethod": "testFileSmallerThanOneStripe",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-793720479",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.writeConfigFile(TestDecommissionWithStriped.java:585)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:126)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1343464601"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-2",
        "testClass": "org.apache.hadoop.hdfs.TestPread",
        "testMethod": "testPreadLocalFS",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1719952536",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.TestPread.writeFile(TestPread.java:89)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS(TestPread.java:503)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS$$CONFUZZ(TestPread.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1240549928"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-2",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithStriped",
        "testMethod": "testFileFullBlockGroup",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-821516988",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.writeConfigFile(TestDecommissionWithStriped.java:585)",
            "org.apache.hadoop.hdfs.TestDecommissionWithStriped.setup(TestDecommissionWithStriped.java:126)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "1340376100"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager",
        "testMethod": "testNoLogs",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "Image file check. expected:<[/foo1/current/fsimage_0000000000000000100,/foo1/current/fsimage_0000000000000000200]> but was:<[]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.runTest(TestNNStorageRetentionManager.java:314)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testNoLogs(TestNNStorageRetentionManager.java:143)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testNoLogs$$CONFUZZ(TestNNStorageRetentionManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.num.checkpoints.retained": "1075872255"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager",
        "testMethod": "testPurgeEasyCase",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "Image file check. expected:<[/foo1/current/fsimage_0000000000000000100,/foo1/current/fsimage_0000000000000000200]> but was:<[]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.runTest(TestNNStorageRetentionManager.java:314)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testPurgeEasyCase(TestNNStorageRetentionManager.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testPurgeEasyCase$$CONFUZZ(TestNNStorageRetentionManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.num.checkpoints.retained": "1789587126"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager",
        "testMethod": "testOldInProgress",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "Image file check. expected:<[/foo1/current/fsimage_0000000000000000100,/foo1/current/fsimage_0000000000000000200]> but was:<[]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.runTest(TestNNStorageRetentionManager.java:314)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testOldInProgress(TestNNStorageRetentionManager.java:168)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testOldInProgress$$CONFUZZ(TestNNStorageRetentionManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.num.checkpoints.retained": "12985"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager",
        "testMethod": "testRetainExtraLogs",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "Image file check. expected:<[/foo1/current/fsimage_0000000000000000100,/foo1/current/fsimage_0000000000000000200]> but was:<[]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.runTest(TestNNStorageRetentionManager.java:314)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testRetainExtraLogs(TestNNStorageRetentionManager.java:205)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testRetainExtraLogs$$CONFUZZ(TestNNStorageRetentionManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.num.checkpoints.retained": "3330"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList",
        "testMethod": "testNonDfsUsedMetricForVolume",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<200> but was:<0>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList.testNonDfsUsedMetricForVolume(TestFsVolumeList.java:248)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList.testNonDfsUsedMetricForVolume$$CONFUZZ(TestFsVolumeList.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.du.reserved.disk": "17218"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testCrashBetweenSyncLogAndPersistPaxosData",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=3 < max=3 for QueuedThreadPool[qtp1844339839]@6dee647f{STARTED,3<=3<=3,i=3,r=-1,q=0}[ReservedThreadExecutor@5fea6cdb{s=0/1,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:120)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster.<init>(MiniJournalCluster.java:47)",
            "org.apache.hadoop.hdfs.qjournal.MiniJournalCluster$Builder.build(MiniJournalCluster.java:79)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.setup(TestQuorumJournalManager.java:111)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.threads": "3"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFS",
        "testMethod": "testWebHdfsAllowandDisallowSnapshots",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=3 < max=3 for QueuedThreadPool[qtp966734782]@399f33be{STARTED,3<=3<=3,i=3,r=-1,q=0}[ReservedThreadExecutor@58bc1e1f{s=0/1,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:170)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:954)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:765)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testWebHdfsAllowandDisallowSnapshots(TestWebHDFS.java:531)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testWebHdfsAllowandDisallowSnapshots$$CONFUZZ(TestWebHDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.threads": "3"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testHttpServer",
        "failure": "java.lang.IllegalStateException",
        "errorMessage": "Insufficient configured threads: required=3 < max=3 for QueuedThreadPool[qtp1359673572]@510af8e4{STARTED,3<=3<=3,i=3,r=-1,q=0}[ReservedThreadExecutor@4fdb4052{s=0/1,p=0}]",
        "stackTrace": [
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141)",
            "org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191)",
            "org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169)",
            "org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110)",
            "org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321)",
            "org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81)",
            "org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.eclipse.jetty.server.Server.doStart(Server.java:401)",
            "org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73)",
            "org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNodeHttpServer.start(JournalNodeHttpServer.java:86)",
            "org.apache.hadoop.hdfs.qjournal.server.JournalNode.start(JournalNode.java:238)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.setup(TestJournalNode.java:147)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.threads": "3"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-156",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testRootDirEZTrash",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "File /encFile could only be written to 0 of the 1 minReplication nodes. There are 1 datanode(s) running and 1 node(s) are excluded in this operation.        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2315)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2960)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:904)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1088)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1915)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1717)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-156",
        "testClass": "org.apache.hadoop.hdfs.server.balancer.TestBalancer",
        "testMethod": "testUnknownDatanodeSimple",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "File /tmp.txt could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and 3 node(s) are excluded in this operation. at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2315) at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2960) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:904) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1088)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1915)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1717)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-156",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement",
        "testMethod": "testBlockMoveAcrossStorageInSameNode",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "File /testBlockMoveAcrossStorageInSameNode/file could only be written to 0 of the 1 minReplication nodes. There are 1 datanode(s) running and 1 node(s) are excluded in this operation. at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2315) at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2960) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:904) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy29.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy30.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1088)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1915)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1717)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-156",
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testAppend",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "File /testAppend/f could only be written to 0 of the 1 minReplication nodes. There are 2 datanode(s) running and 2 node(s) are excluded in this operation. at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2315) at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2960) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:904) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572) at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556) at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043) at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1088)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1915)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1717)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-29",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testRootDirEZTrash",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayList.<init>(ArrayList.java:154)",
            "org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler$ReencryptionBatch.<init>(ReencryptionHandler.java:488)",
            "org.apache.hadoop.hdfs.server.namenode.ReencryptionHandler.<init>(ReencryptionHandler.java:248)",
            "org.apache.hadoop.hdfs.server.namenode.EncryptionZoneManager.<init>(EncryptionZoneManager.java:250)",
            "org.apache.hadoop.hdfs.server.namenode.FSDirectory.<init>(FSDirectory.java:411)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:977)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.reencrypt.batch.size": "1640153608"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr",
        "testMethod": "testRawXAttrs",
        "failure": "java.lang.AssertionError",
        "errorMessage": "setXAttr should have thrown",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest$17.run(FSXAttrBaseTest.java:1052)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.server.namenode.FSXAttrBaseTest.testRawXAttrs(FSXAttrBaseTest.java:1036)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr.testRawXAttrs$$CONFUZZ(TestFileContextXAttr.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.permissions.enabled": "false"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-2",
        "testClass": "org.apache.hadoop.hdfs.TestPread",
        "testMethod": "testPreadLocalFS",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.TestPread.writeFile(TestPread.java:89)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS(TestPread.java:503)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS$$CONFUZZ(TestPread.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "2147483390"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-2",
        "testClass": "org.apache.hadoop.hdfs.TestPread",
        "testMethod": "testPreadLocalFS",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.TestPread.writeFile(TestPread.java:89)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS(TestPread.java:503)",
            "org.apache.hadoop.hdfs.TestPread.testPreadLocalFS$$CONFUZZ(TestPread.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "2130640638"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS",
        "testMethod": "testRead",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.block.deletion.increment must be a positive integer.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:1008)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead(TestBlockTokenWithDFS.java:357)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFS.testRead$$CONFUZZ(TestBlockTokenWithDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.block.deletion.increment": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testSeekPastEndOfFileThenReseekAndRead",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.block.deletion.increment must be a positive integer.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:1008)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek.createCluster(TestHDFSContractSeek.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.block.deletion.increment": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testReadFullyZeroBytebufferPastEOF",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.block.deletion.increment must be a positive integer.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:1008)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek.createCluster(TestHDFSContractSeek.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.block.deletion.increment": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestBootstrapStandby",
        "testMethod": "testSharedEditsMissingLogs",
        "failure": "java.io.EOFException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)",
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "15"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractRename",
        "testMethod": "testRenameNewFileSameDir",
        "failure": "java.io.EOFException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)",
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "63"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal",
        "testMethod": "testStatisticsForErasureCodingRead",
        "failure": "java.io.EOFException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)",
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "31"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestGetGroupsWithHA",
        "testMethod": "testMultipleNonExistingUsers",
        "failure": "java.io.EOFException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)",
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "37"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDisableConnCache",
        "testMethod": "testDisableCache",
        "failure": "java.io.EOFException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)",
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "1"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testFilePermissions",
        "failure": "java.io.EOFException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)",
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "15"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileStatus",
        "testMethod": "testGetFileInfo",
        "failure": "java.io.EOFException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)",
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "7"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal",
        "testMethod": "testStatisticsForErasureCodingRead",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal.testStatisticsForErasureCodingRead(TestBlockReaderLocal.java:822)",
            "org.apache.hadoop.hdfs.client.impl.TestBlockReaderLocal.testStatisticsForErasureCodingRead$$CONFUZZ(TestBlockReaderLocal.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "31961985d",
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "8197723s"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint",
        "testMethod": "testCheckpointTriggerOnTxnCount",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testCheckpointTriggerOnTxnCount(TestCheckpoint.java:2176)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testCheckpointTriggerOnTxnCount$$CONFUZZ(TestCheckpoint.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.observation.window.ms": "7d",
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "3ms"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-64",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemLock",
        "testMethod": "testFSWriteLockReportSuppressed",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.addMetric(FSNamesystemLock.java:359)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:287)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystemLock.writeUnlock(FSNamesystemLock.java:236)",
            "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemLock.testFSWriteLockReportSuppressed(TestFSNamesystemLock.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.TestFSNamesystemLock.testFSWriteLockReportSuppressed$$CONFUZZ(TestFSNamesystemLock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.lock.detailed-metrics.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus",
        "testMethod": "testListFilesFileRecursive",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractGetFileStatus.createCluster(TestHDFSContractGetFileStatus.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.volumes.replica-add.threadpool.size": "291594243"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclEntriesMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Permission denied. user=super is not the owner of inode=/p31/bruce/file        at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkOwner(FSPermissionChecker.java:409)        at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:360)        at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermissionWithContext(FSPermissionChecker.java:370)        at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:240)        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1943)        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1927)        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkOwner(FSDirectory.java:1872)        at org.apache.hadoop.hdfs.server.namenode.FSDirAclOp.removeAclEntries(FSDirAclOp.java:74)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeAclEntries(FSNamesystem.java:7659)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.removeAclEntries(NameNodeRpcServer.java:2164)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.removeAclEntries(ClientNamenodeProtocolServerSideTranslatorPB.java:1530)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.removeAclEntries(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.removeAclEntries(ClientNamenodeProtocolTranslatorPB.java:1517)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.removeAclEntries(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.removeAclEntries(DFSClient.java:2709)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$48.doCall(DistributedFileSystem.java:2612)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$48.doCall(DistributedFileSystem.java:2609)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.removeAclEntries(DistributedFileSystem.java:2621)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testRemoveAclEntriesMustBeOwnerOrSuper(FSAclBaseTest.java:1347)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.testRemoveAclEntriesMustBeOwnerOrSuper$$CONFUZZ(TestFileContextAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.permissions.superusergroup": "xqvbuyuvsroaflwbypttiapduwerdudtjucklrlsgmjjnphlilzxxftdclxocdxaghpdkswibaggroup"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testWriteReadAndDeleteOneBlock",
        "failure": "org.junit.runners.model.TestTimedOutException",
        "errorMessage": "test timed out after 30000 milliseconds",
        "stackTrace": [
            "java.base@11.0.19/java.lang.Thread.start0(Native Method)",
            "java.base@11.0.19/java.lang.Thread.start(Thread.java:798)",
            "app//org.apache.hadoop.ipc.Server.start(Server.java:3422)",
            "app//org.apache.hadoop.hdfs.server.datanode.DataNode.runDatanodeDaemon(DataNode.java:2686)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1789)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "app//org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "app//org.apache.hadoop.hdfs.TestHDFSFileSystemContract.setUp(TestHDFSFileSystemContract.java:46)",
            "java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566)",
            "app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "app//org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base@11.0.19/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "20290"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement",
        "testMethod": "testBlockMoveAcrossStorageInSameNode",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement.testBlockMoveAcrossStorageInSameNode(TestBlockReplacement.java:294)",
            "org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement.testBlockMoveAcrossStorageInSameNode$$CONFUZZ(TestBlockReplacement.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.block.access.token.enable": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor",
        "testMethod": "testDecommissionDeadDN",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatus.createCluster(TestDecommissioningStatus.java:122)",
            "org.apache.hadoop.hdfs.server.namenode.TestDecommissioningStatusWithBackoffMonitor.setUp(TestDecommissioningStatusWithBackoffMonitor.java:68)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "334533507"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testDu",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "68259855"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot",
        "testMethod": "testXAttrForSnapshotRootAfterRemove",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot.initCluster(TestXAttrWithSnapshot.java:401)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot.init(TestXAttrWithSnapshot.java:78)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "67224083"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testRemoveAclEntries",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "273678539"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestRollingUpgrade",
        "testMethod": "testDFSAdminDatanodeUpgradeControlCommands",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestRollingUpgrade.testDFSAdminDatanodeUpgradeControlCommands(TestRollingUpgrade.java:413)",
            "org.apache.hadoop.hdfs.TestRollingUpgrade.testDFSAdminDatanodeUpgradeControlCommands$$CONFUZZ(TestRollingUpgrade.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.polling.ms": "556798"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-109",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testSetAclOnlyAccess",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.hdfs.DFSUtilClient.getThreadPoolExecutor(DFSUtilClient.java:949)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.initializeStripedBlkReconstructionThreadPool(ErasureCodingWorker.java:109)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:70)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.threads": "0"
        }
    },
    {
        "status": "NO-MSG",
        "bugId": "Bug-109",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover",
        "testMethod": "testPipelineRecoveryStress",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.hdfs.DFSUtilClient.getThreadPoolExecutor(DFSUtilClient.java:949)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.initializeStripedBlkReconstructionThreadPool(ErasureCodingWorker.java:109)",
            "org.apache.hadoop.hdfs.server.datanode.erasurecode.ErasureCodingWorker.<init>(ErasureCodingWorker.java:70)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.startDataNode(DataNode.java:1431)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:507)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2828)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.HAStressTestHarness.startCluster(HAStressTestHarness.java:73)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testPipelineRecoveryStress(TestPipelinesFailover.java:465)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestPipelinesFailover.testPipelineRecoveryStress$$CONFUZZ(TestPipelinesFailover.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.ec.reconstruction.threads": "0"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-156",
        "testClass": "org.apache.hadoop.hdfs.TestTrashWithSecureEncryptionZones",
        "testMethod": "testTrashExpunge",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "File /zone41/encFile61 could only be written to 0 of the 1 minReplication nodes. There are 1 datanode(s) running and 1 node(s) are excluded in this operation.        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2315)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2960)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:904)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy77.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy78.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1088)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1915)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1717)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer.cipher.suites": "NoPadding",
            "dfs.encrypt.data.transfer": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand",
        "testMethod": "testRunMultipleCommandsUnderOneSetup",
        "failure": "java.io.IOException",
        "errorMessage": "Failed to save in any storage directories while saving namespace.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.FSImage.saveFSImageInAllDirs(FSImage.java:1243)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.saveFSImageInAllDirs(FSImage.java:1200)",
            "org.apache.hadoop.hdfs.server.namenode.FSImage.format(FSImage.java:191)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1278)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.diskbalancer.command.TestDiskBalancerCommand.setUp(TestDiskBalancerCommand.java:96)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2139128575",
            "dfs.namenode.top.enabled": "false",
            "dfs.replication.max": "12487",
            "dfs.image.compress": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFS",
        "testMethod": "testWebHdfsAllowandDisallowSnapshots",
        "failure": "java.io.IOException",
        "errorMessage": "Content-Type \"text/html;charset=iso-8859-1\" is incompatible with \"application/json\" (parsed=\"text/html; charset=iso-8859-1\")",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.jsonParse(WebHdfsFileSystem.java:484)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:507)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:739)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.allowSnapshot(WebHdfsFileSystem.java:1339)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testWebHdfsAllowandDisallowSnapshots(TestWebHDFS.java:541)",
            "org.apache.hadoop.hdfs.web.TestWebHDFS.testWebHdfsAllowandDisallowSnapshots$$CONFUZZ(TestWebHDFS.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.request.header.size": "7"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testSetAclMustBeOwnerOrSuper",
        "failure": "java.io.IOException",
        "errorMessage": "Content-Type \"text/html;charset=iso-8859-1\" is incompatible with \"application/json\" (parsed=\"text/html; charset=iso-8859-1\")",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.jsonParse(WebHdfsFileSystem.java:484)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:507)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:739)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.mkdirs(WebHdfsFileSystem.java:1142)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testSetAclMustBeOwnerOrSuper(FSAclBaseTest.java:1384)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testSetAclMustBeOwnerOrSuper$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.request.header.size": "15"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testRemoveAclEntriesMustBeOwnerOrSuper",
        "failure": "java.io.IOException",
        "errorMessage": "Content-Type \"text/html;charset=iso-8859-1\" is incompatible with \"application/json\" (parsed=\"text/html; charset=iso-8859-1\")",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.jsonParse(WebHdfsFileSystem.java:484)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:507)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:739)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.mkdirs(WebHdfsFileSystem.java:1142)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testRemoveAclEntriesMustBeOwnerOrSuper(FSAclBaseTest.java:1340)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testRemoveAclEntriesMustBeOwnerOrSuper$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.max.request.header.size": "1"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks",
        "testMethod": "testSkewedRack2",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.invalidate.work.pct.per.iteration = '0.0' is invalid. It should be a positive, non-zero float value, not greater than 1.0f, to indicate a percentage.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.DFSUtil.getInvalidateWorkPctPerIteration(DFSUtil.java:1485)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:547)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.DFSTestUtil.setupCluster(DFSTestUtil.java:2491)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.setupCluster(TestErasureCodingMultipleRacks.java:96)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2(TestErasureCodingMultipleRacks.java:131)",
            "org.apache.hadoop.hdfs.TestErasureCodingMultipleRacks.testSkewedRack2$$CONFUZZ(TestErasureCodingMultipleRacks.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.invalidate.work.pct.per.iteration": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testDefaultAclNewSymlinkIntermediate",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.invalidate.work.pct.per.iteration = '0.0' is invalid. It should be a positive, non-zero float value, not greater than 1.0f, to indicate a percentage.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.DFSUtil.getInvalidateWorkPctPerIteration(DFSUtil.java:1485)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:547)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.invalidate.work.pct.per.iteration": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions",
        "testMethod": "testTransitionActiveToStandby",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.invalidate.work.pct.per.iteration = '0.0' is invalid. It should be a positive, non-zero float value, not greater than 1.0f, to indicate a percentage.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.DFSUtil.getInvalidateWorkPctPerIteration(DFSUtil.java:1485)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:547)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions.testTransitionActiveToStandby(TestHAStateTransitions.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions.testTransitionActiveToStandby$$CONFUZZ(TestHAStateTransitions.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.invalidate.work.pct.per.iteration": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileCreation",
        "testMethod": "testServerDefaultsWithCaching",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.invalidate.work.pct.per.iteration = '0.0' is invalid. It should be a positive, non-zero float value, not greater than 1.0f, to indicate a percentage.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.DFSUtil.getInvalidateWorkPctPerIteration(DFSUtil.java:1485)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:547)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithCaching(TestFileCreation.java:199)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithCaching$$CONFUZZ(TestFileCreation.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.invalidate.work.pct.per.iteration": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testDuSnapshots",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.invalidate.work.pct.per.iteration = '0.0' is invalid. It should be a positive, non-zero float value, not greater than 1.0f, to indicate a percentage.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.DFSUtil.getInvalidateWorkPctPerIteration(DFSUtil.java:1485)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:547)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.invalidate.work.pct.per.iteration": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.permission.TestStickyBit",
        "testMethod": "testAclStickyBitPersistence",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.invalidate.work.pct.per.iteration = '0.0' is invalid. It should be a positive, non-zero float value, not greater than 1.0f, to indicate a percentage.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.DFSUtil.getInvalidateWorkPctPerIteration(DFSUtil.java:1485)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:547)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.permission.TestStickyBit.initCluster(TestStickyBit.java:79)",
            "org.apache.hadoop.fs.permission.TestStickyBit.init(TestStickyBit.java:74)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.invalidate.work.pct.per.iteration": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations",
        "testMethod": "testGetBlockLocationsRacingWithDelete",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.invalidate.work.pct.per.iteration = '0.0' is invalid. It should be a positive, non-zero float value, not greater than 1.0f, to indicate a percentage.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.DFSUtil.getInvalidateWorkPctPerIteration(DFSUtil.java:1485)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:547)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.setupFileSystem(TestGetBlockLocations.java:135)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.testGetBlockLocationsRacingWithDelete(TestGetBlockLocations.java:65)",
            "org.apache.hadoop.hdfs.server.namenode.TestGetBlockLocations.testGetBlockLocationsRacingWithDelete$$CONFUZZ(TestGetBlockLocations.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.invalidate.work.pct.per.iteration": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testClusterStats",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.invalidate.work.pct.per.iteration = '0.0' is invalid. It should be a positive, non-zero float value, not greater than 1.0f, to indicate a percentage.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.DFSUtil.getInvalidateWorkPctPerIteration(DFSUtil.java:1485)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:547)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:414)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:392)",
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.startCluster(AdminStatesBaseTest.java:424)",
            "org.apache.hadoop.hdfs.TestDecommission.testClusterStats(TestDecommission.java:528)",
            "org.apache.hadoop.hdfs.TestDecommission.testClusterStats(TestDecommission.java:512)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testClusterStats$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.invalidate.work.pct.per.iteration": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestClusterId",
        "testMethod": "testFormatWithEmptyDir",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.invalidate.work.pct.per.iteration = '0.0' is invalid. It should be a positive, non-zero float value, not greater than 1.0f, to indicate a percentage.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.DFSUtil.getInvalidateWorkPctPerIteration(DFSUtil.java:1485)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:547)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1726)",
            "org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithEmptyDir(TestClusterId.java:168)",
            "org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithEmptyDir$$CONFUZZ(TestClusterId.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.invalidate.work.pct.per.iteration": "0.0f"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot",
        "testMethod": "testXAttrForSnapshotRootAfterChange",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.namenode.invalidate.work.pct.per.iteration = '0.0' is invalid. It should be a positive, non-zero float value, not greater than 1.0f, to indicate a percentage.",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.DFSUtil.getInvalidateWorkPctPerIteration(DFSUtil.java:1485)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:547)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot.initCluster(TestXAttrWithSnapshot.java:401)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot.init(TestXAttrWithSnapshot.java:78)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.invalidate.work.pct.per.iteration": "0.0f"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-157",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl",
        "testMethod": "testRemoveAclMustBeOwnerOrSuper",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.server.namenode.TestFileContextAcl.init(TestFileContextAcl.java:41)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.directoryscan.threads": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-32",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA",
        "testMethod": "testCreateSymlink",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:191)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:250)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:318)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:556)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:553)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:567)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1242)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:466)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:447)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:440)",
            "org.apache.hadoop.hdfs.DFSTestUtil.createFile(DFSTestUtil.java:433)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA$CreateSymlinkOp.prepare(TestRetryCacheWithHA.java:678)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testClientRetryWithFailover(TestRetryCacheWithHA.java:1303)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testCreateSymlink(TestRetryCacheWithHA.java:1218)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA.testCreateSymlink$$CONFUZZ(TestRetryCacheWithHA.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "2130640638"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint",
        "testMethod": "testSecondaryPurgesEditLogs",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Edit log files were not purged from 2NN expected:<1> but was:<5>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryPurgesEditLogs(TestCheckpoint.java:2282)",
            "org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryPurgesEditLogs$$CONFUZZ(TestCheckpoint.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.num.checkpoints.retained": "13312"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestEncryptionZones",
        "testMethod": "testGetTrashRoots",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Must set a positive value for dfs.namenode.decommission.blocks.per.interval",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager.activate(DatanodeAdminManager.java:125)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.activate(DatanodeManager.java:451)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.activate(BlockManager.java:740)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startCommonServices(FSNamesystem.java:1278)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:870)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestEncryptionZones.setup(TestEncryptionZones.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.decommission.blocks.per.interval": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testSetPermission",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Must set a positive value for dfs.namenode.decommission.blocks.per.interval",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeAdminManager.activate(DatanodeAdminManager.java:125)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.activate(DatanodeManager.java:451)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.activate(BlockManager.java:740)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startCommonServices(FSNamesystem.java:1278)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.startCommonServices(NameNode.java:870)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:791)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.decommission.blocks.per.interval": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestClusterId",
        "testMethod": "testFormatWithNonInteractive",
        "failure": "org.apache.hadoop.hdfs.server.namenode.NameNodeFormatException",
        "errorMessage": "NameNode format aborted as reformat is disabled for this cluster.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1267)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1726)",
            "org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithNonInteractive(TestClusterId.java:331)",
            "org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithNonInteractive$$CONFUZZ(TestClusterId.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.reformat.disabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestClusterId",
        "testMethod": "testFormatWithoutForceEnterNo",
        "failure": "org.apache.hadoop.hdfs.server.namenode.NameNodeFormatException",
        "errorMessage": "NameNode format aborted as reformat is disabled for this cluster.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1267)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1726)",
            "org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithoutForceEnterNo(TestClusterId.java:451)",
            "org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithoutForceEnterNo$$CONFUZZ(TestClusterId.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.reformat.disabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestStartup",
        "testMethod": "testChkpointStartup1",
        "failure": "java.lang.AssertionError",
        "errorMessage": "java.io.IOException: Unexpected configuration parameters: dfs.namenode.replication.min = 29171 > dfs.replication.max = 930        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:532)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:869)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)        at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)        at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)        at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)        at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)        at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)        at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)        at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)        at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)        at org.apache.hadoop.hdfs.server.namenode.TestStartup.createCheckPoint(TestStartup.java:151)        at org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1(TestStartup.java:348)        at org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1$$CONFUZZ(TestStartup.java)        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.base/java.lang.reflect.Method.invoke(Method.java:566)        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)        at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)        at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)        at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)        at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)        at edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)        at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)        at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)        at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)        at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)        at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)        at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)        at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)        at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)        at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)        at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)        at org.junit.runners.ParentRunner.run(ParentRunner.java:413)        at org.junit.runner.JUnitCore.run(JUnitCore.java:137)        at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)        at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.createCheckPoint(TestStartup.java:173)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1(TestStartup.java:348)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1$$CONFUZZ(TestStartup.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "29171"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestStartup",
        "testMethod": "testChkpointStartup1",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1503)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:973)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.checkNameNodeFiles(TestStartup.java:264)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1(TestStartup.java:350)",
            "org.apache.hadoop.hdfs.server.namenode.TestStartup.testChkpointStartup1$$CONFUZZ(TestStartup.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.safemode.replication.min": "803"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerFailures",
        "testMethod": "testCheckingClosedVolume",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.disk.check.timeout - 0 (should be > 0)",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker.<init>(DatasetVolumeChecker.java:125)",
            "org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerFailures.testCheckingClosedVolume(TestDatasetVolumeCheckerFailures.java:104)",
            "org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerFailures.testCheckingClosedVolume$$CONFUZZ(TestDatasetVolumeCheckerFailures.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "0m"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister",
        "testMethod": "testInvalidConfigurationValue",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.disk.check.timeout - 0 (should be > 0)",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker.<init>(DatasetVolumeChecker.java:125)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:481)",
            "org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister.lambda$testInvalidConfigurationValue$0(TestDatanodeRegister.java:175)",
            "org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:498)",
            "org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:384)",
            "org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:453)",
            "org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister.testInvalidConfigurationValue(TestDatanodeRegister.java:172)",
            "org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister.testInvalidConfigurationValue$$CONFUZZ(TestDatanodeRegister.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "0d"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat",
        "testMethod": "testBackwardsCompat",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.disk.check.timeout - 0 (should be > 0)",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker.<init>(DatasetVolumeChecker.java:125)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.<init>(DataNode.java:441)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat$NullDataNode.<init>(TestDataXceiverBackwardsCompat.java:86)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat(TestDataXceiverBackwardsCompat.java:147)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat$$CONFUZZ(TestDataXceiverBackwardsCompat.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "00ms"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerFailures",
        "testMethod": "testMinGapIsEnforcedForSyncChecks",
        "failure": "org.apache.hadoop.HadoopIllegalArgumentException",
        "errorMessage": "Invalid value configured for dfs.datanode.disk.check.timeout - 0 (should be > 0)",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker.<init>(DatasetVolumeChecker.java:125)",
            "org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerFailures.testMinGapIsEnforcedForSyncChecks(TestDatasetVolumeCheckerFailures.java:120)",
            "org.apache.hadoop.hdfs.server.datanode.checker.TestDatasetVolumeCheckerFailures.testMinGapIsEnforcedForSyncChecks$$CONFUZZ(TestDatasetVolumeCheckerFailures.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "0h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestHeartbeatHandling",
        "testMethod": "testHeartbeatStopWatch",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertFalse(Assert.java:65)",
            "org.junit.Assert.assertFalse(Assert.java:75)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestHeartbeatHandling.testHeartbeatStopWatch(TestHeartbeatHandling.java:278)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestHeartbeatHandling.testHeartbeatStopWatch$$CONFUZZ(TestHeartbeatHandling.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.stale.datanode.interval": "83",
            "dfs.namenode.avoid.write.stale.datanode": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testAddVolumeWithSameStorageUuid",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "configured value 500for dfs.datanode.cache.revocation.polling.ms is too high.  It must not be more than half of the value of dfs.datanode.cache.revocation.timeout.ms.  Reconfigure this to 172",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.<init>(FsDatasetCache.java:174)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:375)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "344"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testLoadingDfsUsedForVolumes",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "configured value 500for dfs.datanode.cache.revocation.polling.ms is too high.  It must not be more than half of the value of dfs.datanode.cache.revocation.timeout.ms.  Reconfigure this to 7",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.<init>(FsDatasetCache.java:174)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:375)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "14"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testRemoveOneVolume",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "configured value 18665for dfs.datanode.cache.revocation.polling.ms is too high.  It must not be more than half of the value of dfs.datanode.cache.revocation.timeout.ms.  Reconfigure this to 401",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.<init>(FsDatasetCache.java:174)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:375)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "802"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testProvidedBlockRead",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "configured value 500for dfs.datanode.cache.revocation.polling.ms is too high.  It must not be more than half of the value of dfs.datanode.cache.revocation.timeout.ms.  Reconfigure this to 161",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetCache.<init>(FsDatasetCache.java:174)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:375)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.setUp(TestProvidedImpl.java:342)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "323"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade",
        "testMethod": "testDatanodeRollingUpgradeWithRollback",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.deleteAndEnsureInTrash(TestDataNodeRollingUpgrade.java:141)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback(TestDataNodeRollingUpgrade.java:274)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataNodeRollingUpgrade.testDatanodeRollingUpgradeWithRollback$$CONFUZZ(TestDataNodeRollingUpgrade.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.startup.delay.block.deletion.sec": "20403"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testDu",
        "failure": "java.io.IOException",
        "errorMessage": "Unable to close file because the last block BP-1587010755-172.17.0.2-1689689423354:blk_1073741826_1002 does not have enough number of replicas.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:969)",
            "org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:909)",
            "org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:892)",
            "org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "org.apache.hadoop.hdfs.TestDFSShell.writeFile(TestDFSShell.java:141)",
            "org.apache.hadoop.hdfs.TestDFSShell.testDu(TestDFSShell.java:257)",
            "org.apache.hadoop.hdfs.TestDFSShell.testDu$$CONFUZZ(TestDFSShell.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.heartbeat.interval": "537362175",
            "dfs.blockreport.incremental.intervalMsec": "128317504"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testSecureAuthParamsInUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.getWebHdfsFileSystem(TestWebHdfsUrl.java:391)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSecureAuthParamsInUrl(TestWebHdfsUrl.java:145)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testSecureAuthParamsInUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "fs.webhdfs.impl.disable.cache": "true",
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testBatchedListingUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.getWebHdfsFileSystem(TestWebHdfsUrl.java:391)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testBatchedListingUrl(TestWebHdfsUrl.java:352)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testBatchedListingUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "fs.webhdfs.impl.disable.cache": "true",
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testEncodedPathUrl",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "No value for dfs.webhdfs.oauth2.access.token.provider found in conf file.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.oauth2.Utils.notNull(Utils.java:37)",
            "org.apache.hadoop.hdfs.web.oauth2.OAuth2ConnectionConfigurator.<init>(OAuth2ConnectionConfigurator.java:55)",
            "org.apache.hadoop.hdfs.web.URLConnectionFactory.newOAuth2URLConnectionFactory(URLConnectionFactory.java:138)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.initialize(WebHdfsFileSystem.java:242)",
            "org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469)",
            "org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl(TestWebHdfsUrl.java:77)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "fs.webhdfs.impl.disable.cache": "true",
            "dfs.webhdfs.oauth2.enabled": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleDatanodes",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertTrue(Assert.java:53)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleDatanodes(TestSortLocatedBlock.java:197)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.heartbeat.interval": "1867501415"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-59",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleDatanodes",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.Comparator.lambda$comparing$77a9974f$1(Comparator.java:469)",
            "java.base/java.util.TimSort.countRunAndMakeAscending(TimSort.java:355)",
            "java.base/java.util.TimSort.sort(TimSort.java:220)",
            "java.base/java.util.Arrays.sort(Arrays.java:1515)",
            "java.base/java.util.ArrayList.sort(ArrayList.java:1750)",
            "java.base/java.util.Collections.sort(Collections.java:179)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.lambda$createSecondaryNodeSorter$0(DatanodeManager.java:654)",
            "org.apache.hadoop.net.NetworkTopology.sortByDistance(NetworkTopology.java:983)",
            "org.apache.hadoop.net.NetworkTopology.sortByDistanceUsingNetworkLocation(NetworkTopology.java:946)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlock(DatanodeManager.java:637)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlocks(DatanodeManager.java:554)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleDatanodes(TestSortLocatedBlock.java:188)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.read.considerStorageType": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testErrOutPut",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "the number of requested top users must be at least 1",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:237)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.num.users": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore",
        "testMethod": "testStorageRestoreFailure",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "the number of requested top users must be at least 1",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:237)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testStorageRestoreFailure(TestStorageRestore.java:397)",
            "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testStorageRestoreFailure$$CONFUZZ(TestStorageRestore.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.num.users": "0"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-123",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA",
        "testMethod": "testHarUriWithHaUriWithNoPort",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort(TestHarFileSystemWithHA.java:60)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort$$CONFUZZ(TestHarFileSystemWithHA.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "5532"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testEnterSafeModeInANNShouldNotThrowNPE",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93)",
            "org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68)",
            "org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:114)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:456)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:447)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:447)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.copyNameDirs(MiniDFSCluster.java:1326)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1121)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "1882163822"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-7",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testProvidedBlockRead",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209)",
            "org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56)",
            "org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161)",
            "org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372)",
            "org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976)",
            "org.apache.hadoop.hdfs.server.datanode.ProvidedReplica.getDataInputStream(ProvidedReplica.java:191)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockInputStreamWithCheckingPmemCache(FsDatasetImpl.java:859)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getBlockInputStream(FsDatasetImpl.java:836)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.testProvidedBlockRead(TestProvidedImpl.java:424)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.testProvidedBlockRead$$CONFUZZ(TestProvidedImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.file.buffer.size": "2147417854"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier",
        "testMethod": "testWhenStoragePolicySetToONESSD",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.startCluster(TestExternalStoragePolicySatisfier.java:211)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.createCluster(TestExternalStoragePolicySatisfier.java:194)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWhenStoragePolicySetToONESSD(TestExternalStoragePolicySatisfier.java:480)",
            "org.apache.hadoop.hdfs.server.sps.TestExternalStoragePolicySatisfier.testWhenStoragePolicySetToONESSD$$CONFUZZ(TestExternalStoragePolicySatisfier.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.window.num.buckets": "170507386",
            "dfs.namenode.top.windows.minutes": "9596,8351,5998"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-54",
        "testClass": "org.apache.hadoop.hdfs.TestFileCreation",
        "testMethod": "testServerDefaultsWithCaching",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1187239463",
        "stackTrace": [
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:136)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithCaching(TestFileCreation.java:199)",
            "org.apache.hadoop.hdfs.TestFileCreation.testServerDefaultsWithCaching$$CONFUZZ(TestFileCreation.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "9281ms",
            "dfs.namenode.gc.time.monitor.observation.window.ms": "8011895h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList",
        "testMethod": "testGetCachedVolumeCapacity",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<4000> but was:<0>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList.testGetCachedVolumeCapacity(TestFsVolumeList.java:429)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsVolumeList.testGetCachedVolumeCapacity$$CONFUZZ(TestFsVolumeList.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.du.reserved.ram_disk": "18496"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testRemoveOneVolume",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.datanode.fsdatasetasyncdisk.max.threads.per.volume must be a positive integer.",
        "stackTrace": [
            "org.apache.hadoop.util.Preconditions.checkArgument(Preconditions.java:185)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService.<init>(FsDatasetAsyncDiskService.java:98)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:366)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.setUp(TestFsDatasetImpl.java:198)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.fsdatasetasyncdisk.max.threads.per.volume": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testScannerWithProvidedVolumes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.datanode.fsdatasetasyncdisk.max.threads.per.volume must be a positive integer.",
        "stackTrace": [
            "org.apache.hadoop.util.Preconditions.checkArgument(Preconditions.java:185)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService.<init>(FsDatasetAsyncDiskService.java:98)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.<init>(FsDatasetImpl.java:366)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.setUp(TestProvidedImpl.java:342)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.fsdatasetasyncdisk.max.threads.per.volume": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testRemoveOneVolume",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException",
        "errorMessage": "Out of space: The volume with the most available space (=0 B) is less than the block size (=0 B).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:96)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:68)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy.doChooseVolume(AvailableSpaceVolumeChoosingPolicy.java:141)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy.chooseVolume(AvailableSpaceVolumeChoosingPolicy.java:129)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.chooseVolume(FsVolumeList.java:88)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.getNextVolume(FsVolumeList.java:118)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.createRbw(FsDatasetImpl.java:1476)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testRemoveOneVolume(TestFsDatasetImpl.java:397)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testRemoveOneVolume$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "fs.getspaceused.classname": "org.apache.hadoop.fs.DFCachingGetSpaceUsed",
            "dfs.datanode.fsdataset.volume.choosing.policy": "org.apache.hadoop.hdfs.server.datanode.fsdataset.AvailableSpaceVolumeChoosingPolicy"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl",
        "testMethod": "testRemoveOneVolume",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskOutOfSpaceException",
        "errorMessage": "Out of space: The volume with the most available space (=0 B) is less than the block size (=0 B).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:96)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy.chooseVolume(RoundRobinVolumeChoosingPolicy.java:68)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.chooseVolume(FsVolumeList.java:88)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.getNextVolume(FsVolumeList.java:118)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.createRbw(FsDatasetImpl.java:1476)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testRemoveOneVolume(TestFsDatasetImpl.java:397)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl.testRemoveOneVolume$$CONFUZZ(TestFsDatasetImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "fs.getspaceused.classname": "org.apache.hadoop.fs.DFCachingGetSpaceUsed"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore",
        "testMethod": "testStorageRestoreFailure",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Cannot create directory /test. Name node is in safe mode.Resources are low on NN. Please add or free up more resourcesthen turn off safe mode manually. NOTE:  If you turn off safe mode before adding resources, the NN will immediately return to safe mode. Use \"hdfs dfsadmin -safemode leave\" to turn safe mode off. NamenodeHostName:localhost        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1577)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1564)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3404)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1159)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.mkdirs(ClientNamenodeProtocolServerSideTranslatorPB.java:740)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy27.mkdirs(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:674)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy28.mkdirs(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2507)",
            "org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2483)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1485)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1482)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1499)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1474)",
            "org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2388)",
            "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testStorageRestoreFailure(TestStorageRestore.java:405)",
            "org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testStorageRestoreFailure$$CONFUZZ(TestStorageRestore.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "767"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator",
        "testMethod": "testReservedSpacePercentage",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<1000> but was:<412851000>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.checkReserved(TestReservedSpaceCalculator.java:169)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.testReservedSpacePercentage(TestReservedSpaceCalculator.java:91)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.testReservedSpacePercentage$$CONFUZZ(TestReservedSpaceCalculator.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.du.reserved.pct.archive": "4128510"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator",
        "testMethod": "testReservedSpacePercentage",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<1000> but was:<151170972000>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.checkReserved(TestReservedSpaceCalculator.java:169)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.testReservedSpacePercentage(TestReservedSpaceCalculator.java:90)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.testReservedSpacePercentage$$CONFUZZ(TestReservedSpaceCalculator.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.du.reserved.pct.ssd": "1511709720"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator",
        "testMethod": "testReservedSpacePercentage",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<1000> but was:<26850073500>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.checkReserved(TestReservedSpaceCalculator.java:169)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.testReservedSpacePercentage(TestReservedSpaceCalculator.java:89)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReservedSpaceCalculator.testReservedSpacePercentage$$CONFUZZ(TestReservedSpaceCalculator.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.du.reserved.pct.disk": "268500735"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testSetAclMustBeOwnerOrSuper",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Invalid values: dfs.bytes-per-checksum (=120) must divide block size (=134217728).",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:89)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:522)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$300(WebHdfsFileSystem.java:145)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner$1.close(WebHdfsFileSystem.java:1043)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.testSetAclMustBeOwnerOrSuper(FSAclBaseTest.java:1386)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.testSetAclMustBeOwnerOrSuper$$CONFUZZ(TestWebHDFSAcl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "120"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart",
        "testMethod": "testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister",
        "failure": "java.io.IOException",
        "errorMessage": "Filesystem closed",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DFSClient.checkOpen(DFSClient.java:494)",
            "org.apache.hadoop.hdfs.DFSClient.open(DFSClient.java:1043)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:340)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$4.doCall(DistributedFileSystem.java:336)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.open(DistributedFileSystem.java:353)",
            "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart.testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister(TestFileLengthOnClusterRestart.java:55)",
            "org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart.testFileLengthWithHSyncAndClusterRestartWithOutDNsRegister$$CONFUZZ(TestFileLengthOnClusterRestart.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "fs.trash.interval": "13018"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleAndSlowDatanodes",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "expected:<[4.4.4.4]> but was:<[3.3.3.3]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.junit.Assert.assertEquals(Assert.java:146)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes(TestSortLocatedBlock.java:155)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.stale.datanode.minimum.interval": "16085"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-59",
        "testClass": "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock",
        "testMethod": "testAviodStaleAndSlowDatanodes",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.Comparator.lambda$comparing$77a9974f$1(Comparator.java:469)",
            "java.base/java.util.TimSort.countRunAndMakeAscending(TimSort.java:355)",
            "java.base/java.util.TimSort.sort(TimSort.java:220)",
            "java.base/java.util.Arrays.sort(Arrays.java:1515)",
            "java.base/java.util.ArrayList.sort(ArrayList.java:1750)",
            "java.base/java.util.Collections.sort(Collections.java:179)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.lambda$createSecondaryNodeSorter$0(DatanodeManager.java:654)",
            "org.apache.hadoop.net.NetworkTopology.sortByDistance(NetworkTopology.java:983)",
            "org.apache.hadoop.net.NetworkTopology.sortByDistanceUsingNetworkLocation(NetworkTopology.java:946)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlock(DatanodeManager.java:637)",
            "org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.sortLocatedBlocks(DatanodeManager.java:554)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes(TestSortLocatedBlock.java:144)",
            "org.apache.hadoop.hdfs.server.blockmanagement.TestSortLocatedBlock.testAviodStaleAndSlowDatanodes$$CONFUZZ(TestSortLocatedBlock.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.heartbeat.interval": "29697",
            "dfs.namenode.read.considerStorageType": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-33",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHDFSAcl",
        "testMethod": "testModifyAclEntriesStickyBit",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.runDatanodeDaemon(DataNode.java:2686)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1789)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.startCluster(FSAclBaseTest.java:91)",
            "org.apache.hadoop.hdfs.web.TestWebHDFSAcl.init(TestWebHDFSAcl.java:34)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "879558531"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-33",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd",
        "testMethod": "testWhenSomeNodesAreNotGood",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.ipc.Server.start(Server.java:3418)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.runDatanodeDaemon(DataNode.java:2686)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1789)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.setUpBeforeClass(TestFavoredNodesEndToEnd.java:71)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.handler.count": "604012420"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-167",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs",
        "testMethod": "testNameEditsConfigsFailure",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure(TestNameEditsConfigs.java:450)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure$$CONFUZZ(TestNameEditsConfigs.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.edits.dir.minimum": "251625215"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker",
        "testMethod": "testCheckAvailability",
        "failure": "java.lang.AssertionError",
        "errorMessage": "isResourceAvailable must return true if disk usage is lower than threshold",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker.testCheckAvailability(TestNameNodeResourceChecker.java:65)",
            "org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker.testCheckAvailability$$CONFUZZ(TestNameNodeResourceChecker.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.resource.checked.volumes.minimum": "70081660"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-120",
        "testClass": "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor",
        "testMethod": "testNodeUsageWhileDecommissioining",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hdfs.AdminStatesBaseTest.cleanupFile(AdminStatesBaseTest.java:459)",
            "org.apache.hadoop.hdfs.TestDecommission.nodeUsageVerification(TestDecommission.java:1575)",
            "org.apache.hadoop.hdfs.TestDecommission.testNodeUsageWhileDecommissioining(TestDecommission.java:1510)",
            "org.apache.hadoop.hdfs.TestDecommissionWithBackoffMonitor.testNodeUsageWhileDecommissioining$$CONFUZZ(TestDecommissionWithBackoffMonitor.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek",
        "testMethod": "testReadFullyZeroBytebufferPastEOF",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "window size must be a multiplication of number of buckets",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.top.window.RollingWindowManager.<init>(RollingWindowManager.java:232)",
            "org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics.<init>(TopMetrics.java:93)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.initAuditLoggers(FSNamesystem.java:1173)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:983)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.fs.contract.hdfs.HDFSContract.createCluster(HDFSContract.java:58)",
            "org.apache.hadoop.fs.contract.hdfs.TestHDFSContractSeek.createCluster(TestHDFSContractSeek.java:36)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.top.windows.minutes": "4314,48,2145",
            "dfs.namenode.top.window.num.buckets": "1312766"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager",
        "testMethod": "testSelectViaRpcAfterJNRestart",
        "failure": "org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream$PrematureEOFException",
        "errorMessage": "got premature end-of-file at txid 0; expected file to go up to 10",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream.nextOp(RedundantEditLogInputStream.java:209)",
            "org.apache.hadoop.hdfs.server.namenode.EditLogInputStream.readOp(EditLogInputStream.java:85)",
            "org.apache.hadoop.hdfs.qjournal.QJMTestUtil.verifyEdits(QJMTestUtil.java:130)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testSelectViaRpcAfterJNRestart(TestQuorumJournalManager.java:1119)",
            "org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testSelectViaRpcAfterJNRestart$$CONFUZZ(TestQuorumJournalManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.simple.anonymous.allowed": "false"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestHDFSFileSystemContract",
        "testMethod": "testAppend",
        "failure": "org.junit.runners.model.TestTimedOutException",
        "errorMessage": "test timed out after 30000 milliseconds",
        "stackTrace": [
            "java.base@11.0.19/java.lang.Thread.sleep(Native Method)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:973)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.completeFile(DFSOutputStream.java:909)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.closeImpl(DFSOutputStream.java:892)",
            "app//org.apache.hadoop.hdfs.DFSOutputStream.close(DFSOutputStream.java:847)",
            "app//org.apache.hadoop.fs.FSDataOutputStream$PositionCache.close(FSDataOutputStream.java:77)",
            "app//org.apache.hadoop.fs.FSDataOutputStream.close(FSDataOutputStream.java:106)",
            "app//org.apache.hadoop.hdfs.AppendTestUtil.testAppend(AppendTestUtil.java:257)",
            "app//org.apache.hadoop.hdfs.TestHDFSFileSystemContract.testAppend(TestHDFSFileSystemContract.java:68)",
            "app//org.apache.hadoop.hdfs.TestHDFSFileSystemContract.testAppend$$CONFUZZ(TestHDFSFileSystemContract.java)",
            "java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566)",
            "app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base@11.0.19/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.blockreport.incremental.intervalMsec": "512"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-108",
        "testClass": "org.apache.hadoop.hdfs.TestDFSShell",
        "testMethod": "testFilePermissions",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:130)",
            "org.apache.hadoop.util.GcTimeMonitor.<init>(GcTimeMonitor.java:135)",
            "org.apache.hadoop.util.GcTimeMonitor$Builder.build(GcTimeMonitor.java:90)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:759)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:1020)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:995)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1769)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:1374)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1143)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.TestDFSShell.setup(TestDFSShell.java:123)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.gc.time.monitor.sleep.interval.ms": "615ms",
            "dfs.namenode.gc.time.monitor.observation.window.ms": "29h"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager",
        "testMethod": "testRetainExtraLogs",
        "failure": "org.junit.ComparisonFailure",
        "errorMessage": "Check old edits are removed. expected:<...-0000000000000000200[]> but was:<...-0000000000000000200[,/foo2/current/edits_0000000000000000201-0000000000000000300]>",
        "stackTrace": [
            "org.junit.Assert.assertEquals(Assert.java:117)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.runTest(TestNNStorageRetentionManager.java:323)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testRetainExtraLogs(TestNNStorageRetentionManager.java:205)",
            "org.apache.hadoop.hdfs.server.namenode.TestNNStorageRetentionManager.testRetainExtraLogs$$CONFUZZ(TestNNStorageRetentionManager.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.max.extra.edits.segments.retained": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode",
        "testMethod": "testComplexFailoverIntoSafemode",
        "failure": "org.apache.hadoop.util.DiskChecker$DiskErrorException",
        "errorMessage": "Too many failed volumes - current valid volumes: 0, volumes configured: 2, volumes failed: 2, volume failures tolerated: 0",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.datanode.checker.StorageLocationChecker.check(StorageLocationChecker.java:233)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.makeInstance(DataNode.java:2821)",
            "org.apache.hadoop.hdfs.server.datanode.DataNode.instantiateDataNode(DataNode.java:2734)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(MiniDFSCluster.java:1755)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:969)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.setupCluster(TestHASafeMode.java:106)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.disk.check.timeout": "615ms",
            "ipc.server.read.threadpool.size": "3522"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot",
        "testMethod": "testXAttrForSnapshotRootAfterChange",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Cannot add additional XAttr to inode, would exceed limit of 1        at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setINodeXAttrs(FSDirXAttrOp.java:398)        at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:274)        at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:89)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:8271)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2282)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1709)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy31.setXAttr(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setXAttr(ClientNamenodeProtocolTranslatorPB.java:1741)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy32.setXAttr(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSClient.setXAttr(DFSClient.java:2866)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$58.doCall(DistributedFileSystem.java:2912)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$58.doCall(DistributedFileSystem.java:2908)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.setXAttr(DistributedFileSystem.java:2921)",
            "org.apache.hadoop.fs.FileSystem.setXAttr(FileSystem.java:3104)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot.testXAttrForSnapshotRootAfterChange(TestXAttrWithSnapshot.java:209)",
            "org.apache.hadoop.hdfs.server.namenode.snapshot.TestXAttrWithSnapshot.testXAttrForSnapshotRootAfterChange$$CONFUZZ(TestXAttrWithSnapshot.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.max-xattrs-per-inode": "1"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.TestDFSOutputStream",
        "testMethod": "testEndLeaseCall",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Exceeded the configured number of objects 1 in the filesystem.        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkFsObjectLimit(FSNamesystem.java:5167)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:393)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2703)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2596)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:799)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:494)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy29.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:382)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy30.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:280)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1271)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1250)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1232)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1170)",
            "org.apache.hadoop.hdfs.TestDFSOutputStream.testEndLeaseCall(TestDFSOutputStream.java:427)",
            "org.apache.hadoop.hdfs.TestDFSOutputStream.testEndLeaseCall$$CONFUZZ(TestDFSOutputStream.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.max.objects": "1"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.mover.TestMover",
        "testMethod": "testMoverCliWithFederationHA",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.batched.ls.limit must be greater than zero",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:914)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576)",
            "org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518)",
            "org.apache.hadoop.hdfs.server.mover.TestMover.testMoverCliWithFederationHA(TestMover.java:583)",
            "org.apache.hadoop.hdfs.server.mover.TestMover.testMoverCliWithFederationHA$$CONFUZZ(TestMover.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.batched.ls.limit": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestClusterId",
        "testMethod": "testFormat",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "dfs.batched.ls.limit must be greater than zero",
        "stackTrace": [
            "org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:914)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:796)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1256)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1726)",
            "org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormat(TestClusterId.java:143)",
            "org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormat$$CONFUZZ(TestClusterId.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.batched.ls.limit": "0"
        }
    },
    {
        "status": "Repeated-BUG",
        "bugId": "Bug-156",
        "testClass": "org.apache.hadoop.hdfs.TestMultipleNNPortQOP",
        "testMethod": "testAuxiliaryPortSendingQOP",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "File /filetestAuxiliaryPortSendingQOPPrimary could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and 3 node(s) are excluded in this operation.        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2315)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2960)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:904)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:604)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:572)        at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:556)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1093)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1043)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:971)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2976)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129)",
            "com.sun.proxy.$Proxy32.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)",
            "com.sun.proxy.$Proxy33.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1088)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1915)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1717)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:713)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.transfer.cipher.suites": "AES"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes",
        "testMethod": "testSnapshotPathINodesAfterModification",
        "failure": "java.io.IOException",
        "errorMessage": "Failed to replace a bad datanode on the existing pipeline due to no more good datanodes being available to try. (Nodes: current=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-143100b1-1780-4e37-94ae-0c178b8d113b,DISK]], original=[DatanodeInfoWithStorage[127.0.0.1:41153,DS-143100b1-1780-4e37-94ae-0c178b8d113b,DISK]]). The current failed datanode replacement policy is DEFAULT, and a client may configure this via 'dfs.client.block.write.replace-datanode-on-failure.policy' in its configuration.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.DataStreamer.findNewDatanode(DataStreamer.java:1352)",
            "org.apache.hadoop.hdfs.DataStreamer.addDatanode2ExistingPipeline(DataStreamer.java:1420)",
            "org.apache.hadoop.hdfs.DataStreamer.handleDatanodeReplacement(DataStreamer.java:1646)",
            "org.apache.hadoop.hdfs.DataStreamer.setupPipelineInternal(DataStreamer.java:1547)",
            "org.apache.hadoop.hdfs.DataStreamer.setupPipelineForAppendOrRecovery(DataStreamer.java:1529)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:717)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.overwrite.downstream.derived.qop": "true"
        }
    },
    {
        "status": "BUG",
        "bugId": "Bug-168",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat",
        "testMethod": "testBackwardsCompat",
        "failure": "java.lang.AssertionError",
        "errorMessage": "Exception occurred before anything was written: java.lang.NullPointerException; nulljava.lang.NullPointerException        at org.apache.hadoop.hdfs.server.datanode.DataXceiver.writeBlock(DataXceiver.java:814)        at org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat(TestDataXceiverBackwardsCompat.java:195)        at org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat$$CONFUZZ(TestDataXceiverBackwardsCompat.java)        at jdk.internal.reflect.GeneratedMethodAccessor38.invoke(Unknown Source)        at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.base/java.lang.reflect.Method.invoke(Method.java:566)        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)        at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)        at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)        at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)        at java.base/java.lang.Thread.run(Thread.java:829)",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.failWithException(TestDataXceiverBackwardsCompat.java:74)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat(TestDataXceiverBackwardsCompat.java:222)",
            "org.apache.hadoop.hdfs.server.datanode.TestDataXceiverBackwardsCompat.testBackwardsCompat$$CONFUZZ(TestDataXceiverBackwardsCompat.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.encrypt.data.overwrite.downstream.derived.qop": "true"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode",
        "testMethod": "testHttpServer",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<200> but was:<401>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hdfs.DFSTestUtil.urlGetBytes(DFSTestUtil.java:1003)",
            "org.apache.hadoop.hdfs.DFSTestUtil.urlGet(DFSTestUtil.java:993)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.testHttpServer(TestJournalNode.java:318)",
            "org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.testHttpServer$$CONFUZZ(TestJournalNode.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.http.authentication.simple.anonymous.allowed": "false"
        }
    },
    {
        "status": "Repeated",
        "bugId": "Bug-157",
        "testClass": "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl",
        "testMethod": "testScannerWithProvidedVolumes",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293)",
            "java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215)",
            "java.base/java.util.concurrent.Executors.newFixedThreadPool(Executors.java:155)",
            "org.apache.hadoop.hdfs.server.datanode.DirectoryScanner.<init>(DirectoryScanner.java:316)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.testScannerWithProvidedVolumes(TestProvidedImpl.java:604)",
            "org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestProvidedImpl.testScannerWithProvidedVolumes$$CONFUZZ(TestProvidedImpl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.directoryscan.threads": "0"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testEncodedPathUrl",
        "failure": "java.io.IOException",
        "errorMessage": "localhost:0: Access denied: dfs.http.policy is HTTPS_ONLY.",
        "stackTrace": [
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:710)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:1767)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:377)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getAuthParameters(WebHdfsFileSystem.java:598)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toUrl(WebHdfsFileSystem.java:626)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl(TestWebHdfsUrl.java:83)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos",
            "dfs.http.policy": "HTTPS_ONLY"
        }
    },
    {
        "status": "FP",
        "bugId": "",
        "testClass": "org.apache.hadoop.hdfs.web.TestWebHdfsUrl",
        "testMethod": "testEncodedPathUrl",
        "failure": "java.net.ConnectException",
        "errorMessage": "localhost:0: Connection refused (Connection refused)",
        "stackTrace": [
            "java.base/java.net.PlainSocketImpl.socketConnect(Native Method)",
            "java.base/java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:412)",
            "java.base/java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:255)",
            "java.base/java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:237)",
            "java.base/java.net.Socket.connect(Socket.java:609)",
            "java.base/sun.net.NetworkClient.doConnect(NetworkClient.java:177)",
            "java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:507)",
            "java.base/sun.net.www.http.HttpClient.openServer(HttpClient.java:602)",
            "java.base/sun.net.www.http.HttpClient.<init>(HttpClient.java:275)",
            "java.base/sun.net.www.http.HttpClient.New(HttpClient.java:374)",
            "java.base/sun.net.www.http.HttpClient.New(HttpClient.java:395)",
            "java.base/sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:1253)",
            "java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1187)",
            "java.base/sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1081)",
            "java.base/sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:1015)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:789)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:736)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:814)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:637)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:675)",
            "java.base/java.security.AccessController.doPrivileged(Native Method)",
            "java.base/javax.security.auth.Subject.doAs(Subject.java:423)",
            "org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:671)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:1767)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getDelegationToken(WebHdfsFileSystem.java:377)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.getAuthParameters(WebHdfsFileSystem.java:598)",
            "org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toUrl(WebHdfsFileSystem.java:626)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl(TestWebHdfsUrl.java:83)",
            "org.apache.hadoop.hdfs.web.TestWebHdfsUrl.testEncodedPathUrl$$CONFUZZ(TestWebHdfsUrl.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "org.junit.runners.ParentRunner.run(ParentRunner.java:413)",
            "org.junit.runner.JUnitCore.run(JUnitCore.java:137)",
            "edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208)",
            "edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hadoop.security.authentication": "kerberos"
        }
    }
]
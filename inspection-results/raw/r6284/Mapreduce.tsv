Note	exception	times	BUG or FP	lines						min_config																																																																																																																																																																																																																																																																																																																																																																																																	
fs.permissions.umask-mode missing regex	java.lang.IllegalArgumentException	25	FP	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterV2TaskCleanupEnabled	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 46 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 46 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:281),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled(TestFileOutputCommitter.java:331),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'fs.permissions.umask-mode': '46'}	["fs.permissions.umask-mode"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterV2TaskCleanupEnabled/campaign/failures/debug_000001	['debug_000001']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testRecoveryUpgradeV1V2	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 1195255995 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 1195255995 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapred.FileOutputCommitter.setupJob(FileOutputCommitter.java:131),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:103),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryUpgradeV1V2(TestFileOutputCommitter.java:171),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryUpgradeV1V2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testRecoveryUpgradeV1V2/campaign/failures/debug_000001	{'fs.permissions.umask-mode': '1195255995'}	['debug_000001']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testUncompressedInputWithLargeSplitSize	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value -583072856 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value -583072856 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1196),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052),at org.apache.hadoop.mapred.TestLineRecordReader.createInputFile(TestLineRecordReader.java:363),at org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputWithLargeSplitSize(TestLineRecordReader.java:377),at org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputWithLargeSplitSize$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testUncompressedInputWithLargeSplitSize/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '-583072856'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterV1	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 31092 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 31092 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapred.FileOutputCommitter.setupJob(FileOutputCommitter.java:131),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:333),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1(TestFileOutputCommitter.java:355),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterV1/campaign/failures/debug_000002	{'fs.permissions.umask-mode': '31092'}	['debug_000002']\n", "org.apache.hadoop.mapred.TestTaskProgressReporter#testBytesWrittenRespectingLimit	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 1608810215 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 1608810215 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1196),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.mapred.TestTaskProgressReporter.testBytesWrittenLimit(TestTaskProgressReporter.java:313),at org.apache.hadoop.mapred.TestTaskProgressReporter.testBytesWrittenRespectingLimit(TestTaskProgressReporter.java:279),at org.apache.hadoop.mapred.TestTaskProgressReporter.testBytesWrittenRespectingLimit$$CONFUZZ(TestTaskProgressReporter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestTaskProgressReporter/testBytesWrittenRespectingLimit/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '1608810215'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.IllegalArgumentException	Illegal bufferSize	java.lang.IllegalArgumentException: Illegal bufferSize,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000006	{'fs.permissions.umask-mode': '228'}	['debug_000006', 'debug_000004']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithFailureV1	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 15285 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 15285 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:415),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV1(TestFileOutputCommitter.java:388),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithFailureV1/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '15285'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV2	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 22859 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 22859 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:614),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '22859'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV1	java.lang.IllegalArgumentException	Illegal bufferSize	java.lang.IllegalArgumentException: Illegal bufferSize,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV1/campaign/failures/debug_000006	{'fs.permissions.umask-mode': '370773792'}	['debug_000006', 'debug_000005']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testConcurrentCommitTaskWithSubDirV1	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value -1585330977 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value -1585330977 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDir(TestFileOutputCommitter.java:765),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1(TestFileOutputCommitter.java:823),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testConcurrentCommitTaskWithSubDirV1/campaign/failures/debug_000003	{'fs.permissions.umask-mode': '-1585330977'}	['debug_000003']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testConcurrentCommitTaskWithSubDirV2	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 22781 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 22781 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDir(TestFileOutputCommitter.java:765),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV2(TestFileOutputCommitter.java:828),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testConcurrentCommitTaskWithSubDirV2/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '22781'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testUncompressedInputDefaultDelimiterPosValue	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value -456678170 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value -456678170 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1196),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052),at org.apache.hadoop.mapred.TestLineRecordReader.createInputFile(TestLineRecordReader.java:363),at org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue(TestLineRecordReader.java:607),at org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputDefaultDelimiterPosValue$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testUncompressedInputDefaultDelimiterPosValue/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '-456678170'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputFormat#testCheckOutputSpecsException	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value -231918951 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value -231918951 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputFormat.testCheckOutputSpecsException(TestFileOutputFormat.java:54),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputFormat.testCheckOutputSpecsException$$CONFUZZ(TestFileOutputFormat.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputFormat/testCheckOutputSpecsException/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '-231918951'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	SequenceFile doesn't work with GzipCodec without native-hadoop code!	java.lang.IllegalArgumentException: SequenceFile doesn't work with GzipCodec without native-hadoop code!,at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000012	{'fs.permissions.umask-mode': '255307495'}	['debug_000012', 'debug_000004', 'debug_000019']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	capacity < 0: (-1178096465 < 0)	java.lang.IllegalArgumentException: capacity < 0: (-1178096465 < 0),at java.base/java.nio.Buffer.createCapacityException(Buffer.java:256),at java.base/java.nio.Buffer.<init>(Buffer.java:220),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:281),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:289),at java.base/java.nio.MappedByteBuffer.<init>(MappedByteBuffer.java:90),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:114),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000018	{'fs.permissions.umask-mode': '255307495'}	['debug_000018']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	Illegal bufferSize	java.lang.IllegalArgumentException: Illegal bufferSize,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42),at org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000013	{'fs.permissions.umask-mode': '255307495'}	['debug_000013', 'debug_000016', 'debug_000010']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	capacity < 0: (-1361363707 < 0)	java.lang.IllegalArgumentException: capacity < 0: (-1361363707 < 0),at java.base/java.nio.Buffer.createCapacityException(Buffer.java:256),at java.base/java.nio.Buffer.<init>(Buffer.java:220),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:281),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:289),at java.base/java.nio.MappedByteBuffer.<init>(MappedByteBuffer.java:90),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:114),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000017	{'fs.permissions.umask-mode': '255307495'}	['debug_000017']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	capacity < 0: (-2146364006 < 0)	java.lang.IllegalArgumentException: capacity < 0: (-2146364006 < 0),at java.base/java.nio.Buffer.createCapacityException(Buffer.java:256),at java.base/java.nio.Buffer.<init>(Buffer.java:220),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:281),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:289),at java.base/java.nio.MappedByteBuffer.<init>(MappedByteBuffer.java:90),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:114),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000026	{'fs.permissions.umask-mode': '255307495'}	['debug_000026']\n", "org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory#testBoundCommitterWithDefault	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 72338756 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 72338756 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.hdfs.client.impl.DfsClientConf.<init>(DfsClientConf.java:250),at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:324),at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:308),at org.apache.hadoop.hdfs.DistributedFileSystem.initDFSClient(DistributedFileSystem.java:202),at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:187),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:162),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:118),at org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory.createFileOutputCommitter(PathOutputCommitterFactory.java:134),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory.createOutputCommitter(FileOutputCommitterFactory.java:35),at org.apache.hadoop.mapreduce.lib.output.BindingPathOutputCommitter.<init>(BindingPathOutputCommitter.java:87),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testBoundCommitterWithDefault(TestPathOutputCommitterFactory.java:383),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testBoundCommitterWithDefault$$CONFUZZ(TestPathOutputCommitterFactory.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory/testBoundCommitterWithDefault/campaign/failures/debug_000001	{'fs.permissions.umask-mode': '72338756'}	['debug_000001']\n", "org.apache.hadoop.mapred.TestIndexCache#testCreateRace	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 1894513377 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 1894513377 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:424),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.mapred.TestIndexCache.writeFile(TestIndexCache.java:320),at org.apache.hadoop.mapred.TestIndexCache.testCreateRace(TestIndexCache.java:262),at org.apache.hadoop.mapred.TestIndexCache.testCreateRace$$CONFUZZ(TestIndexCache.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestIndexCache/testCreateRace/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '1894513377'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	SequenceFile doesn't work with GzipCodec without native-hadoop code!	java.lang.IllegalArgumentException: SequenceFile doesn't work with GzipCodec without native-hadoop code!,at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.IllegalArgumentException	SequenceFile doesn't work with GzipCodec without native-hadoop code!	java.lang.IllegalArgumentException: SequenceFile doesn't work with GzipCodec without native-hadoop code!,at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000008	{'fs.permissions.umask-mode': '253'}	['debug_000008', 'debug_000002', 'debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	capacity < 0: (-1449965598 < 0)	java.lang.IllegalArgumentException: capacity < 0: (-1449965598 < 0),at java.base/java.nio.Buffer.createCapacityException(Buffer.java:256),at java.base/java.nio.Buffer.<init>(Buffer.java:220),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:281),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:289),at java.base/java.nio.MappedByteBuffer.<init>(MappedByteBuffer.java:90),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:114),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000024	{'fs.permissions.umask-mode': '26061'}	['debug_000024']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithDuplicatedCommitV2	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 633314872 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 633314872 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:357),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:341),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithDuplicatedCommitV2/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '633314872'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV1	java.lang.IllegalArgumentException	Illegal bufferSize	java.lang.IllegalArgumentException: Illegal bufferSize,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV1/campaign/failures/debug_000006	{'fs.permissions.umask-mode': '-1394217577'}	['debug_000006', 'debug_000003']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV2	java.lang.IllegalArgumentException	Illegal bufferSize	java.lang.IllegalArgumentException: Illegal bufferSize,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42),at org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV2/campaign/failures/debug_000004	{'fs.permissions.umask-mode': '44'}	['debug_000004', 'debug_000005']\n"]																																																																																																																																												
	java.lang.ClassNotFoundException	6	FP	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterV2TaskCleanupEnabled	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:286),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled(TestFileOutputCommitter.java:331),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:286),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled(TestFileOutputCommitter.java:331),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterV2TaskCleanupEnabled/campaign/failures/debug_000002	['debug_000002']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV2	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000003	{'hadoop.security.authentication': 'kerberos'}	['debug_000003']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000008	{'hadoop.security.authentication': 'kerberos'}	['debug_000008']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testAbortV2	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000002	{'hadoop.security.authentication': 'kerberos'}	['debug_000002']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000003	{'hadoop.security.authentication': 'kerberos'}	['debug_000003']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001']\n"]																																																																																																																																																																																																																																																																																																																																										
	java.lang.AssertionError	9	FP	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterV2TaskCleanupEnabled	java.lang.AssertionError	job temp dir still exists	java.lang.AssertionError: job temp dir still exists,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.junit.Assert.assertFalse(Assert.java:65),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:311),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled(TestFileOutputCommitter.java:331),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	java.lang.AssertionError	job temp dir still exists	java.lang.AssertionError: job temp dir still exists,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.junit.Assert.assertFalse(Assert.java:65),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:311),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled(TestFileOutputCommitter.java:331),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2TaskCleanupEnabled$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterV2TaskCleanupEnabled/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterV2	java.lang.AssertionError	job temp dir still exists	java.lang.AssertionError: job temp dir still exists,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.junit.Assert.assertFalse(Assert.java:65),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:311),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:326),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.AssertionError	job temp dir still exists	java.lang.AssertionError: job temp dir still exists,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.junit.Assert.assertFalse(Assert.java:65),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:311),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:326),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterV2/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testConcurrentCommitTaskWithSubDirV1	java.lang.AssertionError	Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/SUB_DIR/part-m-00000	java.lang.AssertionError: Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/SUB_DIR/part-m-00000,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:223),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDir(TestFileOutputCommitter.java:817),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1(TestFileOutputCommitter.java:823),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.AssertionError	Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/SUB_DIR/part-m-00000	java.lang.AssertionError: Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/SUB_DIR/part-m-00000,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:223),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDir(TestFileOutputCommitter.java:817),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1(TestFileOutputCommitter.java:823),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testConcurrentCommitTaskWithSubDirV1/campaign/failures/debug_000004	{'hadoop.security.authentication': 'kerberos'}	['debug_000004']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testConcurrentCommitTaskWithSubDirV2	java.lang.AssertionError	Must not end up with sub_dir/sub_dir	java.lang.AssertionError: Must not end up with sub_dir/sub_dir,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.junit.Assert.assertFalse(Assert.java:65),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDir(TestFileOutputCommitter.java:813),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV2(TestFileOutputCommitter.java:828),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.AssertionError	Must not end up with sub_dir/sub_dir	java.lang.AssertionError: Must not end up with sub_dir/sub_dir,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.junit.Assert.assertFalse(Assert.java:65),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDir(TestFileOutputCommitter.java:813),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV2(TestFileOutputCommitter.java:828),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testConcurrentCommitTaskWithSubDirV2/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testRecordSpanningMultipleSplits	java.lang.AssertionError	Wrong number of records expected:<4> but was:<14>	java.lang.AssertionError: Wrong number of records expected:<4> but was:<14>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:197),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits(TestLineRecordReader.java:214),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.AssertionError	Wrong number of records expected:<4> but was:<14>	java.lang.AssertionError: Wrong number of records expected:<4> but was:<14>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:197),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits(TestLineRecordReader.java:214),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testRecordSpanningMultipleSplits/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testRecordSpanningMultipleSplitsCompressed	java.lang.AssertionError	Wrong number of records expected:<4> but was:<3>	java.lang.AssertionError: Wrong number of records expected:<4> but was:<3>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:197),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed(TestLineRecordReader.java:225),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.AssertionError	Wrong number of records expected:<4> but was:<3>	java.lang.AssertionError: Wrong number of records expected:<4> but was:<3>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:197),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed(TestLineRecordReader.java:225),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testRecordSpanningMultipleSplitsCompressed/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithDuplicatedCommitV2	java.lang.AssertionError	Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000	java.lang.AssertionError: Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:223),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:370),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:341),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.AssertionError	Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000	java.lang.AssertionError: Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:223),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:370),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:341),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithDuplicatedCommitV2/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithDuplicatedCommitV1	java.lang.AssertionError	Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000	java.lang.AssertionError: Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:223),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:370),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:336),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.AssertionError	Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000	java.lang.AssertionError: Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:223),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:370),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:336),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithDuplicatedCommitV1/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testRecordSpanningMultipleSplits	java.lang.AssertionError	Wrong number of records expected:<4> but was:<0>	java.lang.AssertionError: Wrong number of records expected:<4> but was:<0>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.apache.hadoop.mapred.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:252),at org.apache.hadoop.mapred.TestLineRecordReader.testRecordSpanningMultipleSplits(TestLineRecordReader.java:269),at org.apache.hadoop.mapred.TestLineRecordReader.testRecordSpanningMultipleSplits$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.AssertionError	Wrong number of records expected:<4> but was:<0>	java.lang.AssertionError: Wrong number of records expected:<4> but was:<0>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.apache.hadoop.mapred.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:252),at org.apache.hadoop.mapred.TestLineRecordReader.testRecordSpanningMultipleSplits(TestLineRecordReader.java:269),at org.apache.hadoop.mapred.TestLineRecordReader.testRecordSpanningMultipleSplits$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testRecordSpanningMultipleSplits/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																												
WHAT THE HECK	java.lang.IllegalArgumentException	39	FP	["org.apache.hadoop.mapred.TestFileOutputCommitter#testRecoveryV1	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value -107073310 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value -107073310 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapred.FileOutputCommitter.setupJob(FileOutputCommitter.java:131),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:103),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:161),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testRecoveryV1/campaign/failures/debug_000001	['debug_000001']\n", "org.apache.hadoop.mapred.TestIndexCache#testRemoveMap	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value -347941232 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value -347941232 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:424),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.mapred.TestIndexCache.writeFile(TestIndexCache.java:320),at org.apache.hadoop.mapred.TestIndexCache.testRemoveMap(TestIndexCache.java:218),at org.apache.hadoop.mapred.TestIndexCache.testRemoveMap$$CONFUZZ(TestIndexCache.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestIndexCache/testRemoveMap/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory#testCommitterFallbackDefault	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value -150665246 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value -150665246 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.hdfs.client.impl.DfsClientConf.<init>(DfsClientConf.java:250),at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:324),at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:308),at org.apache.hadoop.hdfs.DistributedFileSystem.initDFSClient(DistributedFileSystem.java:202),at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:187),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:162),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:118),at org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory.createFileOutputCommitter(PathOutputCommitterFactory.java:134),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory.createOutputCommitter(FileOutputCommitterFactory.java:35),at org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory.createCommitter(PathOutputCommitterFactory.java:201),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.createCommitter(TestPathOutputCommitterFactory.java:237),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testCommitterFallbackDefault(TestPathOutputCommitterFactory.java:82),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testCommitterFallbackDefault$$CONFUZZ(TestPathOutputCommitterFactory.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory/testCommitterFallbackDefault/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithFailureV1	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value -1126726138 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value -1126726138 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapred.FileOutputCommitter.setupJob(FileOutputCommitter.java:131),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:237),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV1(TestFileOutputCommitter.java:214),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithFailureV1/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testFailAbortV2	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 13202 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 13202 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapred.FileOutputCommitter.setupJob(FileOutputCommitter.java:131),at org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:516),at org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV2(TestFileOutputCommitter.java:565),at org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testFailAbortV2/campaign/failures/debug_000002	{'hadoop.security.authentication': 'kerberos'}	['debug_000002']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testProgressDuringMerge	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 29331 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 29331 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:455),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testProgressDuringMerge/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testProgressDuringMerge	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:73),at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testProgressDuringMerge/campaign/failures/debug_000005	{'hadoop.security.authentication': 'kerberos'}	['debug_000005']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterV2	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 1809139829 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 1809139829 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapred.FileOutputCommitter.setupJob(FileOutputCommitter.java:131),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:333),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterV2/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterV1	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value -923991862 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value -923991862 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapred.FileOutputCommitter.setupJob(FileOutputCommitter.java:131),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:333),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1(TestFileOutputCommitter.java:355),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterV1/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterV2	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 13916 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 13916 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:281),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:326),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterV2/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testUncompressedInputCustomDelimiterPosValue	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 8916 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 8916 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1196),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.createInputFile(TestLineRecordReader.java:312),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue(TestLineRecordReader.java:417),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testUncompressedInputCustomDelimiterPosValue/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV2	java.lang.IllegalArgumentException	Illegal bufferSize	java.lang.IllegalArgumentException: Illegal bufferSize,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000006	{'hadoop.security.authentication': 'kerberos'}	['debug_000006', 'debug_000005']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV1	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 253553941 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 253553941 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:614),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV1/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testConcurrentCommitTaskWithSubDirV1	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 728 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 728 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDir(TestFileOutputCommitter.java:765),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1(TestFileOutputCommitter.java:823),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testConcurrentCommitTaskWithSubDirV1/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	Illegal bufferSize	java.lang.IllegalArgumentException: Illegal bufferSize,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42),at org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000012	{'hadoop.security.authentication': 'kerberos'}	['debug_000012', 'debug_000018', 'debug_000014']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	SequenceFile doesn't work with GzipCodec without native-hadoop code!	java.lang.IllegalArgumentException: SequenceFile doesn't work with GzipCodec without native-hadoop code!,at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000007	{'hadoop.security.authentication': 'kerberos'}	['debug_000007', 'debug_000004', 'debug_000010']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	capacity < 0: (-2087838312 < 0)	java.lang.IllegalArgumentException: capacity < 0: (-2087838312 < 0),at java.base/java.nio.Buffer.createCapacityException(Buffer.java:256),at java.base/java.nio.Buffer.<init>(Buffer.java:220),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:281),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:289),at java.base/java.nio.MappedByteBuffer.<init>(MappedByteBuffer.java:90),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:114),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000023	{'hadoop.security.authentication': 'kerberos'}	['debug_000023']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:73),at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000027	{'hadoop.security.authentication': 'kerberos'}	['debug_000027', 'debug_000017', 'debug_000021']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	capacity < 0: (-876833582 < 0)	java.lang.IllegalArgumentException: capacity < 0: (-876833582 < 0),at java.base/java.nio.Buffer.createCapacityException(Buffer.java:256),at java.base/java.nio.Buffer.<init>(Buffer.java:220),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:281),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:289),at java.base/java.nio.MappedByteBuffer.<init>(MappedByteBuffer.java:90),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:114),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000020	{'hadoop.security.authentication': 'kerberos'}	['debug_000020']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	capacity < 0: (-2084866685 < 0)	java.lang.IllegalArgumentException: capacity < 0: (-2084866685 < 0),at java.base/java.nio.Buffer.createCapacityException(Buffer.java:256),at java.base/java.nio.Buffer.<init>(Buffer.java:220),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:281),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:289),at java.base/java.nio.MappedByteBuffer.<init>(MappedByteBuffer.java:90),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:114),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000022	{'hadoop.security.authentication': 'kerberos'}	['debug_000022']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 1222403262 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 1222403262 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapred.FileOutputCommitter.setupJob(FileOutputCommitter.java:131),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:375),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testUncompressedInput	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 28280 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 28280 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1196),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.createInputFile(TestLineRecordReader.java:312),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInput(TestLineRecordReader.java:326),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testUncompressedInput$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testUncompressedInput/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testAbortV2	java.lang.IllegalArgumentException	Illegal bufferSize	java.lang.IllegalArgumentException: Illegal bufferSize,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000006	{'hadoop.security.authentication': 'kerberos'}	['debug_000006', 'debug_000005']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testAbortV2	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 313702514 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 313702514 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapred.FileOutputCommitter.setupJob(FileOutputCommitter.java:131),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:451),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	capacity < 0: (-1005790319 < 0)	java.lang.IllegalArgumentException: capacity < 0: (-1005790319 < 0),at java.base/java.nio.Buffer.createCapacityException(Buffer.java:256),at java.base/java.nio.Buffer.<init>(Buffer.java:220),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:281),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:289),at java.base/java.nio.MappedByteBuffer.<init>(MappedByteBuffer.java:90),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:114),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000007	{'hadoop.security.authentication': 'kerberos'}	['debug_000007']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:73),at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000023	{'hadoop.security.authentication': 'kerberos'}	['debug_000023']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	Illegal bufferSize	java.lang.IllegalArgumentException: Illegal bufferSize,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42),at org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000006	{'hadoop.security.authentication': 'kerberos'}	['debug_000006', 'debug_000021', 'debug_000028']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	capacity < 0: (-1030986111 < 0)	java.lang.IllegalArgumentException: capacity < 0: (-1030986111 < 0),at java.base/java.nio.Buffer.createCapacityException(Buffer.java:256),at java.base/java.nio.Buffer.<init>(Buffer.java:220),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:281),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:289),at java.base/java.nio.MappedByteBuffer.<init>(MappedByteBuffer.java:90),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:114),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000022	{'hadoop.security.authentication': 'kerberos'}	['debug_000022']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	capacity < 0: (-1360244123 < 0)	java.lang.IllegalArgumentException: capacity < 0: (-1360244123 < 0),at java.base/java.nio.Buffer.createCapacityException(Buffer.java:256),at java.base/java.nio.Buffer.<init>(Buffer.java:220),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:281),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:289),at java.base/java.nio.MappedByteBuffer.<init>(MappedByteBuffer.java:90),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:114),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000019	{'hadoop.security.authentication': 'kerberos'}	['debug_000019']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.IllegalArgumentException	newLimit > capacity: (16 > 14)	java.lang.IllegalArgumentException: newLimit > capacity: (16 > 14),at java.base/java.nio.Buffer.createLimitException(Buffer.java:372),at java.base/java.nio.Buffer.limit(Buffer.java:346),at java.base/java.nio.ByteBuffer.limit(ByteBuffer.java:1107),at java.base/java.nio.MappedByteBuffer.limit(MappedByteBuffer.java:235),at java.base/java.nio.MappedByteBuffer.limit(MappedByteBuffer.java:67),at org.xerial.snappy.Snappy.compress(Snappy.java:156),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.compressDirectBuf(SnappyCompressor.java:282),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.compress(SnappyCompressor.java:210),at org.apache.hadoop.io.compress.BlockCompressorStream.compress(BlockCompressorStream.java:149),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:131),at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81),at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142),at java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.writeBuffer(SequenceFile.java:1588),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.sync(SequenceFile.java:1606),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.close(SequenceFile.java:1629),at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat$1.close(MapFileOutputFormat.java:83),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeMapFileOutput(TestFileOutputCommitter.java:138),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:556),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000026	{'hadoop.security.authentication': 'kerberos'}	['debug_000026']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testRecoveryV1	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 19737 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 19737 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:156),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:209),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testRecoveryV1/campaign/failures/debug_000002	{'hadoop.security.authentication': 'kerberos'}	['debug_000002']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	SequenceFile doesn't work with GzipCodec without native-hadoop code!	java.lang.IllegalArgumentException: SequenceFile doesn't work with GzipCodec without native-hadoop code!,at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1187),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000012	{'hadoop.security.authentication': 'kerberos'}	['debug_000012', 'debug_000011', 'debug_000003']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	Illegal bufferSize	java.lang.IllegalArgumentException: Illegal bufferSize,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42),at org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000018	{'hadoop.security.authentication': 'kerberos'}	['debug_000018', 'debug_000014', 'debug_000019']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:73),at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000023	{'hadoop.security.authentication': 'kerberos'}	['debug_000023', 'debug_000017', 'debug_000021']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	capacity < 0: (-1656800680 < 0)	java.lang.IllegalArgumentException: capacity < 0: (-1656800680 < 0),at java.base/java.nio.Buffer.createCapacityException(Buffer.java:256),at java.base/java.nio.Buffer.<init>(Buffer.java:220),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:281),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:289),at java.base/java.nio.MappedByteBuffer.<init>(MappedByteBuffer.java:90),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:114),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000015	{'hadoop.security.authentication': 'kerberos'}	['debug_000015']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	capacity < 0: (-1849527397 < 0)	java.lang.IllegalArgumentException: capacity < 0: (-1849527397 < 0),at java.base/java.nio.Buffer.createCapacityException(Buffer.java:256),at java.base/java.nio.Buffer.<init>(Buffer.java:220),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:281),at java.base/java.nio.ByteBuffer.<init>(ByteBuffer.java:289),at java.base/java.nio.MappedByteBuffer.<init>(MappedByteBuffer.java:90),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:114),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000022	{'hadoop.security.authentication': 'kerberos'}	['debug_000022']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithDuplicatedCommitV1	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 180 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 180 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:357),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:336),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithDuplicatedCommitV1/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testRecoveryV2	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 1651385139 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 1651385139 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapred.FileOutputCommitter.setupJob(FileOutputCommitter.java:131),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:103),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV2(TestFileOutputCommitter.java:166),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testRecoveryV2/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testMultipleClose	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:207),at org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56),at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161),at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372),at org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896),at org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52),at org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894),at org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:92),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testMultipleClose(TestLineRecordReader.java:285),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testMultipleClose$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testMultipleClose/campaign/failures/debug_000003	{'hadoop.security.authentication': 'kerberos'}	['debug_000003']\n"]
fs.permissions.umask-mode should be	java.io.FileNotFoundException	2	FP	["org.apache.hadoop.mapred.TestFileOutputCommitter#testRecoveryV1	java.io.FileNotFoundException	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/task_200707121733_0001_m_000000/part-00000 (No such file or directory)	java.io.FileNotFoundException: /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/task_200707121733_0001_m_000000/part-00000 (No such file or directory),at java.base/java.io.FileInputStream.open0(Native Method),at java.base/java.io.FileInputStream.open(FileInputStream.java:219),at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157),at org.apache.hadoop.mapred.TestFileOutputCommitter.slurp(TestFileOutputCommitter.java:570),at org.apache.hadoop.mapred.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:184),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:121),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:161),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'fs.permissions.umask-mode': '128197316'}	["fs.permissions.umask-mode"]	java.io.FileNotFoundException	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/task_200707121733_0001_m_000000/part-00000 (No such file or directory)	java.io.FileNotFoundException: /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/task_200707121733_0001_m_000000/part-00000 (No such file or directory),at java.base/java.io.FileInputStream.open0(Native Method),at java.base/java.io.FileInputStream.open(FileInputStream.java:219),at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157),at org.apache.hadoop.mapred.TestFileOutputCommitter.slurp(TestFileOutputCommitter.java:570),at org.apache.hadoop.mapred.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:184),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:121),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:161),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testRecoveryV1/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testUncompressedInputCustomDelimiterPosValue	java.io.FileNotFoundException	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/data/TestTextInputFormat/input/test.txt (Permission denied)	java.io.FileNotFoundException: /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/data/TestTextInputFormat/input/test.txt (Permission denied),at java.base/java.io.FileInputStream.open0(Native Method),at java.base/java.io.FileInputStream.open(FileInputStream.java:219),at java.base/java.io.FileInputStream.<init>(FileInputStream.java:157),at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileInputStream.<init>(RawLocalFileSystem.java:146),at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161),at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372),at org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896),at org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52),at org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894),at org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:115),at org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue(TestLineRecordReader.java:491),at org.apache.hadoop.mapred.TestLineRecordReader.testUncompressedInputCustomDelimiterPosValue$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testUncompressedInputCustomDelimiterPosValue/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '557'}	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																		
hadoop.security.groups.cache.background.reload.threads >= 0	java.lang.IllegalArgumentException	5	FP	["org.apache.hadoop.mapreduce.task.reduce.TestMergeManager#testLargeMemoryLimits	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 1345600422 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 1345600422 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:424),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052),at org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<init>(OnDiskMapOutput.java:88),at org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.reserve(MergeManagerImpl.java:274),at org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.verifyReservedMapOutputType(TestMergeManager.java:309),at org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testLargeMemoryLimits(TestMergeManager.java:303),at org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testLargeMemoryLimits$$CONFUZZ(TestMergeManager.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'hadoop.security.groups.cache.background.reload.threads': '-2009635460', 'hadoop.security.groups.cache.background.reload': 'true'}	["hadoop.security.groups.cache.background.reload", "hadoop.security.groups.cache.background.reload.threads"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.task.reduce.TestMergeManager/testLargeMemoryLimits/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithDuplicatedCommitV1	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value 25649 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value 25649 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:356),at org.apache.hadoop.mapred.FileOutputCommitter.setupJob(FileOutputCommitter.java:131),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:289),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:269),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithDuplicatedCommitV1/campaign/failures/debug_000000	{'hadoop.security.groups.cache.background.reload': 'true', 'hadoop.security.groups.cache.background.reload.threads': '-1254070382'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:73),at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000008	{'hadoop.security.groups.cache.background.reload.threads': '-1061223288', 'hadoop.security.groups.cache.background.reload': 'true'}	['debug_000008', 'debug_000023']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testBzipWithMultibyteDelimiter	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:207),at org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56),at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161),at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372),at org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896),at org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52),at org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894),at org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:92),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:87),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:646),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testBzipWithMultibyteDelimiter/campaign/failures/debug_000002	{'hadoop.security.groups.cache.background.reload': 'true', 'hadoop.security.groups.cache.background.reload.threads': '-827601380'}	['debug_000002']\n", "org.apache.hadoop.mapreduce.task.reduce.TestFetcher#testCorruptedIFile	java.lang.IllegalArgumentException	Unable to parse configuration fs.permissions.umask-mode with value -260841145 as octal or symbolic umask.	java.lang.IllegalArgumentException: Unable to parse configuration fs.permissions.umask-mode with value -260841145 as octal or symbolic umask.,at org.apache.hadoop.fs.permission.FsPermission.getUMask(FsPermission.java:324),at org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:644),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700),at org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:424),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052),at org.apache.hadoop.mapreduce.task.reduce.OnDiskMapOutput.<init>(OnDiskMapOutput.java:88),at org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCorruptedIFile(TestFetcher.java:539),at org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCorruptedIFile$$CONFUZZ(TestFetcher.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.task.reduce.TestFetcher/testCorruptedIFile/campaign/failures/debug_000000	{'hadoop.security.groups.cache.background.reload': 'true', 'hadoop.security.groups.cache.background.reload.threads': '-964983109'}	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																				
	java.lang.OutOfMemoryError	6	BUG	["org.apache.hadoop.mapred.lib.TestCombineFileRecordReader#testInitNextRecordReader	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.util.LineReader.<init>(LineReader.java:142),at org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37),at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.<init>(UncompressedSplitLineReader.java:46),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:142),at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67),at org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper.<init>(CombineFileRecordReaderWrapper.java:60),at org.apache.hadoop.mapred.lib.TestCombineFileRecordReader$TextRecordReaderWrapper.<init>(TestCombineFileRecordReader.java:52),at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490),at org.apache.hadoop.mapred.lib.CombineFileRecordReader.initNextRecordReader(CombineFileRecordReader.java:142),at org.apache.hadoop.mapred.lib.CombineFileRecordReader.<init>(CombineFileRecordReader.java:117),at org.apache.hadoop.mapred.lib.TestCombineFileRecordReader.testInitNextRecordReader(TestCombineFileRecordReader.java:77),at org.apache.hadoop.mapred.lib.TestCombineFileRecordReader.testInitNextRecordReader$$CONFUZZ(TestCombineFileRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	REPRODUCIBLE	{'io.file.buffer.size': '1466105869'}	["io.file.buffer.size"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.lib.TestCombineFileRecordReader/testInitNextRecordReader/campaign/failures/debug_000001	['debug_000001', 'debug_000002', 'debug_000000']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testBzip2SplitEndsAtCR	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.util.LineReader.<init>(LineReader.java:142),at org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37),at org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader.<init>(CompressedSplitLineReader.java:122),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:123),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:81),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecords(TestLineRecordReader.java:62),at org.apache.hadoop.mapred.TestLineRecordReader.testBzip2SplitEndsAtCR(TestLineRecordReader.java:156),at org.apache.hadoop.mapred.TestLineRecordReader.testBzip2SplitEndsAtCR$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testBzip2SplitEndsAtCR/campaign/failures/debug_000000	{'io.file.buffer.size': '1372554133'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testBzipWithMultibyteDelimiter	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.util.LineReader.<init>(LineReader.java:142),at org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37),at org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader.<init>(CompressedSplitLineReader.java:122),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:123),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:81),at org.apache.hadoop.mapred.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:684),at org.apache.hadoop.mapred.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testBzipWithMultibyteDelimiter/campaign/failures/debug_000001	{'io.file.buffer.size': '1669972020'}	['debug_000001', 'debug_000002', 'debug_000000']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testSafeguardSplittingUnsplittableFiles	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.util.LineReader.<init>(LineReader.java:142),at org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:135),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:81),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecords(TestLineRecordReader.java:62),at org.apache.hadoop.mapred.TestLineRecordReader.testSafeguardSplittingUnsplittableFiles(TestLineRecordReader.java:192),at org.apache.hadoop.mapred.TestLineRecordReader.testSafeguardSplittingUnsplittableFiles$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testSafeguardSplittingUnsplittableFiles/campaign/failures/debug_000001	{'io.file.buffer.size': '1565348751'}	['debug_000001', 'debug_000002', 'debug_000003']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testBzip2SplitStartAtBlockMarker	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209),at org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56),at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161),at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372),at org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896),at org.apache.hadoop.fs.ChecksumFileSystem$$Lambda$116/0x000000084018fc40.call(Unknown Source),at org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52),at org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894),at org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:115),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:81),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecords(TestLineRecordReader.java:62),at org.apache.hadoop.mapred.TestLineRecordReader.testBzip2SplitStartAtBlockMarker(TestLineRecordReader.java:176),at org.apache.hadoop.mapred.TestLineRecordReader.testBzip2SplitStartAtBlockMarker$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testBzip2SplitStartAtBlockMarker/campaign/failures/debug_000001	{'io.file.buffer.size': '2135651315'}	['debug_000001', 'debug_000002', 'debug_000000']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testMultipleClose	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testMultipleClose/campaign/failures/debug_000001	{'io.file.buffer.size': '1398198412'}	['debug_000001', 'debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																										
	java.lang.IllegalArgumentException	7	FP	["org.apache.hadoop.mapred.lib.TestCombineFileRecordReader#testInitNextRecordReader	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:207),at org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56),at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161),at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372),at org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896),at org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52),at org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894),at org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:115),at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67),at org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper.<init>(CombineFileRecordReaderWrapper.java:60),at org.apache.hadoop.mapred.lib.TestCombineFileRecordReader$TextRecordReaderWrapper.<init>(TestCombineFileRecordReader.java:52),at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490),at org.apache.hadoop.mapred.lib.CombineFileRecordReader.initNextRecordReader(CombineFileRecordReader.java:142),at org.apache.hadoop.mapred.lib.CombineFileRecordReader.<init>(CombineFileRecordReader.java:117),at org.apache.hadoop.mapred.lib.TestCombineFileRecordReader.testInitNextRecordReader(TestCombineFileRecordReader.java:77),at org.apache.hadoop.mapred.lib.TestCombineFileRecordReader.testInitNextRecordReader$$CONFUZZ(TestCombineFileRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'io.file.buffer.size': '0'}	["io.file.buffer.size"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.lib.TestCombineFileRecordReader/testInitNextRecordReader/campaign/failures/debug_000004	['debug_000004']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testBzip2SplitEndsAtCR	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:207),at org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56),at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161),at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372),at org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896),at org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52),at org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894),at org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:115),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:81),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecords(TestLineRecordReader.java:62),at org.apache.hadoop.mapred.TestLineRecordReader.testBzip2SplitEndsAtCR(TestLineRecordReader.java:156),at org.apache.hadoop.mapred.TestLineRecordReader.testBzip2SplitEndsAtCR$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testBzip2SplitEndsAtCR/campaign/failures/debug_000001	{'io.file.buffer.size': '0'}	['debug_000001']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testStripBOM	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:207),at org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56),at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161),at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372),at org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896),at org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52),at org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894),at org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:92),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testStripBOM(TestLineRecordReader.java:250),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testStripBOM$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testStripBOM/campaign/failures/debug_000001	{'io.file.buffer.size': '0'}	['debug_000001']\n", "org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader#testProgressIsReportedIfInputASeriesOfEmptyFiles	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:207),at org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56),at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161),at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372),at org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896),at org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52),at org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894),at org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:92),at org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReaderWrapper.initialize(CombineFileRecordReaderWrapper.java:69),at org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.initialize(CombineFileRecordReader.java:59),at org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader.testProgressIsReportedIfInputASeriesOfEmptyFiles(TestCombineFileRecordReader.java:86),at org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader.testProgressIsReportedIfInputASeriesOfEmptyFiles$$CONFUZZ(TestCombineFileRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader/testProgressIsReportedIfInputASeriesOfEmptyFiles/campaign/failures/debug_000003	{'io.file.buffer.size': '0'}	['debug_000003']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testStripBOM	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:207),at org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56),at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161),at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372),at org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896),at org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52),at org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894),at org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:115),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:96),at org.apache.hadoop.mapred.TestLineRecordReader.testStripBOM(TestLineRecordReader.java:300),at org.apache.hadoop.mapred.TestLineRecordReader.testStripBOM$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testStripBOM/campaign/failures/debug_000000	{'io.file.buffer.size': '0'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testBzipWithMultibyteDelimiter	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:207),at org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56),at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161),at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372),at org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896),at org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52),at org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894),at org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:115),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:81),at org.apache.hadoop.mapred.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:684),at org.apache.hadoop.mapred.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testBzipWithMultibyteDelimiter/campaign/failures/debug_000003	{'io.file.buffer.size': '0'}	['debug_000003']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testSafeguardSplittingUnsplittableFiles	java.lang.IllegalArgumentException	Buffer size <= 0	java.lang.IllegalArgumentException: Buffer size <= 0,at java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:207),at org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56),at org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161),at org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372),at org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896),at org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52),at org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894),at org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:115),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:81),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecords(TestLineRecordReader.java:62),at org.apache.hadoop.mapred.TestLineRecordReader.testSafeguardSplittingUnsplittableFiles(TestLineRecordReader.java:192),at org.apache.hadoop.mapred.TestLineRecordReader.testSafeguardSplittingUnsplittableFiles$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testSafeguardSplittingUnsplittableFiles/campaign/failures/debug_000004	{'io.file.buffer.size': '0'}	['debug_000004']\n"]																																																																																																																																																																																																																																																																																																																																
L3514 of Filesystem.java throws an illegal error but the actual error thrown is error in initializer?	java.lang.IllegalStateException	1	FP	["org.apache.hadoop.mapred.lib.TestCombineFileRecordReader#testInitNextRecordReader	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:111),at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67),at org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper.<init>(CombineFileRecordReaderWrapper.java:60),at org.apache.hadoop.mapred.lib.TestCombineFileRecordReader$TextRecordReaderWrapper.<init>(TestCombineFileRecordReader.java:52),at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490),at org.apache.hadoop.mapred.lib.CombineFileRecordReader.initNextRecordReader(CombineFileRecordReader.java:142),at org.apache.hadoop.mapred.lib.CombineFileRecordReader.<init>(CombineFileRecordReader.java:117),at org.apache.hadoop.mapred.lib.TestCombineFileRecordReader.testInitNextRecordReader(TestCombineFileRecordReader.java:77),at org.apache.hadoop.mapred.lib.TestCombineFileRecordReader.testInitNextRecordReader$$CONFUZZ(TestCombineFileRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'fs.creation.parallel.count': '0'}	["fs.creation.parallel.count"]	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:111),at org.apache.hadoop.mapred.TextInputFormat.getRecordReader(TextInputFormat.java:67),at org.apache.hadoop.mapred.lib.CombineFileRecordReaderWrapper.<init>(CombineFileRecordReaderWrapper.java:60),at org.apache.hadoop.mapred.lib.TestCombineFileRecordReader$TextRecordReaderWrapper.<init>(TestCombineFileRecordReader.java:52),at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490),at org.apache.hadoop.mapred.lib.CombineFileRecordReader.initNextRecordReader(CombineFileRecordReader.java:142),at org.apache.hadoop.mapred.lib.CombineFileRecordReader.<init>(CombineFileRecordReader.java:117),at org.apache.hadoop.mapred.lib.TestCombineFileRecordReader.testInitNextRecordReader(TestCombineFileRecordReader.java:77),at org.apache.hadoop.mapred.lib.TestCombineFileRecordReader.testInitNextRecordReader$$CONFUZZ(TestCombineFileRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.lib.TestCombineFileRecordReader/testInitNextRecordReader/campaign/failures/debug_000003	['debug_000003']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.IllegalStateException	14	FP	["org.apache.hadoop.mapred.TestLineRecordReader#testRecordSpanningMultipleSplitsCompressed	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:111),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:96),at org.apache.hadoop.mapred.TestLineRecordReader.readRecords(TestLineRecordReader.java:215),at org.apache.hadoop.mapred.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:249),at org.apache.hadoop.mapred.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed(TestLineRecordReader.java:279),at org.apache.hadoop.mapred.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'file.bytes-per-checksum': '0'}	["file.bytes-per-checksum"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testRecordSpanningMultipleSplitsCompressed/campaign/failures/debug_000001	['debug_000001']\n", "org.apache.hadoop.mapreduce.TestJobResourceUploader#testPathsWithNoFragNoSchemeRelative	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:496),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:787),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:783),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testPathsWithNoFragNoSchemeRelative(TestJobResourceUploader.java:241),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testPathsWithNoFragNoSchemeRelative$$CONFUZZ(TestJobResourceUploader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.TestJobResourceUploader/testPathsWithNoFragNoSchemeRelative/campaign/failures/debug_000000	{'file.bytes-per-checksum': '0'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.TestJobResourceUploader#testStringToPath	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:496),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testStringToPath(TestJobResourceUploader.java:65),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testStringToPath$$CONFUZZ(TestJobResourceUploader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.TestJobResourceUploader/testStringToPath/campaign/failures/debug_000000	{'file.bytes-per-checksum': '0'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterV2	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:162),at org.apache.hadoop.mapred.FileOutputCommitter.getWrapped(FileOutputCommitter.java:66),at org.apache.hadoop.mapred.FileOutputCommitter.setupJob(FileOutputCommitter.java:131),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:333),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterV2/campaign/failures/debug_000003	{'file.bytes-per-checksum': '0'}	['debug_000003']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testStripBOM	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:88),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testStripBOM(TestLineRecordReader.java:250),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testStripBOM$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testStripBOM/campaign/failures/debug_000000	{'file.bytes-per-checksum': '0'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.TestJobResourceUploader#testPathsWithNoFragNoSchemeAbsolute	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:496),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:787),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:783),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testPathsWithNoFragNoSchemeAbsolute(TestJobResourceUploader.java:259),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testPathsWithNoFragNoSchemeAbsolute$$CONFUZZ(TestJobResourceUploader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.TestJobResourceUploader/testPathsWithNoFragNoSchemeAbsolute/campaign/failures/debug_000000	{'file.bytes-per-checksum': '0'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.TestJobResourceUploader#testPathsWithNoFragWithSchemeAbsolute	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:496),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:787),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:783),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testPathsWithNoFragWithSchemeAbsolute(TestJobResourceUploader.java:331),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testPathsWithNoFragWithSchemeAbsolute$$CONFUZZ(TestJobResourceUploader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.TestJobResourceUploader/testPathsWithNoFragWithSchemeAbsolute/campaign/failures/debug_000000	{'file.bytes-per-checksum': '0'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader#testProgressIsReportedIfInputASeriesOfEmptyFiles	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:88),at org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReaderWrapper.initialize(CombineFileRecordReaderWrapper.java:69),at org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.initialize(CombineFileRecordReader.java:59),at org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader.testProgressIsReportedIfInputASeriesOfEmptyFiles(TestCombineFileRecordReader.java:86),at org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader.testProgressIsReportedIfInputASeriesOfEmptyFiles$$CONFUZZ(TestCombineFileRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader/testProgressIsReportedIfInputASeriesOfEmptyFiles/campaign/failures/debug_000000	{'file.bytes-per-checksum': '0'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.TestJobResourceUploader#testOverResourcesMBLimit	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:496),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:787),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:783),at org.apache.hadoop.mapreduce.TestJobResourceUploader.runLimitsTest(TestJobResourceUploader.java:520),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testOverResourcesMBLimit(TestJobResourceUploader.java:159),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testOverResourcesMBLimit$$CONFUZZ(TestJobResourceUploader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.TestJobResourceUploader/testOverResourcesMBLimit/campaign/failures/debug_000000	{'file.bytes-per-checksum': '0'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testStripBOM	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:111),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:96),at org.apache.hadoop.mapred.TestLineRecordReader.testStripBOM(TestLineRecordReader.java:300),at org.apache.hadoop.mapred.TestLineRecordReader.testStripBOM$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testStripBOM/campaign/failures/debug_000001	{'file.bytes-per-checksum': '0'}	['debug_000001']\n", "org.apache.hadoop.mapreduce.TestJobResourceUploader#testPathsWithFragsAndWildCard	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:496),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:787),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testPathsWithFragsAndWildCard(TestJobResourceUploader.java:367),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testPathsWithFragsAndWildCard$$CONFUZZ(TestJobResourceUploader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.TestJobResourceUploader/testPathsWithFragsAndWildCard/campaign/failures/debug_000000	{'file.bytes-per-checksum': '0'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestLineRecordReader#testBzipWithMultibyteDelimiter	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapred.LineRecordReader.<init>(LineRecordReader.java:111),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:81),at org.apache.hadoop.mapred.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:684),at org.apache.hadoop.mapred.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testBzipWithMultibyteDelimiter/campaign/failures/debug_000004	{'file.bytes-per-checksum': '0'}	['debug_000004']\n", "org.apache.hadoop.mapreduce.task.reduce.TestMerger#testCompressed	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:496),at org.apache.hadoop.mapreduce.task.reduce.TestMerger.setup(TestMerger.java:101),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.task.reduce.TestMerger/testCompressed/campaign/failures/debug_000000	{'file.bytes-per-checksum': '0'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.TestJobResourceUploader#testPathsWithFragNoSchemeAbsolute	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:496),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:787),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:783),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testPathsWithFragNoSchemeAbsolute(TestJobResourceUploader.java:277),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testPathsWithFragNoSchemeAbsolute$$CONFUZZ(TestJobResourceUploader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.TestJobResourceUploader/testPathsWithFragNoSchemeAbsolute/campaign/failures/debug_000000	{'file.bytes-per-checksum': '0'}	['debug_000000']\n"]																																																																																																																																																																																																																																																										
mapreduce.input.linerecordreader.line.maxlength >= something	java.lang.AssertionError	1	FP	["org.apache.hadoop.mapred.TestLineRecordReader#testRecordSpanningMultipleSplitsCompressed	java.lang.AssertionError	Wrong number of records expected:<4> but was:<3>	java.lang.AssertionError: Wrong number of records expected:<4> but was:<3>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.apache.hadoop.mapred.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:252),at org.apache.hadoop.mapred.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed(TestLineRecordReader.java:279),at org.apache.hadoop.mapred.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.input.linerecordreader.line.maxlength': '351'}	["mapreduce.input.linerecordreader.line.maxlength"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testRecordSpanningMultipleSplitsCompressed/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.io.IOException	9	FP	["org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory#testCommitterFallbackDefault	java.io.IOException	Only 1 or 2 algorithm version is supported	java.io.IOException: Only 1 or 2 algorithm version is supported,at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:144),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:118),at org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory.createFileOutputCommitter(PathOutputCommitterFactory.java:134),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory.createOutputCommitter(FileOutputCommitterFactory.java:35),at org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory.createCommitter(PathOutputCommitterFactory.java:201),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.createCommitter(TestPathOutputCommitterFactory.java:237),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testCommitterFallbackDefault(TestPathOutputCommitterFactory.java:82),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testCommitterFallbackDefault$$CONFUZZ(TestPathOutputCommitterFactory.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	java.io.IOException	Only 1 or 2 algorithm version is supported	java.io.IOException: Only 1 or 2 algorithm version is supported,at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:144),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:118),at org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory.createFileOutputCommitter(PathOutputCommitterFactory.java:134),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory.createOutputCommitter(FileOutputCommitterFactory.java:35),at org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory.createCommitter(PathOutputCommitterFactory.java:201),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.createCommitter(TestPathOutputCommitterFactory.java:237),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testCommitterFallbackDefault(TestPathOutputCommitterFactory.java:82),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testCommitterFallbackDefault$$CONFUZZ(TestPathOutputCommitterFactory.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory/testCommitterFallbackDefault/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testRecoveryUpgradeV1V2	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:109),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryUpgradeV1V2(TestFileOutputCommitter.java:171),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryUpgradeV1V2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:109),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryUpgradeV1V2(TestFileOutputCommitter.java:171),at org.apache.hadoop.mapred.TestFileOutputCommitter.testRecoveryUpgradeV1V2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testRecoveryUpgradeV1V2/campaign/failures/debug_000002	{'hadoop.security.authentication': 'kerberos'}	['debug_000002', 'debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testFailAbortV2	java.io.IOException	Mkdirs failed to create faildel:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/_temporary/_attempt_200707121733_0001_m_000000_0	java.io.IOException: Mkdirs failed to create faildel:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/_temporary/_attempt_200707121733_0001_m_000000_0,at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:425),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125),at org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:529),at org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV2(TestFileOutputCommitter.java:565),at org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.io.IOException	Mkdirs failed to create faildel:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/_temporary/_attempt_200707121733_0001_m_000000_0	java.io.IOException: Mkdirs failed to create faildel:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1/_temporary/_attempt_200707121733_0001_m_000000_0,at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:425),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125),at org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:529),at org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV2(TestFileOutputCommitter.java:565),at org.apache.hadoop.mapred.TestFileOutputCommitter.testFailAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testFailAbortV2/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001', 'debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testProgressDuringMerge	java.io.IOException	Mkdirs failed to create directory file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1414253474/_temporary/attempt_200707121733_0001_m_000000_0/part-m-00000	java.io.IOException: Mkdirs failed to create directory file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1414253474/_temporary/attempt_200707121733_0001_m_000000_0/part-m-00000,at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:269),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.io.IOException	Mkdirs failed to create directory file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1414253474/_temporary/attempt_200707121733_0001_m_000000_0/part-m-00000	java.io.IOException: Mkdirs failed to create directory file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1414253474/_temporary/attempt_200707121733_0001_m_000000_0/part-m-00000,at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:269),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testProgressDuringMerge/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterV2	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1157535690/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1157535690/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1157535690/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/1157535690/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterV2/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001']\n", "org.apache.hadoop.mapreduce.TestJobSubmissionFiles#testGetStagingWhenFileOwnerNameAndCurrentUserNameDoesNotMatch	java.io.IOException	The ownership on the staging directory Mock for Path, hashCode: 292872563 is not as expected. It is owned by someuser. The directory must be owned by the submitter ctestfuzz or ctestfuzz or user1 or user1@HADOOP.APACHE.ORG	java.io.IOException: The ownership on the staging directory Mock for Path, hashCode: 292872563 is not as expected. It is owned by someuser. The directory must be owned by the submitter ctestfuzz or ctestfuzz or user1 or user1@HADOOP.APACHE.ORG,at org.apache.hadoop.mapreduce.JobSubmissionFiles.getStagingDir(JobSubmissionFiles.java:150),at org.apache.hadoop.mapreduce.TestJobSubmissionFiles.testGetStagingWhenFileOwnerNameAndCurrentUserNameDoesNotMatch(TestJobSubmissionFiles.java:98),at org.apache.hadoop.mapreduce.TestJobSubmissionFiles.testGetStagingWhenFileOwnerNameAndCurrentUserNameDoesNotMatch$$CONFUZZ(TestJobSubmissionFiles.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.io.IOException	The ownership on the staging directory Mock for Path, hashCode: 292872563 is not as expected. It is owned by someuser. The directory must be owned by the submitter ctestfuzz or ctestfuzz or user1 or user1@HADOOP.APACHE.ORG	java.io.IOException: The ownership on the staging directory Mock for Path, hashCode: 292872563 is not as expected. It is owned by someuser. The directory must be owned by the submitter ctestfuzz or ctestfuzz or user1 or user1@HADOOP.APACHE.ORG,at org.apache.hadoop.mapreduce.JobSubmissionFiles.getStagingDir(JobSubmissionFiles.java:150),at org.apache.hadoop.mapreduce.TestJobSubmissionFiles.testGetStagingWhenFileOwnerNameAndCurrentUserNameDoesNotMatch(TestJobSubmissionFiles.java:98),at org.apache.hadoop.mapreduce.TestJobSubmissionFiles.testGetStagingWhenFileOwnerNameAndCurrentUserNameDoesNotMatch$$CONFUZZ(TestJobSubmissionFiles.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.TestJobSubmissionFiles/testGetStagingWhenFileOwnerNameAndCurrentUserNameDoesNotMatch/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.split.TestJobSplitWriter#testMaxBlockLocationsOldSplits	java.io.IOException	Split metadata size exceeded 30. Aborting job job__0000	java.io.IOException: Split metadata size exceeded 30. Aborting job job__0000,at org.apache.hadoop.mapreduce.split.SplitMetaInfoReader.readSplitMetaInfo(SplitMetaInfoReader.java:53),at org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits(TestJobSplitWriter.java:77),at org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits$$CONFUZZ(TestJobSplitWriter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.io.IOException	Split metadata size exceeded 30. Aborting job job__0000	java.io.IOException: Split metadata size exceeded 30. Aborting job job__0000,at org.apache.hadoop.mapreduce.split.SplitMetaInfoReader.readSplitMetaInfo(SplitMetaInfoReader.java:53),at org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits(TestJobSplitWriter.java:77),at org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits$$CONFUZZ(TestJobSplitWriter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.split.TestJobSplitWriter/testMaxBlockLocationsOldSplits/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory#testFileOutputCommitterFactory	java.io.IOException	Only 1 or 2 algorithm version is supported	java.io.IOException: Only 1 or 2 algorithm version is supported,at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:144),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:118),at org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory.createFileOutputCommitter(PathOutputCommitterFactory.java:134),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory.createOutputCommitter(FileOutputCommitterFactory.java:35),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.createCommitter(TestPathOutputCommitterFactory.java:215),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testFileOutputCommitterFactory(TestPathOutputCommitterFactory.java:281),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testFileOutputCommitterFactory$$CONFUZZ(TestPathOutputCommitterFactory.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.io.IOException	Only 1 or 2 algorithm version is supported	java.io.IOException: Only 1 or 2 algorithm version is supported,at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:144),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:118),at org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory.createFileOutputCommitter(PathOutputCommitterFactory.java:134),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory.createOutputCommitter(FileOutputCommitterFactory.java:35),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.createCommitter(TestPathOutputCommitterFactory.java:215),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testFileOutputCommitterFactory(TestPathOutputCommitterFactory.java:281),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testFileOutputCommitterFactory$$CONFUZZ(TestPathOutputCommitterFactory.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory/testFileOutputCommitterFactory/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithDuplicatedCommitV2	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/-472614055/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/-472614055/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:362),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:341),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/-472614055/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/-472614055/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:362),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:341),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithDuplicatedCommitV2/campaign/failures/debug_000003	{'hadoop.security.authentication': 'kerberos'}	['debug_000003']\n"]																																																																																																																																																																																																																																																																																																												
	java.io.IOException	2	not-reproducible	["org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager#testDetermineTimestamps	java.io.IOException	Unable to parse configuration fs.permissions.umask-mode with value -1239221895 as octal or symbolic umask.	java.io.IOException: Unable to parse configuration fs.permissions.umask-mode with value -1239221895 as octal or symbolic umask.,at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.createTempFile(TestClientDistributedCacheManager.java:254),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.setup(TestClientDistributedCacheManager.java:78),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'fs.creation.parallel.count': '11883'}	["fs.creation.parallel.count"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager/testDetermineTimestamps/campaign/failures/debug_000001	['debug_000001']\n", "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager#testDetermineCacheVisibilities	java.io.IOException	Unable to parse configuration fs.permissions.umask-mode with value 17881 as octal or symbolic umask.	java.io.IOException: Unable to parse configuration fs.permissions.umask-mode with value 17881 as octal or symbolic umask.,at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.createTempFile(TestClientDistributedCacheManager.java:254),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.setup(TestClientDistributedCacheManager.java:78),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager/testDetermineCacheVisibilities/campaign/failures/debug_000001	{'fs.creation.parallel.count': '14228'}	['debug_000001']\n"]																																																																																																																																																																																																																																																																																																																																																																																		
	java.lang.OutOfMemoryError	2	not-reproducible	["org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager#testDetermineTimestamps	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75),at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:333),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.createTempFile(TestClientDistributedCacheManager.java:249),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.setup(TestClientDistributedCacheManager.java:78),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	DIFFERENT	{'fs.creation.parallel.count': '22443'}	["fs.creation.parallel.count"]	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75),at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:333),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.createTempFile(TestClientDistributedCacheManager.java:249),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.setup(TestClientDistributedCacheManager.java:78),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager/testDetermineTimestamps/campaign/failures/debug_000002	['debug_000002', 'debug_000003']\n", "org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager#testDetermineCacheVisibilities	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager/testDetermineCacheVisibilities/campaign/failures/debug_000004	{'fs.creation.parallel.count': '931'}	['debug_000004', 'debug_000002', 'debug_000003']\n"]																																																																																																																																																																																																																																																																																																																																																																																		
	java.lang.AssertionError	1	not-reproducible	["org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager#testDetermineTimestamps	java.lang.AssertionError	Missing/extra entries found in the stats cache expected:<2> but was:<3>	java.lang.AssertionError: Missing/extra entries found in the stats cache expected:<2> but was:<3>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.testDetermineTimestamps(TestClientDistributedCacheManager.java:107),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.testDetermineTimestamps$$CONFUZZ(TestClientDistributedCacheManager.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'fs.creation.parallel.count': '23'}	["fs.creation.parallel.count"]	java.lang.AssertionError	Missing/extra entries found in the stats cache expected:<2> but was:<3>	java.lang.AssertionError: Missing/extra entries found in the stats cache expected:<2> but was:<3>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.testDetermineTimestamps(TestClientDistributedCacheManager.java:107),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.testDetermineTimestamps$$CONFUZZ(TestClientDistributedCacheManager.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager/testDetermineTimestamps/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
Use this for debugging BS can be triggered by the whole config set but not the minimal set	java.lang.OutOfMemoryError	1	CONFUZZ-BUG	["org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	DIFFERENT	{'mapreduce.job.working.dir': 'file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core'}	["mapreduce.job.working.dir"]	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000008	['debug_000008', 'debug_000007']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
Use this for debugging BS can be triggered by the whole config set but not the minimal set	java.lang.ClassNotFoundException	1	CONFUZZ-BUG	["org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'mapreduce.job.working.dir': 'file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core'}	["mapreduce.job.working.dir"]	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000001	['debug_000001']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
Use this for debugging BS can be triggered by the whole config set but not the minimal set	java.lang.IllegalArgumentException	1	CONFUZZ-BUG	["org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.IllegalArgumentException	Illegal bufferSize	java.lang.IllegalArgumentException: Illegal bufferSize,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'mapreduce.job.working.dir': 'file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core'}	["mapreduce.job.working.dir"]	java.lang.IllegalArgumentException	Illegal bufferSize	java.lang.IllegalArgumentException: Illegal bufferSize,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000006	['debug_000006', 'debug_000003']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
Use this for debugging BS can be triggered by the whole config set but not the minimal set	java.lang.RuntimeException	1	CONFUZZ-BUG	["org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'mapreduce.job.working.dir': 'file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core'}	["mapreduce.job.working.dir"]	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000004	['debug_000004']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.NoClassDefFoundError	7	not-reproducible	["org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'fs.permissions.umask-mode': '-162769284'}	["fs.permissions.umask-mode"]	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000002	['debug_000002']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000003	{'fs.permissions.umask-mode': '228'}	['debug_000003']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV1	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV1/campaign/failures/debug_000004	{'fs.permissions.umask-mode': '370773792'}	['debug_000004']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000007	{'fs.permissions.umask-mode': '255307495'}	['debug_000007', 'debug_000006', 'debug_000005']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000012	{'fs.permissions.umask-mode': '253'}	['debug_000012', 'debug_000014', 'debug_000004']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV1	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV1/campaign/failures/debug_000004	{'fs.permissions.umask-mode': '31237'}	['debug_000004']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV2	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV2/campaign/failures/debug_000003	{'fs.permissions.umask-mode': '-632964725'}	['debug_000003']\n"]																																																																																																																																																																																																																																																																																																																																
	java.lang.UnsupportedOperationException	6	not-reproducible	["org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV2	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000002	{'hadoop.security.authentication': 'kerberos'}	['debug_000002']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001', 'debug_000006', 'debug_000002']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testAbortV2	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000004	{'hadoop.security.authentication': 'kerberos'}	['debug_000004']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001', 'debug_000010', 'debug_000005']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000006	{'hadoop.security.authentication': 'kerberos'}	['debug_000006', 'debug_000004', 'debug_000002']\n"]																																																																																																																																																																																																																																																																																																																																										
	java.lang.ArrayIndexOutOfBoundsException	1	not-reproducible	["org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:71),at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:86),at org.apache.hadoop.mapred.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:61),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:244),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'mapreduce.job.working.dir': 'file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core'}	["mapreduce.job.working.dir"]	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:71),at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:86),at org.apache.hadoop.mapred.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:61),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:244),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:220),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000005	['debug_000005']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
looks like a state polluter	java.io.IOException	3	BUG	["org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithFailureV1	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/642/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/642/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV1(TestFileOutputCommitter.java:214),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.job.working.dir': 'file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core'}	["mapreduce.job.working.dir"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithFailureV1/campaign/failures/debug_000001	['debug_000001']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterWithFailureV1	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/429/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/429/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:243),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV1(TestFileOutputCommitter.java:214),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterWithFailureV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterWithFailureV1/campaign/failures/debug_000002	{'mapreduce.job.working.dir': 'file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core'}	['debug_000002']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterV1	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/76150103/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/76150103/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:113),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1(TestFileOutputCommitter.java:355),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterV1/campaign/failures/debug_000001	{'mapreduce.job.working.dir': 'file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core'}	['debug_000001']\n"]																																																																																																																																																																																																																																																																																																																																																																								
	java.lang.IllegalStateException	3	FP	["org.apache.hadoop.mapreduce.TestJobResourceUploader#testAtSingleResourceMBLimit	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:496),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:787),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:783),at org.apache.hadoop.mapreduce.TestJobResourceUploader.runLimitsTest(TestJobResourceUploader.java:520),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testAtSingleResourceMBLimit(TestJobResourceUploader.java:173),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testAtSingleResourceMBLimit$$CONFUZZ(TestJobResourceUploader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:496),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:787),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:783),at org.apache.hadoop.mapreduce.TestJobResourceUploader.runLimitsTest(TestJobResourceUploader.java:520),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testAtSingleResourceMBLimit(TestJobResourceUploader.java:173),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testAtSingleResourceMBLimit$$CONFUZZ(TestJobResourceUploader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.TestJobResourceUploader/testAtSingleResourceMBLimit/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapreduce.TestJobResourceUploader#testAllDefaults	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:496),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:787),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:783),at org.apache.hadoop.mapreduce.TestJobResourceUploader.runLimitsTest(TestJobResourceUploader.java:520),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testAllDefaults(TestJobResourceUploader.java:92),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testAllDefaults$$CONFUZZ(TestJobResourceUploader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.getLocal(FileSystem.java:496),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:787),at org.apache.hadoop.mapreduce.TestJobResourceUploader$StubedUploader.<init>(TestJobResourceUploader.java:783),at org.apache.hadoop.mapreduce.TestJobResourceUploader.runLimitsTest(TestJobResourceUploader.java:520),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testAllDefaults(TestJobResourceUploader.java:92),at org.apache.hadoop.mapreduce.TestJobResourceUploader.testAllDefaults$$CONFUZZ(TestJobResourceUploader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.TestJobResourceUploader/testAllDefaults/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testRecordSpanningMultipleSplits	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:88),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.readRecords(TestLineRecordReader.java:160),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:194),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits(TestLineRecordReader.java:214),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:88),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.readRecords(TestLineRecordReader.java:160),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:194),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits(TestLineRecordReader.java:214),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testRecordSpanningMultipleSplits/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001']\n"]																																																																																																																																																																																																																																																																																																																																																																								
	java.lang.OutOfMemoryError	9	not-reproducible	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testProgressDuringMerge	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	DIFFERENT	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testProgressDuringMerge/campaign/failures/debug_000004	['debug_000004', 'debug_000003']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV2	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46),at org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46),at org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000007	{'hadoop.security.authentication': 'kerberos'}	['debug_000007', 'debug_000009']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000015	{'hadoop.security.authentication': 'kerberos'}	['debug_000015', 'debug_000016', 'debug_000019']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.OutOfMemoryError	Direct buffer memory	java.lang.OutOfMemoryError: Direct buffer memory,at java.base/java.nio.Bits.reserveMemory(Bits.java:175),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:60),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.OutOfMemoryError	Direct buffer memory	java.lang.OutOfMemoryError: Direct buffer memory,at java.base/java.nio.Bits.reserveMemory(Bits.java:175),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:60),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000025	{'hadoop.security.authentication': 'kerberos'}	['debug_000025', 'debug_000024']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testAbortV2	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46),at org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:70),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46),at org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:70),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000007	{'hadoop.security.authentication': 'kerberos'}	['debug_000007', 'debug_000009']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.OutOfMemoryError	Direct buffer memory	java.lang.OutOfMemoryError: Direct buffer memory,at java.base/java.nio.Bits.reserveMemory(Bits.java:175),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:60),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.OutOfMemoryError	Direct buffer memory	java.lang.OutOfMemoryError: Direct buffer memory,at java.base/java.nio.Bits.reserveMemory(Bits.java:175),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:60),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000018	{'hadoop.security.authentication': 'kerberos'}	['debug_000018', 'debug_000027', 'debug_000020', 'debug_000024', 'debug_000030']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75),at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:285),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75),at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:285),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000015	{'hadoop.security.authentication': 'kerberos'}	['debug_000015', 'debug_000017', 'debug_000016']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000020	{'hadoop.security.authentication': 'kerberos'}	['debug_000020', 'debug_000016', 'debug_000005']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.OutOfMemoryError	Direct buffer memory	java.lang.OutOfMemoryError: Direct buffer memory,at java.base/java.nio.Bits.reserveMemory(Bits.java:175),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:60),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.OutOfMemoryError	Direct buffer memory	java.lang.OutOfMemoryError: Direct buffer memory,at java.base/java.nio.Bits.reserveMemory(Bits.java:175),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:60),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000025	{'hadoop.security.authentication': 'kerberos'}	['debug_000025', 'debug_000026']\n"]																																																																																																																																																																																																																																																																																																												
	java.lang.ClassNotFoundException	6	not-reproducible	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testProgressDuringMerge	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'fs.permissions.umask-mode': '344'}	["fs.permissions.umask-mode"]	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge(TestFileOutputCommitter.java:460),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testProgressDuringMerge$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testProgressDuringMerge/campaign/failures/debug_000002	['debug_000002']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '228'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV1	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV1/campaign/failures/debug_000003	{'fs.permissions.umask-mode': '370773792'}	['debug_000003']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithDuplicatedCommitV2	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:362),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:341),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:362),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2(TestFileOutputCommitter.java:341),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithDuplicatedCommitV2/campaign/failures/debug_000002	{'fs.permissions.umask-mode': '5259'}	['debug_000002']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV1	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV1/campaign/failures/debug_000001	{'fs.permissions.umask-mode': '-1394217577'}	['debug_000001']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV2	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV2/campaign/failures/debug_000001	{'fs.permissions.umask-mode': '44'}	['debug_000001']\n"]																																																																																																																																																																																																																																																																																																																																										
	java.io.IOException	2	not-reproducible	["org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterV2	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/-532046421/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/-532046421/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'fs.permissions.umask-mode': '4127'}	["fs.permissions.umask-mode"]	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/-532046421/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/-532046421/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:360),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterV2/campaign/failures/debug_000002	['debug_000002']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testCommitterV1	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/591837536/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/591837536/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1(TestFileOutputCommitter.java:355),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/591837536/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/output/_temporary/591837536/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1081),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:125),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:339),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1(TestFileOutputCommitter.java:355),at org.apache.hadoop.mapred.TestFileOutputCommitter.testCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testCommitterV1/campaign/failures/debug_000003	{'fs.permissions.umask-mode': '397'}	['debug_000003']\n"]																																																																																																																																																																																																																																																																																																																																																																																		
	java.lang.AssertionError	4	not-reproducible	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterV2	java.lang.AssertionError	Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000	java.lang.AssertionError: Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:223),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:315),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:326),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'fs.permissions.umask-mode': '523302782'}	["fs.permissions.umask-mode"]	java.lang.AssertionError	Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000	java.lang.AssertionError: Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:223),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterInternal(TestFileOutputCommitter.java:315),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2(TestFileOutputCommitter.java:326),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterV2/campaign/failures/debug_000002	['debug_000002']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testFailAbortV1	java.lang.AssertionError	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1/_temporary/attempt_200707121733_0001_m_000000_0/part-m-00000 does not exists	java.lang.AssertionError: /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1/_temporary/attempt_200707121733_0001_m_000000_0/part-m-00000 does not exists,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:703),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1(TestFileOutputCommitter.java:720),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.AssertionError	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1/_temporary/attempt_200707121733_0001_m_000000_0/part-m-00000 does not exists	java.lang.AssertionError: /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1/_temporary/attempt_200707121733_0001_m_000000_0/part-m-00000 does not exists,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:703),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1(TestFileOutputCommitter.java:720),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testFailAbortV1/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '1178671700'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testRecoveryV2	java.lang.AssertionError	Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000	java.lang.AssertionError: Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:223),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:203),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV2(TestFileOutputCommitter.java:214),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.AssertionError	Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000	java.lang.AssertionError: Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/part-m-00000,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:223),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:203),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV2(TestFileOutputCommitter.java:214),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testRecoveryV2/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '1966949268'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testRecoveryV1	java.lang.AssertionError	Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1/task_200707121733_0001_m_000000/part-m-00000	java.lang.AssertionError: Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1/task_200707121733_0001_m_000000/part-m-00000,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:171),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:209),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.AssertionError	Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1/task_200707121733_0001_m_000000/part-m-00000	java.lang.AssertionError: Could not find /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/1/task_200707121733_0001_m_000000/part-m-00000,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.assertTrue(Assert.java:42),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.validateContent(TestFileOutputCommitter.java:228),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:171),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:209),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testRecoveryV1/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '-320131112'}	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																														
	java.lang.OutOfMemoryError	7	not-reproducible	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	DIFFERENT	{'fs.permissions.umask-mode': '228'}	["fs.permissions.umask-mode"]	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000008	['debug_000008', 'debug_000007']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV1	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46),at org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46),at org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV1/campaign/failures/debug_000007	{'fs.permissions.umask-mode': '370773792'}	['debug_000007', 'debug_000009']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.OutOfMemoryError	Direct buffer memory	java.lang.OutOfMemoryError: Direct buffer memory,at java.base/java.nio.Bits.reserveMemory(Bits.java:175),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.OutOfMemoryError	Direct buffer memory	java.lang.OutOfMemoryError: Direct buffer memory,at java.base/java.nio.Bits.reserveMemory(Bits.java:175),at java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118),at java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317),at org.apache.hadoop.io.compress.snappy.SnappyCompressor.<init>(SnappyCompressor.java:59),at org.apache.hadoop.io.compress.SnappyCodec.createCompressor(SnappyCodec.java:116),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000027	{'fs.permissions.umask-mode': '255307495'}	['debug_000027', 'debug_000025', 'debug_000024']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75),at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:285),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75),at org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:285),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000015	{'fs.permissions.umask-mode': '-1892176153'}	['debug_000015', 'debug_000021', 'debug_000022']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testFailAbortV2	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:685),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV2(TestFileOutputCommitter.java:725),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134),at org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:58),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortInternal(TestFileOutputCommitter.java:685),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV2(TestFileOutputCommitter.java:725),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testFailAbortV2/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '-1584906598'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV1	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV1/campaign/failures/debug_000008	{'fs.permissions.umask-mode': '753266157'}	['debug_000008', 'debug_000005']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV2	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV2/campaign/failures/debug_000007	{'fs.permissions.umask-mode': '44'}	['debug_000007', 'debug_000006']\n"]																																																																																																																																																																																																																																																																																																																																
	java.lang.UnsupportedOperationException	5	not-reproducible	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'fs.permissions.umask-mode': '228'}	["fs.permissions.umask-mode"]	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000001	['debug_000001']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV1	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV1/campaign/failures/debug_000002	{'fs.permissions.umask-mode': '588'}	['debug_000002']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.getCompressorType(PassthroughCodec.java:124),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000001	{'fs.permissions.umask-mode': '255307495'}	['debug_000001', 'debug_000020', 'debug_000003']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV1	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV1/campaign/failures/debug_000002	{'fs.permissions.umask-mode': '-1394217577'}	['debug_000002']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV2	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.UnsupportedOperationException	No message	java.lang.UnsupportedOperationException,at org.apache.hadoop.io.compress.PassthroughCodec.createOutputStream(PassthroughCodec.java:113),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV2/campaign/failures/debug_000002	{'fs.permissions.umask-mode': '44'}	['debug_000002']\n"]																																																																																																																																																																																																																																																																																																																																																				
	java.lang.RuntimeException	5	not-reproducible	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'fs.permissions.umask-mode': '228'}	["fs.permissions.umask-mode"]	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:420),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000002	['debug_000002']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV1	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV1/campaign/failures/debug_000001	{'fs.permissions.umask-mode': '544'}	['debug_000001']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000009	{'fs.permissions.umask-mode': '255307495'}	['debug_000009', 'debug_000014', 'debug_000011']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV1	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV1/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '-1394217577'}	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV2	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:505),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV2/campaign/failures/debug_000000	{'fs.permissions.umask-mode': '44'}	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																				
	java.lang.ArrayIndexOutOfBoundsException	5	not-reproducible	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithFailureV2	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:78),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:93),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:114),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:421),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'fs.permissions.umask-mode': '228'}	["fs.permissions.umask-mode"]	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:78),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:93),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:114),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureInternal(TestFileOutputCommitter.java:421),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2(TestFileOutputCommitter.java:394),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithFailureV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithFailureV2/campaign/failures/debug_000005	['debug_000005']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV1	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:78),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:93),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:114),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:620),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:78),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:93),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:114),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:620),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1(TestFileOutputCommitter.java:639),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV1/campaign/failures/debug_000008	{'fs.permissions.umask-mode': '370773792'}	['debug_000008']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81),at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142),at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:182),at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:191),at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.close(WritableSerialization.java:103),at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:1397),at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306),at org.apache.hadoop.mapred.MapFileOutputFormat$1.close(MapFileOutputFormat.java:80),at org.apache.hadoop.mapred.TestFileOutputCommitter.writeMapFileOutput(TestFileOutputCommitter.java:85),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:382),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),Suppressed: java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81),at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142),at java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123),at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:182),at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.close(WritableSerialization.java:103),at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:1397),at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306),at org.apache.hadoop.mapred.MapFileOutputFormat$1.close(MapFileOutputFormat.java:80),at org.apache.hadoop.mapred.TestFileOutputCommitter.writeMapFileOutput(TestFileOutputCommitter.java:85),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:382),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at jdk.internal.reflect.GeneratedMethodAccessor17.invoke(Unknown Source),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),... 23 more,	DIFFERENT	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81),at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142),at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:182),at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:191),at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.close(WritableSerialization.java:103),at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:1397),at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306),at org.apache.hadoop.mapred.MapFileOutputFormat$1.close(MapFileOutputFormat.java:80),at org.apache.hadoop.mapred.TestFileOutputCommitter.writeMapFileOutput(TestFileOutputCommitter.java:85),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:382),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),Suppressed: java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81),at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142),at java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123),at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:182),at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.close(WritableSerialization.java:103),at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:1397),at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306),at org.apache.hadoop.mapred.MapFileOutputFormat$1.close(MapFileOutputFormat.java:80),at org.apache.hadoop.mapred.TestFileOutputCommitter.writeMapFileOutput(TestFileOutputCommitter.java:85),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:382),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at jdk.internal.reflect.GeneratedMethodAccessor17.invoke(Unknown Source),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),... 23 more,	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000028	{'fs.permissions.umask-mode': '267661520'}	['debug_000028']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV1	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:78),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:93),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:114),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:506),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:78),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:93),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:114),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:506),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1(TestFileOutputCommitter.java:473),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV1/campaign/failures/debug_000007	{'fs.permissions.umask-mode': '748'}	['debug_000007']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterRepeatableV2	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:78),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:93),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:114),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:506),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:78),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:93),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:114),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRetryInternal(TestFileOutputCommitter.java:506),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2(TestFileOutputCommitter.java:478),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterRepeatableV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterRepeatableV2/campaign/failures/debug_000008	{'fs.permissions.umask-mode': '44'}	['debug_000008']\n"]																																																																																																																																																																																																																																																																																																																																																				
	java.lang.NegativeArraySizeException	1	not-reproducible	["org.apache.hadoop.mapreduce.security.TestTokenCache#testBinaryCredentialsWithScheme	java.lang.NegativeArraySizeException	-785780108	java.lang.NegativeArraySizeException: -785780108,at org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052),at org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331),at org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:325),at org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentials(TestTokenCache.java:99),at org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithScheme(TestTokenCache.java:74),at org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithScheme$$CONFUZZ(TestTokenCache.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'yarn.resourcemanager.ha.enabled': 'true'}	["yarn.resourcemanager.ha.enabled"]	java.lang.NegativeArraySizeException	-785780108	java.lang.NegativeArraySizeException: -785780108,at org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55),at org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052),at org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331),at org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:325),at org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentials(TestTokenCache.java:99),at org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithScheme(TestTokenCache.java:74),at org.apache.hadoop.mapreduce.security.TestTokenCache.testBinaryCredentialsWithScheme$$CONFUZZ(TestTokenCache.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.security.TestTokenCache/testBinaryCredentialsWithScheme/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.io.IOException	2	FP	["org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory#testCommitterNullOutputPath	java.io.IOException	Only 1 or 2 algorithm version is supported	java.io.IOException: Only 1 or 2 algorithm version is supported,at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:144),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:118),at org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory.createFileOutputCommitter(PathOutputCommitterFactory.java:134),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory.createOutputCommitter(FileOutputCommitterFactory.java:35),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.createCommitter(TestPathOutputCommitterFactory.java:215),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testCommitterNullOutputPath(TestPathOutputCommitterFactory.java:138),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testCommitterNullOutputPath$$CONFUZZ(TestPathOutputCommitterFactory.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.fileoutputcommitter.algorithm.version': '-732444723'}	["mapreduce.fileoutputcommitter.algorithm.version"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory/testCommitterNullOutputPath/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory#testBoundCommitterWithDefault	java.io.IOException	Only 1 or 2 algorithm version is supported	java.io.IOException: Only 1 or 2 algorithm version is supported,at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:144),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.<init>(FileOutputCommitter.java:118),at org.apache.hadoop.mapreduce.lib.output.PathOutputCommitterFactory.createFileOutputCommitter(PathOutputCommitterFactory.java:134),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitterFactory.createOutputCommitter(FileOutputCommitterFactory.java:35),at org.apache.hadoop.mapreduce.lib.output.BindingPathOutputCommitter.<init>(BindingPathOutputCommitter.java:87),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testBoundCommitterWithDefault(TestPathOutputCommitterFactory.java:383),at org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory.testBoundCommitterWithDefault$$CONFUZZ(TestPathOutputCommitterFactory.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestPathOutputCommitterFactory/testBoundCommitterWithDefault/campaign/failures/debug_000000	{'mapreduce.fileoutputcommitter.algorithm.version': '1580203054'}	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																		
	java.lang.ArrayIndexOutOfBoundsException	4	not-reproducible	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV2	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:78),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:93),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:114),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:620),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:78),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:93),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:114),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:620),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000008	['debug_000008']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81),at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142),at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:182),at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:191),at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.close(WritableSerialization.java:103),at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:1397),at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306),at org.apache.hadoop.mapred.MapFileOutputFormat$1.close(MapFileOutputFormat.java:80),at org.apache.hadoop.mapred.TestFileOutputCommitter.writeMapFileOutput(TestFileOutputCommitter.java:85),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:382),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),Suppressed: java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81),at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142),at java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123),at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:182),at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.close(WritableSerialization.java:103),at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:1397),at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306),at org.apache.hadoop.mapred.MapFileOutputFormat$1.close(MapFileOutputFormat.java:80),at org.apache.hadoop.mapred.TestFileOutputCommitter.writeMapFileOutput(TestFileOutputCommitter.java:85),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:382),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at jdk.internal.reflect.GeneratedMethodAccessor17.invoke(Unknown Source),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),... 23 more,	DIFFERENT	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81),at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142),at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:182),at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:191),at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.close(WritableSerialization.java:103),at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:1397),at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306),at org.apache.hadoop.mapred.MapFileOutputFormat$1.close(MapFileOutputFormat.java:80),at org.apache.hadoop.mapred.TestFileOutputCommitter.writeMapFileOutput(TestFileOutputCommitter.java:85),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:382),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),Suppressed: java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81),at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142),at java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123),at java.base/java.io.FilterOutputStream.close(FilterOutputStream.java:182),at org.apache.hadoop.io.serializer.WritableSerialization$WritableSerializer.close(WritableSerialization.java:103),at org.apache.hadoop.io.SequenceFile$Writer.close(SequenceFile.java:1397),at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306),at org.apache.hadoop.mapred.MapFileOutputFormat$1.close(MapFileOutputFormat.java:80),at org.apache.hadoop.mapred.TestFileOutputCommitter.writeMapFileOutput(TestFileOutputCommitter.java:85),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:382),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at jdk.internal.reflect.GeneratedMethodAccessor17.invoke(Unknown Source),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),... 23 more,	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000026	{'hadoop.security.authentication': 'kerberos'}	['debug_000026']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testAbortV2	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:71),at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:86),at org.apache.hadoop.mapred.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:61),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:458),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.DataOutputStream.write(DataOutputStream.java:107),at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.writeObject(TextOutputFormat.java:71),at org.apache.hadoop.mapred.TextOutputFormat$LineRecordWriter.write(TextOutputFormat.java:86),at org.apache.hadoop.mapred.TestFileOutputCommitter.writeOutput(TestFileOutputCommitter.java:61),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:458),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000008	{'hadoop.security.authentication': 'kerberos'}	['debug_000008']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81),at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142),at java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.writeBuffer(SequenceFile.java:1588),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.sync(SequenceFile.java:1605),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.close(SequenceFile.java:1629),at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat$1.close(MapFileOutputFormat.java:83),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeMapFileOutput(TestFileOutputCommitter.java:138),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:556),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.ArrayIndexOutOfBoundsException	No message	java.lang.ArrayIndexOutOfBoundsException,at org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86),at org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112),at java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81),at java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142),at java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.writeBuffer(SequenceFile.java:1588),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.sync(SequenceFile.java:1605),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.close(SequenceFile.java:1629),at org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat$1.close(MapFileOutputFormat.java:83),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeMapFileOutput(TestFileOutputCommitter.java:138),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:556),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000029	{'hadoop.security.authentication': 'kerberos'}	['debug_000029', 'debug_000025']\n"]																																																																																																																																																																																																																																																																																																																																																														
	java.lang.RuntimeException	6	not-reproducible	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV2	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000001	['debug_000001']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000', 'debug_000005', 'debug_000003']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testAbortV2	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:582),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000013	{'hadoop.security.authentication': 'kerberos'}	['debug_000013', 'debug_000009', 'debug_000011']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testRecoveryV1	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:161),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:209),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.ZStandardCodec.createOutputStream(ZStandardCodec.java:125),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryInternal(TestFileOutputCommitter.java:161),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1(TestFileOutputCommitter.java:209),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testRecoveryV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testRecoveryV1/campaign/failures/debug_000001	{'hadoop.security.authentication': 'kerberos'}	['debug_000001']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.RuntimeException	native zStandard library not available: this version of libhadoop was built without zstd support.	java.lang.RuntimeException: native zStandard library not available: this version of libhadoop was built without zstd support.,at org.apache.hadoop.io.compress.ZStandardCodec.checkNativeCodeLoaded(ZStandardCodec.java:65),at org.apache.hadoop.io.compress.ZStandardCodec.getCompressorType(ZStandardCodec.java:153),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:150),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000009	{'hadoop.security.authentication': 'kerberos'}	['debug_000009', 'debug_000010', 'debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																										
	java.lang.NoClassDefFoundError	4	not-reproducible	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testAbortV2	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:129),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:619),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:644),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000004	['debug_000004']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV2	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2(TestFileOutputCommitter.java:402),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV2/campaign/failures/debug_000013	{'hadoop.security.authentication': 'kerberos'}	['debug_000013', 'debug_000009', 'debug_000011']\n", "org.apache.hadoop.mapred.TestFileOutputCommitter#testAbortV2	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131),at org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70),at org.apache.hadoop.mapred.TextOutputFormat.getRecordWriter(TextOutputFormat.java:127),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortInternal(TestFileOutputCommitter.java:457),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2(TestFileOutputCommitter.java:482),at org.apache.hadoop.mapred.TestFileOutputCommitter.testAbortV2$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testAbortV2/campaign/failures/debug_000003	{'hadoop.security.authentication': 'kerberos'}	['debug_000003']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.NoClassDefFoundError	net/jpountz/lz4/LZ4Factory	java.lang.NoClassDefFoundError: net/jpountz/lz4/LZ4Factory,at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapreduce.lib.output.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:73),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:555),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:577),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000013	{'hadoop.security.authentication': 'kerberos'}	['debug_000013', 'debug_000008', 'debug_000007']\n"]																																																																																																																																																																																																																																																																																																																																																														
	java.io.FileNotFoundException	1	not-reproducible	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testConcurrentCommitTaskWithSubDirV1	java.io.FileNotFoundException	File file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/613 does not exist	java.io.FileNotFoundException: File file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/613 does not exist,at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:597),at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972),at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDir(TestFileOutputCommitter.java:810),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1(TestFileOutputCommitter.java:823),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	java.io.FileNotFoundException	File file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/613 does not exist	java.io.FileNotFoundException: File file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/613 does not exist,at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:597),at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972),at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDir(TestFileOutputCommitter.java:810),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1(TestFileOutputCommitter.java:823),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testConcurrentCommitTaskWithSubDirV1/campaign/failures/debug_000001	['debug_000001']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
looks like a state polluter	java.nio.file.AccessDeniedException	1	BUG	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testConcurrentCommitTaskWithSubDirV1	java.nio.file.AccessDeniedException	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/32068570: Permission denied	java.nio.file.AccessDeniedException: /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/32068570: Permission denied,at org.apache.hadoop.fs.FileUtil.list(FileUtil.java:1455),at org.apache.hadoop.fs.RawLocalFileSystem.listStatus(RawLocalFileSystem.java:601),at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:1972),at org.apache.hadoop.fs.FileSystem.listStatus(FileSystem.java:2014),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.getAllCommittedTaskPaths(FileOutputCommitter.java:334),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:404),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDir(TestFileOutputCommitter.java:810),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1(TestFileOutputCommitter.java:823),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.job.application.attempt.id': '32068570'}	["mapreduce.job.application.attempt.id"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testConcurrentCommitTaskWithSubDirV1/campaign/failures/debug_000002	['debug_000002']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
looks like a state polluter	java.io.FileNotFoundException	1	BUG	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testConcurrentCommitTaskWithSubDirV1	java.io.FileNotFoundException	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_SUCCESS (Permission denied)	java.io.FileNotFoundException: /home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_SUCCESS (Permission denied),at java.base/java.io.FileOutputStream.open0(Native Method),at java.base/java.io.FileOutputStream.open(FileOutputStream.java:298),at java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237),at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:321),at org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294),at org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428),at org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJobInternal(FileOutputCommitter.java:440),at org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.commitJob(FileOutputCommitter.java:377),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDir(TestFileOutputCommitter.java:810),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1(TestFileOutputCommitter.java:823),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testConcurrentCommitTaskWithSubDirV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'fs.creation.parallel.count': '485'}	["fs.creation.parallel.count"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testConcurrentCommitTaskWithSubDirV1/campaign/failures/debug_000005	['debug_000005']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.ClassNotFoundException	1	not-reproducible	["org.apache.hadoop.mapred.TestFileOutputCommitter#testMapFileOutputCommitterV1	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.groups.cache.background.reload': 'true', 'hadoop.security.groups.cache.background.reload.threads': '-1061223400'}	["hadoop.security.groups.cache.background.reload", "hadoop.security.groups.cache.background.reload.threads"]	java.lang.ClassNotFoundException	net.jpountz.lz4.LZ4Factory	java.lang.ClassNotFoundException: net.jpountz.lz4.LZ4Factory,at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581),at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178),at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522),at org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:66),at org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152),at org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:168),at org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1306),at org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194),at org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569),at org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278),at org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:131),at org.apache.hadoop.mapred.MapFileOutputFormat.getRecordWriter(MapFileOutputFormat.java:68),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterInternal(TestFileOutputCommitter.java:381),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1(TestFileOutputCommitter.java:397),at org.apache.hadoop.mapred.TestFileOutputCommitter.testMapFileOutputCommitterV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestFileOutputCommitter/testMapFileOutputCommitterV1/campaign/failures/debug_000002	['debug_000002']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.AssertionError	1	FP	["org.apache.hadoop.mapred.TestJobConf#testNegativeValueForTaskVmem	java.lang.AssertionError	expected:<1024> but was:<9019>	java.lang.AssertionError: expected:<1024> but was:<9019>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.junit.Assert.assertEquals(Assert.java:633),at org.apache.hadoop.mapred.TestJobConf.testNegativeValueForTaskVmem(TestJobConf.java:280),at org.apache.hadoop.mapred.TestJobConf.testNegativeValueForTaskVmem$$CONFUZZ(TestJobConf.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.reduce.memory.mb': '9019'}	["mapreduce.reduce.memory.mb"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobConf/testNegativeValueForTaskVmem/campaign/failures/debug_000001	['debug_000001']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.AssertionError	1	FP	["org.apache.hadoop.mapred.TestJobConf#testNegativeValueForTaskVmem	java.lang.AssertionError	expected:<1024> but was:<6280>	java.lang.AssertionError: expected:<1024> but was:<6280>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.junit.Assert.assertEquals(Assert.java:633),at org.apache.hadoop.mapred.TestJobConf.testNegativeValueForTaskVmem(TestJobConf.java:278),at org.apache.hadoop.mapred.TestJobConf.testNegativeValueForTaskVmem$$CONFUZZ(TestJobConf.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.map.memory.mb': '6280'}	["mapreduce.map.memory.mb"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobConf/testNegativeValueForTaskVmem/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	org.junit.ComparisonFailure	1	not-reproducible	["org.apache.hadoop.mapred.TestTaskProgressReporter#testTaskProgress	org.junit.ComparisonFailure	expected:<[2]> but was:<[4]>	org.junit.ComparisonFailure: expected:<[2]> but was:<[4]>,at org.apache.hadoop.mapred.TestTaskProgressReporter.testTaskProgress(TestTaskProgressReporter.java:273),at org.apache.hadoop.mapred.TestTaskProgressReporter.testTaskProgress$$CONFUZZ(TestTaskProgressReporter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	PASS	{}	[]	org.junit.ComparisonFailure	expected:<[2]> but was:<[4]>	org.junit.ComparisonFailure: expected:<[2]> but was:<[4]>,at org.apache.hadoop.mapred.TestTaskProgressReporter.testTaskProgress(TestTaskProgressReporter.java:273),at org.apache.hadoop.mapred.TestTaskProgressReporter.testTaskProgress$$CONFUZZ(TestTaskProgressReporter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestTaskProgressReporter/testTaskProgress/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	org.junit.ComparisonFailure	2	not-reproducible	["org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager#testDetermineCacheVisibilities	org.junit.ComparisonFailure	The file paths were not found to be publicly visible even though the full path is publicly accessible expected:<true,true[]> but was:<true,true[,true]>	org.junit.ComparisonFailure: The file paths were not found to be publicly visible even though the full path is publicly accessible expected:<true,true[]> but was:<true,true[,true]>,at org.junit.Assert.assertEquals(Assert.java:117),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.testDetermineCacheVisibilities(TestClientDistributedCacheManager.java:156),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.testDetermineCacheVisibilities$$CONFUZZ(TestClientDistributedCacheManager.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	org.junit.ComparisonFailure	The file paths were not found to be publicly visible even though the full path is publicly accessible expected:<true,true[]> but was:<true,true[,true]>	org.junit.ComparisonFailure: The file paths were not found to be publicly visible even though the full path is publicly accessible expected:<true,true[]> but was:<true,true[,true]>,at org.junit.Assert.assertEquals(Assert.java:117),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.testDetermineCacheVisibilities(TestClientDistributedCacheManager.java:156),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.testDetermineCacheVisibilities$$CONFUZZ(TestClientDistributedCacheManager.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager/testDetermineCacheVisibilities/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testRecordSpanningMultipleSplits	org.junit.ComparisonFailure	expected:<...lly long line, which[ will surely span multiple splits,]> but was:<...lly long line, which[]>	org.junit.ComparisonFailure: expected:<...lly long line, which[ will surely span multiple splits,]> but was:<...lly long line, which[]>,at org.junit.Assert.assertEquals(Assert.java:117),at org.junit.Assert.assertEquals(Assert.java:146),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:201),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits(TestLineRecordReader.java:214),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	org.junit.ComparisonFailure	expected:<...lly long line, which[ will surely span multiple splits,]> but was:<...lly long line, which[]>	org.junit.ComparisonFailure: expected:<...lly long line, which[ will surely span multiple splits,]> but was:<...lly long line, which[]>,at org.junit.Assert.assertEquals(Assert.java:117),at org.junit.Assert.assertEquals(Assert.java:146),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:201),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits(TestLineRecordReader.java:214),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplits$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testRecordSpanningMultipleSplits/campaign/failures/debug_000002	{'hadoop.security.authentication': 'kerberos'}	['debug_000002']\n"]																																																																																																																																																																																																																																																																																																																																																																																		
	org.junit.internal.runners.model.MultipleFailureException	2	not-reproducible	["org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager#testDetermineCacheVisibilities	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.lang.IllegalStateException(bytes per checksum should be positive but was 0),  java.lang.NullPointerException(null)	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.setup(TestClientDistributedCacheManager.java:75),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),java.lang.NullPointerException,at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.tearDown(TestClientDistributedCacheManager.java:84),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'file.bytes-per-checksum': '0'}	["file.bytes-per-checksum"]	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.lang.IllegalStateException(bytes per checksum should be positive but was 0),  java.lang.NullPointerException(null)	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.setup(TestClientDistributedCacheManager.java:75),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),java.lang.NullPointerException,at org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager.tearDown(TestClientDistributedCacheManager.java:84),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.filecache.TestClientDistributedCacheManager/testDetermineCacheVisibilities/campaign/failures/debug_000005	['debug_000005']\n", "org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testFailAbortV1	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.lang.IllegalStateException(bytes per checksum should be positive but was 0),  java.lang.IllegalStateException(bytes per checksum should be positive but was 0)	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.cleanup(TestFileOutputCommitter.java:95),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.setUp(TestFileOutputCommitter.java:101),at jdk.internal.reflect.GeneratedMethodAccessor17.invoke(Unknown Source),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.cleanup(TestFileOutputCommitter.java:95),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.tearDown(TestFileOutputCommitter.java:106),at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.lang.IllegalStateException(bytes per checksum should be positive but was 0),  java.lang.IllegalStateException(bytes per checksum should be positive but was 0)	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.cleanup(TestFileOutputCommitter.java:95),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.setUp(TestFileOutputCommitter.java:101),at jdk.internal.reflect.GeneratedMethodAccessor17.invoke(Unknown Source),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.cleanup(TestFileOutputCommitter.java:95),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.tearDown(TestFileOutputCommitter.java:106),at jdk.internal.reflect.GeneratedMethodAccessor19.invoke(Unknown Source),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testFailAbortV1/campaign/failures/debug_000001	{'file.bytes-per-checksum': '0'}	['debug_000001']\n"]																																																																																																																																																																																																																																																																																																																																																																																		
mapreduce.job.end-notification.timeout >= 0	java.lang.AssertionError	2	FP	["org.apache.hadoop.mapred.TestJobEndNotifier#testLocalJobRunnerUriSubstitution	java.lang.AssertionError	expected:<1> but was:<0>	java.lang.AssertionError: expected:<1> but was:<0>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.junit.Assert.assertEquals(Assert.java:633),at org.apache.hadoop.mapred.TestJobEndNotifier.testLocalJobRunnerUriSubstitution(TestJobEndNotifier.java:146),at org.apache.hadoop.mapred.TestJobEndNotifier.testLocalJobRunnerUriSubstitution$$CONFUZZ(TestJobEndNotifier.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.job.end-notification.timeout': '-1909943585'}	["mapreduce.job.end-notification.timeout"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobEndNotifier/testLocalJobRunnerUriSubstitution/campaign/failures/debug_000001	['debug_000001']\n", "org.apache.hadoop.mapred.TestJobEndNotifier#testLocalJobRunnerRetryCount	java.lang.AssertionError	expected:<4> but was:<0>	java.lang.AssertionError: expected:<4> but was:<0>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.junit.Assert.assertEquals(Assert.java:633),at org.apache.hadoop.mapred.TestJobEndNotifier.testLocalJobRunnerRetryCount(TestJobEndNotifier.java:164),at org.apache.hadoop.mapred.TestJobEndNotifier.testLocalJobRunnerRetryCount$$CONFUZZ(TestJobEndNotifier.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobEndNotifier/testLocalJobRunnerRetryCount/campaign/failures/debug_000003	{'mapreduce.job.end-notification.timeout': '-1973757396'}	['debug_000003']\n"]																																																																																																																																																																																																																																																																																																																																																																																		
	java.lang.NullPointerException	1	not-reproducible	["org.apache.hadoop.mapred.TestJobEndNotifier#testLocalJobRunnerUriSubstitution	java.lang.NullPointerException	config	java.lang.NullPointerException: config,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899),at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298),at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277),at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279),at org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	PASS	{}	[]	java.lang.NullPointerException	config	java.lang.NullPointerException: config,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899),at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298),at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277),at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279),at org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobEndNotifier/testLocalJobRunnerUriSubstitution/campaign/failures/debug_000002	['debug_000002']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	org.junit.internal.runners.model.MultipleFailureException	1	not-reproducible	["org.apache.hadoop.mapred.TestJobEndNotifier#testLocalJobRunnerUriSubstitution	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.io.IOException(java.lang.IllegalArgumentException),  java.lang.NullPointerException(null)	java.io.IOException: java.lang.IllegalArgumentException,at org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:682),at org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:129),at org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:468),at org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:111),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),Caused by: java.lang.IllegalArgumentException,at java.base/java.util.concurrent.ScheduledThreadPoolExecutor.scheduleAtFixedRate(ScheduledThreadPoolExecutor.java:623),at java.base/java.util.concurrent.Executors$DelegatedScheduledExecutorService.scheduleAtFixedRate(Executors.java:785),at org.apache.hadoop.security.authentication.util.RolloverSignerSecretProvider.startScheduler(RolloverSignerSecretProvider.java:96),at org.apache.hadoop.security.authentication.util.RolloverSignerSecretProvider.init(RolloverSignerSecretProvider.java:72),at org.apache.hadoop.security.authentication.server.AuthenticationFilter.constructSecretProvider(AuthenticationFilter.java:243),at org.apache.hadoop.http.HttpServer2.constructSecretProvider(HttpServer2.java:789),at org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:675),... 31 more,java.lang.NullPointerException,at org.apache.hadoop.mapred.TestJobEndNotifier.tearDown(TestJobEndNotifier.java:127),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.http.authentication.token.validity': '-525723654'}	["hadoop.http.authentication.token.validity"]	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.io.IOException(java.lang.IllegalArgumentException),  java.lang.NullPointerException(null)	java.io.IOException: java.lang.IllegalArgumentException,at org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:682),at org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:129),at org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:468),at org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:111),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),Caused by: java.lang.IllegalArgumentException,at java.base/java.util.concurrent.ScheduledThreadPoolExecutor.scheduleAtFixedRate(ScheduledThreadPoolExecutor.java:623),at java.base/java.util.concurrent.Executors$DelegatedScheduledExecutorService.scheduleAtFixedRate(Executors.java:785),at org.apache.hadoop.security.authentication.util.RolloverSignerSecretProvider.startScheduler(RolloverSignerSecretProvider.java:96),at org.apache.hadoop.security.authentication.util.RolloverSignerSecretProvider.init(RolloverSignerSecretProvider.java:72),at org.apache.hadoop.security.authentication.server.AuthenticationFilter.constructSecretProvider(AuthenticationFilter.java:243),at org.apache.hadoop.http.HttpServer2.constructSecretProvider(HttpServer2.java:789),at org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:675),... 31 more,java.lang.NullPointerException,at org.apache.hadoop.mapred.TestJobEndNotifier.tearDown(TestJobEndNotifier.java:127),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobEndNotifier/testLocalJobRunnerUriSubstitution/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
Insufficient configured threads: required=11911 < max=15	java.lang.IllegalStateException	2	FP	["org.apache.hadoop.mapred.TestJobEndNotifier#testLocalJobRunnerUriSubstitution	java.lang.IllegalStateException	Insufficient configured threads: required=11911 < max=15 for QueuedThreadPool[qtp1972335962]@758f755a{STARTED,8<=8<=15,i=8,r=-1,q=0}[ReservedThreadExecutor@7bc342f6{s=0/1,p=0}]	java.lang.IllegalStateException: Insufficient configured threads: required=11911 < max=15 for QueuedThreadPool[qtp1972335962]@758f755a{STARTED,8<=8<=15,i=8,r=-1,q=0}[ReservedThreadExecutor@7bc342f6{s=0/1,p=0}],at org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165),at org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141),at org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191),at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320),at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81),at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234),at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73),at org.eclipse.jetty.server.Server.doStart(Server.java:401),at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73),at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276),at org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'hadoop.http.acceptor.count': '11910'}	["hadoop.http.acceptor.count"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobEndNotifier/testLocalJobRunnerUriSubstitution/campaign/failures/debug_000003	['debug_000003']\n", "org.apache.hadoop.mapred.TestJobEndNotifier#testLocalJobRunnerRetryCount	java.lang.IllegalStateException	Insufficient configured threads: required=20787 < max=110 for QueuedThreadPool[qtp145561644]@8ad182c{STARTED,8<=8<=110,i=8,r=-1,q=0}[ReservedThreadExecutor@6771fc29{s=0/2,p=0}]	java.lang.IllegalStateException: Insufficient configured threads: required=20787 < max=110 for QueuedThreadPool[qtp145561644]@8ad182c{STARTED,8<=8<=110,i=8,r=-1,q=0}[ReservedThreadExecutor@6771fc29{s=0/2,p=0}],at org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165),at org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141),at org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191),at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320),at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81),at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234),at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73),at org.eclipse.jetty.server.Server.doStart(Server.java:401),at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73),at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276),at org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobEndNotifier/testLocalJobRunnerRetryCount/campaign/failures/debug_000002	{'hadoop.http.acceptor.count': '20785'}	['debug_000002']\n"]																																																																																																																																																																																																																																																																																																																																																																																		
	java.lang.OutOfMemoryError	1	not-reproducible	["org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testBzipWithMultibyteDelimiter	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.util.LineReader.<init>(LineReader.java:142),at org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37),at org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader.<init>(CompressedSplitLineReader.java:122),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:103),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:87),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:646),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.groups.cache.background.reload': 'true', 'hadoop.security.groups.cache.background.reload.threads': '-827601380'}	["hadoop.security.groups.cache.background.reload", "hadoop.security.groups.cache.background.reload.threads"]	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.util.LineReader.<init>(LineReader.java:142),at org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37),at org.apache.hadoop.mapreduce.lib.input.CompressedSplitLineReader.<init>(CompressedSplitLineReader.java:122),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:103),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:87),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:646),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testBzipWithMultibyteDelimiter/campaign/failures/debug_000001	['debug_000001']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.IllegalStateException	3	not-reproducible	["org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testBzipWithMultibyteDelimiter	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:88),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:87),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:646),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.groups.cache.background.reload': 'true', 'hadoop.security.groups.cache.background.reload.threads': '-827601380'}	["hadoop.security.groups.cache.background.reload", "hadoop.security.groups.cache.background.reload.threads"]	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:88),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:87),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:646),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testBzipWithMultibyteDelimiter/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testRecordSpanningMultipleSplitsCompressed	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:88),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.readRecords(TestLineRecordReader.java:160),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:194),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed(TestLineRecordReader.java:225),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:88),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.readRecords(TestLineRecordReader.java:160),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.checkRecordSpanningMultipleSplits(TestLineRecordReader.java:194),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed(TestLineRecordReader.java:225),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testRecordSpanningMultipleSplitsCompressed$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testRecordSpanningMultipleSplitsCompressed/campaign/failures/debug_000001	{'hadoop.security.groups.cache.background.reload': 'true', 'hadoop.security.groups.cache.background.reload.threads': '-1373412559'}	['debug_000001']\n", "org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testMultipleClose	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:88),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testMultipleClose(TestLineRecordReader.java:285),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testMultipleClose$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.IllegalStateException	bytes per checksum should be positive but was 0	java.lang.IllegalStateException: bytes per checksum should be positive but was 0,at org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkState(Preconditions.java:562),at org.apache.hadoop.fs.ChecksumFileSystem.setConf(ChecksumFileSystem.java:80),at org.apache.hadoop.util.ReflectionUtils.setConf(ReflectionUtils.java:79),at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:139),at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3467),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:288),at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:524),at org.apache.hadoop.fs.Path.getFileSystem(Path.java:365),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:88),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testMultipleClose(TestLineRecordReader.java:285),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testMultipleClose$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testMultipleClose/campaign/failures/debug_000002	{'hadoop.security.groups.cache.background.reload': 'true', 'hadoop.security.groups.cache.background.reload.threads': '-1220242282'}	['debug_000002']\n"]																																																																																																																																																																																																																																																																																																																																																																								
	java.lang.AssertionError	1	not-reproducible	["org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader#testBzipWithMultibyteDelimiter	java.lang.AssertionError	Unexpected number of records in split  expected:<60> but was:<61>	java.lang.AssertionError: Unexpected number of records in split  expected:<60> but was:<61>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:114),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:646),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.groups.cache.background.reload': 'true', 'hadoop.security.groups.cache.background.reload.threads': '-827601380'}	["hadoop.security.groups.cache.background.reload", "hadoop.security.groups.cache.background.reload.threads"]	java.lang.AssertionError	Unexpected number of records in split  expected:<60> but was:<61>	java.lang.AssertionError: Unexpected number of records in split  expected:<60> but was:<61>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:114),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:646),at org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestLineRecordReader/testBzipWithMultibyteDelimiter/campaign/failures/debug_000003	['debug_000003']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	org.junit.internal.runners.model.MultipleFailureException	2	not-reproducible	["org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC#testMaxBlockLocationsNewSplitsWithErasureCoding	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.lang.IllegalArgumentException(-1661287464),  java.lang.NullPointerException(null)	java.lang.IllegalArgumentException: -1661287464,at org.apache.hadoop.fs.permission.PermissionParser.applyNormalPattern(PermissionParser.java:70),at org.apache.hadoop.fs.permission.PermissionParser.<init>(PermissionParser.java:56),at org.apache.hadoop.fs.permission.RawParser.<init>(RawParser.java:36),at org.apache.hadoop.fs.permission.FsPermission.<init>(FsPermission.java:145),at org.apache.hadoop.hdfs.server.namenode.NNStorage.setStorageDirectories(NNStorage.java:323),at org.apache.hadoop.hdfs.server.namenode.NNStorage.<init>(NNStorage.java:179),at org.apache.hadoop.hdfs.server.namenode.FSImage.<init>(FSImage.java:167),at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1253),at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450),at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261),at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132),at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016),at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948),at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576),at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518),at org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC.setup(TestJobSplitWriterWithEC.java:72),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),java.lang.NullPointerException,at org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC.after(TestJobSplitWriterWithEC.java:89),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.authentication': 'kerberos'}	["hadoop.security.authentication"]	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.lang.IllegalArgumentException(-1661287464),  java.lang.NullPointerException(null)	java.lang.IllegalArgumentException: -1661287464,at org.apache.hadoop.fs.permission.PermissionParser.applyNormalPattern(PermissionParser.java:70),at org.apache.hadoop.fs.permission.PermissionParser.<init>(PermissionParser.java:56),at org.apache.hadoop.fs.permission.RawParser.<init>(RawParser.java:36),at org.apache.hadoop.fs.permission.FsPermission.<init>(FsPermission.java:145),at org.apache.hadoop.hdfs.server.namenode.NNStorage.setStorageDirectories(NNStorage.java:323),at org.apache.hadoop.hdfs.server.namenode.NNStorage.<init>(NNStorage.java:179),at org.apache.hadoop.hdfs.server.namenode.FSImage.<init>(FSImage.java:167),at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1253),at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450),at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261),at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132),at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016),at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948),at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576),at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518),at org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC.setup(TestJobSplitWriterWithEC.java:72),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),java.lang.NullPointerException,at org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC.after(TestJobSplitWriterWithEC.java:89),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC/testMaxBlockLocationsNewSplitsWithErasureCoding/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC#testMaxBlockLocationsOldSplitsWithErasureCoding	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.io.IOException(The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem),  java.lang.NullPointerException(null)	java.io.IOException: The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem,at org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296),at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228),at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450),at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261),at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132),at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016),at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948),at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576),at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518),at org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC.setup(TestJobSplitWriterWithEC.java:72),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),java.lang.NullPointerException,at org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC.after(TestJobSplitWriterWithEC.java:89),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.io.IOException(The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem),  java.lang.NullPointerException(null)	java.io.IOException: The option dfs.namenode.support.allow.format is set to false for this filesystem, so it cannot be formatted. You will need to set dfs.namenode.support.allow.format parameter to true in order to format this filesystem,at org.apache.hadoop.hdfs.server.namenode.NameNode.checkAllowFormat(NameNode.java:1296),at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1228),at org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:450),at org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:261),at org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1132),at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1016),at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:948),at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:576),at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:518),at org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC.setup(TestJobSplitWriterWithEC.java:72),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),java.lang.NullPointerException,at org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC.after(TestJobSplitWriterWithEC.java:89),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.split.TestJobSplitWriterWithEC/testMaxBlockLocationsOldSplitsWithErasureCoding/campaign/failures/debug_000000	{'hadoop.security.authentication': 'kerberos'}	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																		
	org.junit.internal.runners.model.MultipleFailureException	1	not-reproducible	["org.apache.hadoop.mapred.TestJobEndNotifier#testNotificationTimeout	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.lang.OutOfMemoryError(Java heap space),  java.lang.NullPointerException(null)	java.lang.OutOfMemoryError: Java heap space,at org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228),at org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44),at org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215),at org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114),at org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534),at org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511),at org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:111),at jdk.internal.reflect.GeneratedMethodAccessor13.invoke(Unknown Source),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),java.lang.NullPointerException,at org.apache.hadoop.mapred.TestJobEndNotifier.tearDown(TestJobEndNotifier.java:127),at jdk.internal.reflect.GeneratedMethodAccessor15.invoke(Unknown Source),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.http.acceptor.count': '949699245'}	["hadoop.http.acceptor.count"]	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.lang.OutOfMemoryError(Java heap space),  java.lang.NullPointerException(null)	java.lang.OutOfMemoryError: Java heap space,at org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228),at org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44),at org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215),at org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114),at org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534),at org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511),at org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:111),at jdk.internal.reflect.GeneratedMethodAccessor13.invoke(Unknown Source),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),java.lang.NullPointerException,at org.apache.hadoop.mapred.TestJobEndNotifier.tearDown(TestJobEndNotifier.java:127),at jdk.internal.reflect.GeneratedMethodAccessor15.invoke(Unknown Source),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobEndNotifier/testNotificationTimeout/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.OutOfMemoryError	1	not-reproducible	["org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader#testProgressIsReportedIfInputASeriesOfEmptyFiles	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.util.LineReader.<init>(LineReader.java:142),at org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37),at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.<init>(UncompressedSplitLineReader.java:46),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:123),at org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReaderWrapper.initialize(CombineFileRecordReaderWrapper.java:69),at org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.initialize(CombineFileRecordReader.java:59),at org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader.testProgressIsReportedIfInputASeriesOfEmptyFiles(TestCombineFileRecordReader.java:86),at org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader.testProgressIsReportedIfInputASeriesOfEmptyFiles$$CONFUZZ(TestCombineFileRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	PASS	{}	[]	java.lang.OutOfMemoryError	Java heap space	java.lang.OutOfMemoryError: Java heap space,at org.apache.hadoop.util.LineReader.<init>(LineReader.java:142),at org.apache.hadoop.mapreduce.lib.input.SplitLineReader.<init>(SplitLineReader.java:37),at org.apache.hadoop.mapreduce.lib.input.UncompressedSplitLineReader.<init>(UncompressedSplitLineReader.java:46),at org.apache.hadoop.mapreduce.lib.input.LineRecordReader.initialize(LineRecordReader.java:123),at org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReaderWrapper.initialize(CombineFileRecordReaderWrapper.java:69),at org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.initialize(CombineFileRecordReader.java:59),at org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader.testProgressIsReportedIfInputASeriesOfEmptyFiles(TestCombineFileRecordReader.java:86),at org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader.testProgressIsReportedIfInputASeriesOfEmptyFiles$$CONFUZZ(TestCombineFileRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader/testProgressIsReportedIfInputASeriesOfEmptyFiles/campaign/failures/debug_000001	['debug_000001', 'debug_000002']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
mapreduce.task.io.sort.factor should be default	java.lang.AssertionError	1	FP	["org.apache.hadoop.mapreduce.task.reduce.TestMergeManager#testIoSortDefaults	java.lang.AssertionError	expected:<10> but was:<530>	java.lang.AssertionError: expected:<10> but was:<530>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.junit.Assert.assertEquals(Assert.java:633),at org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testIoSortDefaults(TestMergeManager.java:214),at org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testIoSortDefaults$$CONFUZZ(TestMergeManager.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.task.io.sort.factor': '530'}	["mapreduce.task.io.sort.factor"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.task.reduce.TestMergeManager/testIoSortDefaults/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.RuntimeException	1	FP	["org.apache.hadoop.mapreduce.task.reduce.TestMergeManager#testZeroShuffleMemoryLimitPercent	java.lang.RuntimeException	Invalid configuration: maxSingleShuffleLimit should be less than mergeThreshold maxSingleShuffleLimit: 0mergeThreshold: 0	java.lang.RuntimeException: Invalid configuration: maxSingleShuffleLimit should be less than mergeThreshold maxSingleShuffleLimit: 0mergeThreshold: 0,at org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl.<init>(MergeManagerImpl.java:215),at org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testZeroShuffleMemoryLimitPercent(TestMergeManager.java:320),at org.apache.hadoop.mapreduce.task.reduce.TestMergeManager.testZeroShuffleMemoryLimitPercent$$CONFUZZ(TestMergeManager.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.reduce.shuffle.merge.percent': '1.1597876437008381E-8', 'mapreduce.reduce.memory.totalbytes': '26124'}	["mapreduce.reduce.memory.totalbytes", "mapreduce.reduce.shuffle.merge.percent"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.task.reduce.TestMergeManager/testZeroShuffleMemoryLimitPercent/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.NullPointerException	2	not-reproducible	["org.apache.hadoop.mapred.TestTask#testStatusUpdateExitsInNonUberMode	java.lang.NullPointerException	No message	java.lang.NullPointerException,at org.apache.hadoop.mapred.TestTask.setupTest(TestTask.java:70),at org.apache.hadoop.mapred.TestTask.testStatusUpdateExitsInNonUberMode(TestTask.java:60),at org.apache.hadoop.mapred.TestTask.testStatusUpdateExitsInNonUberMode$$CONFUZZ(TestTask.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'mapreduce.job.counters.group.name.max': '-1455352016'}	["mapreduce.job.counters.group.name.max"]	java.lang.NullPointerException	No message	java.lang.NullPointerException,at org.apache.hadoop.mapred.TestTask.setupTest(TestTask.java:70),at org.apache.hadoop.mapred.TestTask.testStatusUpdateExitsInNonUberMode(TestTask.java:60),at org.apache.hadoop.mapred.TestTask.testStatusUpdateExitsInNonUberMode$$CONFUZZ(TestTask.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestTask/testStatusUpdateExitsInNonUberMode/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapred.TestTask#testStatusUpdateDoesNotExitInUberMode	java.lang.NullPointerException	No message	java.lang.NullPointerException,at org.apache.hadoop.mapred.TestTask.setupTest(TestTask.java:70),at org.apache.hadoop.mapred.TestTask.testStatusUpdateDoesNotExitInUberMode(TestTask.java:53),at org.apache.hadoop.mapred.TestTask.testStatusUpdateDoesNotExitInUberMode$$CONFUZZ(TestTask.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	java.lang.NullPointerException	No message	java.lang.NullPointerException,at org.apache.hadoop.mapred.TestTask.setupTest(TestTask.java:70),at org.apache.hadoop.mapred.TestTask.testStatusUpdateDoesNotExitInUberMode(TestTask.java:53),at org.apache.hadoop.mapred.TestTask.testStatusUpdateDoesNotExitInUberMode$$CONFUZZ(TestTask.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestTask/testStatusUpdateDoesNotExitInUberMode/campaign/failures/debug_000000	{'mapreduce.job.counters.group.name.max': '-1533323479'}	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																		
	java.lang.AssertionError	4	FP	["org.apache.hadoop.mapred.TestJobConf#testNegativeValuesForMemoryParams	java.lang.AssertionError	expected:<1024> but was:<686>	java.lang.AssertionError: expected:<1024> but was:<686>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.junit.Assert.assertEquals(Assert.java:633),at org.apache.hadoop.mapred.TestJobConf.testNegativeValuesForMemoryParams(TestJobConf.java:299),at org.apache.hadoop.mapred.TestJobConf.testNegativeValuesForMemoryParams$$CONFUZZ(TestJobConf.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapred.task.maxvmem': '720305260'}	["mapred.task.maxvmem"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobConf/testNegativeValuesForMemoryParams/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapred.TestJobConf#testDeprecatedPropertyNameForTaskVmem	java.lang.AssertionError	expected:<1024> but was:<0>	java.lang.AssertionError: expected:<1024> but was:<0>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.junit.Assert.assertEquals(Assert.java:633),at org.apache.hadoop.mapred.TestJobConf.testDeprecatedPropertyNameForTaskVmem(TestJobConf.java:173),at org.apache.hadoop.mapred.TestJobConf.testDeprecatedPropertyNameForTaskVmem$$CONFUZZ(TestJobConf.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobConf/testDeprecatedPropertyNameForTaskVmem/campaign/failures/debug_000000	{'mapred.task.maxvmem': '22682'}	['debug_000000']\n", "org.apache.hadoop.mapred.TestJobConf#testJobConf	java.lang.AssertionError	No message	java.lang.AssertionError,at org.junit.Assert.fail(Assert.java:87),at org.junit.Assert.assertTrue(Assert.java:42),at org.junit.Assert.assertFalse(Assert.java:65),at org.junit.Assert.assertFalse(Assert.java:75),at org.apache.hadoop.mapred.TestJobConf.testJobConf(TestJobConf.java:48),at org.apache.hadoop.mapred.TestJobConf.testJobConf$$CONFUZZ(TestJobConf.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobConf/testJobConf/campaign/failures/debug_000001	{'mapred.task.maxvmem': '27435'}	['debug_000001']\n", "org.apache.hadoop.mapred.TestJobConf#testJobConf	java.lang.AssertionError	expected null, but was:<1934410701>	java.lang.AssertionError: expected null, but was:<1934410701>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotNull(Assert.java:756),at org.junit.Assert.assertNull(Assert.java:738),at org.junit.Assert.assertNull(Assert.java:748),at org.apache.hadoop.mapred.TestJobConf.testJobConf(TestJobConf.java:53),at org.apache.hadoop.mapred.TestJobConf.testJobConf$$CONFUZZ(TestJobConf.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobConf/testJobConf/campaign/failures/debug_000000	{'mapred.task.maxvmem': '634'}	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																														
	org.junit.ComparisonFailure	2	FP	["org.apache.hadoop.mapred.TestJobConf#testMemoryConfigForMapOrReduceTask	org.junit.ComparisonFailure	expected:<[300]L> but was:<[1886]L>	org.junit.ComparisonFailure: expected:<[300]L> but was:<[1886]L>,at org.apache.hadoop.mapred.TestJobConf.testMemoryConfigForMapOrReduceTask(TestJobConf.java:229),at org.apache.hadoop.mapred.TestJobConf.testMemoryConfigForMapOrReduceTask$$CONFUZZ(TestJobConf.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapred.task.maxvmem': '1978425156'}	["mapred.task.maxvmem"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobConf/testMemoryConfigForMapOrReduceTask/campaign/failures/debug_000000	['debug_000000']\n", "org.apache.hadoop.mapred.TestJobConf#testMaxVirtualMemoryForTask	org.junit.ComparisonFailure	expected:<[1073741824]L> but was:<[229338933]L>	org.junit.ComparisonFailure: expected:<[1073741824]L> but was:<[229338933]L>,at org.apache.hadoop.mapred.TestJobConf.testMaxVirtualMemoryForTask(TestJobConf.java:317),at org.apache.hadoop.mapred.TestJobConf.testMaxVirtualMemoryForTask$$CONFUZZ(TestJobConf.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobConf/testMaxVirtualMemoryForTask/campaign/failures/debug_000000	{'mapred.task.maxvmem': '229338933'}	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																		
HIGHLY NON TRIVIAL	java.lang.AssertionError	1	BUG	["org.apache.hadoop.mapred.TestLineRecordReader#testBzipWithMultibyteDelimiter	java.lang.AssertionError	Unexpected number of records in split expected:<60> but was:<61>	java.lang.AssertionError: Unexpected number of records in split expected:<60> but was:<61>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:110),at org.apache.hadoop.mapred.TestLineRecordReader.testBzipWithMultibyteDelimiter(TestLineRecordReader.java:684),at org.apache.hadoop.mapred.TestLineRecordReader.testBzipWithMultibyteDelimiter$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'io.file.buffer.size': '188'}	["io.file.buffer.size"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testBzipWithMultibyteDelimiter/campaign/failures/debug_000005	['debug_000005']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.io.IOException	1	not-reproducible	["org.apache.hadoop.mapred.TestLineRecordReader#testSafeguardSplittingUnsplittableFiles	java.io.IOException	not a gzip file	java.io.IOException: not a gzip file,at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.processBasicHeader(BuiltInGzipDecompressor.java:496),at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeHeaderState(BuiltInGzipDecompressor.java:257),at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:186),at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:111),at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:105),at java.base/java.io.InputStream.read(InputStream.java:205),at org.apache.hadoop.util.LineReader.fillBuffer(LineReader.java:191),at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227),at org.apache.hadoop.util.LineReader.readLine(LineReader.java:185),at org.apache.hadoop.mapred.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:221),at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:259),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:86),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecords(TestLineRecordReader.java:62),at org.apache.hadoop.mapred.TestLineRecordReader.testSafeguardSplittingUnsplittableFiles(TestLineRecordReader.java:192),at org.apache.hadoop.mapred.TestLineRecordReader.testSafeguardSplittingUnsplittableFiles$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	PASS	{}	[]	java.io.IOException	not a gzip file	java.io.IOException: not a gzip file,at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.processBasicHeader(BuiltInGzipDecompressor.java:496),at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.executeHeaderState(BuiltInGzipDecompressor.java:257),at org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.decompress(BuiltInGzipDecompressor.java:186),at org.apache.hadoop.io.compress.DecompressorStream.decompress(DecompressorStream.java:111),at org.apache.hadoop.io.compress.DecompressorStream.read(DecompressorStream.java:105),at java.base/java.io.InputStream.read(InputStream.java:205),at org.apache.hadoop.util.LineReader.fillBuffer(LineReader.java:191),at org.apache.hadoop.util.LineReader.readDefaultLine(LineReader.java:227),at org.apache.hadoop.util.LineReader.readLine(LineReader.java:185),at org.apache.hadoop.mapred.LineRecordReader.skipUtfByteOrderMark(LineRecordReader.java:221),at org.apache.hadoop.mapred.LineRecordReader.next(LineRecordReader.java:259),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecordsForFile(TestLineRecordReader.java:86),at org.apache.hadoop.mapred.TestLineRecordReader.testSplitRecords(TestLineRecordReader.java:62),at org.apache.hadoop.mapred.TestLineRecordReader.testSafeguardSplittingUnsplittableFiles(TestLineRecordReader.java:192),at org.apache.hadoop.mapred.TestLineRecordReader.testSafeguardSplittingUnsplittableFiles$$CONFUZZ(TestLineRecordReader.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestLineRecordReader/testSafeguardSplittingUnsplittableFiles/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.io.IOException	1	FP	["org.apache.hadoop.mapreduce.security.TestTokenCache#testSingleTokenFetch	java.io.IOException	Can't get Master Kerberos principal for use as renewer	java.io.IOException: Can't get Master Kerberos principal for use as renewer,at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:134),at org.apache.hadoop.mapreduce.security.TokenCache.obtainTokensForNamenodesInternal(TokenCache.java:102),at org.apache.hadoop.mapreduce.security.TestTokenCache.testSingleTokenFetch(TestTokenCache.java:175),at org.apache.hadoop.mapreduce.security.TestTokenCache.testSingleTokenFetch$$CONFUZZ(TestTokenCache.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.framework.name': 'classic'}	["mapreduce.framework.name"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.security.TestTokenCache/testSingleTokenFetch/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.Exception	1	FP	["org.apache.hadoop.mapred.TestDebug#test	java.lang.Exception	Fake Bug FATAL	java.lang.Exception: Fake Bug FATAL,at org.apache.hadoop.mapred.TestDebug.test(TestDebug.java:21),at org.apache.hadoop.mapred.TestDebug.test$$CONFUZZ(TestDebug.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'yarn.app.mapreduce.am.log.level': 'FATAL'}	["yarn.app.mapreduce.am.log.level"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestDebug/test/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.io.IOException	1	not-reproducible	["org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithDuplicatedCommitV1	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/31360/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/31360/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:362),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:336),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.security.groups.cache.background.reload.threads': '-1099972641', 'hadoop.security.groups.cache.background.reload': 'true'}	["hadoop.security.groups.cache.background.reload", "hadoop.security.groups.cache.background.reload.threads"]	java.io.IOException	Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/31360/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core)	java.io.IOException: Mkdirs failed to create file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/test-dir/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/_temporary/31360/_temporary/attempt_200707121733_0001_m_000000_0 (exists=false, cwd=file:/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:515),at org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175),at org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064),at org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.getRecordWriter(TextOutputFormat.java:126),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitInternal(TestFileOutputCommitter.java:362),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1(TestFileOutputCommitter.java:336),at org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testCommitterWithDuplicatedCommitV1$$CONFUZZ(TestFileOutputCommitter.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter/testCommitterWithDuplicatedCommitV1/campaign/failures/debug_000002	['debug_000002']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	org.junit.internal.runners.model.MultipleFailureException	1	not-reproducible	["org.apache.hadoop.mapred.TestJobEndNotifier#testLocalJobRunnerRetryCount	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.lang.OutOfMemoryError(Java heap space),  java.lang.NullPointerException(null)	java.lang.OutOfMemoryError: Java heap space,at org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99),at org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600),at org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223),at org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216),at org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114),at org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534),at org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511),at org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:111),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),java.lang.NullPointerException,at org.apache.hadoop.mapred.TestJobEndNotifier.tearDown(TestJobEndNotifier.java:127),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	DIFFERENT	{'hadoop.http.selector.count': '2065160455'}	["hadoop.http.selector.count"]	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:,  java.lang.OutOfMemoryError(Java heap space),  java.lang.NullPointerException(null)	java.lang.OutOfMemoryError: Java heap space,at org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99),at org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600),at org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223),at org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216),at org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114),at org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534),at org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511),at org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:111),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),java.lang.NullPointerException,at org.apache.hadoop.mapred.TestJobEndNotifier.tearDown(TestJobEndNotifier.java:127),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62),at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunAfters.invokeMethod(RunAfters.java:46),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobEndNotifier/testLocalJobRunnerRetryCount/campaign/failures/debug_000001	['debug_000001']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.IllegalStateException	1	FP	["org.apache.hadoop.mapred.TestJobEndNotifier#testLocalJobRunnerRetryCount	java.lang.IllegalStateException	Insufficient configured threads: required=19381 < max=110 for QueuedThreadPool[qtp608709199]@24482a4f{STARTED,8<=8<=110,i=8,r=-1,q=0}[ReservedThreadExecutor@b53ce18{s=0/2,p=0}]	java.lang.IllegalStateException: Insufficient configured threads: required=19381 < max=110 for QueuedThreadPool[qtp608709199]@24482a4f{STARTED,8<=8<=110,i=8,r=-1,q=0}[ReservedThreadExecutor@b53ce18{s=0/2,p=0}],at org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165),at org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141),at org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191),at org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255),at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73),at org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169),at org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110),at org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321),at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81),at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234),at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73),at org.eclipse.jetty.server.Server.doStart(Server.java:401),at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73),at org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276),at org.apache.hadoop.mapred.TestJobEndNotifier.setUp(TestJobEndNotifier.java:115),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33),at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24),at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'hadoop.http.selector.count': '19378'}	["hadoop.http.selector.count"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestJobEndNotifier/testLocalJobRunnerRetryCount/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.IllegalArgumentException	1	FP	["org.apache.hadoop.mapreduce.tools.TestCLI#testLogs	java.lang.IllegalArgumentException	timeout value is negative	java.lang.IllegalArgumentException: timeout value is negative,at java.base/java.lang.Thread.sleep(Native Method),at org.apache.hadoop.mapreduce.tools.CLI.getJob(CLI.java:669),at org.apache.hadoop.mapreduce.tools.CLI.run(CLI.java:470),at org.apache.hadoop.mapreduce.tools.TestCLI.testLogs(TestCLI.java:221),at org.apache.hadoop.mapreduce.tools.TestCLI.testLogs$$CONFUZZ(TestCLI.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'yarn.app.mapreduce.client.job.retry-interval': '-1126731493'}	["yarn.app.mapreduce.client.job.retry-interval"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapreduce.tools.TestCLI/testLogs/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.AssertionError	1	FP	["org.apache.hadoop.mapred.TestSkipBadRecords#testSkipBadRecords	java.lang.AssertionError	expected:<0> but was:<-1285593292>	java.lang.AssertionError: expected:<0> but was:<-1285593292>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.junit.Assert.assertEquals(Assert.java:633),at org.apache.hadoop.mapred.TestSkipBadRecords.testSkipBadRecords(TestSkipBadRecords.java:38),at org.apache.hadoop.mapred.TestSkipBadRecords.testSkipBadRecords$$CONFUZZ(TestSkipBadRecords.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.map.skip.maxrecords': '-1285593292'}	["mapreduce.map.skip.maxrecords"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestSkipBadRecords/testSkipBadRecords/campaign/failures/debug_000001	['debug_000001']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.AssertionError	1	FP	["org.apache.hadoop.mapred.TestSkipBadRecords#testSkipBadRecords	java.lang.AssertionError	No message	java.lang.AssertionError,at org.junit.Assert.fail(Assert.java:87),at org.junit.Assert.assertTrue(Assert.java:42),at org.junit.Assert.assertTrue(Assert.java:53),at org.apache.hadoop.mapred.TestSkipBadRecords.testSkipBadRecords(TestSkipBadRecords.java:36),at org.apache.hadoop.mapred.TestSkipBadRecords.testSkipBadRecords$$CONFUZZ(TestSkipBadRecords.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.map.skip.proc-count.auto-incr': 'false'}	["mapreduce.map.skip.proc-count.auto-incr"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestSkipBadRecords/testSkipBadRecords/campaign/failures/debug_000002	['debug_000002']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
	java.lang.AssertionError	1	FP	["org.apache.hadoop.mapred.TestSkipBadRecords#testSkipBadRecords	java.lang.AssertionError	expected:<2> but was:<17872>	java.lang.AssertionError: expected:<2> but was:<17872>,at org.junit.Assert.fail(Assert.java:89),at org.junit.Assert.failNotEquals(Assert.java:835),at org.junit.Assert.assertEquals(Assert.java:647),at org.junit.Assert.assertEquals(Assert.java:633),at org.apache.hadoop.mapred.TestSkipBadRecords.testSkipBadRecords(TestSkipBadRecords.java:35),at org.apache.hadoop.mapred.TestSkipBadRecords.testSkipBadRecords$$CONFUZZ(TestSkipBadRecords.java),at java.base/java.lang.reflect.Method.invoke(Method.java:566),at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59),at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12),at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65),at edu.berkeley.cs.jqf.fuzz.guidance.Guidance.run(Guidance.java:222),at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),at org.junit.runners.ParentRunner.run(ParentRunner.java:413),at org.junit.runner.JUnitCore.run(JUnitCore.java:137),at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:36),	REPRODUCIBLE	{'mapreduce.task.skip.start.attempts': '17872'}	["mapreduce.task.skip.start.attempts"]	None	None	None	/home/ctestfuzz/fuzz-hadoop/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/target/meringue/org.apache.hadoop.mapred.TestSkipBadRecords/testSkipBadRecords/campaign/failures/debug_000000	['debug_000000']\n"]																																																																																																																																																																																																																																																																																																																																																																																												
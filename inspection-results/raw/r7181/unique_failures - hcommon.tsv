note	bugid	status	times	testName	failure	failureMessage	stackTrace	reproStatus	replayedFailure	replayedErrorMessage	replayedStackTrace	replayedFile	minConfig	debugFiles																																																																																																																																																																																																																	
			6	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testInternalGetAllStoragePolicies	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-1022502820	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testInternalGetAllStoragePolicies/campaign/failures/debug_000000	{"file.bytes-per-checksum": "363607164"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testConfLinkSlash	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-1052192289	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testConfLinkSlash/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1314745511"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testCreateNonRecursive	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-908345595	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testCreateNonRecursive/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1330728477"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testRenameAcrossMounts2	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-216040175	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testRenameAcrossMounts2/campaign/failures/debug_000001	{"file.bytes-per-checksum": "930432713"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testRenameAcrossMounts1	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-247277956	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testRenameAcrossMounts1/campaign/failures/debug_000000	{"file.bytes-per-checksum": "449743260"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testInternalGetAllStoragePolicies	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-382997163	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testInternalGetAllStoragePolicies/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1389100525"}	["debug_000001"]																																																																																																																																																										
	Bug-2	Repeated	17	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testInternalGetAllStoragePolicies	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testInternalGetAllStoragePolicies/campaign/failures/debug_000002	{"file.bytes-per-checksum": "2142553805"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testReadFullyZeroByteFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testReadFullyZeroByteFile/campaign/failures/debug_000000	{"file.bytes-per-checksum": "707704759"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testRenameDirectoryAsNonExistentDirectory	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.doTestRenameDirectoryAsNonExistentDirectory(FSMainOperationsBaseTest.java:995), org.apache.hadoop.fs.FSMainOperationsBaseTest.testRenameDirectoryAsNonExistentDirectory(FSMainOperationsBaseTest.java:984), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testRenameDirectoryAsNonExistentDirectory$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testRenameDirectoryAsNonExistentDirectory/campaign/failures/debug_000003	{"file.bytes-per-checksum": "2147417854"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestViewFsTrash#testTrash	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemTestHelper.writeFile(FileSystemTestHelper.java:190), org.apache.hadoop.fs.TestTrash.trashShell(TestTrash.java:161), org.apache.hadoop.fs.viewfs.TestViewFsTrash.testTrash(TestViewFsTrash.java:65), org.apache.hadoop.fs.viewfs.TestViewFsTrash.testTrash$$CONFUZZ(TestViewFsTrash.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsTrash/testTrash/campaign/failures/debug_000001	{"file.bytes-per-checksum": "2147483390"}	["debug_000001"]	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testWriteInNonExistentDirectory	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteInNonExistentDirectory(FSMainOperationsBaseTest.java:739), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testWriteInNonExistentDirectory$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testWriteInNonExistentDirectory/campaign/failures/debug_000002	{"file.bytes-per-checksum": "2139291390"}	["debug_000002"]	org.apache.hadoop.fs.TestChecksumFileSystem#testRenameFileIntoDir	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemTestHelper.writeFile(FileSystemTestHelper.java:190), org.apache.hadoop.fs.TestChecksumFileSystem.verifyRename(TestChecksumFileSystem.java:299), org.apache.hadoop.fs.TestChecksumFileSystem.testRenameFileIntoDir(TestChecksumFileSystem.java:252), org.apache.hadoop.fs.TestChecksumFileSystem.testRenameFileIntoDir$$CONFUZZ(TestChecksumFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestChecksumFileSystem/testRenameFileIntoDir/campaign/failures/debug_000002	{"file.bytes-per-checksum": "715375035"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testGetBlockLocations	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testGetBlockLocations/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1667147502"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testReadFullyPastEOFZeroByteFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testReadFullyPastEOFZeroByteFile/campaign/failures/debug_000000	{"file.bytes-per-checksum": "2140110591"}	["debug_000000"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameFileUnderFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractRenameTest.expectRenameUnderFileFails(AbstractContractRenameTest.java:335), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameFileUnderFile(AbstractContractRenameTest.java:311), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename.testRenameFileUnderFile$$CONFUZZ(TestLocalFSContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameFileUnderFile/campaign/failures/debug_000001	{"file.bytes-per-checksum": "714893822"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestVLong#testVLong5Bytes	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestVLong.writeAndVerify(TestVLong.java:82), org.apache.hadoop.io.file.tfile.TestVLong.testVLong5Bytes(TestVLong.java:121), org.apache.hadoop.io.file.tfile.TestVLong.testVLong5Bytes$$CONFUZZ(TestVLong.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestVLong/testVLong5Bytes/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1666456338"}	["debug_000001"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testRenameFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:165), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testRenameFile(TestSFTPFileSystem.java:299), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testRenameFile$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testRenameFile/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1189528281"}	["debug_000001"]	org.apache.hadoop.security.TestUserGroupInformation#testExternalTokenFiles	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:325), org.apache.hadoop.security.TestUserGroupInformation.testExternalTokenFiles(TestUserGroupInformation.java:1043), org.apache.hadoop.security.TestUserGroupInformation.testExternalTokenFiles$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testExternalTokenFiles/campaign/failures/debug_000000	{"file.bytes-per-checksum": "2147417854"}	["debug_000000"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameFileWithDestParentSymlink	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameFileWithDestParentSymlink(SymlinkBaseTest.java:1234), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testRenameFileWithDestParentSymlink(TestSymlinkLocalFSFileSystem.java:67), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testRenameFileWithDestParentSymlink$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameFileWithDestParentSymlink/campaign/failures/debug_000000	{"file.bytes-per-checksum": "708442782"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testInternalGetAllStoragePolicies	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testInternalGetAllStoragePolicies/campaign/failures/debug_000002	{"file.bytes-per-checksum": "2139586438"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testResolvePathMountPoints	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testResolvePathMountPoints/campaign/failures/debug_000001	{"file.bytes-per-checksum": "2141899163"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteTwoBlocks	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:685), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteTwoBlocks(FSMainOperationsBaseTest.java:675), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testWriteReadAndDeleteTwoBlocks$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteTwoBlocks/campaign/failures/debug_000002	{"file.bytes-per-checksum": "2139095042"}	["debug_000002"]	org.apache.hadoop.io.TestSequenceFile#testCreateWriterOnExistingFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.TestSequenceFile.testCreateWriterOnExistingFile(TestSequenceFile.java:643), org.apache.hadoop.io.TestSequenceFile.testCreateWriterOnExistingFile$$CONFUZZ(TestSequenceFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFile/testCreateWriterOnExistingFile/campaign/failures/debug_000000	{"file.bytes-per-checksum": "2142189469"}	["debug_000000"]																																	
	Bug-8	Repeated	8	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testInternalGetAllStoragePolicies	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testInternalGetAllStoragePolicies/campaign/failures/debug_000001	{"file.stream-buffer-size": "1218374078", "file.bytes-per-checksum": "1047943258"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testConfLinkSlash	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testConfLinkSlash/campaign/failures/debug_000002	{"file.bytes-per-checksum": "163252912", "file.stream-buffer-size": "1384556404"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testRenameAcrossMounts2	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testRenameAcrossMounts2/campaign/failures/debug_000002	{"file.stream-buffer-size": "1620008700", "file.bytes-per-checksum": "556396774"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureOneEntryKnownLength	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileStreams.setUp(TestTFileStreams.java:76), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.setUp(TestTFileNoneCodecsStreams.java:30), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureOneEntryKnownLength/campaign/failures/debug_000000	{"file.stream-buffer-size": "526377808", "file.bytes-per-checksum": "178432805"}	["debug_000000", "debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testSeekBigFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testSeekBigFile/campaign/failures/debug_000002	{"file.stream-buffer-size": "1405161074", "file.bytes-per-checksum": "551344631"}	["debug_000002"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameDirToSymlinkToFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameDirToSymlinkToFile(SymlinkBaseTest.java:913), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testRenameDirToSymlinkToFile$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameDirToSymlinkToFile/campaign/failures/debug_000000	{"file.stream-buffer-size": "1998642147", "file.bytes-per-checksum": "1013565405"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testFailureOneEntryKnownLength	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileStreams.setUp(TestTFileStreams.java:76), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testFailureOneEntryKnownLength/campaign/failures/debug_000000	{"file.bytes-per-checksum": "581891210", "file.stream-buffer-size": "1710779230"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testCloseChildrenFileSystem	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testCloseChildrenFileSystem/campaign/failures/debug_000002	{"file.bytes-per-checksum": "566185286", "file.stream-buffer-size": "1954742689"}	["debug_000002"]																																																																																																																																				
	Bug-50	Repeated	235	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testInternalGetAllStoragePolicies	java.lang.NegativeArraySizeException	-1409072701	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testInternalGetAllStoragePolicies/campaign/failures/debug_000004	{"file.bytes-per-checksum": "320654955"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestVLong#testVLongShort	java.lang.NegativeArraySizeException	-894615488	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestVLong.writeAndVerify(TestVLong.java:82), org.apache.hadoop.io.file.tfile.TestVLong.testVLongShort(TestVLong.java:99), org.apache.hadoop.io.file.tfile.TestVLong.testVLongShort$$CONFUZZ(TestVLong.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestVLong/testVLongShort/campaign/failures/debug_000001	{"file.bytes-per-checksum": "855035456"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testTwoDataEntries	java.lang.NegativeArraySizeException	-1651586494	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.setUp(TestTFileJClassComparatorByteArrays.java:41), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testTwoDataEntries/campaign/failures/debug_000000	{"file.bytes-per-checksum": "293708978"}	["debug_000000"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testCreatedFileIsVisibleOnFlush	java.lang.NegativeArraySizeException	-2058890845	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreatedFileIsVisibleOnFlush(AbstractContractCreateTest.java:241), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testCreatedFileIsVisibleOnFlush$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testCreatedFileIsVisibleOnFlush/campaign/failures/debug_000001	{"file.bytes-per-checksum": "248452939"}	["debug_000001"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testGetModifyTime	java.lang.NegativeArraySizeException	-868197113	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:165), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetModifyTime(TestSFTPFileSystem.java:356), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetModifyTime$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testGetModifyTime/campaign/failures/debug_000000	{"file.bytes-per-checksum": "857970831"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testOneEntryKnownLength	java.lang.NegativeArraySizeException	-1847536217	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileStreams.setUp(TestTFileStreams.java:76), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.setUp(TestTFileNoneCodecsStreams.java:30), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testOneEntryKnownLength/campaign/failures/debug_000001	{"file.bytes-per-checksum": "749155375"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameFileOverExistingFile	java.lang.NegativeArraySizeException	-468494701	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameFileOverExistingFile(AbstractContractRenameTest.java:100), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename.testRenameFileOverExistingFile$$CONFUZZ(TestLocalFSContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameFileOverExistingFile/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1856819387"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testRenameDirectoryAsNonExistentDirectory	java.lang.NegativeArraySizeException	-1579284331	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.doTestRenameDirectoryAsNonExistentDirectory(FSMainOperationsBaseTest.java:995), org.apache.hadoop.fs.FSMainOperationsBaseTest.testRenameDirectoryAsNonExistentDirectory(FSMainOperationsBaseTest.java:984), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testRenameDirectoryAsNonExistentDirectory$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testRenameDirectoryAsNonExistentDirectory/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1733398317"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestViewFsTrash#testTrash	java.lang.NegativeArraySizeException	-1941143291	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemTestHelper.writeFile(FileSystemTestHelper.java:190), org.apache.hadoop.fs.TestTrash.trashShell(TestTrash.java:161), org.apache.hadoop.fs.viewfs.TestViewFsTrash.testTrash(TestViewFsTrash.java:65), org.apache.hadoop.fs.viewfs.TestViewFsTrash.testTrash$$CONFUZZ(TestViewFsTrash.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsTrash/testTrash/campaign/failures/debug_000002	{"file.bytes-per-checksum": "738754589"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics#testWriteByteArrays	java.lang.NegativeArraySizeException	-1933347238	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.AbstractContractStreamIOStatisticsTest.testWriteByteArrays(AbstractContractStreamIOStatisticsTest.java:154), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics.testWriteByteArrays$$CONFUZZ(TestLocalFSContractStreamIOStatistics.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics/testWriteByteArrays/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1694057994"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testTwoDataEntries	java.lang.NegativeArraySizeException	-962412631	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.setUp(TestTFileNoneCodecsJClassComparatorByteArrays.java:37), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testTwoDataEntries/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1801939617"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testConfLinkSlash	java.lang.NegativeArraySizeException	-594889969	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testConfLinkSlash/campaign/failures/debug_000001	{"file.bytes-per-checksum": "411119703"}	["debug_000001"]	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteTwoBlocks	java.lang.NegativeArraySizeException	-644179117	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:685), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteTwoBlocks(FSMainOperationsBaseTest.java:675), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testWriteReadAndDeleteTwoBlocks$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteTwoBlocks/campaign/failures/debug_000003	{"file.bytes-per-checksum": "405643131"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testOutputStreamClosedTwice	java.lang.NegativeArraySizeException	-767189289	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FSMainOperationsBaseTest.testOutputStreamClosedTwice(FSMainOperationsBaseTest.java:1103), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testOutputStreamClosedTwice$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testOutputStreamClosedTwice/campaign/failures/debug_000004	{"file.bytes-per-checksum": "1346412511"}	["debug_000004"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testChildrenFileSystemLeak	java.lang.NegativeArraySizeException	-1485584837	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testChildrenFileSystemLeak/campaign/failures/debug_000004	{"file.bytes-per-checksum": "789372195"}	["debug_000004"]	org.apache.hadoop.fs.TestFsShellCopy#testMoveFileFromLocal	java.lang.NegativeArraySizeException	-1057056934	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestFsShellCopy.prepFiles(TestFsShellCopy.java:74), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testMoveFileFromLocal/campaign/failures/debug_000001	{"file.bytes-per-checksum": "359767818"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFile#testUnsortedTFileFeatures	java.lang.NegativeArraySizeException	-1985138517	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFile.createFSOutput(TestTFile.java:277), org.apache.hadoop.io.file.tfile.TestTFile.unsortedWithSomeCodec(TestTFile.java:339), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures(TestTFile.java:365), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures$$CONFUZZ(TestTFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFile/testUnsortedTFileFeatures/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1211084819"}	["debug_000003"]	org.apache.hadoop.util.TestGenericOptionsParser#testTokenCacheOption	java.lang.NegativeArraySizeException	-797508499	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:325), org.apache.hadoop.util.TestGenericOptionsParser.testTokenCacheOption(TestGenericOptionsParser.java:283), org.apache.hadoop.util.TestGenericOptionsParser.testTokenCacheOption$$CONFUZZ(TestGenericOptionsParser.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.util.TestGenericOptionsParser/testTokenCacheOption/campaign/failures/debug_000003	{"file.bytes-per-checksum": "388606533"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testOneDataEntry	java.lang.NegativeArraySizeException	-78795142	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.setUp(TestTFileJClassComparatorByteArrays.java:41), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testOneDataEntry/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1900119338"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testCreateFileUnderFile	java.lang.NegativeArraySizeException	-149096743	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractCreateTest.createFile(AbstractContractCreateTest.java:447), org.apache.hadoop.fs.contract.AbstractContractCreateTest.expectCreateUnderFileFails(AbstractContractCreateTest.java:413), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreateFileUnderFile(AbstractContractCreateTest.java:348), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testCreateFileUnderFile$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testCreateFileUnderFile/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1892308049"}	["debug_000001"]
			104	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testInternalGetAllStoragePolicies	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testInternalGetAllStoragePolicies/campaign/failures/debug_000003	{"file.bytes-per-checksum": "2030142880"}	["debug_000003"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testReadFullyZeroByteFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testReadFullyZeroByteFile/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1111443333"}	["debug_000002"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testGetModifyTime	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:165), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetModifyTime(TestSFTPFileSystem.java:356), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetModifyTime$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:165), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetModifyTime(TestSFTPFileSystem.java:356), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testGetModifyTime/campaign/failures/debug_000001	{"file.bytes-per-checksum": "2130640638"}	["debug_000001"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testGetModifyTime	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:165), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetModifyTime(TestSFTPFileSystem.java:356), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testGetModifyTime/campaign/failures/debug_000003	{"file.bytes-per-checksum": "2079223142"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testRenameDirectoryAsNonExistentDirectory	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.doTestRenameDirectoryAsNonExistentDirectory(FSMainOperationsBaseTest.java:995), org.apache.hadoop.fs.FSMainOperationsBaseTest.testRenameDirectoryAsNonExistentDirectory(FSMainOperationsBaseTest.java:984), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testRenameDirectoryAsNonExistentDirectory/campaign/failures/debug_000004	{"file.bytes-per-checksum": "2130640638"}	["debug_000004"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testConfLinkSlash	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testConfLinkSlash/campaign/failures/debug_000003	{"file.bytes-per-checksum": "648058184"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testChildrenFileSystemLeak	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testChildrenFileSystemLeak/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1601681292"}	["debug_000003"]	org.apache.hadoop.fs.TestFsShellCopy#testMoveFileFromLocal	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestFsShellCopy.prepFiles(TestFsShellCopy.java:74), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testMoveFileFromLocal/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1603875147"}	["debug_000003"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testFileStatusBlocksizeEmptyFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.touch(ContractTestUtils.java:672), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testFileStatusBlocksizeEmptyFile(AbstractContractCreateTest.java:302), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testFileStatusBlocksizeEmptyFile/campaign/failures/debug_000002	{"file.bytes-per-checksum": "2032998061"}	["debug_000002"]	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testDeleteRecursively	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testDeleteRecursively(FSMainOperationsBaseTest.java:759), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testDeleteRecursively/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1658282516"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays#testScan	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.setUp(TestTFileUnsortedByteArrays.java:72), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays/testScan/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1492535592"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureBadCompressionCodec	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.setUp(TestTFileNoneCodecsJClassComparatorByteArrays.java:37), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureBadCompressionCodec/campaign/failures/debug_000001	{"file.bytes-per-checksum": "704750675"}	["debug_000001"]	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testWriteInNonExistentDirectory	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteInNonExistentDirectory(FSMainOperationsBaseTest.java:739), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testWriteInNonExistentDirectory/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1091895558"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testFailureValueTooShort	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileStreams.setUp(TestTFileStreams.java:76), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testFailureValueTooShort/campaign/failures/debug_000003	{"file.bytes-per-checksum": "217900979"}	["debug_000003"]	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testRenameDirectoryAsNonEmptyDirectory	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testRenameDirectoryAsNonEmptyDirectory(FSMainOperationsBaseTest.java:1042), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testRenameDirectoryAsNonEmptyDirectory/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1936441959"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureWriteMetaBlocksWithSameName	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.setUp(TestTFileNoneCodecsByteArrays.java:29), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureWriteMetaBlocksWithSameName/campaign/failures/debug_000003	{"file.bytes-per-checksum": "2053171806"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testCreateNonRecursive	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testCreateNonRecursive/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1073907719"}	["debug_000002"]	org.apache.hadoop.fs.shell.TestPathData#testRelativeGlob	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1134), org.apache.hadoop.fs.FileSystem.createNewFile(FileSystem.java:1439), org.apache.hadoop.fs.shell.TestPathData.initialize(TestPathData.java:61), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestPathData/testRelativeGlob/campaign/failures/debug_000003	{"file.bytes-per-checksum": "2051176185"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureKeyTooShort	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileStreams.setUp(TestTFileStreams.java:76), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.setUp(TestTFileNoneCodecsStreams.java:30), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureKeyTooShort/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1540309817"}	["debug_000001"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameLinkTarget	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameLinkTarget(SymlinkBaseTest.java:1209), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameLinkTarget/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1505508381"}	["debug_000002"]
	Bug-7	Repeated	25	org.apache.hadoop.io.file.tfile.TestVLong#testVLongShort	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestVLong.writeAndVerify(TestVLong.java:82), org.apache.hadoop.io.file.tfile.TestVLong.testVLongShort(TestVLong.java:99), org.apache.hadoop.io.file.tfile.TestVLong.testVLongShort$$CONFUZZ(TestVLong.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestVLong/testVLongShort/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1549390571", "io.file.buffer.size": "1436225330"}	["debug_000000"]	org.apache.hadoop.fs.TestFsShellCopy#testMoveFileFromLocal	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestFsShellCopy.prepFiles(TestFsShellCopy.java:74), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testMoveFileFromLocal/campaign/failures/debug_000002	{"io.file.buffer.size": "651831545", "file.bytes-per-checksum": "1045483065"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractMkdir#testMkdirOverParentFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractMkdirTest.testMkdirOverParentFile(AbstractContractMkdirTest.java:92), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractMkdir.testMkdirOverParentFile$$CONFUZZ(TestLocalFSContractMkdir.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractMkdir/testMkdirOverParentFile/campaign/failures/debug_000000	{"io.file.buffer.size": "1274042731", "file.bytes-per-checksum": "978132028"}	["debug_000000"]	org.apache.hadoop.fs.TestFsShellCopy#testMoveDirFromLocalDestExists	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestFsShellCopy.prepFiles(TestFsShellCopy.java:74), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testMoveDirFromLocalDestExists/campaign/failures/debug_000000	{"io.file.buffer.size": "1927003123", "file.bytes-per-checksum": "2012684450"}	["debug_000000"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics#testWriteSingleByte	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.AbstractContractStreamIOStatisticsTest.testWriteSingleByte(AbstractContractStreamIOStatisticsTest.java:126), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics.testWriteSingleByte$$CONFUZZ(TestLocalFSContractStreamIOStatistics.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics/testWriteSingleByte/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1143659767", "io.file.buffer.size": "859795909"}	["debug_000000"]	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testSourceIsFileAndDestinationIsNonExistentDirectory	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:418), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:341), org.apache.hadoop.fs.LocalFileSystem.copyFromLocalFile(LocalFileSystem.java:82), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2411), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testSourceIsFileAndDestinationIsNonExistentDirectory(AbstractContractCopyFromLocalTest.java:150), org.apache.hadoop.fs.TestLocalFSCopyFromLocal.testSourceIsFileAndDestinationIsNonExistentDirectory$$CONFUZZ(TestLocalFSCopyFromLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testSourceIsFileAndDestinationIsNonExistentDirectory/campaign/failures/debug_000000	{"io.file.buffer.size": "458238468", "file.bytes-per-checksum": "534215489"}	["debug_000000"]	org.apache.hadoop.security.alias.TestCredShell#testCredentialSuccessfulLifecycle	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:728), org.apache.hadoop.security.alias.KeyStoreProvider.getOutputStreamForKeystore(KeyStoreProvider.java:54), org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.flush(AbstractJavaKeyStoreProvider.java:292), org.apache.hadoop.security.alias.CredentialShell$CreateCommand.execute(CredentialShell.java:447), org.apache.hadoop.tools.CommandShell.run(CommandShell.java:72), org.apache.hadoop.security.alias.TestCredShell.testCredentialSuccessfulLifecycle(TestCredShell.java:69), org.apache.hadoop.security.alias.TestCredShell.testCredentialSuccessfulLifecycle$$CONFUZZ(TestCredShell.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.alias.TestCredShell/testCredentialSuccessfulLifecycle/campaign/failures/debug_000002	{"file.bytes-per-checksum": "132683616", "io.file.buffer.size": "1665090051"}	["debug_000002"]	org.apache.hadoop.fs.TestHarFileSystemBasics#testHarFsWithoutAuthority	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1134), org.apache.hadoop.fs.FileSystem.createNewFile(FileSystem.java:1439), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:84), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testHarFsWithoutAuthority/campaign/failures/debug_000002	{"file.bytes-per-checksum": "205466377", "io.file.buffer.size": "153706050"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestVLong#testVLong4Bytes	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestVLong.writeAndVerify(TestVLong.java:82), org.apache.hadoop.io.file.tfile.TestVLong.testVLong4Bytes(TestVLong.java:114), org.apache.hadoop.io.file.tfile.TestVLong.testVLong4Bytes$$CONFUZZ(TestVLong.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestVLong/testVLong4Bytes/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1514602991", "io.file.buffer.size": "2014886019"}	["debug_000001"]	org.apache.hadoop.fs.TestFsShellCopy#testCopyNoParent	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestFsShellCopy.prepFiles(TestFsShellCopy.java:74), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testCopyNoParent/campaign/failures/debug_000000	{"io.file.buffer.size": "1692300214", "file.bytes-per-checksum": "631402339"}	["debug_000000", "debug_000001"]	org.apache.hadoop.fs.TestFileUtil#testWriteStringFileSystem	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.createNonRecursive(ChecksumFileSystem.java:565), org.apache.hadoop.fs.FileSystem$FileSystemDataOutputStreamBuilder.build(FileSystem.java:4523), org.apache.hadoop.fs.FileUtil.write(FileUtil.java:1824), org.apache.hadoop.fs.TestFileUtil.testWriteStringFileSystem(TestFileUtil.java:1599), org.apache.hadoop.fs.TestFileUtil.testWriteStringFileSystem$$CONFUZZ(TestFileUtil.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFileUtil/testWriteStringFileSystem/campaign/failures/debug_000000	{"file.bytes-per-checksum": "536132275", "io.file.buffer.size": "1092860732"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureKeyLongerThan64K	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileStreams.setUp(TestTFileStreams.java:76), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.setUp(TestTFileNoneCodecsStreams.java:30), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureKeyLongerThan64K/campaign/failures/debug_000000	{"io.file.buffer.size": "710301481", "file.bytes-per-checksum": "617357844"}	["debug_000000"]	org.apache.hadoop.fs.TestPath#testGlobEscapeStatus	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestPath.testGlobEscapeStatus(TestPath.java:432), org.apache.hadoop.fs.TestPath.testGlobEscapeStatus$$CONFUZZ(TestPath.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestPath/testGlobEscapeStatus/campaign/failures/debug_000000	{"file.bytes-per-checksum": "55369220", "io.file.buffer.size": "1734823760"}	["debug_000000"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameSymlinkToExistingFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameSymlinkToExistingFile(SymlinkBaseTest.java:1034), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testRenameSymlinkToExistingFile$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameSymlinkToExistingFile/campaign/failures/debug_000001	{"file.bytes-per-checksum": "646074365", "io.file.buffer.size": "1070311805"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameFileUnderFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractRenameTest.expectRenameUnderFileFails(AbstractContractRenameTest.java:335), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameFileUnderFile(AbstractContractRenameTest.java:311), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename.testRenameFileUnderFile$$CONFUZZ(TestLocalFSContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameFileUnderFile/campaign/failures/debug_000000	{"file.bytes-per-checksum": "652467437", "io.file.buffer.size": "593551643"}	["debug_000000"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameFileViaSymlink	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameFileViaSymlink(SymlinkBaseTest.java:821), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testRenameFileViaSymlink$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameFileViaSymlink/campaign/failures/debug_000001	{"io.file.buffer.size": "1511932707", "file.bytes-per-checksum": "614159479"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestVLong#testVLong5Bytes	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestVLong.writeAndVerify(TestVLong.java:82), org.apache.hadoop.io.file.tfile.TestVLong.testVLong5Bytes(TestVLong.java:121), org.apache.hadoop.io.file.tfile.TestVLong.testVLong5Bytes$$CONFUZZ(TestVLong.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestVLong/testVLong5Bytes/campaign/failures/debug_000002	{"file.bytes-per-checksum": "2135394062", "io.file.buffer.size": "663543326"}	["debug_000002"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testCreateFileViaSymlink	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testCreateFileViaSymlink(SymlinkBaseTest.java:626), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testCreateFileViaSymlink$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testCreateFileViaSymlink/campaign/failures/debug_000002	{"file.bytes-per-checksum": "2028926680", "io.file.buffer.size": "971214069"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testThreeBlocks	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.setUp(TestTFileNoneCodecsByteArrays.java:29), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testThreeBlocks/campaign/failures/debug_000001	{"io.file.buffer.size": "1302896190", "file.bytes-per-checksum": "1516204390"}	["debug_000001"]	org.apache.hadoop.security.alias.TestCredShell#testPromptForCredential	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:728), org.apache.hadoop.security.alias.KeyStoreProvider.getOutputStreamForKeystore(KeyStoreProvider.java:54), org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.flush(AbstractJavaKeyStoreProvider.java:292), org.apache.hadoop.security.alias.CredentialShell$CreateCommand.execute(CredentialShell.java:447), org.apache.hadoop.tools.CommandShell.run(CommandShell.java:72), org.apache.hadoop.security.alias.TestCredShell.testPromptForCredential(TestCredShell.java:179), org.apache.hadoop.security.alias.TestCredShell.testPromptForCredential$$CONFUZZ(TestCredShell.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.alias.TestCredShell/testPromptForCredential/campaign/failures/debug_000000	{"io.file.buffer.size": "312560901", "file.bytes-per-checksum": "188384151"}	["debug_000000"]
			1	org.apache.hadoop.io.file.tfile.TestVLong#testVLongShort	java.lang.OutOfMemoryError	Java heap space		FLAKY	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestVLong.writeAndVerify(TestVLong.java:87), org.apache.hadoop.io.file.tfile.TestVLong.testVLongShort(TestVLong.java:99), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestVLong/testVLongShort/campaign/failures/debug_000002	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "1805480288", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "67s", "file.stream-buffer-size": "830610135", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "true", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "949833054", "fs.creation.parallel.count": "558", "file.bytes-per-checksum": "571303927", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "378222777", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "14780", "fs.local.block.size": "328050651", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "32532", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "1096423571", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "127"}	["debug_000002"]																																																																																																																																																																																																																	
		FP	21	org.apache.hadoop.http.TestHttpServerLifecycle#testStartedServerIsAlive	java.lang.IllegalStateException	Insufficient configured threads: required=769 < max=200 for QueuedThreadPool[qtp600252712]@23c72128{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@4c8abec7{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerIsAlive(TestHttpServerLifecycle.java:66), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerIsAlive$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStartedServerIsAlive/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "767"}	["debug_000000"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testKeyStoreSetupWithoutPassword	java.lang.IllegalStateException	Insufficient configured threads: required=768 < max=10 for QueuedThreadPool[qtp1505720819]@59bf79f3{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@2df40273{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutPassword(TestSSLHttpServerConfigs.java:252), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutPassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testKeyStoreSetupWithoutPassword/campaign/failures/debug_000002	{"hadoop.http.acceptor.count": "767"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServer#testHttpResponseOverrideDefaultHeaders	java.lang.IllegalStateException	Insufficient configured threads: required=431 < max=10 for QueuedThreadPool[qtp1164139233]@45635ae1{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@32f14274{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResponseOverrideDefaultHeaders/campaign/failures/debug_000001	{"hadoop.http.acceptor.count": "430"}	["debug_000001"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithoutKeyStorePassword	java.lang.IllegalStateException	Insufficient configured threads: required=9072 < max=10 for QueuedThreadPool[qtp516515090]@1ec96512{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@19412eef{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStorePassword(TestSSLHttpServerConfigs.java:154), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStorePassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithoutKeyStorePassword/campaign/failures/debug_000001	{"hadoop.http.acceptor.count": "9071"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServerLifecycle#testStoppedServerIsNotAlive	java.lang.IllegalStateException	Insufficient configured threads: required=966 < max=200 for QueuedThreadPool[qtp1147820709]@446a5aa5{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@1e01b195{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.HttpServerFunctionalTest.createAndStartTestServer(HttpServerFunctionalTest.java:224), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppedServerIsNotAlive(TestHttpServerLifecycle.java:109), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppedServerIsNotAlive$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStoppedServerIsNotAlive/campaign/failures/debug_000002	{"hadoop.http.acceptor.count": "964"}	["debug_000002"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testKeyStoreSetupWithoutKeyStorePassword	java.lang.IllegalStateException	Insufficient configured threads: required=704 < max=10 for QueuedThreadPool[qtp2065199032]@7b186fb8{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@5d6cac57{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutKeyStorePassword(TestSSLHttpServerConfigs.java:230), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutKeyStorePassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testKeyStoreSetupWithoutKeyStorePassword/campaign/failures/debug_000002	{"hadoop.http.acceptor.count": "703"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServer#testPortRanges	java.lang.IllegalStateException	Insufficient configured threads: required=17169 < max=10 for QueuedThreadPool[qtp939523827]@37fffef3{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@5972e3a{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testPortRanges/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "17168"}	["debug_000000"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetup	java.lang.IllegalStateException	Insufficient configured threads: required=26802 < max=10 for QueuedThreadPool[qtp1208826944]@480d3c40{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@137a70f1{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetup(TestSSLHttpServerConfigs.java:142), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetup$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetup/campaign/failures/debug_000001	{"hadoop.http.acceptor.count": "26801"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServer#testDisabledAuthorizationOfDefaultServlets	java.lang.IllegalStateException	Insufficient configured threads: required=821 < max=10 for QueuedThreadPool[qtp579161899]@22854f2b{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@186d6033{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testDisabledAuthorizationOfDefaultServlets/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "820"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServerLifecycle#testStoppingTwiceServerIsAllowed	java.lang.IllegalStateException	Insufficient configured threads: required=6826 < max=200 for QueuedThreadPool[qtp1859329079]@6ed31c37{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@f502ff4{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.HttpServerFunctionalTest.createAndStartTestServer(HttpServerFunctionalTest.java:224), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppingTwiceServerIsAllowed(TestHttpServerLifecycle.java:121), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppingTwiceServerIsAllowed$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStoppingTwiceServerIsAllowed/campaign/failures/debug_000005	{"hadoop.http.acceptor.count": "6824"}	["debug_000005"]	org.apache.hadoop.http.TestHttpServer#testBindAddress	java.lang.IllegalStateException	Insufficient configured threads: required=11295 < max=10 for QueuedThreadPool[qtp1753178789]@687f62a5{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@58b5d5fc{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testBindAddress/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "11294"}	["debug_000000"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithoutKeyStoreKeyPassword	java.lang.IllegalStateException	Insufficient configured threads: required=32344 < max=10 for QueuedThreadPool[qtp1962233742]@74f54f8e{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@5dd79a57{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStoreKeyPassword(TestSSLHttpServerConfigs.java:160), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStoreKeyPassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithoutKeyStoreKeyPassword/campaign/failures/debug_000002	{"hadoop.http.acceptor.count": "32343"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServerLifecycle#testStartedServerWithRequestLog	java.lang.IllegalStateException	Insufficient configured threads: required=24412 < max=23364 for QueuedThreadPool[qtp839624607]@320ba79f{STARTED,8<=8<=23364,i=8,r=-1,q=0}[ReservedThreadExecutor@6a3e633a{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerWithRequestLog(TestHttpServerLifecycle.java:86), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerWithRequestLog$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStartedServerWithRequestLog/campaign/failures/debug_000001	{"hadoop.http.acceptor.count": "24410"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsXFrameOptions	java.lang.IllegalStateException	Insufficient configured threads: required=16 < max=10 for QueuedThreadPool[qtp1037463541]@3dd66ff5{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@77fceac6{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsXFrameOptions/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "15"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseDoesNotContainXFrameOptions	java.lang.IllegalStateException	Insufficient configured threads: required=6424140 < max=10 for QueuedThreadPool[qtp873636861]@3412a3fd{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@756200d1{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseDoesNotContainXFrameOptions/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "6424139"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServerWithSpnego#testAuthenticationWithProxyUser	java.lang.IllegalStateException	Insufficient configured threads: required=997 < max=200 for QueuedThreadPool[qtp1183302020]@4687c184{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@1b901f7b{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser(TestHttpServerWithSpnego.java:136), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser$$CONFUZZ(TestHttpServerWithSpnego.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerWithSpnego/testAuthenticationWithProxyUser/campaign/failures/debug_000001	{"hadoop.http.acceptor.count": "995"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServer#testBacklogSize	java.lang.IllegalStateException	Insufficient configured threads: required=20272 < max=10 for QueuedThreadPool[qtp456897159]@1b3bb287{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@5b74902c{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testBacklogSize/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "20271"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServer#testHasAdministratorAccess	java.lang.IllegalStateException	Insufficient configured threads: required=268435487 < max=10 for QueuedThreadPool[qtp330045015]@13ac1657{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@7959fbe3{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHasAdministratorAccess/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "268435486"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServerLogs#testLogsEnabled	java.lang.IllegalStateException	Insufficient configured threads: required=16806 < max=22 for QueuedThreadPool[qtp807240950]@301d84f6{STARTED,8<=8<=22,i=8,r=-1,q=0}[ReservedThreadExecutor@611587f7{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServerLogs.startServer(TestHttpServerLogs.java:46), org.apache.hadoop.http.TestHttpServerLogs.testLogsEnabled(TestHttpServerLogs.java:63), org.apache.hadoop.http.TestHttpServerLogs.testLogsEnabled$$CONFUZZ(TestHttpServerLogs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLogs/testLogsEnabled/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "16804"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsDeny	java.lang.IllegalStateException	Insufficient configured threads: required=48 < max=10 for QueuedThreadPool[qtp169710187]@a1d926b{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@1fa58a48{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsDeny/campaign/failures/debug_000002	{"hadoop.http.acceptor.count": "47"}	["debug_000002"]
			1	org.apache.hadoop.http.TestHttpServerLifecycle#testStartedServerIsAlive	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:158), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:77), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerIsAlive(TestHttpServerLifecycle.java:64), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerIsAlive$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	DIFFERENT	java.lang.IllegalStateException	Insufficient configured threads: required=58753153 < max=200 for QueuedThreadPool[qtp292917034]@11758f2a{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@4cc8eb05{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:320), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerIsAlive(TestHttpServerLifecycle.java:66), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStartedServerIsAlive/campaign/failures/debug_000002	{"hadoop.http.acceptor.count": "58753151"}	["debug_000002"]																																																																																																																																																																																																																	
		FP	22	org.apache.hadoop.http.TestHttpServerLifecycle#testStartedServerIsAlive	java.lang.IllegalStateException	Insufficient configured threads: required=422912576 < max=200 for QueuedThreadPool[qtp2059190490]@7abcc0da{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@5ee0cf64{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerIsAlive(TestHttpServerLifecycle.java:66), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerIsAlive$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStartedServerIsAlive/campaign/failures/debug_000001	{"hadoop.http.selector.count": "422912573"}	["debug_000001"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testKeyStoreSetupWithoutPassword	java.lang.IllegalStateException	Insufficient configured threads: required=16744193 < max=10 for QueuedThreadPool[qtp626010908]@25502b1c{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@77afdbc5{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutPassword(TestSSLHttpServerConfigs.java:252), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutPassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testKeyStoreSetupWithoutPassword/campaign/failures/debug_000000	{"hadoop.http.selector.count": "16744191"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServer#testHttpResponseOverrideDefaultHeaders	java.lang.IllegalStateException	Insufficient configured threads: required=7982 < max=10 for QueuedThreadPool[qtp1907565575]@71b32407{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@102f3f05{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResponseOverrideDefaultHeaders/campaign/failures/debug_000005	{"hadoop.http.selector.count": "7980"}	["debug_000005"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithoutKeyStorePassword	java.lang.IllegalStateException	Insufficient configured threads: required=1581 < max=10 for QueuedThreadPool[qtp1327733366]@4f239a76{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@34f2d3a6{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStorePassword(TestSSLHttpServerConfigs.java:154), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStorePassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithoutKeyStorePassword/campaign/failures/debug_000000	{"hadoop.http.selector.count": "1579"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServerLifecycle#testStoppedServerIsNotAlive	java.lang.IllegalStateException	Insufficient configured threads: required=48490 < max=30450 for QueuedThreadPool[qtp1085622114]@40b54762{STARTED,8<=8<=30450,i=8,r=-1,q=0}[ReservedThreadExecutor@60e67c06{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.HttpServerFunctionalTest.createAndStartTestServer(HttpServerFunctionalTest.java:224), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppedServerIsNotAlive(TestHttpServerLifecycle.java:109), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppedServerIsNotAlive$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStoppedServerIsNotAlive/campaign/failures/debug_000000	{"hadoop.http.selector.count": "25504"}	["debug_000000"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testKeyStoreSetupWithoutKeyStorePassword	java.lang.IllegalStateException	Insufficient configured threads: required=1210 < max=10 for QueuedThreadPool[qtp2138211677]@7f72855d{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@66c88fce{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutKeyStorePassword(TestSSLHttpServerConfigs.java:230), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutKeyStorePassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testKeyStoreSetupWithoutKeyStorePassword/campaign/failures/debug_000000	{"hadoop.http.selector.count": "1208"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServer#testPortRanges	java.lang.IllegalStateException	Insufficient configured threads: required=34113281 < max=10 for QueuedThreadPool[qtp715038783]@2a9ea03f{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@4add4dff{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testPortRanges/campaign/failures/debug_000004	{"hadoop.http.selector.count": "34113279"}	["debug_000004"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetup	java.lang.IllegalStateException	Insufficient configured threads: required=32708 < max=10 for QueuedThreadPool[qtp1297151618]@4d50f682{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@6b8683b8{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetup(TestSSLHttpServerConfigs.java:142), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetup$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetup/campaign/failures/debug_000000	{"hadoop.http.selector.count": "32706"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServer#testDisabledAuthorizationOfDefaultServlets	java.lang.IllegalStateException	Insufficient configured threads: required=641 < max=10 for QueuedThreadPool[qtp206016078]@c478e4e{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@234bfc8c{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testDisabledAuthorizationOfDefaultServlets/campaign/failures/debug_000001	{"hadoop.http.selector.count": "639"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServerLifecycle#testStoppingTwiceServerIsAllowed	java.lang.IllegalStateException	Insufficient configured threads: required=428410809 < max=200 for QueuedThreadPool[qtp1023062848]@3cfab340{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@4790b897{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.HttpServerFunctionalTest.createAndStartTestServer(HttpServerFunctionalTest.java:224), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppingTwiceServerIsAllowed(TestHttpServerLifecycle.java:121), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppingTwiceServerIsAllowed$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStoppingTwiceServerIsAllowed/campaign/failures/debug_000001	{"hadoop.http.selector.count": "428410806"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServer#testBindAddress	java.lang.IllegalStateException	Insufficient configured threads: required=12070 < max=10 for QueuedThreadPool[qtp1244242406]@4a29a1e6{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@7eb774c3{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testBindAddress/campaign/failures/debug_000002	{"hadoop.http.selector.count": "12068"}	["debug_000002"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithoutKeyStoreKeyPassword	java.lang.IllegalStateException	Insufficient configured threads: required=81 < max=10 for QueuedThreadPool[qtp902315094]@35c83c56{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@7212d3df{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStoreKeyPassword(TestSSLHttpServerConfigs.java:160), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStoreKeyPassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithoutKeyStoreKeyPassword/campaign/failures/debug_000001	{"hadoop.http.selector.count": "79"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServerLifecycle#testStartedServerWithRequestLog	java.lang.IllegalStateException	Insufficient configured threads: required=1236 < max=200 for QueuedThreadPool[qtp175825728]@a7ae340{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@7404aff2{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerWithRequestLog(TestHttpServerLifecycle.java:86), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerWithRequestLog$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStartedServerWithRequestLog/campaign/failures/debug_000000	{"hadoop.http.selector.count": "1056"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsXFrameOptions	java.lang.IllegalStateException	Insufficient configured threads: required=29603 < max=10 for QueuedThreadPool[qtp2129236490]@7ee9920a{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@1b984ba5{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsXFrameOptions/campaign/failures/debug_000003	{"hadoop.http.selector.count": "29601"}	["debug_000003"]	org.apache.hadoop.http.TestGlobalFilter#testServletFilter	java.lang.IllegalStateException	Insufficient configured threads: required=4585 < max=200 for QueuedThreadPool[qtp1856885570]@6eadd342{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@c7269ad{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestGlobalFilter.testServletFilter(TestGlobalFilter.java:112), org.apache.hadoop.http.TestGlobalFilter.testServletFilter$$CONFUZZ(TestGlobalFilter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestGlobalFilter/testServletFilter/campaign/failures/debug_000001	{"hadoop.http.selector.count": "4582"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseDoesNotContainXFrameOptions	java.lang.IllegalStateException	Insufficient configured threads: required=998 < max=10 for QueuedThreadPool[qtp876029877]@343727b5{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@3661b732{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseDoesNotContainXFrameOptions/campaign/failures/debug_000001	{"hadoop.http.selector.count": "996"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServerWithSpnego#testAuthenticationWithProxyUser	java.lang.IllegalStateException	Insufficient configured threads: required=1395 < max=200 for QueuedThreadPool[qtp626652764]@2559f65c{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@66b3eab0{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser(TestHttpServerWithSpnego.java:136), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser$$CONFUZZ(TestHttpServerWithSpnego.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerWithSpnego/testAuthenticationWithProxyUser/campaign/failures/debug_000002	{"hadoop.http.selector.count": "1392"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServer#testBacklogSize	java.lang.IllegalStateException	Insufficient configured threads: required=290 < max=10 for QueuedThreadPool[qtp210158726]@c86c486{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@64a8d575{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testBacklogSize/campaign/failures/debug_000002	{"hadoop.http.selector.count": "288"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServer#testHasAdministratorAccess	java.lang.IllegalStateException	Insufficient configured threads: required=537 < max=10 for QueuedThreadPool[qtp427033987]@19740583{STARTED,8<=8<=10,i=8,r=-1,q=0}[ReservedThreadExecutor@6019ce4b{s=0/1,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHasAdministratorAccess/campaign/failures/debug_000001	{"hadoop.http.selector.count": "535"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServerLogs#testLogsEnabled	java.lang.IllegalStateException	Insufficient configured threads: required=13021 < max=200 for QueuedThreadPool[qtp1554565380]@5ca8c904{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@417751d3{s=0/2,p=0}]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseTo(ThreadPoolBudget.java:141), org.eclipse.jetty.util.thread.ThreadPoolBudget.leaseFrom(ThreadPoolBudget.java:191), org.eclipse.jetty.io.SelectorManager.doStart(SelectorManager.java:255), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.util.component.ContainerLifeCycle.start(ContainerLifeCycle.java:169), org.eclipse.jetty.util.component.ContainerLifeCycle.doStart(ContainerLifeCycle.java:110), org.eclipse.jetty.server.AbstractConnector.doStart(AbstractConnector.java:321), org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:81), org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:234), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.eclipse.jetty.server.Server.doStart(Server.java:401), org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:73), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1276), org.apache.hadoop.http.TestHttpServerLogs.startServer(TestHttpServerLogs.java:46), org.apache.hadoop.http.TestHttpServerLogs.testLogsEnabled(TestHttpServerLogs.java:63), org.apache.hadoop.http.TestHttpServerLogs.testLogsEnabled$$CONFUZZ(TestHttpServerLogs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLogs/testLogsEnabled/campaign/failures/debug_000003	{"hadoop.http.selector.count": "13018"}	["debug_000003"]
			1	org.apache.hadoop.http.TestHttpServerLifecycle#testStartedServerIsAlive	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerIsAlive(TestHttpServerLifecycle.java:66), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerIsAlive$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStartedServerIsAlive/campaign/failures/debug_000004	{"hadoop.security.token.service.use_ip": "false", "hadoop.http.authentication.token.validity": "33055", "hadoop.prometheus.endpoint.enabled": "true", "hadoop.http.acceptor.count": "111", "hadoop.http.authentication.simple.anonymous.allowed": "false", "hadoop.http.authentication.type": "simple", "hadoop.http.staticuser.user": "uhJTvXQfIMuUTvEkPaCs.fXlZzlWTtHkfmGYd.jH.kBAdLPwOtBhxUSlmOJUJmEdqADikiiaAgZElUNmcLHsSjerTJqnACAZKLOGYnLVeroSvROhqowajHqkwIsSfNQsenvDiEPbq.uvcGftqQuvHNmaZDDhPXGGTlqFVsxKcmDaXYTxFMXgGsfOFHDNWPqKpjWFGsxEgXPLETPPrKIMtOFktu.VCRPGoPpe.ItzCWODYzTiswSbagvYBCWBmjmkDIGVybnthAcBmHKdnRgyXBFShqhmbvTOcqWRumbjOHGym.pZFZFBQzgJRWiEENk.llvfkoySFNa.IaHTqkHCrbcjEabppngVDNSGLafQqIlDZcMdGjIoOAcOvexXajZzBLLyPEzBEiLKAvGspkWYgMRQufImMWTIlG.cwhyXImFlVCCUixIIGE.fNPFFKnTERFHnOLTNHJZZhifpahRcXn.cDgGosblj.CPYybevypIYDnaCdYfyrTKzptIkmSMBQpsiEogoQYLqHVmFLaFJGdFczecUxnISKEbFWIpu.sUeprcVPEXyckovJkMJYPeRCMwCGEsfUvVgKNPdukZfmhMse.qeLhqL.WIcDTWBbcwZZZhHQoiAPIlboHMTfvXtLBZwVGGaoDjEqJSxJDUbokVEdcARnPqV.xRhNR.nXBEhdGfkVNSLUeLyiqEjbZiMPOqzlTqcDUtVLXAsHOkNTyRrPEyKfacySoSrMptJpyowbZEVEuGvtDQxDLpdcSnfeLPEbnwS.CDgGcvjUKUpeyHJPhksRhsnzADTQwZeCkNrOfOybEiCXTyfrkNsOyX.NloLKFYrSIORNvhOUaxqzxyPHmzIoCOoPYwFlGWAvqhtuILeZffmDdf.rpihCEYQSY.jxuKoqCgfG.JIIvhphHoJqEZSgCrIeRBQLiZEvFagELaKuenjXSKT.jWLGtnyPcfpeyjtRWHzkmjOOpdtdvgzcLQhNUprczPwjVDBudPZSVXGNejuFWTdfeDQwNRYiAkRcwhRUSRlXNzHUPqnNCKEZGn.PtCvSCILrXKxoxvXiOOlVXQHAomeoVoFzDZJNxuajly.haQwjXhkASGneoXFGhyJSUBGWpmfNHAkJWcrqlMwjgNFsJnSvhVtmQSqPWslAMVkSHPhUcyRoNXwdc.JRCNRTTOUm.AwopwYFHZpUPbPQyWKdcbGaayOvoGWlAWBtmyPShnjWzYVvFUTluVVwfQDsjFfcxWUIfS.QVfUvkBZxMPLPKAexjrEGGQGdzcUEzFSlQmTyphBNKNLBkAlhEnyPrWxuuktZXmdDkARvPATQbYD.bsSWpdZlzVuYuKXreuovbVVatDxGYuBLUhcqGjPXxpqPHODTisHsrRPA.ScvPlHrqaFyoeOVSfxzqUpEwRKMSBEckIQrSIleaAbepuGASSnPxsLCjlFFTfviFqlxHGOtsOvujA.vMX.kWqzKBvconAZranHywlafQBWRJOaq.CMCIzp.TDjNohttcIGuQYSodIOAHdXtBWXNnxUZYyNI.YDOuIFNbzFoLYgrZKQdrXIdodEwZA.YdPcaRUyaClYbEcwGLbGRkXJtJcmVWMeydcwIVjrODcKKWxGFKGQRDnACUApLuzkyDdZPKmmh.zzoWelXUFSeGtXADyWaOQjcTY.yDlVXUuAGfsvZTShjvRkvIvIPGoJvSfkOkrRIbtoLGzvXinwsOCYeqBwZuWzheIdtbkunFgknHaotdWEio.jquqIMNXZEZNUyeJEZefDi.NvWsmoDZNJgOAzcHqfkSNClSOn.PqOwJNRrbWw.VLOVHp.yygULwvevGCLeGJrOPeEIXYBnvrKUOfHdMAyIepETXeYkpghXaHZJnLayorcnqEqFBf.SdidNBdeSvvhorlkqLKEZUSKDPvaDfNdCSaFyfHkyQTFnabVqvfigiuOMNzH.HZCLakOwCyUwEydaqSYiHdUzPjCeMyuuYLHnMqXJmDgykNcdkZkaHIz.SSglhDenIsNMnnthuZFuaUqmsJLmXYTbcTVQTCnS.wSDanCibWbCsPQzxtzdsNyrdd.IBauGcOTUmWyGVKebVzFjsqeJJLSgQpJBFhKzTicvwsjgbOSkRalCIracmCTFTmGiqykNKNoLtFEVytfYcqhxXBNLzCgiHw.BFFfllztKjpy.dYpGehdTvMRJgPZffdrocKQWrbiGkkrBWTkTgYHIYXbgCdvZdKOAFFulBeOnb.rQfNTnFQNxviPKzkxjquHhiCZAC.rzEnYlEmgyAb.cgiZkxAvFReMydJWNjzHIYHdRKrJvvPcPHToBzpifvxzRFyY.QOjrhCDDBIQHOKYynIyrdTiKQFpIfhbT.CnoZdQopMjuruQLNCmoDDRBnenXJqwIVKXPaOMfRsfwnKfoAYLJBzSZhFnskZDCxgfMiiNECnM.LpOgBiveYMKgetOaZynNMAbKMyaLzdyEWlIQkGkfqT.QhrcETmoGzfLmtMsYFUJKnJVfoxfvZCsETPIHeTSHKBHALBRAgNZngZqpfuYTIGWNQIcfqOifVZa"}	["debug_000004"]																																																																																																																																																																																																																	
			15	org.apache.hadoop.http.TestHttpServerLifecycle#testStartedServerIsAlive	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:158), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:77), org.apache.hadoop.http.TestHttpServerLifecycle.testStartedServerIsAlive(TestHttpServerLifecycle.java:64), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStartedServerIsAlive/campaign/failures/debug_000003	{"hadoop.http.acceptor.count": "791626741"}	["debug_000003"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithNoKeyStorePassword	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithNoKeyStorePassword(TestSSLHttpServerConfigs.java:169), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithNoKeyStorePassword/campaign/failures/debug_000001	{"hadoop.http.acceptor.count": "2144782289"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServer#testHttpResponseOverrideDefaultHeaders	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResponseOverrideDefaultHeaders/campaign/failures/debug_000004	{"hadoop.http.acceptor.count": "1197151291"}	["debug_000004"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithoutKeyStorePassword	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStorePassword(TestSSLHttpServerConfigs.java:154), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithoutKeyStorePassword/campaign/failures/debug_000004	{"hadoop.http.acceptor.count": "980639948"}	["debug_000004"]	org.apache.hadoop.http.TestHttpServerLifecycle#testCreatedServerIsNotAlive	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:158), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:77), org.apache.hadoop.http.TestHttpServerLifecycle.testCreatedServerIsNotAlive(TestHttpServerLifecycle.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testCreatedServerIsNotAlive/campaign/failures/debug_000002	{"hadoop.http.acceptor.count": "1082163219"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServer#testPortRanges	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testPortRanges/campaign/failures/debug_000003	{"hadoop.http.acceptor.count": "1662823356"}	["debug_000003"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetup	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetup(TestSSLHttpServerConfigs.java:142), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetup/campaign/failures/debug_000003	{"hadoop.http.acceptor.count": "1132501015"}	["debug_000003"]	org.apache.hadoop.http.TestHttpServer#testDisabledAuthorizationOfDefaultServlets	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testDisabledAuthorizationOfDefaultServlets/campaign/failures/debug_000007	{"hadoop.http.acceptor.count": "541032191"}	["debug_000007"]	org.apache.hadoop.http.TestHttpServerLifecycle#testStoppingTwiceServerIsAllowed	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:158), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:77), org.apache.hadoop.http.HttpServerFunctionalTest.createAndStartTestServer(HttpServerFunctionalTest.java:223), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppingTwiceServerIsAllowed(TestHttpServerLifecycle.java:121), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStoppingTwiceServerIsAllowed/campaign/failures/debug_000004	{"hadoop.http.acceptor.count": "2007788481"}	["debug_000004"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithoutKeyStoreKeyPassword	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStoreKeyPassword(TestSSLHttpServerConfigs.java:160), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithoutKeyStoreKeyPassword/campaign/failures/debug_000004	{"hadoop.http.acceptor.count": "538969765"}	["debug_000004"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsXFrameOptions	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsXFrameOptions/campaign/failures/debug_000007	{"hadoop.http.acceptor.count": "1956359559"}	["debug_000007"]	org.apache.hadoop.http.TestHttpServer#testHasAdministratorAccess	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHasAdministratorAccess/campaign/failures/debug_000004	{"hadoop.http.acceptor.count": "765374605"}	["debug_000004"]	org.apache.hadoop.http.TestHttpServerLogs#testLogsEnabled	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServerLogs.startServer(TestHttpServerLogs.java:43), org.apache.hadoop.http.TestHttpServerLogs.testLogsEnabled(TestHttpServerLogs.java:63), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLogs/testLogsEnabled/campaign/failures/debug_000002	{"hadoop.http.acceptor.count": "526227364"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsDeny	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsDeny/campaign/failures/debug_000004	{"hadoop.http.acceptor.count": "2047116292"}	["debug_000004"]	org.apache.hadoop.http.TestHttpServer#testAuthorizationOfDefaultServlets	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testAuthorizationOfDefaultServlets/campaign/failures/debug_000004	{"hadoop.http.acceptor.count": "1870249254"}	["debug_000004"]																																																							
	Bug-143	Repeated	61	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testGlobStatusWithMultipleWildCardMatches	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testGlobStatusWithMultipleWildCardMatches/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testOpenFileApplyRead	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testOpenFileApplyRead/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testDeleteEmptyDirectory	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testDeleteEmptyDirectory/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsTrash#testTrash	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestViewFsTrash.setUp(TestViewFsTrash.java:45), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsTrash/testTrash/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegationTokenSupport#testGetCanonicalServiceNameWithDefaultMountTable	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegationTokenSupport.setup(TestViewFileSystemDelegationTokenSupport.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegationTokenSupport/testGetCanonicalServiceNameWithDefaultMountTable/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testListStatusFilterWithSomeMatches	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testListStatusFilterWithSomeMatches/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testInputStreamClosedTwice	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testInputStreamClosedTwice/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsOverloadSchemeListStatus#testListStatusACL	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme.initialize(ViewFileSystemOverloadScheme.java:161), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174), org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574), org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540), org.apache.hadoop.fs.viewfs.TestViewFsOverloadSchemeListStatus.testListStatusACL(TestViewFsOverloadSchemeListStatus.java:92), org.apache.hadoop.fs.viewfs.TestViewFsOverloadSchemeListStatus.testListStatusACL$$CONFUZZ(TestViewFsOverloadSchemeListStatus.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsOverloadSchemeListStatus/testListStatusACL/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testRenameDirectoryToItself	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testRenameDirectoryToItself/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testFileContextStatistics	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testFileContextStatistics/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testGlobStatusFilterWithSomePathMatchesAndTrivialFilter	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testGlobStatusFilterWithSomePathMatchesAndTrivialFilter/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testGetDelegationTokens	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testGetDelegationTokens/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegationTokenSupport#testGetCanonicalServiceNameWithNonDefaultMountTable	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegationTokenSupport.setup(TestViewFileSystemDelegationTokenSupport.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegationTokenSupport/testGetCanonicalServiceNameWithNonDefaultMountTable/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testGlobStatusFilterWithMultipleWildCardMatchesAndTrivialFilter	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testGlobStatusFilterWithMultipleWildCardMatchesAndTrivialFilter/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcCreateMkdirLocalFs#testMkdirRecursiveWithNonExistingDir	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcCreateMkdirLocalFs.setUp(TestFcCreateMkdirLocalFs.java:34), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcCreateMkdirLocalFs/testMkdirRecursiveWithNonExistingDir/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testMkdirs	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testMkdirs/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testBuilderCreateAppendExistingFile	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testBuilderCreateAppendExistingFile/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testNflyWriteSimple	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testNflyWriteSimple/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testGlobStatusWithMultipleMatchesOfSingleChar	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testGlobStatusWithMultipleMatchesOfSingleChar/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testRenameFileToNonExistentDirectory	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFs$1.<init>(ViewFs.java:239), org.apache.hadoop.fs.viewfs.ViewFs.<init>(ViewFs.java:238), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.fs.AbstractFileSystem.newInstance(AbstractFileSystem.java:143), org.apache.hadoop.fs.AbstractFileSystem.createFileSystem(AbstractFileSystem.java:181), org.apache.hadoop.fs.AbstractFileSystem.get(AbstractFileSystem.java:266), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:342), org.apache.hadoop.fs.FileContext$2.run(FileContext.java:339), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.fs.FileContext.getAbstractFileSystem(FileContext.java:339), org.apache.hadoop.fs.FileContext.getFileContext(FileContext.java:465), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.setupForViewFsLocalFs(ViewFsTestSetup.java:88), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp(TestFcMainOperationsLocalFs.java:38), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testRenameFileToNonExistentDirectory/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]
	Bug-7	BUG	111	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testReadFullyZeroByteFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testReadFullyZeroByteFile/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1651998227"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestViewFsTrash#testTrash	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemTestHelper.writeFile(FileSystemTestHelper.java:190), org.apache.hadoop.fs.TestTrash.trashShell(TestTrash.java:161), org.apache.hadoop.fs.viewfs.TestViewFsTrash.testTrash(TestViewFsTrash.java:65), org.apache.hadoop.fs.viewfs.TestViewFsTrash.testTrash$$CONFUZZ(TestViewFsTrash.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsTrash/testTrash/campaign/failures/debug_000003	{"file.bytes-per-checksum": "2130640638"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testChildrenFileSystemLeak	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testChildrenFileSystemLeak/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1141144728"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testOneDataEntry	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.setUp(TestTFileJClassComparatorByteArrays.java:41), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testOneDataEntry/campaign/failures/debug_000000	{"file.bytes-per-checksum": "636684774"}	["debug_000000"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testCreateFileUnderFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractCreateTest.createFile(AbstractContractCreateTest.java:447), org.apache.hadoop.fs.contract.AbstractContractCreateTest.expectCreateUnderFileFails(AbstractContractCreateTest.java:413), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreateFileUnderFile(AbstractContractCreateTest.java:348), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testCreateFileUnderFile$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testCreateFileUnderFile/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1545803539"}	["debug_000000"]	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testDeleteRecursively	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testDeleteRecursively(FSMainOperationsBaseTest.java:759), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testDeleteRecursively$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testDeleteRecursively/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1133630474"}	["debug_000000"]	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testWriteInNonExistentDirectory	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteInNonExistentDirectory(FSMainOperationsBaseTest.java:739), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testWriteInNonExistentDirectory$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testWriteInNonExistentDirectory/campaign/failures/debug_000000	{"file.bytes-per-checksum": "640452763"}	["debug_000000"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testReadFullyZeroBytebufferPastEOF	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testReadFullyZeroBytebufferPastEOF/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1941856166"}	["debug_000001"]	org.apache.hadoop.fs.TestHarFileSystemBasics#testPositiveListFilesNotEndInColon	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1134), org.apache.hadoop.fs.FileSystem.createNewFile(FileSystem.java:1439), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:84), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testPositiveListFilesNotEndInColon/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1969123127"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testFailureValueTooShort	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileStreams.setUp(TestTFileStreams.java:76), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testFailureValueTooShort/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1116287172"}	["debug_000000"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus#testListFilesFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.touch(ContractTestUtils.java:672), org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.touchf(AbstractContractGetFileStatusTest.java:466), org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.testListFilesFile(AbstractContractGetFileStatusTest.java:398), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus.testListFilesFile$$CONFUZZ(TestLocalFSContractGetFileStatus.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus/testListFilesFile/campaign/failures/debug_000000	{"file.bytes-per-checksum": "662932921"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureWriteMetaBlocksWithSameName	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.setUp(TestTFileNoneCodecsByteArrays.java:29), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureWriteMetaBlocksWithSameName/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1602722640"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testGetDelegationTokens	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testGetDelegationTokens/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1536805605"}	["debug_000001"]	org.apache.hadoop.fs.shell.TestPathData#testRelativeGlob	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1134), org.apache.hadoop.fs.FileSystem.createNewFile(FileSystem.java:1439), org.apache.hadoop.fs.shell.TestPathData.initialize(TestPathData.java:61), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestPathData/testRelativeGlob/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1610459404"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testTwoDataEntries	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.setUp(TestTFileNoneCodecsByteArrays.java:29), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testTwoDataEntries/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1660056134"}	["debug_000000", "debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testMkdirUnderFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractCreateTest.createFile(AbstractContractCreateTest.java:447), org.apache.hadoop.fs.contract.AbstractContractCreateTest.expectMkdirsUnderFileFails(AbstractContractCreateTest.java:430), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testMkdirUnderFile(AbstractContractCreateTest.java:377), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testMkdirUnderFile$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testMkdirUnderFile/campaign/failures/debug_000002	{"file.bytes-per-checksum": "638227363"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testGetWrappedInputStream	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testGetWrappedInputStream(FSMainOperationsBaseTest.java:1114), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testGetWrappedInputStream$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testGetWrappedInputStream/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1495400512"}	["debug_000000", "debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureOpenEmptyFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureOpenEmptyFile/campaign/failures/debug_000000	{"file.bytes-per-checksum": "653631678"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testMkdirsFailsForSubdirectoryOfExistingFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testMkdirsFailsForSubdirectoryOfExistingFile(FSMainOperationsBaseTest.java:234), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testMkdirsFailsForSubdirectoryOfExistingFile$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testMkdirsFailsForSubdirectoryOfExistingFile/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1091043392"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testNoEntry	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileStreams.setUp(TestTFileStreams.java:76), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testNoEntry/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1937452769"}	["debug_000000"]
		FP	1	org.apache.hadoop.ipc.TestIPC#testProxyUserBinding	org.mockito.exceptions.verification.junit.ArgumentsAreDifferent	Argument(s) are different! Wanted:socket.bind(6294a9692606/172.17.0.2:0);-> at org.apache.hadoop.ipc.TestIPC.checkUserBinding(TestIPC.java:1691)Actual invocations have different arguments:socket.setTcpNoDelay(true);-> at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:669)socket.setKeepAlive(true);-> at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:670)socket.setReuseAddress(true);-> at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:701)socket.bind(0.0.0.0/0.0.0.0:0);-> at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:706)socket.getChannel();-> at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:570)socket.connect(0.0.0.0/0.0.0.0:0, 20000);-> at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:584)socket.close();-> at org.apache.hadoop.ipc.Client$Connection.closeConnection(Client.java:942)	org.apache.hadoop.ipc.TestIPC.checkUserBinding(TestIPC.java:1691), org.apache.hadoop.ipc.TestIPC.testProxyUserBinding(TestIPC.java:1675), org.apache.hadoop.ipc.TestIPC.testProxyUserBinding$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testProxyUserBinding/campaign/failures/debug_000000	{"ipc.client.bind.wildcard.addr": "true"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	4	org.apache.hadoop.ipc.TestIPC#testProxyUserBinding	org.apache.hadoop.security.authentication.util.KerberosName$NoMatchingRule	No rules applied to client@REALM	org.apache.hadoop.security.authentication.util.KerberosName.getShortName(KerberosName.java:429), org.apache.hadoop.security.User.<init>(User.java:48), org.apache.hadoop.security.User.<init>(User.java:43), org.apache.hadoop.security.UserGroupInformation.createRemoteUser(UserGroupInformation.java:1418), org.apache.hadoop.security.UserGroupInformation.createRemoteUser(UserGroupInformation.java:1402), org.apache.hadoop.ipc.TestIPC.checkConnect(TestIPC.java:1708), org.apache.hadoop.ipc.TestIPC.checkUserBinding(TestIPC.java:1681), org.apache.hadoop.ipc.TestIPC.testProxyUserBinding(TestIPC.java:1675), org.apache.hadoop.ipc.TestIPC.testProxyUserBinding$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testProxyUserBinding/campaign/failures/debug_000001	{"hadoop.security.authentication": "kerberos"}	["debug_000001"]	org.apache.hadoop.security.TestUserGroupInformation#testEqualsWithRealUser	org.apache.hadoop.security.authentication.util.KerberosName$NoMatchingRule	No rules applied to user1@HADOOP.APACHE.ORG	org.apache.hadoop.security.authentication.util.KerberosName.getShortName(KerberosName.java:429), org.apache.hadoop.security.User.<init>(User.java:48), org.apache.hadoop.security.UserGroupInformation.createProxyUser(UserGroupInformation.java:1494), org.apache.hadoop.security.TestUserGroupInformation.testEqualsWithRealUser(TestUserGroupInformation.java:502), org.apache.hadoop.security.TestUserGroupInformation.testEqualsWithRealUser$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testEqualsWithRealUser/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos"}	["debug_000000"]	org.apache.hadoop.security.TestUserGroupInformation#testTokenRaceCondition	org.apache.hadoop.security.authentication.util.KerberosName$NoMatchingRule	No rules applied to user1@HADOOP.APACHE.ORG	org.apache.hadoop.security.authentication.util.KerberosName.getShortName(KerberosName.java:429), org.apache.hadoop.security.User.<init>(User.java:48), org.apache.hadoop.security.User.<init>(User.java:43), org.apache.hadoop.security.UserGroupInformation.createRemoteUser(UserGroupInformation.java:1418), org.apache.hadoop.security.UserGroupInformation.createRemoteUser(UserGroupInformation.java:1402), org.apache.hadoop.security.UserGroupInformation.createUserForTesting(UserGroupInformation.java:1555), org.apache.hadoop.security.TestUserGroupInformation.testTokenRaceCondition(TestUserGroupInformation.java:967), org.apache.hadoop.security.TestUserGroupInformation.testTokenRaceCondition$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testTokenRaceCondition/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos"}	["debug_000000"]	org.apache.hadoop.security.TestUserGroupInformation#testLogin	org.apache.hadoop.security.authentication.util.KerberosName$NoMatchingRule	No rules applied to user1@HADOOP.APACHE.ORG	org.apache.hadoop.security.authentication.util.KerberosName.getShortName(KerberosName.java:429), org.apache.hadoop.security.User.<init>(User.java:48), org.apache.hadoop.security.User.<init>(User.java:43), org.apache.hadoop.security.UserGroupInformation.createRemoteUser(UserGroupInformation.java:1418), org.apache.hadoop.security.UserGroupInformation.createRemoteUser(UserGroupInformation.java:1402), org.apache.hadoop.security.UserGroupInformation.createUserForTesting(UserGroupInformation.java:1555), org.apache.hadoop.security.TestUserGroupInformation.testLogin(TestUserGroupInformation.java:236), org.apache.hadoop.security.TestUserGroupInformation.testLogin$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testLogin/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos"}	["debug_000000"]																																																																																																																																																																																
		FP	6	org.apache.hadoop.ipc.TestDecayRpcScheduler#testPeriodic	java.lang.IllegalArgumentException	the number of top users for scheduler metrics must be at least 1	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:246), org.apache.hadoop.ipc.TestDecayRpcScheduler.testPeriodic(TestDecayRpcScheduler.java:251), org.apache.hadoop.ipc.TestDecayRpcScheduler.testPeriodic$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testPeriodic/campaign/failures/debug_000000	{"decay-scheduler.metrics.top.user.count": "0"}	["debug_000000"]	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.IllegalArgumentException	the number of top users for scheduler metrics must be at least 1	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:246), org.apache.hadoop.ipc.TestDecayRpcScheduler.getSchedulerWithWeightedTimeCostProvider(TestDecayRpcScheduler.java:390), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:290), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000005	{"decay-scheduler.metrics.top.user.count": "0"}	["debug_000005"]	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseFactor	java.lang.IllegalArgumentException	the number of top users for scheduler metrics must be at least 1	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:246), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseFactor(TestDecayRpcScheduler.java:89), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseFactor$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseFactor/campaign/failures/debug_000004	{"decay-scheduler.metrics.top.user.count": "0"}	["debug_000004"]	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProviderNoRequests	java.lang.IllegalArgumentException	the number of top users for scheduler metrics must be at least 1	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:246), org.apache.hadoop.ipc.TestDecayRpcScheduler.getSchedulerWithWeightedTimeCostProvider(TestDecayRpcScheduler.java:390), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProviderNoRequests(TestDecayRpcScheduler.java:374), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProviderNoRequests$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProviderNoRequests/campaign/failures/debug_000001	{"decay-scheduler.metrics.top.user.count": "0"}	["debug_000001"]	org.apache.hadoop.ipc.TestDecayRpcScheduler#testPriority	java.lang.IllegalArgumentException	the number of top users for scheduler metrics must be at least 1	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:246), org.apache.hadoop.ipc.TestDecayRpcScheduler.testPriority(TestDecayRpcScheduler.java:215), org.apache.hadoop.ipc.TestDecayRpcScheduler.testPriority$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testPriority/campaign/failures/debug_000002	{"decay-scheduler.metrics.top.user.count": "0"}	["debug_000002"]	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseThresholds	java.lang.IllegalArgumentException	the number of top users for scheduler metrics must be at least 1	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:246), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds(TestDecayRpcScheduler.java:113), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseThresholds/campaign/failures/debug_000007	{"decay-scheduler.metrics.top.user.count": "0"}	["debug_000007"]																																																																																																																																																										
			13	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testTwoDataEntries	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:136), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testTwoDataEntries/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2126894347"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testOneBlockPlusOneEntry	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneBlockPlusOneEntry(TestTFileByteArrays.java:165), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testOneBlockPlusOneEntry/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureFileWriteNotAt0Position	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureFileWriteNotAt0Position(TestTFileByteArrays.java:561), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureFileWriteNotAt0Position/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureNegativeOffset	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeOffset(TestTFileByteArrays.java:459), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureNegativeOffset/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2139095102"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testTwoDataEntries	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:136), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testTwoDataEntries/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureOpenEmptyFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenEmptyFile(TestTFileByteArrays.java:381), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureOpenEmptyFile/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2104939578"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureWriteRecordAfterMetaBlock	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteRecordAfterMetaBlock(TestTFileByteArrays.java:321), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureWriteRecordAfterMetaBlock/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays#testScanRange	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.setUp(TestTFileUnsortedByteArrays.java:74), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays/testScanRange/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2115590851"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testThreeBlocks	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testThreeBlocks(TestTFileByteArrays.java:184), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testThreeBlocks/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "2147462909"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureBadCompressionCodec	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureBadCompressionCodec(TestTFileByteArrays.java:366), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureBadCompressionCodec/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "2132928144"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureKeyLongerThan64K	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureKeyLongerThan64K(TestTFileByteArrays.java:426), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureKeyLongerThan64K/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureBadCompressionCodec	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureBadCompressionCodec(TestTFileByteArrays.java:366), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureBadCompressionCodec/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2070762662"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testNoDataEntry	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testNoDataEntry(TestTFileByteArrays.java:108), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testNoDataEntry/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000002"]																																																																													
	Bug-17	Repeated	20	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testTwoDataEntries	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:136), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testTwoDataEntries$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testTwoDataEntries/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2125262204"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testTwoDataEntries	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:136), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testTwoDataEntries$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testTwoDataEntries/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2139922407"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureBadCompressionCodec	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureBadCompressionCodec(TestTFileByteArrays.java:366), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureBadCompressionCodec$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureBadCompressionCodec/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "2070888457"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testOneBlockPlusOneEntry	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneBlockPlusOneEntry(TestTFileByteArrays.java:165), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneBlockPlusOneEntry$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testOneBlockPlusOneEntry/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureFileWriteNotAt0Position	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureFileWriteNotAt0Position(TestTFileByteArrays.java:561), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureFileWriteNotAt0Position$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureFileWriteNotAt0Position/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "2147451392"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureWriteMetaBlocksWithSameName	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteMetaBlocksWithSameName(TestTFileByteArrays.java:271), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureWriteMetaBlocksWithSameName$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureWriteMetaBlocksWithSameName/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2079723629"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testOneBlockPlusOneEntry	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneBlockPlusOneEntry(TestTFileByteArrays.java:165), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testOneBlockPlusOneEntry$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testOneBlockPlusOneEntry/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testTwoBlocks	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoBlocks(TestTFileByteArrays.java:175), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoBlocks$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testTwoBlocks/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2130673407"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureNegativeOffset	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeOffset(TestTFileByteArrays.java:459), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeOffset$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureNegativeOffset/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "2139127550"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureNegativeOffset	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeOffset(TestTFileByteArrays.java:459), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureNegativeOffset$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureNegativeOffset/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "2133481317"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureOutOfOrderKeys	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOutOfOrderKeys(TestTFileByteArrays.java:438), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureOutOfOrderKeys$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureOutOfOrderKeys/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2141684354"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureOpenRandomFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenRandomFile(TestTFileByteArrays.java:398), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureOpenRandomFile$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureOpenRandomFile/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "2141257470"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testThreeBlocks	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testThreeBlocks(TestTFileByteArrays.java:184), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testThreeBlocks$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testThreeBlocks/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testOneDataEntry	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneDataEntry(TestTFileByteArrays.java:122), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneDataEntry$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testOneDataEntry/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureOpenEmptyFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenEmptyFile(TestTFileByteArrays.java:381), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureOpenEmptyFile$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureOpenEmptyFile/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureBadCompressionCodec	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureBadCompressionCodec(TestTFileByteArrays.java:366), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureBadCompressionCodec$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureBadCompressionCodec/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureBadCompressionCodec	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureBadCompressionCodec(TestTFileByteArrays.java:366), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureBadCompressionCodec$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureBadCompressionCodec/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "2094535374"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureKeyLongerThan64K	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureKeyLongerThan64K(TestTFileByteArrays.java:426), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureKeyLongerThan64K$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureKeyLongerThan64K/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "2125248391"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureWriteMetaBlocksWithSameName	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteMetaBlocksWithSameName(TestTFileByteArrays.java:271), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteMetaBlocksWithSameName$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureWriteMetaBlocksWithSameName/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2084961486"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureGetNonExistentMetaBlock	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock(TestTFileByteArrays.java:293), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureGetNonExistentMetaBlock$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureGetNonExistentMetaBlock/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000001"]
	Bug-48	Repeated	35	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testTwoDataEntries	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:581), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:136), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testTwoDataEntries$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testTwoDataEntries/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "0"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays#testScan	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.closeOutput(TestTFileUnsortedByteArrays.java:206), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.setUp(TestTFileUnsortedByteArrays.java:78), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays/testScan/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureBadCompressionCodec	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureBadCompressionCodec(TestTFileByteArrays.java:366), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureBadCompressionCodec$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureBadCompressionCodec/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "0"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testOneBlockPlusOneEntry	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:581), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneBlockPlusOneEntry(TestTFileByteArrays.java:165), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneBlockPlusOneEntry$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testOneBlockPlusOneEntry/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "0"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureFileWriteNotAt0Position	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureFileWriteNotAt0Position(TestTFileByteArrays.java:561), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureFileWriteNotAt0Position$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureFileWriteNotAt0Position/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "0"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureNegativeOffset	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeOffset(TestTFileByteArrays.java:459), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureNegativeOffset$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureNegativeOffset/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "0"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testNoDataEntry	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testNoDataEntry(TestTFileByteArrays.java:108), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testNoDataEntry$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testNoDataEntry/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureOpenEmptyFile	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenEmptyFile(TestTFileByteArrays.java:381), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenEmptyFile$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureOpenEmptyFile/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "0"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testNoEntry	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileStreams.closeOutput(TestTFileStreams.java:437), org.apache.hadoop.io.file.tfile.TestTFileStreams.testNoEntry(TestTFileStreams.java:96), org.apache.hadoop.io.file.tfile.TestTFileStreams.testNoEntry$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testNoEntry/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureWriteMetaBlocksWithSameName	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteMetaBlocksWithSameName(TestTFileByteArrays.java:286), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureWriteMetaBlocksWithSameName$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureWriteMetaBlocksWithSameName/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testTwoBlocks	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:581), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoBlocks(TestTFileByteArrays.java:175), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoBlocks$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testTwoBlocks/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureFileWriteNotAt0Position	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureFileWriteNotAt0Position(TestTFileByteArrays.java:561), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureFileWriteNotAt0Position$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureFileWriteNotAt0Position/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "0"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureKeyLongerThan64K	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileStreams.closeOutput(TestTFileStreams.java:437), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureKeyLongerThan64K(TestTFileStreams.java:324), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testFailureKeyLongerThan64K$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureKeyLongerThan64K/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryUnknownLength	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileStreams.closeOutput(TestTFileStreams.java:437), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:425), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryUnknownLength(TestTFileStreams.java:113), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryUnknownLength$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryUnknownLength/campaign/failures/debug_000005	{"tfile.fs.output.buffer.size": "0"}	["debug_000005"]	org.apache.hadoop.io.file.tfile.TestTFile#testMetaBlocks	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFile.testMetaBlocks(TestTFile.java:430), org.apache.hadoop.io.file.tfile.TestTFile.testMetaBlocks$$CONFUZZ(TestTFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFile/testMetaBlocks/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "0"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryMixedLengths2	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileStreams.closeOutput(TestTFileStreams.java:437), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:425), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths2(TestTFileStreams.java:135), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths2$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryMixedLengths2/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureGetNonExistentMetaBlock	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock(TestTFileByteArrays.java:301), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureGetNonExistentMetaBlock$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureGetNonExistentMetaBlock/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureOpenRandomFile	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenRandomFile(TestTFileByteArrays.java:398), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureOpenRandomFile$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureOpenRandomFile/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "0"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays#testScanRange	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.closeOutput(TestTFileUnsortedByteArrays.java:206), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.setUp(TestTFileUnsortedByteArrays.java:78), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays/testScanRange/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testOneDataEntry	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.fs.FSOutputSummer.write(FSOutputSummer.java:109), org.apache.hadoop.fs.FSDataOutputStream$PositionCache.write(FSDataOutputStream.java:62), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flushBuffer(SimpleBufferedOutputStream.java:40), org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.flush(SimpleBufferedOutputStream.java:69), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.finish(BCFile.java:181), org.apache.hadoop.io.file.tfile.BCFile$Writer$BlockAppender.close(BCFile.java:263), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:323), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:581), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneDataEntry(TestTFileByteArrays.java:122), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneDataEntry$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testOneDataEntry/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]
	Bug-8	Repeated	25	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testCreatedFileIsVisibleOnFlush	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreatedFileIsVisibleOnFlush(AbstractContractCreateTest.java:241), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testCreatedFileIsVisibleOnFlush$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testCreatedFileIsVisibleOnFlush/campaign/failures/debug_000000	{"file.stream-buffer-size": "2130640638"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testRenameDirectoryAsNonExistentDirectory	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.doTestRenameDirectoryAsNonExistentDirectory(FSMainOperationsBaseTest.java:995), org.apache.hadoop.fs.FSMainOperationsBaseTest.testRenameDirectoryAsNonExistentDirectory(FSMainOperationsBaseTest.java:984), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testRenameDirectoryAsNonExistentDirectory$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testRenameDirectoryAsNonExistentDirectory/campaign/failures/debug_000001	{"file.stream-buffer-size": "2130640638"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics#testWriteByteArrays	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.AbstractContractStreamIOStatisticsTest.testWriteByteArrays(AbstractContractStreamIOStatisticsTest.java:154), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics.testWriteByteArrays$$CONFUZZ(TestLocalFSContractStreamIOStatistics.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics/testWriteByteArrays/campaign/failures/debug_000000	{"file.stream-buffer-size": "2091188997"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem#testLocalFsCreateAndDelete	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1134), org.apache.hadoop.fs.FileSystem.createNewFile(FileSystem.java:1439), org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem.testLocalFsCreateAndDelete(TestViewFileSystemOverloadSchemeLocalFileSystem.java:113), org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem.testLocalFsCreateAndDelete$$CONFUZZ(TestViewFileSystemOverloadSchemeLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem/testLocalFsCreateAndDelete/campaign/failures/debug_000001	{"file.stream-buffer-size": "2130640638"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testOutputStreamClosedTwice	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FSMainOperationsBaseTest.testOutputStreamClosedTwice(FSMainOperationsBaseTest.java:1103), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testOutputStreamClosedTwice$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testOutputStreamClosedTwice/campaign/failures/debug_000002	{"file.stream-buffer-size": "2130640638"}	["debug_000002"]	org.apache.hadoop.fs.TestFsShellCopy#testMoveFileFromLocal	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.create(CommandWithDestination.java:532), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:494), org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:417), org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:352), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.copyFileToTarget(CopyCommandWithMultiThread.java:144), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:287), org.apache.hadoop.fs.shell.MoveCommands$MoveFromLocal.processPath(MoveCommands.java:67), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:272), org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:370), org.apache.hadoop.fs.shell.Command.processPaths(Command.java:333), org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:306), org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:267), org.apache.hadoop.fs.shell.Command.processArgument(Command.java:288), org.apache.hadoop.fs.shell.Command.processArguments(Command.java:272), org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:238), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.processArguments(CopyCommandWithMultiThread.java:89), org.apache.hadoop.fs.shell.CopyCommands$Put.processArguments(CopyCommands.java:312), org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:121), org.apache.hadoop.fs.shell.Command.run(Command.java:179), org.apache.hadoop.fs.FsShell.run(FsShell.java:327), org.apache.hadoop.fs.TestFsShellCopy.testMoveFileFromLocal(TestFsShellCopy.java:442),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testMoveFileFromLocal/campaign/failures/debug_000000	{"file.stream-buffer-size": "1355437367"}	["debug_000000"]	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testRenameDirectoryAsNonEmptyDirectory	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testRenameDirectoryAsNonEmptyDirectory(FSMainOperationsBaseTest.java:1042), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testRenameDirectoryAsNonEmptyDirectory$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testRenameDirectoryAsNonEmptyDirectory/campaign/failures/debug_000001	{"file.stream-buffer-size": "2107051057"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testOneBlockPlusOneEntry	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.setUp(TestTFileNoneCodecsJClassComparatorByteArrays.java:37), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testOneBlockPlusOneEntry/campaign/failures/debug_000001	{"file.stream-buffer-size": "2088283113"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics#testWriteSingleByte	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.AbstractContractStreamIOStatisticsTest.testWriteSingleByte(AbstractContractStreamIOStatisticsTest.java:126), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics.testWriteSingleByte$$CONFUZZ(TestLocalFSContractStreamIOStatistics.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics/testWriteSingleByte/campaign/failures/debug_000002	{"file.stream-buffer-size": "2111164535"}	["debug_000002"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameFileToDestViaSymlink	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameFileToDestViaSymlink(SymlinkBaseTest.java:838), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testRenameFileToDestViaSymlink$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameFileToDestViaSymlink/campaign/failures/debug_000001	{"file.stream-buffer-size": "2139097274"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader#testMountTableFileLoadingWhenMultipleFilesExist	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.addMountLinksToFile(ViewFsTestSetup.java:152), org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader.testMountTableFileLoadingWhenMultipleFilesExist(TestHCFSMountTableConfigLoader.java:98), org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader.testMountTableFileLoadingWhenMultipleFilesExist$$CONFUZZ(TestHCFSMountTableConfigLoader.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader/testMountTableFileLoadingWhenMultipleFilesExist/campaign/failures/debug_000000	{"file.stream-buffer-size": "2130640638"}	["debug_000000", "debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testSeekFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testSeekFile/campaign/failures/debug_000002	{"file.stream-buffer-size": "2142736863"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testTwoBlocks	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testTwoBlocks/campaign/failures/debug_000002	{"file.stream-buffer-size": "2102537177"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureWriteRecordAfterMetaBlock	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.setUp(TestTFileNoneCodecsByteArrays.java:29), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureWriteRecordAfterMetaBlock/campaign/failures/debug_000002	{"file.stream-buffer-size": "2137857522"}	["debug_000002"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameSymlinkToExistingFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameSymlinkToExistingFile(SymlinkBaseTest.java:1034), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testRenameSymlinkToExistingFile$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameSymlinkToExistingFile/campaign/failures/debug_000002	{"file.stream-buffer-size": "2139095294"}	["debug_000002"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testCreateLinkToDot	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testCreateLinkToDot(SymlinkBaseTest.java:772), org.apache.hadoop.fs.TestSymlinkLocalFS.testCreateLinkToDot(TestSymlinkLocalFS.java:218), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testCreateLinkToDot$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testCreateLinkToDot/campaign/failures/debug_000001	{"file.stream-buffer-size": "2139265892"}	["debug_000001"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testStatNonLinks	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testStatNonLinks(SymlinkBaseTest.java:319), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testStatNonLinks$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testStatNonLinks/campaign/failures/debug_000000	{"file.stream-buffer-size": "2118183801"}	["debug_000000"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testCreateFileViaSymlink	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testCreateFileViaSymlink(SymlinkBaseTest.java:626), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testCreateFileViaSymlink$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testCreateFileViaSymlink/campaign/failures/debug_000001	{"file.stream-buffer-size": "2079219208"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testResolvePathThroughMountPoints	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testResolvePathThroughMountPoints/campaign/failures/debug_000002	{"file.stream-buffer-size": "2098347877"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testRenameDirectoryAsFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testRenameDirectoryAsFile(FSMainOperationsBaseTest.java:1072), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testRenameDirectoryAsFile$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testRenameDirectoryAsFile/campaign/failures/debug_000001	{"file.stream-buffer-size": "2075962287"}	["debug_000001"]
			5	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testCreatedFileIsVisibleOnFlush	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreatedFileIsVisibleOnFlush(AbstractContractCreateTest.java:241), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testCreatedFileIsVisibleOnFlush/campaign/failures/debug_000002	{"file.stream-buffer-size": "721912235", "file.bytes-per-checksum": "149898050"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testReadFullyZeroBytebufferPastEOF	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testReadFullyZeroBytebufferPastEOF/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1049331272", "file.stream-buffer-size": "1295835463"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem#testResolvePath	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:163), org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testResolvePath(TestChRootedFileSystem.java:315), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestChRootedFileSystem/testResolvePath/campaign/failures/debug_000002	{"file.stream-buffer-size": "1131235503", "file.bytes-per-checksum": "135779092"}	["debug_000002"]	org.apache.hadoop.fs.TestHarFileSystemBasics#testPositiveNewHarFsOnTheSameUnderlyingFs	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestHarFileSystemBasics.writeVersionToMasterIndexImpl(TestHarFileSystemBasics.java:117), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:89), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1134), org.apache.hadoop.fs.FileSystem.createNewFile(FileSystem.java:1439), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:84), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testPositiveNewHarFsOnTheSameUnderlyingFs/campaign/failures/debug_000001	{"file.bytes-per-checksum": "522632328", "file.stream-buffer-size": "1592900921"}	["debug_000001"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameFileWithDestParentSymlink	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameFileWithDestParentSymlink(SymlinkBaseTest.java:1234), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testRenameFileWithDestParentSymlink(TestSymlinkLocalFSFileSystem.java:67), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameFileWithDestParentSymlink/campaign/failures/debug_000002	{"file.stream-buffer-size": "1996578091", "file.bytes-per-checksum": "1921323756"}	["debug_000002"]																																																																																																																																																																					
		FP	8	org.apache.hadoop.http.TestSSLHttpServerConfigs#testKeyStoreSetupWithoutPassword	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutPassword(TestSSLHttpServerConfigs.java:252), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutPassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testKeyStoreSetupWithoutPassword/campaign/failures/debug_000006	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000006", "debug_000003"]	org.apache.hadoop.http.TestHttpServer#testHttpResponseOverrideDefaultHeaders	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.getHttpURLConnection(TestHttpServer.java:321), org.apache.hadoop.http.TestHttpServer.testHttpResponseOverrideDefaultHeaders(TestHttpServer.java:743), org.apache.hadoop.http.TestHttpServer.testHttpResponseOverrideDefaultHeaders$$CONFUZZ(TestHttpServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResponseOverrideDefaultHeaders/campaign/failures/debug_000006	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000006"]	org.apache.hadoop.http.TestHttpServer#testPortRanges	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testPortRanges/campaign/failures/debug_000006	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000006", "debug_000005"]	org.apache.hadoop.http.TestHttpServer#testDisabledAuthorizationOfDefaultServlets	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testDisabledAuthorizationOfDefaultServlets/campaign/failures/debug_000006	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000006", "debug_000003"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsXFrameOptions	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.getHttpURLConnection(TestHttpServer.java:321), org.apache.hadoop.http.TestHttpServer.validateXFrameOption(TestHttpServer.java:295), org.apache.hadoop.http.TestHttpServer.testHttpResonseContainsXFrameOptions(TestHttpServer.java:275), org.apache.hadoop.http.TestHttpServer.testHttpResonseContainsXFrameOptions$$CONFUZZ(TestHttpServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsXFrameOptions/campaign/failures/debug_000002	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseDoesNotContainXFrameOptions	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.getHttpURLConnection(TestHttpServer.java:321), org.apache.hadoop.http.TestHttpServer.testHttpResonseDoesNotContainXFrameOptions(TestHttpServer.java:311), org.apache.hadoop.http.TestHttpServer.testHttpResonseDoesNotContainXFrameOptions$$CONFUZZ(TestHttpServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseDoesNotContainXFrameOptions/campaign/failures/debug_000003	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000003"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsDeny	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.getHttpURLConnection(TestHttpServer.java:321), org.apache.hadoop.http.TestHttpServer.validateXFrameOption(TestHttpServer.java:295), org.apache.hadoop.http.TestHttpServer.testHttpResonseContainsDeny(TestHttpServer.java:280), org.apache.hadoop.http.TestHttpServer.testHttpResonseContainsDeny$$CONFUZZ(TestHttpServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsDeny/campaign/failures/debug_000000	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServer#testAuthorizationOfDefaultServlets	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.testAuthorizationOfDefaultServlets(TestHttpServer.java:481), org.apache.hadoop.http.TestHttpServer.testAuthorizationOfDefaultServlets$$CONFUZZ(TestHttpServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testAuthorizationOfDefaultServlets/campaign/failures/debug_000006	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000006", "debug_000007"]																																																																																																																																				
			8	org.apache.hadoop.http.TestSSLHttpServerConfigs#testKeyStoreSetupWithoutPassword	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutPassword(TestSSLHttpServerConfigs.java:252), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testKeyStoreSetupWithoutPassword/campaign/failures/debug_000005	{"hadoop.http.selector.count": "2130640638"}	["debug_000005"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testKeyStoreSetupWithoutKeyStorePassword	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutKeyStorePassword(TestSSLHttpServerConfigs.java:230), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testKeyStoreSetupWithoutKeyStorePassword/campaign/failures/debug_000004	{"hadoop.http.selector.count": "933118483"}	["debug_000004"]	org.apache.hadoop.http.TestServletFilter#testServletFilterWhenInitThrowsException	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestServletFilter.testServletFilterWhenInitThrowsException(TestServletFilter.java:173), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestServletFilter/testServletFilterWhenInitThrowsException/campaign/failures/debug_000002	{"hadoop.http.selector.count": "2130640638"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServerWebapps#testValidServerResource	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:158), org.apache.hadoop.http.TestHttpServerWebapps.testValidServerResource(TestHttpServerWebapps.java:42), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerWebapps/testValidServerResource/campaign/failures/debug_000002	{"hadoop.http.selector.count": "539008928"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServer#testBindAddress	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testBindAddress/campaign/failures/debug_000004	{"hadoop.http.selector.count": "1512808545"}	["debug_000004"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseDoesNotContainXFrameOptions	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseDoesNotContainXFrameOptions/campaign/failures/debug_000004	{"hadoop.http.selector.count": "1873435085"}	["debug_000004"]	org.apache.hadoop.http.TestHttpServerWithSpnego#testAuthenticationWithProxyUser	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser(TestHttpServerWithSpnego.java:135), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerWithSpnego/testAuthenticationWithProxyUser/campaign/failures/debug_000007	{"hadoop.http.selector.count": "1736738767"}	["debug_000007"]	org.apache.hadoop.http.TestHttpServer#testBacklogSize	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testBacklogSize/campaign/failures/debug_000004	{"hadoop.http.selector.count": "1092098671"}	["debug_000004"]																																																																																																																																				
	Bug-11	Repeated	20	org.apache.hadoop.http.TestSSLHttpServerConfigs#testKeyStoreSetupWithoutPassword	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutPassword(TestSSLHttpServerConfigs.java:252), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutPassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testKeyStoreSetupWithoutPassword/campaign/failures/debug_000001	{"hadoop.http.selector.count": "1239009809"}	["debug_000001"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithNoKeyStorePassword	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithNoKeyStorePassword(TestSSLHttpServerConfigs.java:169), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithNoKeyStorePassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithNoKeyStorePassword/campaign/failures/debug_000000	{"hadoop.http.selector.count": "721794633"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServer#testHttpResponseOverrideDefaultHeaders	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResponseOverrideDefaultHeaders/campaign/failures/debug_000003	{"hadoop.http.selector.count": "1722634891"}	["debug_000003"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithoutKeyStorePassword	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStorePassword(TestSSLHttpServerConfigs.java:154), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStorePassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithoutKeyStorePassword/campaign/failures/debug_000003	{"hadoop.http.selector.count": "1078505479"}	["debug_000003"]	org.apache.hadoop.http.TestHttpServerLifecycle#testStoppedServerIsNotAlive	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:158), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:77), org.apache.hadoop.http.HttpServerFunctionalTest.createAndStartTestServer(HttpServerFunctionalTest.java:223), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppedServerIsNotAlive(TestHttpServerLifecycle.java:109), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppedServerIsNotAlive$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStoppedServerIsNotAlive/campaign/failures/debug_000001	{"hadoop.http.selector.count": "1079017599"}	["debug_000001"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testKeyStoreSetupWithoutKeyStorePassword	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutKeyStorePassword(TestSSLHttpServerConfigs.java:230), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutKeyStorePassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testKeyStoreSetupWithoutKeyStorePassword/campaign/failures/debug_000003	{"hadoop.http.selector.count": "1930653447"}	["debug_000003"]	org.apache.hadoop.http.TestAuthenticationSessionCookie#testSessionCookie	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.TestAuthenticationSessionCookie.startServer(TestAuthenticationSessionCookie.java:131), org.apache.hadoop.http.TestAuthenticationSessionCookie.testSessionCookie(TestAuthenticationSessionCookie.java:139), org.apache.hadoop.http.TestAuthenticationSessionCookie.testSessionCookie$$CONFUZZ(TestAuthenticationSessionCookie.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestAuthenticationSessionCookie/testSessionCookie/campaign/failures/debug_000000	{"hadoop.http.selector.count": "2130640638"}	["debug_000000"]	org.apache.hadoop.http.TestServletFilter#testServletFilterWhenInitThrowsException	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestServletFilter.testServletFilterWhenInitThrowsException(TestServletFilter.java:173), org.apache.hadoop.http.TestServletFilter.testServletFilterWhenInitThrowsException$$CONFUZZ(TestServletFilter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestServletFilter/testServletFilterWhenInitThrowsException/campaign/failures/debug_000000	{"hadoop.http.selector.count": "1660594435"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServer#testPortRanges	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testPortRanges/campaign/failures/debug_000002	{"hadoop.http.selector.count": "1640042526"}	["debug_000002"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetup	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetup(TestSSLHttpServerConfigs.java:142), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetup$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetup/campaign/failures/debug_000002	{"hadoop.http.selector.count": "1454651972"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServerLifecycle#testStoppingTwiceServerIsAllowed	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:158), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:77), org.apache.hadoop.http.HttpServerFunctionalTest.createAndStartTestServer(HttpServerFunctionalTest.java:223), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppingTwiceServerIsAllowed(TestHttpServerLifecycle.java:121), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppingTwiceServerIsAllowed$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStoppingTwiceServerIsAllowed/campaign/failures/debug_000002	{"hadoop.http.selector.count": "1813605005"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServer#testBindAddress	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testBindAddress/campaign/failures/debug_000001	{"hadoop.http.selector.count": "1197434084"}	["debug_000001", "debug_000003"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithoutKeyStoreKeyPassword	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStoreKeyPassword(TestSSLHttpServerConfigs.java:160), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStoreKeyPassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithoutKeyStoreKeyPassword/campaign/failures/debug_000003	{"hadoop.http.selector.count": "1640416722"}	["debug_000003"]	org.apache.hadoop.http.TestGlobalFilter#testServletFilter	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestGlobalFilter.testServletFilter(TestGlobalFilter.java:111), org.apache.hadoop.http.TestGlobalFilter.testServletFilter$$CONFUZZ(TestGlobalFilter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestGlobalFilter/testServletFilter/campaign/failures/debug_000000	{"hadoop.http.selector.count": "1065213674"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseDoesNotContainXFrameOptions	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseDoesNotContainXFrameOptions/campaign/failures/debug_000002	{"hadoop.http.selector.count": "1300249951"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServerWithSpnego#testAuthenticationWithProxyUser	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser(TestHttpServerWithSpnego.java:135), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser$$CONFUZZ(TestHttpServerWithSpnego.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerWithSpnego/testAuthenticationWithProxyUser/campaign/failures/debug_000005	{"hadoop.http.selector.count": "2130640638"}	["debug_000005", "debug_000000"]	org.apache.hadoop.http.TestHttpServer#testBacklogSize	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testBacklogSize/campaign/failures/debug_000001	{"hadoop.http.selector.count": "1613152453"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServerLogs#testLogsEnabled	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServerLogs.startServer(TestHttpServerLogs.java:43), org.apache.hadoop.http.TestHttpServerLogs.testLogsEnabled(TestHttpServerLogs.java:63), org.apache.hadoop.http.TestHttpServerLogs.testLogsEnabled$$CONFUZZ(TestHttpServerLogs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLogs/testLogsEnabled/campaign/failures/debug_000001	{"hadoop.http.selector.count": "1747399235"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsDeny	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsDeny/campaign/failures/debug_000001	{"hadoop.http.selector.count": "1273592421"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServer#testAuthorizationOfDefaultServlets	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testAuthorizationOfDefaultServlets/campaign/failures/debug_000003	{"hadoop.http.selector.count": "651713855"}	["debug_000003"]
	Bug-10	Repeated	17	org.apache.hadoop.http.TestSSLHttpServerConfigs#testKeyStoreSetupWithoutPassword	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutPassword(TestSSLHttpServerConfigs.java:252), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutPassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testKeyStoreSetupWithoutPassword/campaign/failures/debug_000004	{"hadoop.http.acceptor.count": "2139131910"}	["debug_000004"]	org.apache.hadoop.http.TestHttpServer#testHttpResponseOverrideDefaultHeaders	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResponseOverrideDefaultHeaders/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "1474308611"}	["debug_000000"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithoutKeyStorePassword	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStorePassword(TestSSLHttpServerConfigs.java:154), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStorePassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithoutKeyStorePassword/campaign/failures/debug_000002	{"hadoop.http.acceptor.count": "1343603804"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServerLifecycle#testCreatedServerIsNotAlive	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:158), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:77), org.apache.hadoop.http.TestHttpServerLifecycle.testCreatedServerIsNotAlive(TestHttpServerLifecycle.java:47), org.apache.hadoop.http.TestHttpServerLifecycle.testCreatedServerIsNotAlive$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testCreatedServerIsNotAlive/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "2130640638"}	["debug_000000", "debug_000001"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testKeyStoreSetupWithoutKeyStorePassword	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutKeyStorePassword(TestSSLHttpServerConfigs.java:230), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutKeyStorePassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testKeyStoreSetupWithoutKeyStorePassword/campaign/failures/debug_000001	{"hadoop.http.acceptor.count": "1099480234"}	["debug_000001"]	org.apache.hadoop.http.TestServletFilter#testServletFilterWhenInitThrowsException	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestServletFilter.testServletFilterWhenInitThrowsException(TestServletFilter.java:173), org.apache.hadoop.http.TestServletFilter.testServletFilterWhenInitThrowsException$$CONFUZZ(TestServletFilter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestServletFilter/testServletFilterWhenInitThrowsException/campaign/failures/debug_000001	{"hadoop.http.acceptor.count": "1509501326"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServer#testPortRanges	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testPortRanges/campaign/failures/debug_000001	{"hadoop.http.acceptor.count": "1541022202"}	["debug_000001"]	org.apache.hadoop.http.TestHttpServerWebapps#testValidServerResource	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:158), org.apache.hadoop.http.TestHttpServerWebapps.testValidServerResource(TestHttpServerWebapps.java:42), org.apache.hadoop.http.TestHttpServerWebapps.testValidServerResource$$CONFUZZ(TestHttpServerWebapps.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerWebapps/testValidServerResource/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "2111408232"}	["debug_000000", "debug_000001"]	org.apache.hadoop.http.TestHttpServer#testDisabledAuthorizationOfDefaultServlets	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testDisabledAuthorizationOfDefaultServlets/campaign/failures/debug_000005	{"hadoop.http.acceptor.count": "1570896972"}	["debug_000005", "debug_000004"]	org.apache.hadoop.http.TestHttpServerLifecycle#testStoppingTwiceServerIsAllowed	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:158), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:77), org.apache.hadoop.http.HttpServerFunctionalTest.createAndStartTestServer(HttpServerFunctionalTest.java:223), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppingTwiceServerIsAllowed(TestHttpServerLifecycle.java:121), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppingTwiceServerIsAllowed$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStoppingTwiceServerIsAllowed/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "1282401977"}	["debug_000000"]	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithoutKeyStoreKeyPassword	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.http.TestSSLHttpServerConfigs.setupServer(TestSSLHttpServerConfigs.java:112), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:123), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStoreKeyPassword(TestSSLHttpServerConfigs.java:160), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStoreKeyPassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithoutKeyStoreKeyPassword/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "1850979288"}	["debug_000000"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsXFrameOptions	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsXFrameOptions/campaign/failures/debug_000006	{"hadoop.http.acceptor.count": "1073815552"}	["debug_000006", "debug_000001"]	org.apache.hadoop.http.TestGlobalFilter#testServletFilter	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestGlobalFilter.testServletFilter(TestGlobalFilter.java:111), org.apache.hadoop.http.TestGlobalFilter.testServletFilter$$CONFUZZ(TestGlobalFilter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestGlobalFilter/testServletFilter/campaign/failures/debug_000002	{"hadoop.http.acceptor.count": "1853088557"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServer#testBacklogSize	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testBacklogSize/campaign/failures/debug_000003	{"hadoop.http.acceptor.count": "1299799375"}	["debug_000003"]	org.apache.hadoop.http.TestHttpServer#testHasAdministratorAccess	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHasAdministratorAccess/campaign/failures/debug_000002	{"hadoop.http.acceptor.count": "770299411"}	["debug_000002", "debug_000003"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsDeny	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsDeny/campaign/failures/debug_000003	{"hadoop.http.acceptor.count": "1057648755"}	["debug_000003"]	org.apache.hadoop.http.TestHttpServer#testAuthorizationOfDefaultServlets	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.server.AbstractConnector.<init>(AbstractConnector.java:228), org.eclipse.jetty.server.AbstractNetworkConnector.<init>(AbstractNetworkConnector.java:44), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:215), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:169), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:92), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:149), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testAuthorizationOfDefaultServlets/campaign/failures/debug_000002	{"hadoop.http.acceptor.count": "572560385"}	["debug_000002"]																																	
	Bug-74	Repeated	8	org.apache.hadoop.security.TestGroupFallback#testNetgroupShell	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.TestGroupFallback.testNetgroupShell(TestGroupFallback.java:59), org.apache.hadoop.security.TestGroupFallback.testNetgroupShell$$CONFUZZ(TestGroupFallback.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupFallback/testNetgroupShell/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000000"]	org.apache.hadoop.security.TestGroupFallback#testGroupWithFallback	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.TestGroupFallback.testGroupWithFallback(TestGroupFallback.java:78), org.apache.hadoop.security.TestGroupFallback.testGroupWithFallback$$CONFUZZ(TestGroupFallback.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupFallback/testGroupWithFallback/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload": "true", "hadoop.security.groups.cache.background.reload.threads": "0"}	["debug_000000"]	org.apache.hadoop.security.TestGroupsCaching#testExceptionsFromImplNotCachedInNegativeCache	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.TestGroupsCaching.testExceptionsFromImplNotCachedInNegativeCache(TestGroupsCaching.java:410), org.apache.hadoop.security.TestGroupsCaching.testExceptionsFromImplNotCachedInNegativeCache$$CONFUZZ(TestGroupsCaching.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupsCaching/testExceptionsFromImplNotCachedInNegativeCache/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000000"]	org.apache.hadoop.security.TestGroupsCaching#testGroupLookupForStaticUsers	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.TestGroupsCaching.testGroupLookupForStaticUsers(TestGroupsCaching.java:309), org.apache.hadoop.security.TestGroupsCaching.testGroupLookupForStaticUsers$$CONFUZZ(TestGroupsCaching.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupsCaching/testGroupLookupForStaticUsers/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000000"]	org.apache.hadoop.security.TestGroupsCaching#testNegativeGroupCaching	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.TestGroupsCaching.testNegativeGroupCaching(TestGroupsCaching.java:340), org.apache.hadoop.security.TestGroupsCaching.testNegativeGroupCaching$$CONFUZZ(TestGroupsCaching.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupsCaching/testNegativeGroupCaching/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000000"]	org.apache.hadoop.security.TestGroupFallback#testNetgroupWithFallback	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.TestGroupFallback.testNetgroupWithFallback(TestGroupFallback.java:97), org.apache.hadoop.security.TestGroupFallback.testNetgroupWithFallback$$CONFUZZ(TestGroupFallback.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupFallback/testNetgroupWithFallback/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000000"]	org.apache.hadoop.security.TestGroupsCaching#testGroupsCaching	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.TestGroupsCaching.testGroupsCaching(TestGroupsCaching.java:229), org.apache.hadoop.security.TestGroupsCaching.testGroupsCaching$$CONFUZZ(TestGroupsCaching.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupsCaching/testGroupsCaching/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000000"]	org.apache.hadoop.security.TestGroupFallback#testGroupShell	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.TestGroupFallback.testGroupShell(TestGroupFallback.java:43), org.apache.hadoop.security.TestGroupFallback.testGroupShell$$CONFUZZ(TestGroupFallback.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupFallback/testGroupShell/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload": "true", "hadoop.security.groups.cache.background.reload.threads": "0"}	["debug_000000"]																																																																																																																																				
			24	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testGetModifyTime	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:165), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetModifyTime(TestSFTPFileSystem.java:356), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetModifyTime$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:165), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetModifyTime(TestSFTPFileSystem.java:356), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testGetModifyTime/campaign/failures/debug_000002	{"io.file.buffer.size": "1658596965", "file.bytes-per-checksum": "506394523"}	["debug_000002"]	org.apache.hadoop.util.TestGenericOptionsParser#testTokenCacheOption	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:325), org.apache.hadoop.util.TestGenericOptionsParser.testTokenCacheOption(TestGenericOptionsParser.java:283), org.apache.hadoop.util.TestGenericOptionsParser.testTokenCacheOption$$CONFUZZ(TestGenericOptionsParser.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:325), org.apache.hadoop.util.TestGenericOptionsParser.testTokenCacheOption(TestGenericOptionsParser.java:283), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.util.TestGenericOptionsParser/testTokenCacheOption/campaign/failures/debug_000000	{"file.bytes-per-checksum": "221343505", "io.file.buffer.size": "1910514806"}	["debug_000000", "debug_000001"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameSymlinkNonExistantDest	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameSymlinkNonExistantDest(SymlinkBaseTest.java:1019), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameSymlinkNonExistantDest/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1617557061", "io.file.buffer.size": "567973646"}	["debug_000003"]	org.apache.hadoop.fs.TestFsShellCopy#testMoveDirFromLocalDestExists	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestFsShellCopy.prepFiles(TestFsShellCopy.java:74), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testMoveDirFromLocalDestExists/campaign/failures/debug_000003	{"io.file.buffer.size": "2068242823", "file.bytes-per-checksum": "2052901350"}	["debug_000003"]	org.apache.hadoop.io.TestSetFile#testSetFileAccessMethods	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:108), org.apache.hadoop.io.SetFile$Writer.<init>(SetFile.java:47), org.apache.hadoop.io.TestSetFile.writeData(TestSetFile.java:87), org.apache.hadoop.io.TestSetFile.testSetFileAccessMethods(TestSetFile.java:68), org.apache.hadoop.io.TestSetFile.testSetFileAccessMethods$$CONFUZZ(TestSetFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170), org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:108), org.apache.hadoop.io.SetFile$Writer.<init>(SetFile.java:47), org.apache.hadoop.io.TestSetFile.writeData(TestSetFile.java:87), org.apache.hadoop.io.TestSetFile.testSetFileAccessMethods(TestSetFile.java:68), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSetFile/testSetFileAccessMethods/campaign/failures/debug_000000	{"io.file.buffer.size": "1653281655", "file.bytes-per-checksum": "2051757920"}	["debug_000000"]	org.apache.hadoop.fs.TestChecksumFileSystem#testRenameFileIntoDir	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemTestHelper.writeFile(FileSystemTestHelper.java:190), org.apache.hadoop.fs.TestChecksumFileSystem.verifyRename(TestChecksumFileSystem.java:299), org.apache.hadoop.fs.TestChecksumFileSystem.testRenameFileIntoDir(TestChecksumFileSystem.java:252), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestChecksumFileSystem/testRenameFileIntoDir/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1652109524", "io.file.buffer.size": "1850278162"}	["debug_000003"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testOverwriteNonEmptyDirectory	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.writeTextFile(ContractTestUtils.java:620), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testOverwriteNonEmptyDirectory(AbstractContractCreateTest.java:181), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testOverwriteNonEmptyDirectory(AbstractContractCreateTest.java:209), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testOverwriteNonEmptyDirectory/campaign/failures/debug_000002	{"io.file.buffer.size": "1852712128", "file.bytes-per-checksum": "1483195081"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestVLong#testVLong4Bytes	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestVLong.writeAndVerify(TestVLong.java:82), org.apache.hadoop.io.file.tfile.TestVLong.testVLong4Bytes(TestVLong.java:114), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestVLong/testVLong4Bytes/campaign/failures/debug_000002	{"file.bytes-per-checksum": "964979584", "io.file.buffer.size": "1185695956"}	["debug_000002"]	org.apache.hadoop.io.TestSequenceFile#testCreateUsesFsArg	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:310), org.apache.hadoop.io.TestSequenceFile.testCreateUsesFsArg(TestSequenceFile.java:555), org.apache.hadoop.io.TestSequenceFile.testCreateUsesFsArg$$CONFUZZ(TestSequenceFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFile/testCreateUsesFsArg/campaign/failures/debug_000001	{"file.bytes-per-checksum": "593086711", "io.file.buffer.size": "1479865538"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureKeyLongerThan64K	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileStreams.setUp(TestTFileStreams.java:76), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.setUp(TestTFileNoneCodecsStreams.java:30), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureKeyLongerThan64K/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1605991775", "io.file.buffer.size": "2023713746"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFile#testMetaBlocks	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFile.createFSOutput(TestTFile.java:277), org.apache.hadoop.io.file.tfile.TestTFile.testMetaBlocks(TestTFile.java:427), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFile/testMetaBlocks/campaign/failures/debug_000001	{"io.file.buffer.size": "896630961", "file.bytes-per-checksum": "1143680812"}	["debug_000001"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testCreateLinkToDot	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testCreateLinkToDot(SymlinkBaseTest.java:772), org.apache.hadoop.fs.TestSymlinkLocalFS.testCreateLinkToDot(TestSymlinkLocalFS.java:218), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testCreateLinkToDot/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1468114202", "io.file.buffer.size": "297652872"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus#testListFilesFileRecursive	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.touch(ContractTestUtils.java:672), org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.touchf(AbstractContractGetFileStatusTest.java:466), org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.testListFilesFileRecursive(AbstractContractGetFileStatusTest.java:413), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus/testListFilesFileRecursive/campaign/failures/debug_000001	{"io.file.buffer.size": "696947392", "file.bytes-per-checksum": "1052546599"}	["debug_000001"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testCreateFileViaSymlink	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testCreateFileViaSymlink(SymlinkBaseTest.java:626), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testCreateFileViaSymlink/campaign/failures/debug_000003	{"file.bytes-per-checksum": "519997093", "io.file.buffer.size": "1264655022"}	["debug_000003"]	org.apache.hadoop.util.TestGenericOptionsParser#testEmptyFilenames	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.util.TestGenericOptionsParser.testEmptyFilenames(TestGenericOptionsParser.java:150), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.util.TestGenericOptionsParser/testEmptyFilenames/campaign/failures/debug_000002	{"file.bytes-per-checksum": "2063131461", "io.file.buffer.size": "577168713"}	["debug_000002"]	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:285), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:634), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:634), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000000	{"io.file.buffer.size": "1279114052", "file.bytes-per-checksum": "105260401"}	["debug_000000", "debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureKeyLongerThan64K	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureKeyLongerThan64K(TestTFileByteArrays.java:426), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureKeyLongerThan64K$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.setUp(TestTFileNoneCodecsByteArrays.java:29), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureKeyLongerThan64K/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1637950872", "io.file.buffer.size": "1065333180"}	["debug_000000"]	org.apache.hadoop.fs.shell.TestPathData#testWithDirStringAndConf	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1134), org.apache.hadoop.fs.FileSystem.createNewFile(FileSystem.java:1439), org.apache.hadoop.fs.shell.TestPathData.initialize(TestPathData.java:61), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestPathData/testWithDirStringAndConf/campaign/failures/debug_000004	{"io.file.buffer.size": "2054222997", "file.bytes-per-checksum": "123"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testNoDataEntry	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testNoDataEntry(TestTFileByteArrays.java:108), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testNoDataEntry$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.setUp(TestTFileNoneCodecsJClassComparatorByteArrays.java:37), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testNoDataEntry/campaign/failures/debug_000001	{"io.file.buffer.size": "274223226", "file.bytes-per-checksum": "1478379627"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testCreateFileOverExistingFileNoOverwrite	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreateFileOverExistingFileNoOverwrite(AbstractContractCreateTest.java:87), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreateFileOverExistingFileNoOverwrite(AbstractContractCreateTest.java:105), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testCreateFileOverExistingFileNoOverwrite/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1182237951", "io.file.buffer.size": "334879460"}	["debug_000003"]
		Filtered	6	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testGetModifyTime	java.lang.AssertionError	Expected: is <1>     but: was <0>	org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20), org.junit.Assert.assertThat(Assert.java:964), org.junit.Assert.assertThat(Assert.java:930), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetModifyTime(TestSFTPFileSystem.java:363), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetModifyTime$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testGetModifyTime/campaign/failures/debug_000004	{"fs.sftp.connection.max": "0"}	["debug_000004"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testCreateFile	java.lang.AssertionError	Expected: is <1>     but: was <0>	org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20), org.junit.Assert.assertThat(Assert.java:964), org.junit.Assert.assertThat(Assert.java:930), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testCreateFile(TestSFTPFileSystem.java:196), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testCreateFile$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testCreateFile/campaign/failures/debug_000000	{"fs.sftp.connection.max": "0"}	["debug_000000"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testCloseFileSystemClosesConnectionPool	java.lang.AssertionError	Expected: is <1>     but: was <0>	org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20), org.junit.Assert.assertThat(Assert.java:964), org.junit.Assert.assertThat(Assert.java:930), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testCloseFileSystemClosesConnectionPool(TestSFTPFileSystem.java:382), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testCloseFileSystemClosesConnectionPool$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testCloseFileSystemClosesConnectionPool/campaign/failures/debug_000000	{"fs.sftp.connection.max": "0"}	["debug_000000"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testStatFile	java.lang.AssertionError	Expected: is <1>     but: was <0>	org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20), org.junit.Assert.assertThat(Assert.java:964), org.junit.Assert.assertThat(Assert.java:930), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testStatFile(TestSFTPFileSystem.java:261), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testStatFile$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testStatFile/campaign/failures/debug_000003	{"fs.sftp.connection.max": "0"}	["debug_000003"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testRenameFile	java.lang.AssertionError	Expected: is <1>     but: was <0>	org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20), org.junit.Assert.assertThat(Assert.java:964), org.junit.Assert.assertThat(Assert.java:930), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testRenameFile(TestSFTPFileSystem.java:311), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testRenameFile$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testRenameFile/campaign/failures/debug_000004	{"fs.sftp.connection.max": "0"}	["debug_000004"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testDeleteNonExistFile	java.lang.AssertionError	Expected: is <1>     but: was <0>	org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20), org.junit.Assert.assertThat(Assert.java:964), org.junit.Assert.assertThat(Assert.java:930), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testDeleteNonExistFile(TestSFTPFileSystem.java:287), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testDeleteNonExistFile$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testDeleteNonExistFile/campaign/failures/debug_000000	{"fs.sftp.connection.max": "0"}	["debug_000000"]																																																																																																																																																										
	Bug-16	Repeated	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testOneEntryKnownLength	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryKnownLength(TestTFileStreams.java:106), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testOneEntryKnownLength$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testOneEntryKnownLength/campaign/failures/debug_000000	{"tfile.fs.input.buffer.size": "1902532711", "file.stream-buffer-size": "1649252750"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testOneEntryKnownLength	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryKnownLength(TestTFileStreams.java:106), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testOneEntryKnownLength/campaign/failures/debug_000002	{"tfile.fs.input.buffer.size": "2140113022"}	["debug_000002"]																																																																																																																																																																																																																	
			15	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testOneEntryKnownLength	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:410), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryKnownLength(TestTFileStreams.java:104), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testOneEntryKnownLength/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "2117554757"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testFailureValueTooShort	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureValueTooShort(TestTFileStreams.java:275), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testFailureValueTooShort/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureKeyTooShort	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureKeyTooShort(TestTFileStreams.java:229), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureKeyTooShort/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "2107038275"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureValueTooShort	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureValueTooShort(TestTFileStreams.java:275), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureValueTooShort/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "2147451006"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryUnknownLength	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Requested array size exceeds VM limit)  java.lang.OutOfMemoryError(Requested array size exceeds VM limit)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Requested array size exceeds VM limit	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:410), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryUnknownLength(TestTFileStreams.java:113), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryUnknownLength/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2147483646"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryMixedLengths1	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:410), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths1(TestTFileStreams.java:125), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryMixedLengths1/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureNegativeOffset	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:410), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureNegativeOffset(TestTFileStreams.java:359), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureNegativeOffset/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "2057373893"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testTwoEntriesKnownLength	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:410), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testTwoEntriesKnownLength(TestTFileStreams.java:144), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testTwoEntriesKnownLength/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2096511347"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testFailureOneEntryKnownLength	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureOneEntryKnownLength(TestTFileStreams.java:189), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testFailureOneEntryKnownLength/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testFailureKeyLongerThan64K	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureKeyLongerThan64K(TestTFileStreams.java:318), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testFailureKeyLongerThan64K/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testFailureCompressionNotWorking	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:410), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureCompressionNotWorking(TestTFileStreams.java:386), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testFailureCompressionNotWorking/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2108585668"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testOneEntryMixedLengths2	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:410), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths2(TestTFileStreams.java:135), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testOneEntryMixedLengths2/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "2124931648"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureCompressionNotWorking	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:410), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureCompressionNotWorking(TestTFileStreams.java:386), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureCompressionNotWorking/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "2129867414"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testFailureValueTooLong	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureValueTooLong(TestTFileStreams.java:249), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testFailureValueTooLong/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "2130640638"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testTwoEntriesKnownLength	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:410), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testTwoEntriesKnownLength(TestTFileStreams.java:144), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testTwoEntriesKnownLength/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "2142244863"}	["debug_000004"]																																																							
			24	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameFileOverExistingFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameFileOverExistingFile(AbstractContractRenameTest.java:100), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameFileOverExistingFile/campaign/failures/debug_000005	{"file.stream-buffer-size": "2102895839"}	["debug_000005"]	org.apache.hadoop.fs.viewfs.TestViewFsTrash#testTrash	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemTestHelper.writeFile(FileSystemTestHelper.java:190), org.apache.hadoop.fs.TestTrash.trashShell(TestTrash.java:161), org.apache.hadoop.fs.viewfs.TestViewFsTrash.testTrash(TestViewFsTrash.java:65), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsTrash/testTrash/campaign/failures/debug_000004	{"file.stream-buffer-size": "2130640638"}	["debug_000004"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics#testWriteByteArrays	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.AbstractContractStreamIOStatisticsTest.testWriteByteArrays(AbstractContractStreamIOStatisticsTest.java:154), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics/testWriteByteArrays/campaign/failures/debug_000001	{"file.stream-buffer-size": "2091321093"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testOneDataEntry	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.setUp(TestTFileJClassComparatorByteArrays.java:41), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testOneDataEntry/campaign/failures/debug_000003	{"file.stream-buffer-size": "2141220126"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testCreateNonRecursive	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.createNonRecursive(ChecksumFileSystem.java:565), org.apache.hadoop.fs.FilterFileSystem.createNonRecursive(FilterFileSystem.java:227), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.createNonRecursive(ChRootedFileSystem.java:206), org.apache.hadoop.fs.viewfs.ViewFileSystem.createNonRecursive(ViewFileSystem.java:454), org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1401), org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1379), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testCreateNonRecursive(ViewFileSystemBaseTest.java:827), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testCreateNonRecursive$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testCreateNonRecursive/campaign/failures/debug_000001	{"file.stream-buffer-size": "2130640638"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractOpen#testOpenFileTwice	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractOpenTest.testOpenFileTwice(AbstractContractOpenTest.java:142), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractOpen/testOpenFileTwice/campaign/failures/debug_000001	{"file.stream-buffer-size": "2078035352"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testGetWrappedInputStream	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testGetWrappedInputStream(FSMainOperationsBaseTest.java:1114), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testGetWrappedInputStream/campaign/failures/debug_000004	{"file.stream-buffer-size": "2130640638"}	["debug_000004"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testRenameAcrossMounts2	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testRenameAcrossMounts2/campaign/failures/debug_000004	{"file.stream-buffer-size": "2130640638"}	["debug_000004"]	org.apache.hadoop.security.alias.TestCredentialProviderFactory#testJksProvider	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:728), org.apache.hadoop.security.alias.KeyStoreProvider.getOutputStreamForKeystore(KeyStoreProvider.java:54), org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.flush(AbstractJavaKeyStoreProvider.java:292), org.apache.hadoop.security.alias.TestCredentialProviderFactory.checkSpecificProvider(TestCredentialProviderFactory.java:164), org.apache.hadoop.security.alias.TestCredentialProviderFactory.testJksProvider(TestCredentialProviderFactory.java:214), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.alias.TestCredentialProviderFactory/testJksProvider/campaign/failures/debug_000003	{"file.stream-buffer-size": "1957650372"}	["debug_000003"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testStatFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testStatFile(TestSFTPFileSystem.java:250), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testStatFile/campaign/failures/debug_000002	{"file.stream-buffer-size": "2126292402"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testRenameAcrossMounts2	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:163), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testRenameAcrossMounts2(ViewFileSystemBaseTest.java:404), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testRenameAcrossMounts2$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testRenameAcrossMounts2/campaign/failures/debug_000001	{"file.stream-buffer-size": "2130640638"}	["debug_000001", "debug_000003"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractMkdir#testNoMkdirOverFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractMkdirTest.testNoMkdirOverFile(AbstractContractMkdirTest.java:66), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractMkdir/testNoMkdirOverFile/campaign/failures/debug_000002	{"file.stream-buffer-size": "2132173886"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testGetContentSummary	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testGetContentSummary/campaign/failures/debug_000005	{"file.stream-buffer-size": "2139685631"}	["debug_000005"]	org.apache.hadoop.io.TestSequenceFile#testCreateUsesFsArg	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFile/testCreateUsesFsArg/campaign/failures/debug_000002	{"file.stream-buffer-size": "2147451933"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testBlockReadZeroByteFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testBlockReadZeroByteFile/campaign/failures/debug_000003	{"file.stream-buffer-size": "2130640638"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testGetContentSummary	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testGetContentSummary/campaign/failures/debug_000004	{"file.stream-buffer-size": "2147458813"}	["debug_000004"]	org.apache.hadoop.fs.TestHarFileSystemBasics#testPositiveNewHarFsOnTheSameUnderlyingFs	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1134), org.apache.hadoop.fs.FileSystem.createNewFile(FileSystem.java:1439), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:84), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testPositiveNewHarFsOnTheSameUnderlyingFs/campaign/failures/debug_000003	{"file.stream-buffer-size": "2128064986"}	["debug_000003"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testSeekBigFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractSeekTest.setup(AbstractContractSeekTest.java:64), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testSeekBigFile/campaign/failures/debug_000003	{"file.stream-buffer-size": "2141290497"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem#testList	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:163), org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testList(TestChRootedFileSystem.java:222), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestChRootedFileSystem/testList/campaign/failures/debug_000002	{"file.stream-buffer-size": "2130640638"}	["debug_000002"]	org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch#testBindUserSwitchPasswordFromAlias	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:728), org.apache.hadoop.security.alias.KeyStoreProvider.getOutputStreamForKeystore(KeyStoreProvider.java:54), org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.flush(AbstractJavaKeyStoreProvider.java:292), org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch.createCredentialForAlias(TestLdapGroupsMappingWithBindUserSwitch.java:171), org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch.testBindUserSwitchPasswordFromAlias(TestLdapGroupsMappingWithBindUserSwitch.java:112), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch/testBindUserSwitchPasswordFromAlias/campaign/failures/debug_000004	{"file.stream-buffer-size": "2132483258"}	["debug_000004"]
			1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameFileOverExistingFile	java.lang.AssertionError	expected rename(file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/iLPaF4Qp9O/source-256.txt, file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/iLPaF4Qp9O/dest-512.txt) to be rejected with false, but destination was overwritten	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertFalse(Assert.java:65), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameFileOverExistingFile(AbstractContractRenameTest.java:123), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename.testRenameFileOverExistingFile$$CONFUZZ(TestLocalFSContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	DIFFERENT	java.lang.AssertionError	rename-overwrites-dest and rename-returns-false-if-dest-exists cannot be both supported	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertFalse(Assert.java:65), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameFileOverExistingFile(AbstractContractRenameTest.java:108), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameFileOverExistingFile/campaign/failures/debug_000000	{"fs.contract.rename-returns-false-if-dest-exists": "true"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameFileOverExistingFile	java.lang.AssertionError	expected rename(file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/HFAtAIg98Y/source-256.txt, file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/HFAtAIg98Y/dest-512.txt) to be rejected with exception, but got overwritten	org.junit.Assert.fail(Assert.java:89), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameFileOverExistingFile(AbstractContractRenameTest.java:129), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename.testRenameFileOverExistingFile$$CONFUZZ(TestLocalFSContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameFileOverExistingFile/campaign/failures/debug_000002	{"fs.defaultFS": "file:///", "fs.contract.rename-overwrites-dest": "false", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "661", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "46121195s", "file.stream-buffer-size": "24285", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "true", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "fs.contract.rename-returns-false-if-dest-exists": "false", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "251", "fs.creation.parallel.count": "1000", "file.bytes-per-checksum": "1001", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "18472", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "31983", "fs.local.block.size": "1613883812", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "23078", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "6858", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "603965401"}	["debug_000002"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameFileOverExistingFile	java.lang.AssertionError	rename-overwrites-dest and rename-returns-false-if-dest-exists cannot be both supported	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertFalse(Assert.java:65), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameFileOverExistingFile(AbstractContractRenameTest.java:108), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename.testRenameFileOverExistingFile$$CONFUZZ(TestLocalFSContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameFileOverExistingFile/campaign/failures/debug_000001	{"fs.contract.rename-returns-false-if-dest-exists": "true"}	["debug_000001"]																																																																																																																																																																																																																	
	Bug-8	Repeated	25	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameFileOverExistingFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameFileOverExistingFile(AbstractContractRenameTest.java:100), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename.testRenameFileOverExistingFile$$CONFUZZ(TestLocalFSContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameFileOverExistingFile/campaign/failures/debug_000004	{"io.file.buffer.size": "1487083736", "file.stream-buffer-size": "574366222"}	["debug_000004"]	org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader#testMountTableFileWithInvalidFormat	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.addMountLinksToFile(ViewFsTestSetup.java:152), org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader.testMountTableFileWithInvalidFormat(TestHCFSMountTableConfigLoader.java:116), org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader.testMountTableFileWithInvalidFormat$$CONFUZZ(TestHCFSMountTableConfigLoader.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader/testMountTableFileWithInvalidFormat/campaign/failures/debug_000000	{"io.file.buffer.size": "1496902917", "file.stream-buffer-size": "1112691723"}	["debug_000000"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testFileStatusBlocksizeEmptyFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.touch(ContractTestUtils.java:672), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testFileStatusBlocksizeEmptyFile(AbstractContractCreateTest.java:302), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testFileStatusBlocksizeEmptyFile$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testFileStatusBlocksizeEmptyFile/campaign/failures/debug_000001	{"io.file.buffer.size": "1603461559", "file.stream-buffer-size": "1465759740"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestVLong#testVLong3Bytes	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestVLong.writeAndVerify(TestVLong.java:82), org.apache.hadoop.io.file.tfile.TestVLong.testVLong3Bytes(TestVLong.java:107), org.apache.hadoop.io.file.tfile.TestVLong.testVLong3Bytes$$CONFUZZ(TestVLong.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestVLong/testVLong3Bytes/campaign/failures/debug_000000	{"file.stream-buffer-size": "1483520389", "io.file.buffer.size": "1579903689"}	["debug_000000", "debug_000001"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameLinkTarget	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameLinkTarget(SymlinkBaseTest.java:1209), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testRenameLinkTarget$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameLinkTarget/campaign/failures/debug_000000	{"io.file.buffer.size": "2047024019", "file.stream-buffer-size": "821750615"}	["debug_000000"]	org.apache.hadoop.fs.TestFsShellCopy#testCopyFileFromLocal	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestFsShellCopy.prepFiles(TestFsShellCopy.java:74), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testCopyFileFromLocal/campaign/failures/debug_000002	{"file.stream-buffer-size": "1203164272", "io.file.buffer.size": "1268721649"}	["debug_000002"]	org.apache.hadoop.fs.TestFsShellCopy#testMoveDirFromLocalDestExists	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestFsShellCopy.prepFiles(TestFsShellCopy.java:74), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testMoveDirFromLocalDestExists/campaign/failures/debug_000002	{"file.stream-buffer-size": "893869686", "io.file.buffer.size": "2007276495"}	["debug_000002"]	org.apache.hadoop.io.TestSetFile#testSetFileAccessMethods	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170), org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:108), org.apache.hadoop.io.SetFile$Writer.<init>(SetFile.java:47), org.apache.hadoop.io.TestSetFile.writeData(TestSetFile.java:87), org.apache.hadoop.io.TestSetFile.testSetFileAccessMethods(TestSetFile.java:68), org.apache.hadoop.io.TestSetFile.testSetFileAccessMethods$$CONFUZZ(TestSetFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSetFile/testSetFileAccessMethods/campaign/failures/debug_000001	{"file.stream-buffer-size": "1826621629", "io.file.buffer.size": "1645981088"}	["debug_000001"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testGetAccessTime	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:165), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetAccessTime(TestSFTPFileSystem.java:341), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetAccessTime$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testGetAccessTime/campaign/failures/debug_000000	{"file.stream-buffer-size": "1842843072", "io.file.buffer.size": "1872438809"}	["debug_000000"]	org.apache.hadoop.fs.TestHarFileSystemBasics#testPositiveLruMetadataCacheFs	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1134), org.apache.hadoop.fs.FileSystem.createNewFile(FileSystem.java:1439), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:84), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testPositiveLruMetadataCacheFs/campaign/failures/debug_000000	{"io.file.buffer.size": "887658899", "file.stream-buffer-size": "1970858149"}	["debug_000000"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testCreateLinkToDirectory	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testCreateLinkToDirectory(SymlinkBaseTest.java:611), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testCreateLinkToDirectory$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testCreateLinkToDirectory/campaign/failures/debug_000001	{"file.stream-buffer-size": "1076183089", "io.file.buffer.size": "1524362146"}	["debug_000001"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testStatLinkToFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testStatLinkToFile(SymlinkBaseTest.java:233), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testStatLinkToFile$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testStatLinkToFile/campaign/failures/debug_000001	{"io.file.buffer.size": "1122829532", "file.stream-buffer-size": "1326846537"}	["debug_000001"]	org.apache.hadoop.fs.TestFsShellCopy#testCopyCrc	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestFsShellCopy.prepFiles(TestFsShellCopy.java:74), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testCopyCrc/campaign/failures/debug_000001	{"file.stream-buffer-size": "1940090854", "io.file.buffer.size": "445102214"}	["debug_000001"]	org.apache.hadoop.fs.TestFileUtil#testWriteBytesFileSystem	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.createNonRecursive(ChecksumFileSystem.java:565), org.apache.hadoop.fs.FileSystem$FileSystemDataOutputStreamBuilder.build(FileSystem.java:4523), org.apache.hadoop.fs.FileUtil.write(FileUtil.java:1690), org.apache.hadoop.fs.TestFileUtil.testWriteBytesFileSystem(TestFileUtil.java:1559), org.apache.hadoop.fs.TestFileUtil.testWriteBytesFileSystem$$CONFUZZ(TestFileUtil.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFileUtil/testWriteBytesFileSystem/campaign/failures/debug_000000	{"file.stream-buffer-size": "951468614", "io.file.buffer.size": "1256034114"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureWriterNotClosed	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.setUp(TestTFileNoneCodecsByteArrays.java:29), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureWriterNotClosed/campaign/failures/debug_000001	{"io.file.buffer.size": "1115374606", "file.stream-buffer-size": "1456771914"}	["debug_000001"]	org.apache.hadoop.util.TestGenericOptionsParser#testEmptyFilenames	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.util.TestGenericOptionsParser.testEmptyFilenames(TestGenericOptionsParser.java:150), org.apache.hadoop.util.TestGenericOptionsParser.testEmptyFilenames$$CONFUZZ(TestGenericOptionsParser.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.util.TestGenericOptionsParser/testEmptyFilenames/campaign/failures/debug_000000	{"file.stream-buffer-size": "1895408703", "io.file.buffer.size": "1127917274"}	["debug_000000"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus#testListStatusFilteredFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.touch(ContractTestUtils.java:672), org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.touchf(AbstractContractGetFileStatusTest.java:466), org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.testListStatusFilteredFile(AbstractContractGetFileStatusTest.java:345), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus.testListStatusFilteredFile$$CONFUZZ(TestLocalFSContractGetFileStatus.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus/testListStatusFilteredFile/campaign/failures/debug_000000	{"io.file.buffer.size": "639618502", "file.stream-buffer-size": "1960016130"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testNoDataEntry	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.setUp(TestTFileNoneCodecsJClassComparatorByteArrays.java:37), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testNoDataEntry/campaign/failures/debug_000000	{"file.stream-buffer-size": "1489403121", "io.file.buffer.size": "796231671"}	["debug_000000"]	org.apache.hadoop.fs.shell.TestFsShellConcat#testUnsupportedFs	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.shell.TestFsShellConcat.before(TestFsShellConcat.java:69), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestFsShellConcat/testUnsupportedFs/campaign/failures/debug_000001	{"file.stream-buffer-size": "1778004281", "io.file.buffer.size": "237001957"}	["debug_000001"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameSymlinkViaSymlink	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameSymlinkViaSymlink(SymlinkBaseTest.java:877), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testRenameSymlinkViaSymlink$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameSymlinkViaSymlink/campaign/failures/debug_000001	{"io.file.buffer.size": "1296337461", "file.stream-buffer-size": "1393892429"}	["debug_000001"]
			18	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testRenameDirectoryAsNonExistentDirectory	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testRenameDirectoryAsNonExistentDirectory/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testOutputStreamClosedTwice	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testOutputStreamClosedTwice/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testListStatusThrowsExceptionForUnreadableDir	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testListStatusThrowsExceptionForUnreadableDir/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testGetWrappedInputStream	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testGetWrappedInputStream/campaign/failures/debug_000001	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testListStatusFilterWithSomeMatches	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testListStatusFilterWithSomeMatches/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testMkdirsFailsForSubdirectoryOfExistingFile	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testMkdirsFailsForSubdirectoryOfExistingFile/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testGlobStatusFilterWithEmptyPathResults	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testGlobStatusFilterWithEmptyPathResults/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testCopyToLocalWithUseRawLocalFileSystemOption	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testCopyToLocalWithUseRawLocalFileSystemOption/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testRenameDirectoryToNonExistentParent	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testRenameDirectoryToNonExistentParent/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testRenameDirectoryToItself	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testRenameDirectoryToItself/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteOneAndAHalfBlocks	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteOneAndAHalfBlocks/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testGlobStatusWithMultipleMatchesOfSingleChar	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testGlobStatusWithMultipleMatchesOfSingleChar/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testGlobStatusThrowsExceptionForUnreadableDir	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testGlobStatusThrowsExceptionForUnreadableDir/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testRenameDirectoryAsFile	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testRenameDirectoryAsFile/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testRenameFileToItself	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testRenameFileToItself/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testOverwrite	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testOverwrite/campaign/failures/debug_000001	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testRenameDirectoryAsNonEmptyDirectory	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testRenameDirectoryAsNonEmptyDirectory/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteTwoBlocks	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.io.IOException(ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key)  java.lang.NullPointerException(null)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.setupForViewFileSystem(ViewFileSystemTestSetup.java:85), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.createFileSystem(TestFSMainOperationsLocalFileSystem.java:38), org.apache.hadoop.fs.FSMainOperationsBaseTest.setUp(FSMainOperationsBaseTest.java:99), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.setUp(TestFSMainOperationsLocalFileSystem.java:47), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteTwoBlocks/campaign/failures/debug_000000	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000000"]																						
	Bug-7	Repeated	55	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractGetFileStatus#testListStatusFilteredFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.touch(ContractTestUtils.java:672), org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.touchf(AbstractContractGetFileStatusTest.java:466), org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.testListStatusFilteredFile(AbstractContractGetFileStatusTest.java:345), org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractGetFileStatus.testListStatusFilteredFile$$CONFUZZ(TestRawlocalContractGetFileStatus.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractGetFileStatus/testListStatusFilteredFile/campaign/failures/debug_000000	{"io.file.buffer.size": "2130640638"}	["debug_000000"]	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testCopyFileOverwrite	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:418), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2482), org.apache.hadoop.fs.FilterFileSystem.copyFromLocalFile(FilterFileSystem.java:376), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:303), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:296), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testCopyFileOverwrite(AbstractContractCopyFromLocalTest.java:88), org.apache.hadoop.fs.TestLocalFSCopyFromLocal.testCopyFileOverwrite$$CONFUZZ(TestLocalFSCopyFromLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testCopyFileOverwrite/campaign/failures/debug_000001	{"io.file.buffer.size": "1236601162"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem#testLocalFsCreateAndDelete	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1134), org.apache.hadoop.fs.FileSystem.createNewFile(FileSystem.java:1439), org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem.testLocalFsCreateAndDelete(TestViewFileSystemOverloadSchemeLocalFileSystem.java:113), org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem.testLocalFsCreateAndDelete$$CONFUZZ(TestViewFileSystemOverloadSchemeLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem/testLocalFsCreateAndDelete/campaign/failures/debug_000000	{"io.file.buffer.size": "2147483390"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testOutputStreamClosedTwice	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FSMainOperationsBaseTest.testOutputStreamClosedTwice(FSMainOperationsBaseTest.java:1103), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testOutputStreamClosedTwice$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testOutputStreamClosedTwice/campaign/failures/debug_000001	{"io.file.buffer.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testFileStatusBlocksizeEmptyFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.touch(ContractTestUtils.java:672), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testFileStatusBlocksizeEmptyFile(AbstractContractCreateTest.java:302), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testFileStatusBlocksizeEmptyFile$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testFileStatusBlocksizeEmptyFile/campaign/failures/debug_000000	{"io.file.buffer.size": "2109288790"}	["debug_000000"]	org.apache.hadoop.fs.TestFsShellCopy#testRepresentsDir	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.create(CommandWithDestination.java:532), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:494), org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:417), org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:352), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.copyFileToTarget(CopyCommandWithMultiThread.java:144), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:287), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:272), org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:370), org.apache.hadoop.fs.shell.Command.processPaths(Command.java:333), org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:306), org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:267), org.apache.hadoop.fs.shell.Command.processArgument(Command.java:288), org.apache.hadoop.fs.shell.Command.processArguments(Command.java:272), org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:238), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.processArguments(CopyCommandWithMultiThread.java:89), org.apache.hadoop.fs.shell.CopyCommands$Put.processArguments(CopyCommands.java:312), org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:121), org.apache.hadoop.fs.shell.Command.run(Command.java:179), org.apache.hadoop.fs.FsShell.run(FsShell.java:327), org.apache.hadoop.fs.TestFsShellCopy.testRepresentsDir(TestFsShellCopy.java:297), org.apache.hadoop.fs.TestFsShellCopy.testRepresentsDir$$CONFUZZ(TestFsShellCopy.java),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testRepresentsDir/campaign/failures/debug_000002	{"io.file.buffer.size": "1147328348"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testMkdirUnderFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractCreateTest.createFile(AbstractContractCreateTest.java:447), org.apache.hadoop.fs.contract.AbstractContractCreateTest.expectMkdirsUnderFileFails(AbstractContractCreateTest.java:430), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testMkdirUnderFile(AbstractContractCreateTest.java:377), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testMkdirUnderFile$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testMkdirUnderFile/campaign/failures/debug_000000	{"io.file.buffer.size": "2080538672"}	["debug_000000"]	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractAppend#testBuilderAppendToExistingFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractAppendTest.testBuilderAppendToExistingFile(AbstractContractAppendTest.java:110), org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractAppend.testBuilderAppendToExistingFile$$CONFUZZ(TestRawlocalContractAppend.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractAppend/testBuilderAppendToExistingFile/campaign/failures/debug_000001	{"io.file.buffer.size": "2107706687"}	["debug_000001"]	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testSourceIsDirectoryAndDestinationIsFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:418), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2482), org.apache.hadoop.fs.FilterFileSystem.copyFromLocalFile(FilterFileSystem.java:376), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:303), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:296), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testSourceIsDirectoryAndDestinationIsFile(AbstractContractCopyFromLocalTest.java:271), org.apache.hadoop.fs.TestLocalFSCopyFromLocal.testSourceIsDirectoryAndDestinationIsFile$$CONFUZZ(TestLocalFSCopyFromLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testSourceIsDirectoryAndDestinationIsFile/campaign/failures/debug_000001	{"io.file.buffer.size": "1863964001"}	["debug_000001"]	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate#testOverwriteExistingFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testOverwriteExistingFile(AbstractContractCreateTest.java:114), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testOverwriteExistingFile(AbstractContractCreateTest.java:130), org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate.testOverwriteExistingFile$$CONFUZZ(TestRawlocalContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate/testOverwriteExistingFile/campaign/failures/debug_000000	{"io.file.buffer.size": "2145853236"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testNflyWriteSimple	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.NflyFSystem$NflyOutputStream.<init>(NflyFSystem.java:301), org.apache.hadoop.fs.viewfs.NflyFSystem$NflyOutputStream.<init>(NflyFSystem.java:283), org.apache.hadoop.fs.viewfs.NflyFSystem.create(NflyFSystem.java:727), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testNflyWriteSimple(TestViewFileSystemLocalFileSystem.java:78), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testNflyWriteSimple$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testNflyWriteSimple/campaign/failures/debug_000002	{"io.file.buffer.size": "1006964178"}	["debug_000002"]	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractDelete#testDeleteNonEmptyDirRecursive	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.writeTextFile(ContractTestUtils.java:620), org.apache.hadoop.fs.contract.AbstractContractDeleteTest.testDeleteNonEmptyDirRecursive(AbstractContractDeleteTest.java:91), org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractDelete.testDeleteNonEmptyDirRecursive$$CONFUZZ(TestRawlocalContractDelete.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractDelete/testDeleteNonEmptyDirRecursive/campaign/failures/debug_000000	{"io.file.buffer.size": "2105810872"}	["debug_000000"]	org.apache.hadoop.security.alias.TestCredentialProviderFactory#testJksProvider	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:728), org.apache.hadoop.security.alias.KeyStoreProvider.getOutputStreamForKeystore(KeyStoreProvider.java:54), org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.flush(AbstractJavaKeyStoreProvider.java:292), org.apache.hadoop.security.alias.TestCredentialProviderFactory.checkSpecificProvider(TestCredentialProviderFactory.java:164), org.apache.hadoop.security.alias.TestCredentialProviderFactory.testJksProvider(TestCredentialProviderFactory.java:214), org.apache.hadoop.security.alias.TestCredentialProviderFactory.testJksProvider$$CONFUZZ(TestCredentialProviderFactory.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.alias.TestCredentialProviderFactory/testJksProvider/campaign/failures/debug_000002	{"io.file.buffer.size": "2073515849"}	["debug_000002"]	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testSourceIsFileAndDestinationIsNonExistentDirectory	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:418), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:341), org.apache.hadoop.fs.LocalFileSystem.copyFromLocalFile(LocalFileSystem.java:82), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2411), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testSourceIsFileAndDestinationIsNonExistentDirectory(AbstractContractCopyFromLocalTest.java:150), org.apache.hadoop.fs.TestLocalFSCopyFromLocal.testSourceIsFileAndDestinationIsNonExistentDirectory$$CONFUZZ(TestLocalFSCopyFromLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testSourceIsFileAndDestinationIsNonExistentDirectory/campaign/failures/debug_000002	{"io.file.buffer.size": "2052939587"}	["debug_000002"]	org.apache.hadoop.fs.TestRawLocalFileSystemContract#testZeroByteFilesAreFiles	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemContractBaseTest.testZeroByteFilesAreFiles(FileSystemContractBaseTest.java:669), org.apache.hadoop.fs.TestRawLocalFileSystemContract.testZeroByteFilesAreFiles$$CONFUZZ(TestRawLocalFileSystemContract.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestRawLocalFileSystemContract/testZeroByteFilesAreFiles/campaign/failures/debug_000000	{"io.file.buffer.size": "2137562788"}	["debug_000000"]	org.apache.hadoop.fs.TestRawLocalFileSystemContract#testMkdirsFailsForSubdirectoryOfExistingFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemContractBaseTest.createFile(FileSystemContractBaseTest.java:588), org.apache.hadoop.fs.FileSystemContractBaseTest.testMkdirsFailsForSubdirectoryOfExistingFile(FileSystemContractBaseTest.java:220), org.apache.hadoop.fs.TestRawLocalFileSystemContract.testMkdirsFailsForSubdirectoryOfExistingFile$$CONFUZZ(TestRawLocalFileSystemContract.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestRawLocalFileSystemContract/testMkdirsFailsForSubdirectoryOfExistingFile/campaign/failures/debug_000000	{"io.file.buffer.size": "2137921227"}	["debug_000000"]	org.apache.hadoop.io.TestSequenceFile#testZlibSequenceFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.SequenceFile$Sorter$SortPass.flush(SequenceFile.java:3100), org.apache.hadoop.io.SequenceFile$Sorter$SortPass.run(SequenceFile.java:3051), org.apache.hadoop.io.SequenceFile$Sorter.sortPass(SequenceFile.java:2949), org.apache.hadoop.io.SequenceFile$Sorter.sort(SequenceFile.java:2897), org.apache.hadoop.io.SequenceFile$Sorter.sort(SequenceFile.java:2938), org.apache.hadoop.io.TestSequenceFile.sortTest(TestSequenceFile.java:286), org.apache.hadoop.io.TestSequenceFile.compressedSeqFileTest(TestSequenceFile.java:145), org.apache.hadoop.io.TestSequenceFile.testZlibSequenceFile(TestSequenceFile.java:57), org.apache.hadoop.io.TestSequenceFile.testZlibSequenceFile$$CONFUZZ(TestSequenceFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFile/testZlibSequenceFile/campaign/failures/debug_000001	{"io.file.buffer.size": "1466676729"}	["debug_000001"]	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename#testRenameDirIntoExistingDir	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:418), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:409), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:341), org.apache.hadoop.fs.RawLocalFileSystem.rename(RawLocalFileSystem.java:505), org.apache.hadoop.fs.contract.AbstractFSContractTestBase.rename(AbstractFSContractTestBase.java:386), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameDirIntoExistingDir(AbstractContractRenameTest.java:168), org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename.testRenameDirIntoExistingDir$$CONFUZZ(TestRawlocalContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename/testRenameDirIntoExistingDir/campaign/failures/debug_000001	{"io.file.buffer.size": "1398525151"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameWithNonEmptySubDir	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.writeTextFile(ContractTestUtils.java:620), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameWithNonEmptySubDir(AbstractContractRenameTest.java:213), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename.testRenameWithNonEmptySubDir$$CONFUZZ(TestLocalFSContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameWithNonEmptySubDir/campaign/failures/debug_000002	{"io.file.buffer.size": "2076313429"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testCopyToLocalWithUseRawLocalFileSystemOption	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeFile(FSMainOperationsBaseTest.java:1138), org.apache.hadoop.fs.FSMainOperationsBaseTest.testCopyToLocalWithUseRawLocalFileSystemOption(FSMainOperationsBaseTest.java:1129), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testCopyToLocalWithUseRawLocalFileSystemOption$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testCopyToLocalWithUseRawLocalFileSystemOption/campaign/failures/debug_000001	{"io.file.buffer.size": "2130640638"}	["debug_000001"]
			56	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractGetFileStatus#testListStatusFilteredFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.touch(ContractTestUtils.java:672), org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.touchf(AbstractContractGetFileStatusTest.java:466), org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.testListStatusFilteredFile(AbstractContractGetFileStatusTest.java:345), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractGetFileStatus/testListStatusFilteredFile/campaign/failures/debug_000001	{"io.file.buffer.size": "2141192206"}	["debug_000001"]	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testCopyFileOverwrite	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:418), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2482), org.apache.hadoop.fs.FilterFileSystem.copyFromLocalFile(FilterFileSystem.java:376), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:303), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:296), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testCopyFileOverwrite(AbstractContractCopyFromLocalTest.java:88), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testCopyFileOverwrite/campaign/failures/debug_000002	{"io.file.buffer.size": "1765540639"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testOutputStreamClosedTwice	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FSMainOperationsBaseTest.testOutputStreamClosedTwice(FSMainOperationsBaseTest.java:1103), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testOutputStreamClosedTwice/campaign/failures/debug_000003	{"io.file.buffer.size": "2141200126"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader#testMountTableFileWithInvalidFormat	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.addMountLinksToFile(ViewFsTestSetup.java:152), org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader.testMountTableFileWithInvalidFormat(TestHCFSMountTableConfigLoader.java:116), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader/testMountTableFileWithInvalidFormat/campaign/failures/debug_000001	{"io.file.buffer.size": "2130673407"}	["debug_000001"]	org.apache.hadoop.fs.TestRawLocalFileSystemContract#testWriteReadAndDeleteEmptyFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(FileSystemContractBaseTest.java:927), org.apache.hadoop.fs.FileSystemContractBaseTest.writeReadAndDelete(FileSystemContractBaseTest.java:359), org.apache.hadoop.fs.FileSystemContractBaseTest.testWriteReadAndDeleteEmptyFile(FileSystemContractBaseTest.java:328), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestRawLocalFileSystemContract/testWriteReadAndDeleteEmptyFile/campaign/failures/debug_000001	{"io.file.buffer.size": "2101391935"}	["debug_000001"]	org.apache.hadoop.fs.TestFsShellCopy#testRepresentsDir	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.create(CommandWithDestination.java:532), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:494), org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:417), org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:352), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.copyFileToTarget(CopyCommandWithMultiThread.java:144), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:287), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:272), org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:370), org.apache.hadoop.fs.shell.Command.processPaths(Command.java:333), org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:306), org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:267), org.apache.hadoop.fs.shell.Command.processArgument(Command.java:288), org.apache.hadoop.fs.shell.Command.processArguments(Command.java:272), org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:238), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.processArguments(CopyCommandWithMultiThread.java:89), org.apache.hadoop.fs.shell.CopyCommands$Put.processArguments(CopyCommands.java:312), org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:121), org.apache.hadoop.fs.shell.Command.run(Command.java:179), org.apache.hadoop.fs.FsShell.run(FsShell.java:327), org.apache.hadoop.fs.TestFsShellCopy.testRepresentsDir(TestFsShellCopy.java:297), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testRepresentsDir/campaign/failures/debug_000003	{"io.file.buffer.size": "1601575211"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestVLong#testVLong3Bytes	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestVLong.writeAndVerify(TestVLong.java:82), org.apache.hadoop.io.file.tfile.TestVLong.testVLong3Bytes(TestVLong.java:107), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestVLong/testVLong3Bytes/campaign/failures/debug_000003	{"io.file.buffer.size": "2110432646"}	["debug_000003"]	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractAppend#testBuilderAppendToExistingFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractAppendTest.testBuilderAppendToExistingFile(AbstractContractAppendTest.java:110), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractAppend/testBuilderAppendToExistingFile/campaign/failures/debug_000002	{"io.file.buffer.size": "2081057973"}	["debug_000002"]	org.apache.hadoop.security.token.TestDtUtilShell#testGet	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.token.DtFileOperations.doFormattedWrite(DtFileOperations.java:113), org.apache.hadoop.security.token.DtFileOperations.getTokenFile(DtFileOperations.java:219), org.apache.hadoop.security.token.DtUtilShell$Get.execute(DtUtilShell.java:243), org.apache.hadoop.tools.CommandShell.run(CommandShell.java:72), org.apache.hadoop.security.token.TestDtUtilShell.testGet(TestDtUtilShell.java:224), org.apache.hadoop.security.token.TestDtUtilShell.testGet$$CONFUZZ(TestDtUtilShell.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.token.TestDtUtilShell.makeTokenFile(TestDtUtilShell.java:124), org.apache.hadoop.security.token.TestDtUtilShell.setup(TestDtUtilShell.java:95), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.TestDtUtilShell/testGet/campaign/failures/debug_000002	{"io.file.buffer.size": "2147455598"}	["debug_000002"]	org.apache.hadoop.fs.TestRawLocalFileSystemContract#testWriteReadAndDeleteTwoBlocks	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(FileSystemContractBaseTest.java:927), org.apache.hadoop.fs.FileSystemContractBaseTest.writeReadAndDelete(FileSystemContractBaseTest.java:359), org.apache.hadoop.fs.FileSystemContractBaseTest.testWriteReadAndDeleteTwoBlocks(FileSystemContractBaseTest.java:348), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestRawLocalFileSystemContract/testWriteReadAndDeleteTwoBlocks/campaign/failures/debug_000001	{"io.file.buffer.size": "2104025786"}	["debug_000001"]	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractDelete#testDeleteNonEmptyDirRecursive	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.writeTextFile(ContractTestUtils.java:620), org.apache.hadoop.fs.contract.AbstractContractDeleteTest.testDeleteNonEmptyDirRecursive(AbstractContractDeleteTest.java:91), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractDelete/testDeleteNonEmptyDirRecursive/campaign/failures/debug_000001	{"io.file.buffer.size": "2129673080"}	["debug_000001"]	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testSourceIsFileAndDestinationIsNonExistentDirectory	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:418), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:341), org.apache.hadoop.fs.LocalFileSystem.copyFromLocalFile(LocalFileSystem.java:82), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2411), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testSourceIsFileAndDestinationIsNonExistentDirectory(AbstractContractCopyFromLocalTest.java:150), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testSourceIsFileAndDestinationIsNonExistentDirectory/campaign/failures/debug_000003	{"io.file.buffer.size": "2031124992"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader#testMountTableFileLoadingWhenMultipleFilesExist	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.viewfs.ViewFsTestSetup.addMountLinksToFile(ViewFsTestSetup.java:152), org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader.testMountTableFileLoadingWhenMultipleFilesExist(TestHCFSMountTableConfigLoader.java:98), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestHCFSMountTableConfigLoader/testMountTableFileLoadingWhenMultipleFilesExist/campaign/failures/debug_000002	{"io.file.buffer.size": "2147483390"}	["debug_000002"]	org.apache.hadoop.fs.TestRawLocalFileSystemContract#testZeroByteFilesAreFiles	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemContractBaseTest.testZeroByteFilesAreFiles(FileSystemContractBaseTest.java:669), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestRawLocalFileSystemContract/testZeroByteFilesAreFiles/campaign/failures/debug_000001	{"io.file.buffer.size": "2147450881"}	["debug_000001"]	org.apache.hadoop.fs.TestRawLocalFileSystemContract#testMkdirsFailsForSubdirectoryOfExistingFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemContractBaseTest.createFile(FileSystemContractBaseTest.java:588), org.apache.hadoop.fs.FileSystemContractBaseTest.testMkdirsFailsForSubdirectoryOfExistingFile(FileSystemContractBaseTest.java:220), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestRawLocalFileSystemContract/testMkdirsFailsForSubdirectoryOfExistingFile/campaign/failures/debug_000001	{"io.file.buffer.size": "2139176702"}	["debug_000001"]	org.apache.hadoop.io.TestSequenceFile#testZlibSequenceFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.SequenceFile$Sorter$SortPass.flush(SequenceFile.java:3102), org.apache.hadoop.io.SequenceFile$Sorter$SortPass.run(SequenceFile.java:3051), org.apache.hadoop.io.SequenceFile$Sorter.sortPass(SequenceFile.java:2949), org.apache.hadoop.io.SequenceFile$Sorter.sort(SequenceFile.java:2897), org.apache.hadoop.io.SequenceFile$Sorter.sort(SequenceFile.java:2938), org.apache.hadoop.io.TestSequenceFile.sortTest(TestSequenceFile.java:286), org.apache.hadoop.io.TestSequenceFile.compressedSeqFileTest(TestSequenceFile.java:145), org.apache.hadoop.io.TestSequenceFile.testZlibSequenceFile(TestSequenceFile.java:57), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFile/testZlibSequenceFile/campaign/failures/debug_000002	{"io.file.buffer.size": "907213179"}	["debug_000002"]	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename#testRenameDirIntoExistingDir	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:418), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:409), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:341), org.apache.hadoop.fs.RawLocalFileSystem.rename(RawLocalFileSystem.java:505), org.apache.hadoop.fs.contract.AbstractFSContractTestBase.rename(AbstractFSContractTestBase.java:386), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameDirIntoExistingDir(AbstractContractRenameTest.java:168), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename/testRenameDirIntoExistingDir/campaign/failures/debug_000002	{"io.file.buffer.size": "1525703768"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testCopyToLocalWithUseRawLocalFileSystemOption	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:418), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:341), org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2547), org.apache.hadoop.fs.FSMainOperationsBaseTest.testCopyToLocalWithUseRawLocalFileSystemOption(FSMainOperationsBaseTest.java:1133), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testCopyToLocalWithUseRawLocalFileSystemOption/campaign/failures/debug_000003	{"io.file.buffer.size": "1957264359"}	["debug_000003"]	org.apache.hadoop.fs.TestRawLocalFileSystemContract#testInputStreamClosedTwice	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemContractBaseTest.createFile(FileSystemContractBaseTest.java:588), org.apache.hadoop.fs.FileSystemContractBaseTest.testInputStreamClosedTwice(FileSystemContractBaseTest.java:570), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestRawLocalFileSystemContract/testInputStreamClosedTwice/campaign/failures/debug_000001	{"io.file.buffer.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameDirIntoExistingDir	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameDirIntoExistingDir(AbstractContractRenameTest.java:160), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameDirIntoExistingDir/campaign/failures/debug_000003	{"io.file.buffer.size": "2130640638"}	["debug_000003"]
			7	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem#testGetStoragePolicy	org.mockito.exceptions.verification.TooManyActualInvocations	fileSystem.getStoragePolicy(    /a/b/storagePolicy);Wanted 1 time:-> at org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testGetStoragePolicy(TestChRootedFileSystem.java:538)But was 2 times:-> at org.apache.hadoop.fs.FilterFileSystem.getStoragePolicy(FilterFileSystem.java:680)-> at org.apache.hadoop.fs.FilterFileSystem.getStoragePolicy(FilterFileSystem.java:680)	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testGetStoragePolicy(TestChRootedFileSystem.java:538), org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testGetStoragePolicy$$CONFUZZ(TestChRootedFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestChRootedFileSystem/testGetStoragePolicy/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem#testGetAllStoragePolicy	org.mockito.exceptions.verification.TooManyActualInvocations	fileSystem.getAllStoragePolicies();Wanted 1 time:-> at org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testGetAllStoragePolicy(TestChRootedFileSystem.java:552)But was 2 times:-> at org.apache.hadoop.fs.FilterFileSystem.getAllStoragePolicies(FilterFileSystem.java:686)-> at org.apache.hadoop.fs.FilterFileSystem.getAllStoragePolicies(FilterFileSystem.java:686)	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testGetAllStoragePolicy(TestChRootedFileSystem.java:552), org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testGetAllStoragePolicy$$CONFUZZ(TestChRootedFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestChRootedFileSystem/testGetAllStoragePolicy/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem#testSetStoragePolicy	org.mockito.exceptions.verification.TooManyActualInvocations	fileSystem.setStoragePolicy(    /a/b/storagePolicy,    "HOT");Wanted 1 time:-> at org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testSetStoragePolicy(TestChRootedFileSystem.java:504)But was 2 times:-> at org.apache.hadoop.fs.FilterFileSystem.setStoragePolicy(FilterFileSystem.java:669)-> at org.apache.hadoop.fs.FilterFileSystem.setStoragePolicy(FilterFileSystem.java:669)	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testSetStoragePolicy(TestChRootedFileSystem.java:504), org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testSetStoragePolicy$$CONFUZZ(TestChRootedFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestChRootedFileSystem/testSetStoragePolicy/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem#testAclMethodsPathTranslation	org.mockito.exceptions.verification.TooManyActualInvocations	fileSystem.modifyAclEntries(/a/b/c, []);Wanted 1 time:-> at org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testAclMethodsPathTranslation(TestChRootedFileSystem.java:380)But was 2 times:-> at org.apache.hadoop.fs.FilterFileSystem.modifyAclEntries(FilterFileSystem.java:594)-> at org.apache.hadoop.fs.FilterFileSystem.modifyAclEntries(FilterFileSystem.java:594)	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testAclMethodsPathTranslation(TestChRootedFileSystem.java:380), org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testAclMethodsPathTranslation$$CONFUZZ(TestChRootedFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestChRootedFileSystem/testAclMethodsPathTranslation/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem#testListLocatedFileStatus	org.mockito.exceptions.verification.TooManyActualInvocations	fileSystem.listLocatedStatus(/user);Wanted 1 time:-> at org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testListLocatedFileStatus(TestChRootedFileSystem.java:410)But was 2 times:-> at org.apache.hadoop.fs.FilterFileSystem.listLocatedStatus(FilterFileSystem.java:287)-> at org.apache.hadoop.fs.FilterFileSystem.listLocatedStatus(FilterFileSystem.java:287)	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testListLocatedFileStatus(TestChRootedFileSystem.java:410), org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testListLocatedFileStatus$$CONFUZZ(TestChRootedFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestChRootedFileSystem/testListLocatedFileStatus/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem#testDeleteSnapshot	org.mockito.exceptions.verification.TooManyActualInvocations	fileSystem.deleteSnapshot(    /a/b/snapPath,    "snap1");Wanted 1 time:-> at org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testDeleteSnapshot(TestChRootedFileSystem.java:469)But was 2 times:-> at org.apache.hadoop.fs.FilterFileSystem.deleteSnapshot(FilterFileSystem.java:588)-> at org.apache.hadoop.fs.FilterFileSystem.deleteSnapshot(FilterFileSystem.java:588)	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testDeleteSnapshot(TestChRootedFileSystem.java:469), org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testDeleteSnapshot$$CONFUZZ(TestChRootedFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestChRootedFileSystem/testDeleteSnapshot/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem#testRenameSnapshot	org.mockito.exceptions.verification.TooManyActualInvocations	fileSystem.renameSnapshot(    /a/b/snapPath,    "snapOldName",    "snapNewName");Wanted 1 time:-> at org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testRenameSnapshot(TestChRootedFileSystem.java:486)But was 2 times:-> at org.apache.hadoop.fs.FilterFileSystem.renameSnapshot(FilterFileSystem.java:582)-> at org.apache.hadoop.fs.FilterFileSystem.renameSnapshot(FilterFileSystem.java:582)	org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testRenameSnapshot(TestChRootedFileSystem.java:486), org.apache.hadoop.fs.viewfs.TestChRootedFileSystem.testRenameSnapshot$$CONFUZZ(TestChRootedFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestChRootedFileSystem/testRenameSnapshot/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																															
		FP	2	org.apache.hadoop.ha.TestZKFailoverController#testOneOfEverything	org.apache.zookeeper.KeeperException$NoNodeException	KeeperErrorCode = NoNode	org.apache.zookeeper.server.DataTree.getData(DataTree.java:657), org.apache.zookeeper.server.ZKDatabase.getData(ZKDatabase.java:467), org.apache.hadoop.ha.MiniZKFCCluster.expireActiveLockHolder(MiniZKFCCluster.java:242), org.apache.hadoop.ha.MiniZKFCCluster.expireAndVerifyFailover(MiniZKFCCluster.java:277), org.apache.hadoop.ha.TestZKFailoverController.testOneOfEverything(TestZKFailoverController.java:625), org.apache.hadoop.ha.TestZKFailoverController.testOneOfEverything$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testOneOfEverything/campaign/failures/debug_000000	{"ha.zookeeper.parent-znode": "/shuai"}	["debug_000000"]	org.apache.hadoop.ha.TestZKFailoverController#testDontFailoverToUnhealthyNode	org.apache.zookeeper.KeeperException$NoNodeException	KeeperErrorCode = NoNode	org.apache.zookeeper.server.DataTree.getData(DataTree.java:657), org.apache.zookeeper.server.ZKDatabase.getData(ZKDatabase.java:467), org.apache.hadoop.ha.MiniZKFCCluster.expireActiveLockHolder(MiniZKFCCluster.java:242), org.apache.hadoop.ha.TestZKFailoverController.testDontFailoverToUnhealthyNode(TestZKFailoverController.java:345), org.apache.hadoop.ha.TestZKFailoverController.testDontFailoverToUnhealthyNode$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testDontFailoverToUnhealthyNode/campaign/failures/debug_000001	{"ha.zookeeper.parent-znode": "/shuai"}	["debug_000001"]																																																																																																																																																																																																						
		FP	1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics#testWriteByteArrays	org.junit.ComparisonFailure	[Counter named stream_write_bytes with expected value 0] expected:<[0]L> but was:<[28]L>	org.apache.hadoop.fs.statistics.IOStatisticAssertions.verifyStatisticValue(IOStatisticAssertions.java:255), org.apache.hadoop.fs.statistics.IOStatisticAssertions.verifyStatisticCounterValue(IOStatisticAssertions.java:173), org.apache.hadoop.fs.contract.AbstractContractStreamIOStatisticsTest.testWriteByteArrays(AbstractContractStreamIOStatisticsTest.java:168), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics.testWriteByteArrays$$CONFUZZ(TestLocalFSContractStreamIOStatistics.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics/testWriteByteArrays/campaign/failures/debug_000003	{"file.bytes-per-checksum": "28", "io.file.buffer.size": "24"}	["debug_000003"]																																																																																																																																																																																																																	
			8	org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal#testSilentFailedWrite	org.apache.hadoop.metrics2.MetricsException	Metrics source testSilentFailedWrite$$CONFUZZ-m1 already exists!	org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newSourceName(DefaultMetricsSystem.java:152), org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.sourceName(DefaultMetricsSystem.java:125), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:229), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase$MyMetrics1.registerWith(RollingFileSystemSinkTestBase.java:102), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testSilentFailedWrite(TestRollingFileSystemSinkWithLocal.java:137), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testSilentFailedWrite$$CONFUZZ(TestRollingFileSystemSinkWithLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal/testSilentFailedWrite/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal#testWrite	org.apache.hadoop.metrics2.MetricsException	Metrics source testWrite$$CONFUZZ-m1 already exists!	org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newSourceName(DefaultMetricsSystem.java:152), org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.sourceName(DefaultMetricsSystem.java:125), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:229), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase$MyMetrics1.registerWith(RollingFileSystemSinkTestBase.java:102), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase.doWriteTest(RollingFileSystemSinkTestBase.java:218), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testWrite(TestRollingFileSystemSinkWithLocal.java:43), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testWrite$$CONFUZZ(TestRollingFileSystemSinkWithLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal/testWrite/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal#testSilentWrite	org.apache.hadoop.metrics2.MetricsException	Metrics source testSilentWrite$$CONFUZZ-m1 already exists!	org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newSourceName(DefaultMetricsSystem.java:152), org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.sourceName(DefaultMetricsSystem.java:125), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:229), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase$MyMetrics1.registerWith(RollingFileSystemSinkTestBase.java:102), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase.doWriteTest(RollingFileSystemSinkTestBase.java:218), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testSilentWrite(TestRollingFileSystemSinkWithLocal.java:56), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testSilentWrite$$CONFUZZ(TestRollingFileSystemSinkWithLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal/testSilentWrite/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal#testExistingWrite2	org.apache.hadoop.metrics2.MetricsException	Metrics source testExistingWrite2$$CONFUZZ-m1 already exists!	org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newSourceName(DefaultMetricsSystem.java:152), org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.sourceName(DefaultMetricsSystem.java:125), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:229), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase$MyMetrics1.registerWith(RollingFileSystemSinkTestBase.java:102), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase.doWriteTest(RollingFileSystemSinkTestBase.java:218), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testExistingWrite2(TestRollingFileSystemSinkWithLocal.java:84), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testExistingWrite2$$CONFUZZ(TestRollingFileSystemSinkWithLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal/testExistingWrite2/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal#testSilentExistingWrite	org.apache.hadoop.metrics2.MetricsException	Metrics source testSilentExistingWrite$$CONFUZZ-m1 already exists!	org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newSourceName(DefaultMetricsSystem.java:152), org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.sourceName(DefaultMetricsSystem.java:125), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:229), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase$MyMetrics1.registerWith(RollingFileSystemSinkTestBase.java:102), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase.doWriteTest(RollingFileSystemSinkTestBase.java:218), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase.doAppendTest(RollingFileSystemSinkTestBase.java:392), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testSilentExistingWrite(TestRollingFileSystemSinkWithLocal.java:97), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testSilentExistingWrite$$CONFUZZ(TestRollingFileSystemSinkWithLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal/testSilentExistingWrite/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal#testFailedWrite	org.apache.hadoop.metrics2.MetricsException	Metrics source testFailedWrite$$CONFUZZ-m1 already exists!	org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newSourceName(DefaultMetricsSystem.java:152), org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.sourceName(DefaultMetricsSystem.java:125), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:229), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase$MyMetrics1.registerWith(RollingFileSystemSinkTestBase.java:102), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testFailedWrite(TestRollingFileSystemSinkWithLocal.java:108), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testFailedWrite$$CONFUZZ(TestRollingFileSystemSinkWithLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal/testFailedWrite/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal#testExistingWrite	org.apache.hadoop.metrics2.MetricsException	Metrics source testExistingWrite$$CONFUZZ-m1 already exists!	org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newSourceName(DefaultMetricsSystem.java:152), org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.sourceName(DefaultMetricsSystem.java:125), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:229), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase$MyMetrics1.registerWith(RollingFileSystemSinkTestBase.java:102), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase.doWriteTest(RollingFileSystemSinkTestBase.java:218), org.apache.hadoop.metrics2.sink.RollingFileSystemSinkTestBase.doAppendTest(RollingFileSystemSinkTestBase.java:392), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testExistingWrite(TestRollingFileSystemSinkWithLocal.java:68), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal.testExistingWrite$$CONFUZZ(TestRollingFileSystemSinkWithLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.metrics2.sink.TestRollingFileSystemSinkWithLocal/testExistingWrite/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.ipc.TestDecayRpcScheduler#testNPEatInitialization	org.apache.hadoop.metrics2.MetricsException	Metrics source DecayRpcSchedulerDetailedMetrics.ipc.14 already exists!	org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.newSourceName(DefaultMetricsSystem.java:152), org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.sourceName(DefaultMetricsSystem.java:125), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:229), org.apache.hadoop.ipc.metrics.DecayRpcSchedulerDetailedMetrics.create(DecayRpcSchedulerDetailedMetrics.java:63), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:250), org.apache.hadoop.ipc.TestDecayRpcScheduler.testNPEatInitialization(TestDecayRpcScheduler.java:279), org.apache.hadoop.ipc.TestDecayRpcScheduler.testNPEatInitialization$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testNPEatInitialization/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																				
		FP	2	org.apache.hadoop.metrics2.sink.TestRollingFileSystemSink#testGetRollInterval	org.apache.hadoop.metrics2.MetricsException	Metrics2 configuration is missing keytab-key property	org.apache.hadoop.metrics2.sink.RollingFileSystemSink.checkIfPropertyExists(RollingFileSystemSink.java:426), org.apache.hadoop.metrics2.sink.RollingFileSystemSink.init(RollingFileSystemSink.java:251), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSink.doTestGetRollInterval(TestRollingFileSystemSink.java:243), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSink.testGetRollInterval(TestRollingFileSystemSink.java:201), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSink.testGetRollInterval$$CONFUZZ(TestRollingFileSystemSink.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.metrics2.sink.TestRollingFileSystemSink/testGetRollInterval/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos"}	["debug_000000"]	org.apache.hadoop.metrics2.sink.TestRollingFileSystemSink#testInit	org.apache.hadoop.metrics2.MetricsException	Metrics2 configuration is missing keytab-key property	org.apache.hadoop.metrics2.sink.RollingFileSystemSink.checkIfPropertyExists(RollingFileSystemSink.java:426), org.apache.hadoop.metrics2.sink.RollingFileSystemSink.init(RollingFileSystemSink.java:251), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSink.testInit(TestRollingFileSystemSink.java:52), org.apache.hadoop.metrics2.sink.TestRollingFileSystemSink.testInit$$CONFUZZ(TestRollingFileSystemSink.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.metrics2.sink.TestRollingFileSystemSink/testInit/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos"}	["debug_000000"]																																																																																																																																																																																																						
	Bug-170	BUG	7	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testCopyFileOverwrite	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:419), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2482), org.apache.hadoop.fs.FilterFileSystem.copyFromLocalFile(FilterFileSystem.java:376), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:303), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:296), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testCopyFileOverwrite(AbstractContractCopyFromLocalTest.java:88), org.apache.hadoop.fs.TestLocalFSCopyFromLocal.testCopyFileOverwrite$$CONFUZZ(TestLocalFSCopyFromLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testCopyFileOverwrite/campaign/failures/debug_000000	{"io.file.buffer.size": "731331990"}	["debug_000000"]	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename#testRenameDirIntoExistingDir	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:419), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:409), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:341), org.apache.hadoop.fs.RawLocalFileSystem.rename(RawLocalFileSystem.java:505), org.apache.hadoop.fs.contract.AbstractFSContractTestBase.rename(AbstractFSContractTestBase.java:386), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameDirIntoExistingDir(AbstractContractRenameTest.java:168), org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename.testRenameDirIntoExistingDir$$CONFUZZ(TestRawlocalContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename/testRenameDirIntoExistingDir/campaign/failures/debug_000000	{"io.file.buffer.size": "936009675"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testCopyToLocalWithUseRawLocalFileSystemOption	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:419), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:341), org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2547), org.apache.hadoop.fs.FSMainOperationsBaseTest.testCopyToLocalWithUseRawLocalFileSystemOption(FSMainOperationsBaseTest.java:1133), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testCopyToLocalWithUseRawLocalFileSystemOption$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testCopyToLocalWithUseRawLocalFileSystemOption/campaign/failures/debug_000002	{"io.file.buffer.size": "1006599540"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameDirIntoExistingDir	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:419), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:409), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:341), org.apache.hadoop.fs.RawLocalFileSystem.rename(RawLocalFileSystem.java:505), org.apache.hadoop.fs.ChecksumFileSystem.rename(ChecksumFileSystem.java:694), org.apache.hadoop.fs.contract.AbstractFSContractTestBase.rename(AbstractFSContractTestBase.java:386), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameDirIntoExistingDir(AbstractContractRenameTest.java:168), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename.testRenameDirIntoExistingDir$$CONFUZZ(TestLocalFSContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameDirIntoExistingDir/campaign/failures/debug_000002	{"io.file.buffer.size": "1023539520"}	["debug_000002"]	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testSrcIsDirWithFilesAndCopySuccessful	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:419), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:409), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2482), org.apache.hadoop.fs.FilterFileSystem.copyFromLocalFile(FilterFileSystem.java:376), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:303), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:296), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testSrcIsDirWithFilesAndCopySuccessful(AbstractContractCopyFromLocalTest.java:165), org.apache.hadoop.fs.TestLocalFSCopyFromLocal.testSrcIsDirWithFilesAndCopySuccessful$$CONFUZZ(TestLocalFSCopyFromLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testSrcIsDirWithFilesAndCopySuccessful/campaign/failures/debug_000001	{"io.file.buffer.size": "923229455"}	["debug_000001"]	org.apache.hadoop.fs.TestFileUtil#testCopy5	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:114), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:502), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:482), org.apache.hadoop.fs.TestFileUtil.testCopy5(TestFileUtil.java:819), org.apache.hadoop.fs.TestFileUtil.testCopy5$$CONFUZZ(TestFileUtil.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFileUtil/testCopy5/campaign/failures/debug_000000	{"io.file.buffer.size": "1112734013"}	["debug_000000"]	org.apache.hadoop.fs.TestFsShellCopy#testCorruptedCopyIgnoreCrc	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:495), org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:417), org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:352), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.copyFileToTarget(CopyCommandWithMultiThread.java:144), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:287), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:272), org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:370), org.apache.hadoop.fs.shell.Command.processPaths(Command.java:333), org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:306), org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:267), org.apache.hadoop.fs.shell.Command.processArgument(Command.java:288), org.apache.hadoop.fs.shell.Command.processArguments(Command.java:272), org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:238), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.processArguments(CopyCommandWithMultiThread.java:89), org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:121), org.apache.hadoop.fs.shell.Command.run(Command.java:179), org.apache.hadoop.fs.FsShell.run(FsShell.java:327), org.apache.hadoop.fs.TestFsShellCopy.shellRun(TestFsShellCopy.java:81), org.apache.hadoop.fs.TestFsShellCopy.testCorruptedCopyIgnoreCrc(TestFsShellCopy.java:113), org.apache.hadoop.fs.TestFsShellCopy.testCorruptedCopyIgnoreCrc$$CONFUZZ(TestFsShellCopy.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testCorruptedCopyIgnoreCrc/campaign/failures/debug_000001	{"io.file.buffer.size": "990716153"}	["debug_000001"]																																																																																																																																															
	Bug-16	Repeated	3	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testTwoDataEntries	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:612), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:137), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testTwoDataEntries$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testTwoDataEntries/campaign/failures/debug_000001	{"tfile.fs.input.buffer.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testNoDataEntry	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testNoDataEntry(TestTFileByteArrays.java:110), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testNoDataEntry$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testNoDataEntry/campaign/failures/debug_000001	{"tfile.fs.input.buffer.size": "2145649814"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureNegativeOffset	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureNegativeOffset(TestTFileStreams.java:361), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testFailureNegativeOffset$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureNegativeOffset/campaign/failures/debug_000001	{"tfile.fs.input.buffer.size": "2130640638"}	["debug_000001"]																																																																																																																																																																																											
	Bug-48	Repeated	13	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testTwoDataEntries	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:399), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:136), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testTwoDataEntries$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testTwoDataEntries/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFile#testUnsortedTFileFeatures	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:399), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFile.writeEmptyRecords(TestTFile.java:165), org.apache.hadoop.io.file.tfile.TestTFile.writeRecords(TestTFile.java:259), org.apache.hadoop.io.file.tfile.TestTFile.unsortedWithSomeCodec(TestTFile.java:341), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures(TestTFile.java:365), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures$$CONFUZZ(TestTFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFile/testUnsortedTFileFeatures/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureWriteMetaBlocksWithSameName	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:399), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteMetaBlocksWithSameName(TestTFileByteArrays.java:271), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureWriteMetaBlocksWithSameName$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureWriteMetaBlocksWithSameName/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureKeyTooShort	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureKeyTooShort(TestTFileStreams.java:231), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testFailureKeyTooShort$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureKeyTooShort/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "0"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testOneBlockPlusOneEntry	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:399), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneBlockPlusOneEntry(TestTFileByteArrays.java:165), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testOneBlockPlusOneEntry$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testOneBlockPlusOneEntry/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "0"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureWriteRecordAfterMetaBlock	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:399), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteRecordAfterMetaBlock(TestTFileByteArrays.java:321), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureWriteRecordAfterMetaBlock$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureWriteRecordAfterMetaBlock/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureCompressionNotWorking2	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:412), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureCompressionNotWorking2(TestTFileStreams.java:397), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testFailureCompressionNotWorking2$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureCompressionNotWorking2/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureCompressionNotWorking	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:399), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureCompressionNotWorking(TestTFileByteArrays.java:550), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureCompressionNotWorking$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureCompressionNotWorking/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureNegativeOffset	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:412), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureNegativeOffset(TestTFileStreams.java:359), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testFailureNegativeOffset$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureNegativeOffset/campaign/failures/debug_000005	{"tfile.fs.output.buffer.size": "0"}	["debug_000005"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testTwoEntriesKnownLength	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:412), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testTwoEntriesKnownLength(TestTFileStreams.java:144), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testTwoEntriesKnownLength$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testTwoEntriesKnownLength/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "0"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testOneEntryMixedLengths2	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:412), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths2(TestTFileStreams.java:135), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testOneEntryMixedLengths2$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testOneEntryMixedLengths2/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureCompressionNotWorking	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:412), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureCompressionNotWorking(TestTFileStreams.java:386), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testFailureCompressionNotWorking$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureCompressionNotWorking/campaign/failures/debug_000005	{"tfile.fs.output.buffer.size": "0"}	["debug_000005"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureGetNonExistentMetaBlock	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:399), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock(TestTFileByteArrays.java:293), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureGetNonExistentMetaBlock$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureGetNonExistentMetaBlock/campaign/failures/debug_000004	{"tfile.fs.output.buffer.size": "0"}	["debug_000004"]																																																																													
			1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testTwoDataEntries	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:612), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:137), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testTwoDataEntries/campaign/failures/debug_000003	{"tfile.fs.input.buffer.size": "1546268038", "io.file.buffer.size": "1109407872"}	["debug_000003"]																																																																																																																																																																																																																	
			7	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testInternalCreate2	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation create not permitted on path /foo.	org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:97), org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:103), org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs.create(ViewFileSystem.java:1342), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:163), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testInternalCreate2(ViewFileSystemBaseTest.java:745), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testInternalCreate2$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testInternalCreate2/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testInternalCreateMissingDir2	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation create not permitted on path viewfs://default/missingDir/miss2/foo.	org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:97), org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:103), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:466), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:163), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testInternalCreateMissingDir2(ViewFileSystemBaseTest.java:755), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testInternalCreateMissingDir2$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testInternalCreateMissingDir2/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testInternalDeleteExisting2	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation delete not permitted on path /internalDir/linkToDir2.	org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:97), org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:103), org.apache.hadoop.fs.viewfs.ViewFileSystem.delete(ViewFileSystem.java:481), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testInternalDeleteExisting2(ViewFileSystemBaseTest.java:782), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testInternalDeleteExisting2$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testInternalDeleteExisting2/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testInternalRenameToSlash	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation rename not permitted on path /.	org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:97), org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:103), org.apache.hadoop.fs.viewfs.ViewFileSystem.rename(ViewFileSystem.java:712), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testInternalRenameToSlash(ViewFileSystemBaseTest.java:812), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testInternalRenameToSlash$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testInternalRenameToSlash/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testInternalCreateMissingDir	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation create not permitted on path viewfs://default/missingDir/foo.	org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:97), org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:103), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:466), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:163), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testInternalCreateMissingDir(ViewFileSystemBaseTest.java:750), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testInternalCreateMissingDir$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testInternalCreateMissingDir/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testInternalCreate1	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation create not permitted on path /foo.	org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:97), org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:103), org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs.create(ViewFileSystem.java:1342), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:163), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testInternalCreate1(ViewFileSystemBaseTest.java:740), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testInternalCreate1$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testInternalCreate1/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testInternalCreate1	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation create not permitted on path /foo.	org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:97), org.apache.hadoop.fs.viewfs.ViewFileSystem.readOnlyMountTable(ViewFileSystem.java:103), org.apache.hadoop.fs.viewfs.ViewFileSystem$InternalDirOfViewFs.create(ViewFileSystem.java:1342), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:163), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testInternalCreate1(ViewFileSystemBaseTest.java:740), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testInternalCreate1$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testInternalCreate1/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																															
	Bug-162	Repeated	2	org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager#testNodesLoadedAfterRestart	org.apache.zookeeper.KeeperException$ConnectionLossException	KeeperErrorCode = ConnectionLoss for /testPath/ZKDTSMRoot/ZKDTSMSeqNumRoot	org.apache.zookeeper.KeeperException.create(KeeperException.java:102), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1637), org.apache.curator.framework.imps.CreateBuilderImpl$17.call(CreateBuilderImpl.java:1180), org.apache.curator.framework.imps.CreateBuilderImpl$17.call(CreateBuilderImpl.java:1156), org.apache.curator.connection.StandardConnectionHandlingPolicy.callWithRetry(StandardConnectionHandlingPolicy.java:64), org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:100), org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:1153), org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:607), org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:597), org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:457), org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:393), org.apache.curator.framework.recipes.shared.SharedValue.start(SharedValue.java:256), org.apache.curator.framework.recipes.shared.SharedCount.start(SharedCount.java:163), org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager.startThreads(ZKDelegationTokenSecretManager.java:332), org.apache.hadoop.security.token.delegation.web.DelegationTokenManager.init(DelegationTokenManager.java:146), org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testNodesLoadedAfterRestart(TestZKDelegationTokenSecretManager.java:464), org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testNodesLoadedAfterRestart$$CONFUZZ(TestZKDelegationTokenSecretManager.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager/testNodesLoadedAfterRestart/campaign/failures/debug_000000	{"zk-dt-secret-manager.zkSessionTimeout": "0"}	["debug_000000"]	org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager#testNodeUpAferAWhile	org.apache.zookeeper.KeeperException$ConnectionLossException	KeeperErrorCode = ConnectionLoss for /testPath/ZKDTSMRoot/ZKDTSMSeqNumRoot	org.apache.zookeeper.KeeperException.create(KeeperException.java:102), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1637), org.apache.curator.framework.imps.CreateBuilderImpl$17.call(CreateBuilderImpl.java:1180), org.apache.curator.framework.imps.CreateBuilderImpl$17.call(CreateBuilderImpl.java:1156), org.apache.curator.connection.StandardConnectionHandlingPolicy.callWithRetry(StandardConnectionHandlingPolicy.java:64), org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:100), org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:1153), org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:607), org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:597), org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:457), org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:393), org.apache.curator.framework.recipes.shared.SharedValue.start(SharedValue.java:256), org.apache.curator.framework.recipes.shared.SharedCount.start(SharedCount.java:163), org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager.startThreads(ZKDelegationTokenSecretManager.java:332), org.apache.hadoop.security.token.delegation.web.DelegationTokenManager.init(DelegationTokenManager.java:146), org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testNodeUpAferAWhile(TestZKDelegationTokenSecretManager.java:154), org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testNodeUpAferAWhile$$CONFUZZ(TestZKDelegationTokenSecretManager.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager/testNodeUpAferAWhile/campaign/failures/debug_000001	{"zk-dt-secret-manager.zkSessionTimeout": "3"}	["debug_000001"]																																																																																																																																																																																																						
	Bug-171	BUG	10	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteTwoBlocks	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:692), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteTwoBlocks(FSMainOperationsBaseTest.java:675), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testWriteReadAndDeleteTwoBlocks$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteTwoBlocks/campaign/failures/debug_000000	{"file.stream-buffer-size": "1497526838"}	["debug_000000"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractOpen#testOpenFileTwice	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.contract.AbstractContractOpenTest.testOpenFileTwice(AbstractContractOpenTest.java:149), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractOpen.testOpenFileTwice$$CONFUZZ(TestLocalFSContractOpen.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractOpen/testOpenFileTwice/campaign/failures/debug_000000	{"file.stream-buffer-size": "1259763914"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureOpenEmptyFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenEmptyFile(TestTFileByteArrays.java:387), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenEmptyFile$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureOpenEmptyFile/campaign/failures/debug_000001	{"file.stream-buffer-size": "1073840193"}	["debug_000001"]	org.apache.hadoop.io.TestSequenceFile#testZlibSequenceFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.SequenceFile$Sorter$SegmentContainer.<init>(SequenceFile.java:3812), org.apache.hadoop.io.SequenceFile$Sorter.merge(SequenceFile.java:3358), org.apache.hadoop.io.SequenceFile$Sorter.mergePass(SequenceFile.java:3336), org.apache.hadoop.io.SequenceFile$Sorter.sort(SequenceFile.java:2899), org.apache.hadoop.io.SequenceFile$Sorter.sort(SequenceFile.java:2938), org.apache.hadoop.io.TestSequenceFile.sortTest(TestSequenceFile.java:286), org.apache.hadoop.io.TestSequenceFile.compressedSeqFileTest(TestSequenceFile.java:145), org.apache.hadoop.io.TestSequenceFile.testZlibSequenceFile(TestSequenceFile.java:57), org.apache.hadoop.io.TestSequenceFile.testZlibSequenceFile$$CONFUZZ(TestSequenceFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFile/testZlibSequenceFile/campaign/failures/debug_000000	{"file.stream-buffer-size": "538977030"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteOneAndAHalfBlocks	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:126), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:694), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteOneAndAHalfBlocks(FSMainOperationsBaseTest.java:670), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testWriteReadAndDeleteOneAndAHalfBlocks$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteOneAndAHalfBlocks/campaign/failures/debug_000002	{"file.stream-buffer-size": "536911873"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testSeekBigFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testSeekBigFile(AbstractContractSeekTest.java:301), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek.testSeekBigFile$$CONFUZZ(TestLocalFSContractSeek.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testSeekBigFile/campaign/failures/debug_000000	{"file.stream-buffer-size": "903228137"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureWriterNotClosed	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriterNotClosed(TestTFileByteArrays.java:256), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureWriterNotClosed$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureWriterNotClosed/campaign/failures/debug_000001	{"file.stream-buffer-size": "1850317150"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testReadFullyPastEOF	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:126), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testReadFullyPastEOF(AbstractContractSeekTest.java:472), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek.testReadFullyPastEOF$$CONFUZZ(TestLocalFSContractSeek.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testReadFullyPastEOF/campaign/failures/debug_000000	{"file.stream-buffer-size": "884714718"}	["debug_000000"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testSyncable	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.contract.AbstractContractCreateTest.validateSyncableSemantics(AbstractContractCreateTest.java:556), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testSyncable(AbstractContractCreateTest.java:459), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testSyncable$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testSyncable/campaign/failures/debug_000002	{"file.stream-buffer-size": "1155186693"}	["debug_000002"]	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteEmptyFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:692), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteEmptyFile(FSMainOperationsBaseTest.java:654), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testWriteReadAndDeleteEmptyFile$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteEmptyFile/campaign/failures/debug_000001	{"file.stream-buffer-size": "1174461423"}	["debug_000001"]																																																																																																														
			17	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteTwoBlocks	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:685), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteTwoBlocks(FSMainOperationsBaseTest.java:675), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteTwoBlocks/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1192301604"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFile#testUnsortedTFileFeatures	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendValue(TFile.java:565), org.apache.hadoop.io.file.tfile.TestTFile.writePrepWithUnkownLength(TestTFile.java:226), org.apache.hadoop.io.file.tfile.TestTFile.writeRecords(TestTFile.java:263), org.apache.hadoop.io.file.tfile.TestTFile.unsortedWithSomeCodec(TestTFile.java:341), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures(TestTFile.java:365), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures$$CONFUZZ(TestTFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	DIFFERENT	java.lang.NegativeArraySizeException	-2097907347	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFile.createFSOutput(TestTFile.java:277), org.apache.hadoop.io.file.tfile.TestTFile.unsortedWithSomeCodec(TestTFile.java:339), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures(TestTFile.java:365), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFile/testUnsortedTFileFeatures/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1198554949"}	["debug_000000"]	org.apache.hadoop.util.TestGenericOptionsParser#testTokenCacheOption	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:325), org.apache.hadoop.util.TestGenericOptionsParser.testTokenCacheOption(TestGenericOptionsParser.java:283), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.util.TestGenericOptionsParser/testTokenCacheOption/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1663753467"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractMkdir#testMkdirOverParentFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractMkdirTest.testMkdirOverParentFile(AbstractContractMkdirTest.java:92), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractMkdir/testMkdirOverParentFile/campaign/failures/debug_000003	{"file.bytes-per-checksum": "236705280"}	["debug_000003"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics#testWriteSingleByte	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.AbstractContractStreamIOStatisticsTest.testWriteSingleByte(AbstractContractStreamIOStatisticsTest.java:126), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractStreamIOStatistics/testWriteSingleByte/campaign/failures/debug_000003	{"file.bytes-per-checksum": "2138987404"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testMkdirsFailsForSubdirectoryOfExistingFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testMkdirsFailsForSubdirectoryOfExistingFile(FSMainOperationsBaseTest.java:234), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testMkdirsFailsForSubdirectoryOfExistingFile/campaign/failures/debug_000003	{"file.bytes-per-checksum": "2139291390"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testNflyWriteSimple	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testNflyWriteSimple/campaign/failures/debug_000004	{"file.bytes-per-checksum": "2147483390"}	["debug_000004"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testFileStatusOnMountLink	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testFileStatusOnMountLink/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1662232376"}	["debug_000003"]	org.apache.hadoop.fs.TestFsShellCopy#testCopyNoParent	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestFsShellCopy.prepFiles(TestFsShellCopy.java:74), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testCopyNoParent/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1670195497"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureWriteRecordAfterMetaBlock	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteRecordAfterMetaBlock(TestTFileByteArrays.java:321), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureWriteRecordAfterMetaBlock$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	DIFFERENT	java.lang.NegativeArraySizeException	-1976094733	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.setUp(TestTFileNoneCodecsByteArrays.java:29), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureWriteRecordAfterMetaBlock/campaign/failures/debug_000001	{"file.bytes-per-checksum": "257652507"}	["debug_000001"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testCreateLinkUsingAbsPaths	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testCreateLinkUsingAbsPaths(SymlinkBaseTest.java:456), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testCreateLinkUsingAbsPaths/campaign/failures/debug_000002	{"file.bytes-per-checksum": "236410663"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameFileUnderFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractRenameTest.expectRenameUnderFileFails(AbstractContractRenameTest.java:335), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameFileUnderFile(AbstractContractRenameTest.java:311), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameFileUnderFile/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1665372969"}	["debug_000002"]	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.snappy.SnappyDecompressor.<init>(SnappyDecompressor.java:57), org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:172), org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:183), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2054), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:621), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-16860292	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:634), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000002	{"file.bytes-per-checksum": "1907000988"}	["debug_000002"]	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testMkdirsFailsForSubdirectoryOfExistingFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FSMainOperationsBaseTest.createFile(FSMainOperationsBaseTest.java:1147), org.apache.hadoop.fs.FSMainOperationsBaseTest.testMkdirsFailsForSubdirectoryOfExistingFile(FSMainOperationsBaseTest.java:234), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testMkdirsFailsForSubdirectoryOfExistingFile/campaign/failures/debug_000002	{"file.bytes-per-checksum": "2140868308"}	["debug_000002"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testRenameFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:165), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testRenameFile(TestSFTPFileSystem.java:299), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testRenameFile/campaign/failures/debug_000003	{"file.bytes-per-checksum": "2140849035"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testLocate	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testLocate(TestTFileByteArrays.java:238), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testLocate$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	DIFFERENT	java.lang.NegativeArraySizeException	-923939953	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.setUp(TestTFileJClassComparatorByteArrays.java:41), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testLocate/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1806214359"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testInternalGetAllStoragePolicies	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testInternalGetAllStoragePolicies/campaign/failures/debug_000004	{"file.bytes-per-checksum": "711664464"}	["debug_000004"]																																	
			1	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteTwoBlocks	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:692), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteTwoBlocks(FSMainOperationsBaseTest.java:675), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testWriteReadAndDeleteTwoBlocks$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:692), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteTwoBlocks(FSMainOperationsBaseTest.java:675), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteTwoBlocks/campaign/failures/debug_000001	{"file.bytes-per-checksum": "570117649", "io.file.buffer.size": "900206047"}	["debug_000001"]																																																																																																																																																																																																																	
			2	org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem#testLocalFsLinkSlashMergeWithOtherMountLinks	java.io.IOException	Mount table mt has already been configured with regular links. A merge slash link should not be configured.	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:602), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme.initialize(ViewFileSystemOverloadScheme.java:161), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174), org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574), org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540), org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem.testLocalFsLinkSlashMergeWithOtherMountLinks(TestViewFileSystemOverloadSchemeLocalFileSystem.java:149), org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem.testLocalFsLinkSlashMergeWithOtherMountLinks$$CONFUZZ(TestViewFileSystemOverloadSchemeLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem/testLocalFsLinkSlashMergeWithOtherMountLinks/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFSOverloadSchemeCentralMountTableConfig#testLocalFsLinkSlashMergeWithOtherMountLinks	java.io.IOException	Mount table mt has already been configured with regular links. A merge slash link should not be configured.	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:602), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme.initialize(ViewFileSystemOverloadScheme.java:161), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174), org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574), org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540), org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem.testLocalFsLinkSlashMergeWithOtherMountLinks(TestViewFileSystemOverloadSchemeLocalFileSystem.java:149), org.apache.hadoop.fs.viewfs.TestViewFSOverloadSchemeCentralMountTableConfig.testLocalFsLinkSlashMergeWithOtherMountLinks$$CONFUZZ(TestViewFSOverloadSchemeCentralMountTableConfig.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFSOverloadSchemeCentralMountTableConfig/testLocalFsLinkSlashMergeWithOtherMountLinks/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																						
			1	org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem#testLocalFsCreateAndDelete	java.lang.OutOfMemoryError	Java heap space		PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemOverloadSchemeLocalFileSystem/testLocalFsCreateAndDelete/campaign/failures/debug_000002	{"hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "564", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "327921s", "file.stream-buffer-size": "2063827529", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "true", "hadoop.security.groups.negative-cache.secs": "472", "fs.creation.parallel.count": "10055", "fs.viewfs.rename.strategy": "SAME_MOUNTPOINT", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "172", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "1407", "fs.local.block.size": "802", "fs.file.impl.disable.cache": "false", "io.file.buffer.size": "11131", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "218", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "fs.viewfs.enable.inner.cache": "false", "hadoop.security.groups.cache.warn.after.ms": "642"}	["debug_000002"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.ipc.TestRPC#testClientBackOff	org.mockito.exceptions.verification.WantedButNotInvoked	Wanted but not invoked:callQueueManager.addInternal(<any>, false);-> at org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1203)However, there was exactly 1 interaction with this mock:callQueueManager.size();-> at org.apache.hadoop.ipc.Server$ConnectionManager.register(Server.java:3800)	org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1203), org.apache.hadoop.ipc.TestRPC.testClientBackOff$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	org.junit.runners.model.TestTimedOutException	test timed out after 30000 milliseconds	java.base@11.0.19/java.lang.Thread.join(Thread.java:1291), java.base@11.0.19/java.lang.Thread.join(Thread.java:1375), app//org.apache.hadoop.ipc.Server$Listener$Reader.shutdown(Server.java:1343), app//org.apache.hadoop.ipc.Server$Listener.doStop(Server.java:1485), app//org.apache.hadoop.ipc.Server.stop(Server.java:3438), app//org.apache.hadoop.ipc.TestRpcBase.stop(TestRpcBase.java:173), app//org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1218), java.base@11.0.19/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base@11.0.19/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base@11.0.19/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testClientBackOff/campaign/failures/debug_000000	{"ipc.server.read.threadpool.size": "22147"}	["debug_000000"]																																																																																																																																																																																																																	
	Bug-1	Repeated	11	org.apache.hadoop.ipc.TestRPC#testClientBackOff	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1181), org.apache.hadoop.ipc.TestRPC.testClientBackOff$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testClientBackOff/campaign/failures/debug_000002	{"ipc.server.read.threadpool.size": "586982544"}	["debug_000002"]	org.apache.hadoop.ipc.TestAsyncIPC#testCallGetReturnRpcResponseMultipleTimes	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.Server.<init>(Server.java:3046), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:226), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:219), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:200), org.apache.hadoop.ipc.TestAsyncIPC.testCallGetReturnRpcResponseMultipleTimes(TestAsyncIPC.java:295), org.apache.hadoop.ipc.TestAsyncIPC.testCallGetReturnRpcResponseMultipleTimes$$CONFUZZ(TestAsyncIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestAsyncIPC/testCallGetReturnRpcResponseMultipleTimes/campaign/failures/debug_000000	{"ipc.server.read.threadpool.size": "1165547071"}	["debug_000000"]	org.apache.hadoop.ipc.TestRPC#testClientRpcTimeout	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRPC.testClientRpcTimeout(TestRPC.java:1551), org.apache.hadoop.ipc.TestRPC.testClientRpcTimeout$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testClientRpcTimeout/campaign/failures/debug_000002	{"ipc.server.read.threadpool.size": "1073839871"}	["debug_000002", "debug_000001"]	org.apache.hadoop.ipc.TestRPC#testRpcMetricsInNanos	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos(TestRPC.java:1861), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testRpcMetricsInNanos/campaign/failures/debug_000005	{"ipc.server.read.threadpool.size": "824147711"}	["debug_000005", "debug_000001"]	org.apache.hadoop.ipc.TestIPC#testRTEDuringConnectionSetup	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.Server.<init>(Server.java:3046), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:226), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:219), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:206), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:190), org.apache.hadoop.ipc.TestIPC.testRTEDuringConnectionSetup(TestIPC.java:698), org.apache.hadoop.ipc.TestIPC.testRTEDuringConnectionSetup$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testRTEDuringConnectionSetup/campaign/failures/debug_000001	{"ipc.server.read.threadpool.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.security.TestDoAsEffectiveUser#testRealUserIPAuthorizationFailure	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserIPAuthorizationFailure(TestDoAsEffectiveUser.java:329), org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserIPAuthorizationFailure$$CONFUZZ(TestDoAsEffectiveUser.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestDoAsEffectiveUser/testRealUserIPAuthorizationFailure/campaign/failures/debug_000000	{"ipc.server.read.threadpool.size": "2130640638"}	["debug_000000"]	org.apache.hadoop.ipc.TestRPC#testConnectionPing	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.ipc.TestRPC.testConnectionPing(TestRPC.java:997), org.apache.hadoop.ipc.TestRPC.testConnectionPing$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testConnectionPing/campaign/failures/debug_000002	{"ipc.server.read.threadpool.size": "999542874"}	["debug_000002"]	org.apache.hadoop.ipc.TestIPC#testHttpGetResponse	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.Server.<init>(Server.java:3046), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:226), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:219), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:206), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:190), org.apache.hadoop.ipc.TestIPC.doIpcVersionTest(TestIPC.java:1743), org.apache.hadoop.ipc.TestIPC.testHttpGetResponse(TestIPC.java:1208), org.apache.hadoop.ipc.TestIPC.testHttpGetResponse$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testHttpGetResponse/campaign/failures/debug_000000	{"ipc.server.read.threadpool.size": "594086770"}	["debug_000000"]	org.apache.hadoop.ipc.TestIPC#testConnectionIdleTimeouts	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.Server.<init>(Server.java:3046), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:226), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:219), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:206), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:190), org.apache.hadoop.ipc.TestIPC.testConnectionIdleTimeouts(TestIPC.java:1019), org.apache.hadoop.ipc.TestIPC.testConnectionIdleTimeouts$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testConnectionIdleTimeouts/campaign/failures/debug_000000	{"ipc.server.read.threadpool.size": "824222047"}	["debug_000000"]	org.apache.hadoop.ipc.TestRPC#testStopsAllThreads	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.ipc.TestRPC.testStopsAllThreads(TestRPC.java:829), org.apache.hadoop.ipc.TestRPC.testStopsAllThreads$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testStopsAllThreads/campaign/failures/debug_000000	{"ipc.server.read.threadpool.size": "2087968584"}	["debug_000000"]	org.apache.hadoop.security.TestDoAsEffectiveUser#testRealUserSetup	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserSetup(TestDoAsEffectiveUser.java:192), org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserSetup$$CONFUZZ(TestDoAsEffectiveUser.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestDoAsEffectiveUser/testRealUserSetup/campaign/failures/debug_000001	{"ipc.server.read.threadpool.size": "1245945502"}	["debug_000001"]																																																																																																			
		FP	1	org.apache.hadoop.ipc.TestRPC#testClientBackOff	java.lang.AssertionError	RetriableException not received	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1223), org.apache.hadoop.ipc.TestRPC.testClientBackOff$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testClientBackOff/campaign/failures/debug_000001	{"ipc.0.callqueue.overflow.trigger.failover": "true"}	["debug_000001"]																																																																																																																																																																																																																	
			3	org.apache.hadoop.ipc.TestRPC#testClientBackOff	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1181), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testClientBackOff/campaign/failures/debug_000003	{"ipc.server.read.threadpool.size": "779353552"}	["debug_000003"]	org.apache.hadoop.ipc.TestRPC#testRpcMetricsInNanos	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos(TestRPC.java:1861), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testRpcMetricsInNanos/campaign/failures/debug_000008	{"ipc.server.read.threadpool.size": "928890743"}	["debug_000008"]	org.apache.hadoop.security.TestDoAsEffectiveUser#testRealUserIPAuthorizationFailure	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserIPAuthorizationFailure(TestDoAsEffectiveUser.java:329), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestDoAsEffectiveUser/testRealUserIPAuthorizationFailure/campaign/failures/debug_000001	{"ipc.server.read.threadpool.size": "709824610"}	["debug_000001"]																																																																																																																																																																																											
	Bug-50	Repeated	1	org.apache.hadoop.fs.TestLocalFileSystem#testStripFragmentFromPath	java.lang.NegativeArraySizeException	-1011537062	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.TestLocalFileSystem.testStripFragmentFromPath(TestLocalFileSystem.java:640), org.apache.hadoop.fs.TestLocalFileSystem.testStripFragmentFromPath$$CONFUZZ(TestLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFileSystem/testStripFragmentFromPath/campaign/failures/debug_000000	{"fs.file.impl.disable.cache": "true", "file.bytes-per-checksum": "842044170"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestLocalFileSystem#testStripFragmentFromPath	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.TestLocalFileSystem.testStripFragmentFromPath(TestLocalFileSystem.java:640), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFileSystem/testStripFragmentFromPath/campaign/failures/debug_000002	{"fs.file.impl.disable.cache": "true", "file.bytes-per-checksum": "1075905536"}	["debug_000002"]																																																																																																																																																																																																																	
	Bug-8	Repeated	1	org.apache.hadoop.fs.TestLocalFileSystem#testStripFragmentFromPath	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.TestLocalFileSystem.testStripFragmentFromPath(TestLocalFileSystem.java:640), org.apache.hadoop.fs.TestLocalFileSystem.testStripFragmentFromPath$$CONFUZZ(TestLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFileSystem/testStripFragmentFromPath/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1564020886", "fs.file.impl.disable.cache": "true"}	["debug_000001"]																																																																																																																																																																																																																	
	Bug-172	BUG	7	org.apache.hadoop.io.compress.TestCodec#testCodecPoolCompressorReinit	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.compress.TestCodec.gzipReinitTest(TestCodec.java:411), org.apache.hadoop.io.compress.TestCodec.testCodecPoolCompressorReinit(TestCodec.java:492), org.apache.hadoop.io.compress.TestCodec.testCodecPoolCompressorReinit$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testCodecPoolCompressorReinit/campaign/failures/debug_000000	{"io.file.buffer.size": "2130640638"}	["debug_000000"]	org.apache.hadoop.io.compress.TestCodec#testSequenceFileDeflateCodec	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:385), org.apache.hadoop.io.compress.TestCodec.sequenceFileCodecTest(TestCodec.java:563), org.apache.hadoop.io.compress.TestCodec.testSequenceFileDeflateCodec(TestCodec.java:548), org.apache.hadoop.io.compress.TestCodec.testSequenceFileDeflateCodec$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSequenceFileDeflateCodec/campaign/failures/debug_000000	{"io.file.buffer.size": "987134562"}	["debug_000000"]	org.apache.hadoop.io.TestSequenceFile#testSequenceFileWriter	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:310), org.apache.hadoop.io.TestSequenceFile.testSequenceFileWriter(TestSequenceFile.java:735), org.apache.hadoop.io.TestSequenceFile.testSequenceFileWriter$$CONFUZZ(TestSequenceFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFile/testSequenceFileWriter/campaign/failures/debug_000000	{"io.file.buffer.size": "1074827327"}	["debug_000000"]	org.apache.hadoop.io.compress.TestCodec#testCodecInitWithCompressionLevel	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.compress.TestCodec.codecTestWithNOCompression(TestCodec.java:447), org.apache.hadoop.io.compress.TestCodec.testCodecInitWithCompressionLevel(TestCodec.java:476), org.apache.hadoop.io.compress.TestCodec.testCodecInitWithCompressionLevel$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testCodecInitWithCompressionLevel/campaign/failures/debug_000000	{"io.file.buffer.size": "2139553534"}	["debug_000000"]	org.apache.hadoop.io.TestSequenceFileAppend#testAppendNoneCompression	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286), org.apache.hadoop.io.TestSequenceFileAppend.testAppendNoneCompression(TestSequenceFileAppend.java:310), org.apache.hadoop.io.TestSequenceFileAppend.testAppendNoneCompression$$CONFUZZ(TestSequenceFileAppend.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFileAppend/testAppendNoneCompression/campaign/failures/debug_000000	{"io.file.buffer.size": "1492746092"}	["debug_000000"]	org.apache.hadoop.io.TestArrayFile#testEmptyFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.ArrayFile$Writer.<init>(ArrayFile.java:45), org.apache.hadoop.io.TestArrayFile.writeTest(TestArrayFile.java:88), org.apache.hadoop.io.TestArrayFile.testEmptyFile(TestArrayFile.java:62), org.apache.hadoop.io.TestArrayFile.testEmptyFile$$CONFUZZ(TestArrayFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestArrayFile/testEmptyFile/campaign/failures/debug_000001	{"io.file.buffer.size": "1875935148"}	["debug_000001"]	org.apache.hadoop.io.TestSequenceFile#testClose	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:333), org.apache.hadoop.io.TestSequenceFile.testClose(TestSequenceFile.java:506), org.apache.hadoop.io.TestSequenceFile.testClose$$CONFUZZ(TestSequenceFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFile/testClose/campaign/failures/debug_000001	{"io.file.buffer.size": "1005035317"}	["debug_000001"]																																																																																																																																															
			7	org.apache.hadoop.io.compress.TestCodec#testCodecPoolCompressorReinit	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.compress.TestCodec.gzipReinitTest(TestCodec.java:411), org.apache.hadoop.io.compress.TestCodec.testCodecPoolCompressorReinit(TestCodec.java:492), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testCodecPoolCompressorReinit/campaign/failures/debug_000001	{"io.file.buffer.size": "2130673407"}	["debug_000001"]	org.apache.hadoop.io.TestSequenceFile#testCreateUsesFsArg	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:310), org.apache.hadoop.io.TestSequenceFile.testCreateUsesFsArg(TestSequenceFile.java:555), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFile/testCreateUsesFsArg/campaign/failures/debug_000000	{"io.file.buffer.size": "1852874857"}	["debug_000000"]	org.apache.hadoop.io.TestMapFile#testMainMethodMapFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.TestMapFile.createWriter(TestMapFile.java:131), org.apache.hadoop.io.TestMapFile.testMainMethodMapFile(TestMapFile.java:673), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestMapFile/testMainMethodMapFile/campaign/failures/debug_000002	{"io.file.buffer.size": "1584827683"}	["debug_000002"]	org.apache.hadoop.io.compress.TestCodec#testCodecInitWithCompressionLevel	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.compress.TestCodec.codecTestWithNOCompression(TestCodec.java:447), org.apache.hadoop.io.compress.TestCodec.testCodecInitWithCompressionLevel(TestCodec.java:476), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testCodecInitWithCompressionLevel/campaign/failures/debug_000001	{"io.file.buffer.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.io.TestSequenceFileAppend#testAppendNoneCompression	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:286), org.apache.hadoop.io.TestSequenceFileAppend.testAppendNoneCompression(TestSequenceFileAppend.java:310), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFileAppend/testAppendNoneCompression/campaign/failures/debug_000001	{"io.file.buffer.size": "2045298685"}	["debug_000001"]	org.apache.hadoop.io.TestArrayFile#testEmptyFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.ArrayFile$Writer.<init>(ArrayFile.java:45), org.apache.hadoop.io.TestArrayFile.writeTest(TestArrayFile.java:88), org.apache.hadoop.io.TestArrayFile.testEmptyFile(TestArrayFile.java:62), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestArrayFile/testEmptyFile/campaign/failures/debug_000002	{"io.file.buffer.size": "2015565588"}	["debug_000002"]	org.apache.hadoop.io.TestSequenceFile#testClose	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.DefaultCodec.createOutputStream(DefaultCodec.java:66), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:333), org.apache.hadoop.io.TestSequenceFile.testClose(TestSequenceFile.java:499), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSequenceFile/testClose/campaign/failures/debug_000003	{"io.file.buffer.size": "1799883145"}	["debug_000003"]																																																																																																																																															
		FP	1	org.apache.hadoop.http.TestHttpServer#testHttpResponseOverrideDefaultHeaders	java.lang.AssertionError	expected:<customXssValue> but was:<null>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:120), org.junit.Assert.assertEquals(Assert.java:146), org.apache.hadoop.http.TestHttpServer.testHttpResponseOverrideDefaultHeaders(TestHttpServer.java:744), org.apache.hadoop.http.TestHttpServer.testHttpResponseOverrideDefaultHeaders$$CONFUZZ(TestHttpServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResponseOverrideDefaultHeaders/campaign/failures/debug_000002	{"hadoop.http.max.request.header.size": "87"}	["debug_000002"]																																																																																																																																																																																																																	
			4	org.apache.hadoop.http.TestHttpServer#testHttpResponseOverrideDefaultHeaders	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.getHttpURLConnection(TestHttpServer.java:321), org.apache.hadoop.http.TestHttpServer.testHttpResponseOverrideDefaultHeaders(TestHttpServer.java:743), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResponseOverrideDefaultHeaders/campaign/failures/debug_000007	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000007"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsXFrameOptions	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.getHttpURLConnection(TestHttpServer.java:321), org.apache.hadoop.http.TestHttpServer.validateXFrameOption(TestHttpServer.java:295), org.apache.hadoop.http.TestHttpServer.testHttpResonseContainsXFrameOptions(TestHttpServer.java:275), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsXFrameOptions/campaign/failures/debug_000004	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000004"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseDoesNotContainXFrameOptions	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.getHttpURLConnection(TestHttpServer.java:321), org.apache.hadoop.http.TestHttpServer.testHttpResonseDoesNotContainXFrameOptions(TestHttpServer.java:311), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseDoesNotContainXFrameOptions/campaign/failures/debug_000005	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000005"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsDeny	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.getHttpURLConnection(TestHttpServer.java:321), org.apache.hadoop.http.TestHttpServer.validateXFrameOption(TestHttpServer.java:295), org.apache.hadoop.http.TestHttpServer.testHttpResonseContainsDeny(TestHttpServer.java:280), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsDeny/campaign/failures/debug_000006	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000006"]																																																																																																																																																																																
			2	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testChildrenFileSystemLeak	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testChildrenFileSystemLeak/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1647148971"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testGetContentSummary	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testGetContentSummary/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1654957281"}	["debug_000001"]																																																																																																																																																																																																						
		FP	1	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testChildrenFileSystemLeak	java.lang.AssertionError	expected:<2> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testChildrenFileSystemLeak(ViewFileSystemBaseTest.java:1360), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testChildrenFileSystemLeak$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testChildrenFileSystemLeak/campaign/failures/debug_000001	{"fs.viewfs.enable.inner.cache": "false"}	["debug_000001"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFile#testUnsortedTFileFeatures	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendValue(TFile.java:565), org.apache.hadoop.io.file.tfile.TestTFile.writePrepWithUnkownLength(TestTFile.java:226), org.apache.hadoop.io.file.tfile.TestTFile.writeRecords(TestTFile.java:263), org.apache.hadoop.io.file.tfile.TestTFile.unsortedWithSomeCodec(TestTFile.java:341), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures(TestTFile.java:365), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFile/testUnsortedTFileFeatures/campaign/failures/debug_000002	{"tfile.io.chunk.size": "2130640638"}	["debug_000002"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFile#testUnsortedTFileFeatures	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFile.unsortedWithSomeCodec(TestTFile.java:346), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures(TestTFile.java:365), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures$$CONFUZZ(TestTFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFile.unsortedWithSomeCodec(TestTFile.java:344), org.apache.hadoop.io.file.tfile.TestTFile.testUnsortedTFileFeatures(TestTFile.java:365), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFile/testUnsortedTFileFeatures/campaign/failures/debug_000001	{"file.stream-buffer-size": "855828719", "tfile.io.chunk.size": "664555359"}	["debug_000001"]																																																																																																																																																																																																																	
	Bug-171	BUG	14	org.apache.hadoop.crypto.key.TestKeyProviderFactory#testJksProviderWithKeytoolKeys	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.crypto.key.JavaKeyStoreProvider.loadFromPath(JavaKeyStoreProvider.java:293), org.apache.hadoop.crypto.key.JavaKeyStoreProvider.tryLoadFromPath(JavaKeyStoreProvider.java:193), org.apache.hadoop.crypto.key.JavaKeyStoreProvider.locateKeystore(JavaKeyStoreProvider.java:164), org.apache.hadoop.crypto.key.JavaKeyStoreProvider.<init>(JavaKeyStoreProvider.java:134), org.apache.hadoop.crypto.key.JavaKeyStoreProvider.<init>(JavaKeyStoreProvider.java:89), org.apache.hadoop.crypto.key.JavaKeyStoreProvider$Factory.createProvider(JavaKeyStoreProvider.java:661), org.apache.hadoop.crypto.key.KeyProviderFactory.get(KeyProviderFactory.java:96), org.apache.hadoop.crypto.key.KeyProviderFactory.getProviders(KeyProviderFactory.java:68), org.apache.hadoop.crypto.key.TestKeyProviderFactory.testJksProviderWithKeytoolKeys(TestKeyProviderFactory.java:448), org.apache.hadoop.crypto.key.TestKeyProviderFactory.testJksProviderWithKeytoolKeys$$CONFUZZ(TestKeyProviderFactory.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.TestKeyProviderFactory/testJksProviderWithKeytoolKeys/campaign/failures/debug_000000	{"io.file.buffer.size": "2073916170"}	["debug_000000"]	org.apache.hadoop.util.TestJsonSerialization#testFileSystemEmptyPath	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896), org.apache.hadoop.fs.ChecksumFileSystem$$Lambda$132/0x0000000840207040.call(Unknown Source), org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52), org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894), org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768), org.apache.hadoop.util.JsonSerialization.load(JsonSerialization.java:271), org.apache.hadoop.util.JsonSerialization.load(JsonSerialization.java:245), org.apache.hadoop.util.TestJsonSerialization.lambda$testFileSystemEmptyPath$2(TestJsonSerialization.java:191), org.apache.hadoop.util.TestJsonSerialization$$Lambda$130/0x0000000840207840.call(Unknown Source), org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:498), org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:384), org.apache.hadoop.util.TestJsonSerialization.testFileSystemEmptyPath(TestJsonSerialization.java:190), org.apache.hadoop.util.TestJsonSerialization.testFileSystemEmptyPath$$CONFUZZ(TestJsonSerialization.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.util.TestJsonSerialization/testFileSystemEmptyPath/campaign/failures/debug_000000	{"io.file.buffer.size": "2071759670"}	["debug_000000"]	org.apache.hadoop.fs.TestRawLocalFileSystemContract#testWriteReadAndDeleteEmptyFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(FileSystemContractBaseTest.java:937), org.apache.hadoop.fs.FileSystemContractBaseTest.writeReadAndDelete(FileSystemContractBaseTest.java:359), org.apache.hadoop.fs.FileSystemContractBaseTest.testWriteReadAndDeleteEmptyFile(FileSystemContractBaseTest.java:328), org.apache.hadoop.fs.TestRawLocalFileSystemContract.testWriteReadAndDeleteEmptyFile$$CONFUZZ(TestRawLocalFileSystemContract.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestRawLocalFileSystemContract/testWriteReadAndDeleteEmptyFile/campaign/failures/debug_000000	{"io.file.buffer.size": "1034157916"}	["debug_000000"]	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractAppend#testBuilderAppendToExistingFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.contract.ContractTestUtils.readDataset(ContractTestUtils.java:214), org.apache.hadoop.fs.contract.AbstractContractAppendTest.testBuilderAppendToExistingFile(AbstractContractAppendTest.java:114), org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractAppend.testBuilderAppendToExistingFile$$CONFUZZ(TestRawlocalContractAppend.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractAppend/testBuilderAppendToExistingFile/campaign/failures/debug_000000	{"io.file.buffer.size": "1654859570"}	["debug_000000"]	org.apache.hadoop.fs.TestChecksumFileSystem#testTruncatedChecksum	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.TestChecksumFileSystem.testTruncatedChecksum(TestChecksumFileSystem.java:146), org.apache.hadoop.fs.TestChecksumFileSystem.testTruncatedChecksum$$CONFUZZ(TestChecksumFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestChecksumFileSystem/testTruncatedChecksum/campaign/failures/debug_000000	{"io.file.buffer.size": "1157101881"}	["debug_000000"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testSyncablePassthroughIfChecksumDisabled	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.contract.AbstractContractCreateTest.validateSyncableSemantics(AbstractContractCreateTest.java:546), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testSyncablePassthroughIfChecksumDisabled(TestLocalFSContractCreate.java:45), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testSyncablePassthroughIfChecksumDisabled$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testSyncablePassthroughIfChecksumDisabled/campaign/failures/debug_000000	{"io.file.buffer.size": "1069440411"}	["debug_000000"]	org.apache.hadoop.fs.TestFsShellCopy#testCopyMerge	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.shell.CopyCommands$Merge.processArguments(CopyCommands.java:101), org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:121), org.apache.hadoop.fs.shell.Command.run(Command.java:179), org.apache.hadoop.fs.FsShell.run(FsShell.java:327), org.apache.hadoop.fs.TestFsShellCopy.testCopyMerge(TestFsShellCopy.java:355), org.apache.hadoop.fs.TestFsShellCopy.testCopyMerge$$CONFUZZ(TestFsShellCopy.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testCopyMerge/campaign/failures/debug_000001	{"io.file.buffer.size": "1320849177"}	["debug_000001"]	org.apache.hadoop.fs.TestFileUtil#testCopy5	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:501), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:482), org.apache.hadoop.fs.TestFileUtil.testCopy5(TestFileUtil.java:819), org.apache.hadoop.fs.TestFileUtil.testCopy5$$CONFUZZ(TestFileUtil.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFileUtil/testCopy5/campaign/failures/debug_000001	{"io.file.buffer.size": "2139426830"}	["debug_000001"]	org.apache.hadoop.fs.shell.TestTextCommand#testOneByteTextFil	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.shell.Display$Cat.getInputStream(Display.java:108), org.apache.hadoop.fs.shell.Display$Text.getInputStream(Display.java:125), org.apache.hadoop.fs.shell.TestTextCommand$1.getInputStream(TestTextCommand.java:118), org.apache.hadoop.fs.shell.TestTextCommand.readUsingTextCommand(TestTextCommand.java:122), org.apache.hadoop.fs.shell.TestTextCommand.testOneByteTextFil(TestTextCommand.java:90), org.apache.hadoop.fs.shell.TestTextCommand.testOneByteTextFil$$CONFUZZ(TestTextCommand.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestTextCommand/testOneByteTextFil/campaign/failures/debug_000000	{"io.file.buffer.size": "2141538090"}	["debug_000000"]	org.apache.hadoop.fs.TestRawLocalFileSystemContract#testWriteReadAndDeleteOneBlock	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(FileSystemContractBaseTest.java:937), org.apache.hadoop.fs.FileSystemContractBaseTest.writeReadAndDelete(FileSystemContractBaseTest.java:359), org.apache.hadoop.fs.FileSystemContractBaseTest.testWriteReadAndDeleteOneBlock(FileSystemContractBaseTest.java:338), org.apache.hadoop.fs.TestRawLocalFileSystemContract.testWriteReadAndDeleteOneBlock$$CONFUZZ(TestRawLocalFileSystemContract.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestRawLocalFileSystemContract/testWriteReadAndDeleteOneBlock/campaign/failures/debug_000000	{"io.file.buffer.size": "1714365668"}	["debug_000000"]	org.apache.hadoop.fs.shell.TestTextCommand#testDisplayForAvroFiles	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.shell.Display$Cat.getInputStream(Display.java:108), org.apache.hadoop.fs.shell.Display$Text.getInputStream(Display.java:125), org.apache.hadoop.fs.shell.TestTextCommand$1.getInputStream(TestTextCommand.java:118), org.apache.hadoop.fs.shell.TestTextCommand.readUsingTextCommand(TestTextCommand.java:122), org.apache.hadoop.fs.shell.TestTextCommand.testDisplayForAvroFiles(TestTextCommand.java:69), org.apache.hadoop.fs.shell.TestTextCommand.testDisplayForAvroFiles$$CONFUZZ(TestTextCommand.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestTextCommand/testDisplayForAvroFiles/campaign/failures/debug_000000	{"io.file.buffer.size": "2130640638"}	["debug_000000"]	org.apache.hadoop.fs.shell.TestTextCommand#testEmptyTextFil	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.shell.Display$Cat.getInputStream(Display.java:108), org.apache.hadoop.fs.shell.Display$Text.getInputStream(Display.java:125), org.apache.hadoop.fs.shell.TestTextCommand$1.getInputStream(TestTextCommand.java:118), org.apache.hadoop.fs.shell.TestTextCommand.readUsingTextCommand(TestTextCommand.java:122), org.apache.hadoop.fs.shell.TestTextCommand.testEmptyTextFil(TestTextCommand.java:80), org.apache.hadoop.fs.shell.TestTextCommand.testEmptyTextFil$$CONFUZZ(TestTextCommand.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestTextCommand/testEmptyTextFil/campaign/failures/debug_000000	{"io.file.buffer.size": "2130640638"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureOpenRandomFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenRandomFile(TestTFileByteArrays.java:411), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureOpenRandomFile$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureOpenRandomFile/campaign/failures/debug_000001	{"io.file.buffer.size": "1553382970"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteTwoBlocks	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FilterFileSystem.open(FilterFileSystem.java:168), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.open(ChRootedFileSystem.java:290), org.apache.hadoop.fs.viewfs.ViewFileSystem.open(ViewFileSystem.java:678), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:692), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteTwoBlocks(FSMainOperationsBaseTest.java:675), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testWriteReadAndDeleteTwoBlocks$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteTwoBlocks/campaign/failures/debug_000001	{"io.file.buffer.size": "2130640638"}	["debug_000001"]																																																																		
			9	org.apache.hadoop.crypto.key.TestKeyProviderFactory#testJksProviderWithKeytoolKeys	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.crypto.key.JavaKeyStoreProvider.loadFromPath(JavaKeyStoreProvider.java:293), org.apache.hadoop.crypto.key.JavaKeyStoreProvider.tryLoadFromPath(JavaKeyStoreProvider.java:193), org.apache.hadoop.crypto.key.JavaKeyStoreProvider.locateKeystore(JavaKeyStoreProvider.java:164), org.apache.hadoop.crypto.key.JavaKeyStoreProvider.<init>(JavaKeyStoreProvider.java:134), org.apache.hadoop.crypto.key.JavaKeyStoreProvider.<init>(JavaKeyStoreProvider.java:89), org.apache.hadoop.crypto.key.JavaKeyStoreProvider$Factory.createProvider(JavaKeyStoreProvider.java:661), org.apache.hadoop.crypto.key.KeyProviderFactory.get(KeyProviderFactory.java:96), org.apache.hadoop.crypto.key.KeyProviderFactory.getProviders(KeyProviderFactory.java:68), org.apache.hadoop.crypto.key.TestKeyProviderFactory.testJksProviderWithKeytoolKeys(TestKeyProviderFactory.java:448), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.TestKeyProviderFactory/testJksProviderWithKeytoolKeys/campaign/failures/debug_000001	{"io.file.buffer.size": "2092842949"}	["debug_000001"]	org.apache.hadoop.fs.TestRawLocalFileSystemContract#testWriteReadAndDeleteTwoBlocks	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(FileSystemContractBaseTest.java:927), org.apache.hadoop.fs.FileSystemContractBaseTest.writeReadAndDelete(FileSystemContractBaseTest.java:359), org.apache.hadoop.fs.FileSystemContractBaseTest.testWriteReadAndDeleteTwoBlocks(FileSystemContractBaseTest.java:348), org.apache.hadoop.fs.TestRawLocalFileSystemContract.testWriteReadAndDeleteTwoBlocks$$CONFUZZ(TestRawLocalFileSystemContract.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(FileSystemContractBaseTest.java:937), org.apache.hadoop.fs.FileSystemContractBaseTest.writeReadAndDelete(FileSystemContractBaseTest.java:359), org.apache.hadoop.fs.FileSystemContractBaseTest.testWriteReadAndDeleteTwoBlocks(FileSystemContractBaseTest.java:348), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestRawLocalFileSystemContract/testWriteReadAndDeleteTwoBlocks/campaign/failures/debug_000000	{"io.file.buffer.size": "2065511351"}	["debug_000000"]	org.apache.hadoop.io.compress.TestCodec#testGzipCodecRead	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.GzipCodec.createInputStream(GzipCodec.java:182), org.apache.hadoop.io.compress.TestCodec.testGzipCodecRead(TestCodec.java:783), org.apache.hadoop.io.compress.TestCodec.testGzipCodecRead$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.compress.TestCodec.testGzipCodecRead(TestCodec.java:782), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testGzipCodecRead/campaign/failures/debug_000000	{"io.file.buffer.size": "2130640638"}	["debug_000000"]	org.apache.hadoop.io.compress.TestCodec#testGzipCodecRead	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.compress.TestCodec.testGzipCodecRead(TestCodec.java:782), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testGzipCodecRead/campaign/failures/debug_000001	{"io.file.buffer.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.fs.TestChecksumFileSystem#testTruncatedChecksum	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FileSystemTestHelper.readFile(FileSystemTestHelper.java:203), org.apache.hadoop.fs.TestChecksumFileSystem.testTruncatedChecksum(TestChecksumFileSystem.java:158), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestChecksumFileSystem/testTruncatedChecksum/campaign/failures/debug_000002	{"io.file.buffer.size": "914874864"}	["debug_000002"]	org.apache.hadoop.fs.shell.TestTextCommand#testOneByteTextFil	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.shell.Display$Cat.getInputStream(Display.java:108), org.apache.hadoop.fs.shell.Display$Text.getInputStream(Display.java:125), org.apache.hadoop.fs.shell.TestTextCommand$1.getInputStream(TestTextCommand.java:118), org.apache.hadoop.fs.shell.TestTextCommand.readUsingTextCommand(TestTextCommand.java:122), org.apache.hadoop.fs.shell.TestTextCommand.testOneByteTextFil(TestTextCommand.java:90), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestTextCommand/testOneByteTextFil/campaign/failures/debug_000001	{"io.file.buffer.size": "2139127859"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testSyncable	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.contract.AbstractContractCreateTest.validateSyncableSemantics(AbstractContractCreateTest.java:556), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testSyncable(AbstractContractCreateTest.java:459), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testSyncable/campaign/failures/debug_000004	{"io.file.buffer.size": "1630685898"}	["debug_000004"]	org.apache.hadoop.fs.shell.TestTextCommand#testDisplayForAvroFiles	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.shell.Display$Cat.getInputStream(Display.java:108), org.apache.hadoop.fs.shell.Display$Text.getInputStream(Display.java:125), org.apache.hadoop.fs.shell.TestTextCommand$1.getInputStream(TestTextCommand.java:118), org.apache.hadoop.fs.shell.TestTextCommand.readUsingTextCommand(TestTextCommand.java:122), org.apache.hadoop.fs.shell.TestTextCommand.testDisplayForAvroFiles(TestTextCommand.java:69), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestTextCommand/testDisplayForAvroFiles/campaign/failures/debug_000001	{"io.file.buffer.size": "2130640638"}	["debug_000001"]	org.apache.hadoop.fs.shell.TestTextCommand#testEmptyTextFil	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.shell.Display$Cat.getInputStream(Display.java:108), org.apache.hadoop.fs.shell.Display$Text.getInputStream(Display.java:125), org.apache.hadoop.fs.shell.TestTextCommand$1.getInputStream(TestTextCommand.java:118), org.apache.hadoop.fs.shell.TestTextCommand.readUsingTextCommand(TestTextCommand.java:122), org.apache.hadoop.fs.shell.TestTextCommand.testEmptyTextFil(TestTextCommand.java:80), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestTextCommand/testEmptyTextFil/campaign/failures/debug_000001	{"io.file.buffer.size": "2137557251"}	["debug_000001"]																																																																																																																									
			3	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testCreateFlagAppendNonExistingFile	java.io.FileNotFoundException	Non existing file: /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/AoDzleGYYW/test/testCreateFlagAppendNonExistingFile. Create option is not specified in [APPEND]	org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:184), org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1294), org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102), org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:353), org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400), org.apache.hadoop.fs.viewfs.ChRootedFs.createInternal(ChRootedFs.java:179), org.apache.hadoop.fs.viewfs.ViewFs.createInternal(ViewFs.java:358), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testCreateFlagAppendNonExistingFile(FileContextMainOperationsBaseTest.java:816), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.testCreateFlagAppendNonExistingFile$$CONFUZZ(TestFcMainOperationsLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testCreateFlagAppendNonExistingFile/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.TestLocalFSFileContextMainOperations#testCreateFlagOverwriteNonExistingFile	java.io.FileNotFoundException	Non existing file: file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/GmTlRGVhfR/test/testCreateFlagOverwriteNonExistingFile. Create option is not specified in [OVERWRITE]	org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:184), org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1294), org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102), org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:353), org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testCreateFlagOverwriteNonExistingFile(FileContextMainOperationsBaseTest.java:801), org.apache.hadoop.fs.TestLocalFSFileContextMainOperations.testCreateFlagOverwriteNonExistingFile$$CONFUZZ(TestLocalFSFileContextMainOperations.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSFileContextMainOperations/testCreateFlagOverwriteNonExistingFile/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.TestLocalFSFileContextMainOperations#testCreateFlagAppendNonExistingFile	java.io.FileNotFoundException	Non existing file: file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/22OfAHkoAX/test/testCreateFlagAppendNonExistingFile. Create option is not specified in [APPEND]	org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:184), org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1294), org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102), org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:353), org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testCreateFlagAppendNonExistingFile(FileContextMainOperationsBaseTest.java:816), org.apache.hadoop.fs.TestLocalFSFileContextMainOperations.testCreateFlagAppendNonExistingFile$$CONFUZZ(TestLocalFSFileContextMainOperations.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSFileContextMainOperations/testCreateFlagAppendNonExistingFile/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																											
		FP	6	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testTokenServiceCreationWithUriFormat	java.lang.IllegalArgumentException	lowWatermark must be > 0 and <= 1	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:225), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat(TestLoadBalancingKMSClientProvider.java:905), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testTokenServiceCreationWithUriFormat/campaign/failures/debug_000000	{"hadoop.security.kms.client.encrypted.key.cache.low-watermark": "0.0f"}	["debug_000000"]	org.apache.hadoop.crypto.key.kms.TestKMSClientProvider#testSelectTokenWhenBothExist	java.lang.IllegalArgumentException	lowWatermark must be > 0 and <= 1	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:225), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenWhenBothExist(TestKMSClientProvider.java:106), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenWhenBothExist$$CONFUZZ(TestKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestKMSClientProvider/testSelectTokenWhenBothExist/campaign/failures/debug_000002	{"hadoop.security.kms.client.encrypted.key.cache.low-watermark": "0.00f"}	["debug_000002"]	org.apache.hadoop.crypto.key.kms.TestKMSClientProvider#testSelectTokenOldService	java.lang.IllegalArgumentException	lowWatermark must be > 0 and <= 1	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:225), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenOldService(TestKMSClientProvider.java:90), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenOldService$$CONFUZZ(TestKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestKMSClientProvider/testSelectTokenOldService/campaign/failures/debug_000000	{"hadoop.security.kms.client.encrypted.key.cache.low-watermark": "0.0f"}	["debug_000000"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testGetActualUGI	java.lang.IllegalArgumentException	lowWatermark must be > 0 and <= 1	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:225), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:941), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:937), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithConf(TestLoadBalancingKMSClientProvider.java:937), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testGetActualUGI(TestLoadBalancingKMSClientProvider.java:978), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testGetActualUGI$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testGetActualUGI/campaign/failures/debug_000002	{"hadoop.security.kms.client.encrypted.key.cache.low-watermark": "0.00f"}	["debug_000002"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testClassCastException	java.lang.IllegalArgumentException	lowWatermark must be > 0 and <= 1	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:225), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$MyKMSClientProvider.<init>(TestLoadBalancingKMSClientProvider.java:223), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClassCastException(TestLoadBalancingKMSClientProvider.java:260), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClassCastException$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testClassCastException/campaign/failures/debug_000000	{"hadoop.security.kms.client.encrypted.key.cache.low-watermark": "0.0f"}	["debug_000000"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testTokenSelectionWithKMSUriInConf	java.lang.IllegalArgumentException	lowWatermark must be > 0 and <= 1	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:225), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:941), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:937), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithConf(TestLoadBalancingKMSClientProvider.java:937), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithKMSUriInConf(TestLoadBalancingKMSClientProvider.java:968), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithKMSUriInConf$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testTokenSelectionWithKMSUriInConf/campaign/failures/debug_000000	{"hadoop.security.kms.client.encrypted.key.cache.low-watermark": "0.0f"}	["debug_000000"]																																																																																																																																																										
		FP	2	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testTokenServiceCreationWithUriFormat	java.lang.IllegalArgumentException	(int) ("numValues" * "lowWatermark") must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:228), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat(TestLoadBalancingKMSClientProvider.java:905), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testTokenServiceCreationWithUriFormat/campaign/failures/debug_000002	{"hadoop.security.kms.client.encrypted.key.cache.size": "11", "hadoop.security.kms.client.encrypted.key.cache.low-watermark": "0.056f"}	["debug_000002"]	org.apache.hadoop.crypto.key.kms.TestKMSClientProvider#testSelectTokenWhenBothExist	java.lang.IllegalArgumentException	(int) ("numValues" * "lowWatermark") must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:228), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenWhenBothExist(TestKMSClientProvider.java:106), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenWhenBothExist$$CONFUZZ(TestKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestKMSClientProvider/testSelectTokenWhenBothExist/campaign/failures/debug_000000	{"hadoop.security.kms.client.encrypted.key.cache.size": "166", "hadoop.security.kms.client.encrypted.key.cache.low-watermark": "0.004f"}	["debug_000000"]																																																																																																																																																																																																						
		FP	10	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testTokenServiceCreationWithUriFormat	java.lang.IllegalArgumentException	numValues must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:224), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat(TestLoadBalancingKMSClientProvider.java:905), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testTokenServiceCreationWithUriFormat/campaign/failures/debug_000001	{"hadoop.security.kms.client.encrypted.key.cache.size": "0"}	["debug_000001"]	org.apache.hadoop.crypto.key.kms.TestKMSClientProvider#testSelectTokenWhenBothExist	java.lang.IllegalArgumentException	numValues must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:224), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenWhenBothExist(TestKMSClientProvider.java:106), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenWhenBothExist$$CONFUZZ(TestKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestKMSClientProvider/testSelectTokenWhenBothExist/campaign/failures/debug_000001	{"hadoop.security.kms.client.encrypted.key.cache.size": "0"}	["debug_000001"]	org.apache.hadoop.crypto.key.kms.TestKMSClientProvider#testSelectTokenOldService	java.lang.IllegalArgumentException	(int) ("numValues" * "lowWatermark") must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:228), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenOldService(TestKMSClientProvider.java:90), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenOldService$$CONFUZZ(TestKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestKMSClientProvider/testSelectTokenOldService/campaign/failures/debug_000002	{"hadoop.security.kms.client.encrypted.key.cache.size": "1"}	["debug_000002"]	org.apache.hadoop.crypto.key.kms.TestKMSClientProvider#testSelectTokenOldService	java.lang.IllegalArgumentException	numValues must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:224), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenOldService(TestKMSClientProvider.java:90), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenOldService$$CONFUZZ(TestKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestKMSClientProvider/testSelectTokenOldService/campaign/failures/debug_000001	{"hadoop.security.kms.client.encrypted.key.cache.size": "0"}	["debug_000001"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testGetActualUGI	java.lang.IllegalArgumentException	numValues must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:224), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:941), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:937), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithConf(TestLoadBalancingKMSClientProvider.java:937), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testGetActualUGI(TestLoadBalancingKMSClientProvider.java:978), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testGetActualUGI$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testGetActualUGI/campaign/failures/debug_000004	{"hadoop.security.kms.client.encrypted.key.cache.size": "0"}	["debug_000004"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testGetActualUGI	java.lang.IllegalArgumentException	(int) ("numValues" * "lowWatermark") must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:228), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:941), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:937), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithConf(TestLoadBalancingKMSClientProvider.java:937), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testGetActualUGI(TestLoadBalancingKMSClientProvider.java:978), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testGetActualUGI$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testGetActualUGI/campaign/failures/debug_000003	{"hadoop.security.kms.client.encrypted.key.cache.size": "2"}	["debug_000003"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testClassCastException	java.lang.IllegalArgumentException	(int) ("numValues" * "lowWatermark") must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:228), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$MyKMSClientProvider.<init>(TestLoadBalancingKMSClientProvider.java:223), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClassCastException(TestLoadBalancingKMSClientProvider.java:260), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClassCastException$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testClassCastException/campaign/failures/debug_000002	{"hadoop.security.kms.client.encrypted.key.cache.size": "1"}	["debug_000002"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testClassCastException	java.lang.IllegalArgumentException	numValues must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:224), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$MyKMSClientProvider.<init>(TestLoadBalancingKMSClientProvider.java:223), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClassCastException(TestLoadBalancingKMSClientProvider.java:260), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClassCastException$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testClassCastException/campaign/failures/debug_000003	{"hadoop.security.kms.client.encrypted.key.cache.size": "0"}	["debug_000003"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testTokenSelectionWithKMSUriInConf	java.lang.IllegalArgumentException	(int) ("numValues" * "lowWatermark") must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:228), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:941), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:937), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithConf(TestLoadBalancingKMSClientProvider.java:937), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithKMSUriInConf(TestLoadBalancingKMSClientProvider.java:968), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithKMSUriInConf$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testTokenSelectionWithKMSUriInConf/campaign/failures/debug_000002	{"hadoop.security.kms.client.encrypted.key.cache.size": "1"}	["debug_000002"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testTokenSelectionWithKMSUriInConf	java.lang.IllegalArgumentException	numValues must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:224), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:941), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:937), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithConf(TestLoadBalancingKMSClientProvider.java:937), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithKMSUriInConf(TestLoadBalancingKMSClientProvider.java:968), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithKMSUriInConf$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testTokenSelectionWithKMSUriInConf/campaign/failures/debug_000003	{"hadoop.security.kms.client.encrypted.key.cache.size": "0"}	["debug_000003"]																																																																																																														
		Filtered	5	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testTokenServiceCreationWithUriFormat	java.lang.IllegalArgumentException	expiry must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:230), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat(TestLoadBalancingKMSClientProvider.java:905), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testTokenServiceCreationWithUriFormat/campaign/failures/debug_000004	{"hadoop.security.kms.client.encrypted.key.cache.expiry": "0"}	["debug_000004"]	org.apache.hadoop.crypto.key.kms.TestKMSClientProvider#testSelectTokenWhenBothExist	java.lang.IllegalArgumentException	expiry must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:230), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenWhenBothExist(TestKMSClientProvider.java:106), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenWhenBothExist$$CONFUZZ(TestKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestKMSClientProvider/testSelectTokenWhenBothExist/campaign/failures/debug_000003	{"hadoop.security.kms.client.encrypted.key.cache.expiry": "0"}	["debug_000003"]	org.apache.hadoop.crypto.key.kms.TestKMSClientProvider#testSelectTokenOldService	java.lang.IllegalArgumentException	expiry must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:230), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenOldService(TestKMSClientProvider.java:90), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenOldService$$CONFUZZ(TestKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestKMSClientProvider/testSelectTokenOldService/campaign/failures/debug_000004	{"hadoop.security.kms.client.encrypted.key.cache.expiry": "0"}	["debug_000004"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testGetActualUGI	java.lang.IllegalArgumentException	expiry must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:230), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:941), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:937), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithConf(TestLoadBalancingKMSClientProvider.java:937), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testGetActualUGI(TestLoadBalancingKMSClientProvider.java:978), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testGetActualUGI$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testGetActualUGI/campaign/failures/debug_000000	{"hadoop.security.kms.client.encrypted.key.cache.expiry": "0"}	["debug_000000"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testTokenSelectionWithKMSUriInConf	java.lang.IllegalArgumentException	expiry must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:230), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:941), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:937), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithConf(TestLoadBalancingKMSClientProvider.java:937), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithKMSUriInConf(TestLoadBalancingKMSClientProvider.java:968), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithKMSUriInConf$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testTokenSelectionWithKMSUriInConf/campaign/failures/debug_000004	{"hadoop.security.kms.client.encrypted.key.cache.expiry": "0"}	["debug_000004"]																																																																																																																																																																					
		Filtered	6	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testTokenServiceCreationWithUriFormat	java.lang.IllegalArgumentException	numFillerThreads must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:231), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat(TestLoadBalancingKMSClientProvider.java:905), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenServiceCreationWithUriFormat$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testTokenServiceCreationWithUriFormat/campaign/failures/debug_000003	{"hadoop.security.kms.client.encrypted.key.cache.num.refill.threads": "0"}	["debug_000003"]	org.apache.hadoop.crypto.key.kms.TestKMSClientProvider#testSelectTokenWhenBothExist	java.lang.IllegalArgumentException	numFillerThreads must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:231), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenWhenBothExist(TestKMSClientProvider.java:106), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenWhenBothExist$$CONFUZZ(TestKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestKMSClientProvider/testSelectTokenWhenBothExist/campaign/failures/debug_000004	{"hadoop.security.kms.client.encrypted.key.cache.num.refill.threads": "0"}	["debug_000004"]	org.apache.hadoop.crypto.key.kms.TestKMSClientProvider#testSelectTokenOldService	java.lang.IllegalArgumentException	numFillerThreads must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:231), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenOldService(TestKMSClientProvider.java:90), org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testSelectTokenOldService$$CONFUZZ(TestKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestKMSClientProvider/testSelectTokenOldService/campaign/failures/debug_000003	{"hadoop.security.kms.client.encrypted.key.cache.num.refill.threads": "0"}	["debug_000003"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testGetActualUGI	java.lang.IllegalArgumentException	numFillerThreads must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:231), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:941), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:937), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithConf(TestLoadBalancingKMSClientProvider.java:937), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testGetActualUGI(TestLoadBalancingKMSClientProvider.java:978), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testGetActualUGI$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testGetActualUGI/campaign/failures/debug_000001	{"hadoop.security.kms.client.encrypted.key.cache.num.refill.threads": "0"}	["debug_000001"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testClassCastException	java.lang.IllegalArgumentException	numFillerThreads must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:231), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$MyKMSClientProvider.<init>(TestLoadBalancingKMSClientProvider.java:223), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClassCastException(TestLoadBalancingKMSClientProvider.java:260), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClassCastException$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testClassCastException/campaign/failures/debug_000001	{"hadoop.security.kms.client.encrypted.key.cache.num.refill.threads": "0"}	["debug_000001"]	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testTokenSelectionWithKMSUriInConf	java.lang.IllegalArgumentException	numFillerThreads must be > 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:231), org.apache.hadoop.crypto.key.kms.ValueQueue.<init>(ValueQueue.java:263), org.apache.hadoop.crypto.key.kms.KMSClientProvider.<init>(KMSClientProvider.java:417), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProviders(KMSClientProvider.java:319), org.apache.hadoop.crypto.key.kms.KMSClientProvider$Factory.createProvider(KMSClientProvider.java:304), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:941), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$1.run(TestLoadBalancingKMSClientProvider.java:937), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithConf(TestLoadBalancingKMSClientProvider.java:937), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithKMSUriInConf(TestLoadBalancingKMSClientProvider.java:968), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testTokenSelectionWithKMSUriInConf$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testTokenSelectionWithKMSUriInConf/campaign/failures/debug_000001	{"hadoop.security.kms.client.encrypted.key.cache.num.refill.threads": "0"}	["debug_000001"]																																																																																																																																																										
			2	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testOneDataEntry	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:612), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneDataEntry(TestTFileByteArrays.java:123), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testOneDataEntry$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testOneDataEntry/campaign/failures/debug_000002	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "29663", "fs.client.resolve.remote.symlinks": "true", "hadoop.service.shutdown.timeout": "16736281h", "file.stream-buffer-size": "12516", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "true", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "tfile.fs.input.buffer.size": "2019061142", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "1206549421", "fs.creation.parallel.count": "11401", "file.bytes-per-checksum": "26550", "fs.automatic.close": "true", "hadoop.security.dns.log-slow-lookups.threshold.ms": "12335", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "542", "zlib.compress.level": "DEFAULT_COMPRESSION", "fs.local.block.size": "2008457880", "fs.file.impl.disable.cache": "true", "hadoop.security.token.service.use_ip": "true", "hadoop.kerberos.min.seconds.before.relogin": "24946", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "tfile.fs.output.buffer.size": "25972", "hadoop.security.groups.cache.warn.after.ms": "6094"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testTwoEntriesKnownLength	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testTwoEntriesKnownLength(TestTFileStreams.java:146), org.apache.hadoop.io.file.tfile.TestTFileStreams.testTwoEntriesKnownLength$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testTwoEntriesKnownLength/campaign/failures/debug_000001	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "1376799982", "fs.client.resolve.remote.symlinks": "true", "hadoop.service.shutdown.timeout": "68591s", "file.stream-buffer-size": "25172", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "tfile.fs.input.buffer.size": "2059735976", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "855", "fs.creation.parallel.count": "219", "file.bytes-per-checksum": "729", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "1943260925", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "9023", "zlib.compress.level": "DEFAULT_COMPRESSION", "fs.local.block.size": "92", "fs.file.impl.disable.cache": "false", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "1407696171", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "tfile.fs.output.buffer.size": "25037", "hadoop.security.groups.cache.warn.after.ms": "773548457"}	["debug_000001"]																																																																																																																																																																																																						
			22	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testCreateFileUnderFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractCreateTest.createFile(AbstractContractCreateTest.java:447), org.apache.hadoop.fs.contract.AbstractContractCreateTest.expectCreateUnderFileFails(AbstractContractCreateTest.java:413), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreateFileUnderFile(AbstractContractCreateTest.java:348), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testCreateFileUnderFile/campaign/failures/debug_000002	{"file.stream-buffer-size": "1610758329", "io.file.buffer.size": "582484717"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus#testListFilesFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.ContractTestUtils.touch(ContractTestUtils.java:672), org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.touchf(AbstractContractGetFileStatusTest.java:466), org.apache.hadoop.fs.contract.AbstractContractGetFileStatusTest.testListFilesFile(AbstractContractGetFileStatusTest.java:398), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractGetFileStatus/testListFilesFile/campaign/failures/debug_000002	{"io.file.buffer.size": "1057013919", "file.stream-buffer-size": "1479838971"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testMkdirUnderFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractCreateTest.createFile(AbstractContractCreateTest.java:447), org.apache.hadoop.fs.contract.AbstractContractCreateTest.expectMkdirsUnderFileFails(AbstractContractCreateTest.java:430), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testMkdirUnderFile(AbstractContractCreateTest.java:377), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testMkdirUnderFile/campaign/failures/debug_000003	{"io.file.buffer.size": "760079079", "file.stream-buffer-size": "1782480859"}	["debug_000003"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameFileToDestViaSymlink	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameFileToDestViaSymlink(SymlinkBaseTest.java:838), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameFileToDestViaSymlink/campaign/failures/debug_000002	{"io.file.buffer.size": "1620975530", "file.stream-buffer-size": "1385607437"}	["debug_000002"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testGetAccessTime	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:165), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testGetAccessTime(TestSFTPFileSystem.java:341), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testGetAccessTime/campaign/failures/debug_000002	{"io.file.buffer.size": "1951203317", "file.stream-buffer-size": "1682761679"}	["debug_000002"]	org.apache.hadoop.fs.TestFileUtil#testWriteStringNoCharSetFileSystem	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.createNonRecursive(ChecksumFileSystem.java:565), org.apache.hadoop.fs.FileSystem$FileSystemDataOutputStreamBuilder.build(FileSystem.java:4523), org.apache.hadoop.fs.FileUtil.write(FileUtil.java:1824), org.apache.hadoop.fs.FileUtil.write(FileUtil.java:1879), org.apache.hadoop.fs.TestFileUtil.testWriteStringNoCharSetFileSystem(TestFileUtil.java:1619), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFileUtil/testWriteStringNoCharSetFileSystem/campaign/failures/debug_000001	{"io.file.buffer.size": "525223009", "file.stream-buffer-size": "1459876333"}	["debug_000001"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testCreateLinkToDirectory	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testCreateLinkToDirectory(SymlinkBaseTest.java:611), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testCreateLinkToDirectory/campaign/failures/debug_000002	{"io.file.buffer.size": "1633557923", "file.stream-buffer-size": "648031648"}	["debug_000002"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testStatLinkToFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testStatLinkToFile(SymlinkBaseTest.java:233), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testStatLinkToFile/campaign/failures/debug_000002	{"file.stream-buffer-size": "2025970833", "io.file.buffer.size": "190202836"}	["debug_000002"]	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testFileExists	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:165), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testFileExists(TestSFTPFileSystem.java:207), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testFileExists/campaign/failures/debug_000003	{"io.file.buffer.size": "1785891604", "file.stream-buffer-size": "1171550075"}	["debug_000003"]	org.apache.hadoop.fs.TestFileUtil#testWriteBytesFileSystem	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.createNonRecursive(ChecksumFileSystem.java:565), org.apache.hadoop.fs.FileSystem$FileSystemDataOutputStreamBuilder.build(FileSystem.java:4523), org.apache.hadoop.fs.FileUtil.write(FileUtil.java:1690), org.apache.hadoop.fs.TestFileUtil.testWriteBytesFileSystem(TestFileUtil.java:1559), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFileUtil/testWriteBytesFileSystem/campaign/failures/debug_000002	{"io.file.buffer.size": "1773430958", "file.stream-buffer-size": "1412835244"}	["debug_000002"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameDirToSymlinkToFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameDirToSymlinkToFile(SymlinkBaseTest.java:913), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameDirToSymlinkToFile/campaign/failures/debug_000002	{"file.stream-buffer-size": "1295384833", "io.file.buffer.size": "1686710746"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureCompressionNotWorking	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.setUp(TestTFileNoneCodecsJClassComparatorByteArrays.java:37), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureCompressionNotWorking/campaign/failures/debug_000002	{"io.file.buffer.size": "1313213532", "file.stream-buffer-size": "1347403509"}	["debug_000002"]	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:634), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000003	{"io.file.buffer.size": "1252261127", "file.stream-buffer-size": "789648051"}	["debug_000003"]	org.apache.hadoop.io.TestMapFile#testMainMethodMapFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.io.SequenceFile$Reader.openFile(SequenceFile.java:1962), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1882), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:412), org.apache.hadoop.io.MapFile.main(MapFile.java:1015), org.apache.hadoop.io.TestMapFile.testMainMethodMapFile(TestMapFile.java:677), org.apache.hadoop.io.TestMapFile.testMainMethodMapFile$$CONFUZZ(TestMapFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170), org.apache.hadoop.io.SequenceFile$RecordCompressWriter.<init>(SequenceFile.java:1499), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:288), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.TestMapFile.createWriter(TestMapFile.java:131), org.apache.hadoop.io.TestMapFile.testMainMethodMapFile(TestMapFile.java:673), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestMapFile/testMainMethodMapFile/campaign/failures/debug_000000	{"io.file.buffer.size": "1960753455", "file.stream-buffer-size": "2013598714"}	["debug_000000", "debug_000001"]	org.apache.hadoop.security.alias.TestCredShell#testPromptForCredential	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:728), org.apache.hadoop.security.alias.KeyStoreProvider.getOutputStreamForKeystore(KeyStoreProvider.java:54), org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.flush(AbstractJavaKeyStoreProvider.java:292), org.apache.hadoop.security.alias.CredentialShell$CreateCommand.execute(CredentialShell.java:447), org.apache.hadoop.tools.CommandShell.run(CommandShell.java:72), org.apache.hadoop.security.alias.TestCredShell.testPromptForCredential(TestCredShell.java:179), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.alias.TestCredShell/testPromptForCredential/campaign/failures/debug_000003	{"file.stream-buffer-size": "2034198549", "io.file.buffer.size": "2032072782"}	["debug_000003"]	org.apache.hadoop.security.token.TestDtUtilShell#testGetWithServiceFlag	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.token.DtFileOperations.doFormattedWrite(DtFileOperations.java:113), org.apache.hadoop.security.token.DtFileOperations.getTokenFile(DtFileOperations.java:219), org.apache.hadoop.security.token.DtUtilShell$Get.execute(DtUtilShell.java:243), org.apache.hadoop.tools.CommandShell.run(CommandShell.java:72), org.apache.hadoop.security.token.TestDtUtilShell.testGetWithServiceFlag(TestDtUtilShell.java:240), org.apache.hadoop.security.token.TestDtUtilShell.testGetWithServiceFlag$$CONFUZZ(TestDtUtilShell.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.token.TestDtUtilShell.makeTokenFile(TestDtUtilShell.java:124), org.apache.hadoop.security.token.TestDtUtilShell.setup(TestDtUtilShell.java:95), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.TestDtUtilShell/testGetWithServiceFlag/campaign/failures/debug_000000	{"io.file.buffer.size": "693303750", "file.stream-buffer-size": "1425997658"}	["debug_000000"]	org.apache.hadoop.security.token.TestDtUtilShell#testGetWithServiceFlag	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.token.TestDtUtilShell.makeTokenFile(TestDtUtilShell.java:124), org.apache.hadoop.security.token.TestDtUtilShell.setup(TestDtUtilShell.java:95), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.TestDtUtilShell/testGetWithServiceFlag/campaign/failures/debug_000003	{"file.stream-buffer-size": "1888232784", "io.file.buffer.size": "1477563602"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestVLong#testVLong8Bytes	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestVLong.writeAndVerify(TestVLong.java:82), org.apache.hadoop.io.file.tfile.TestVLong.verifySixOrMoreBytes(TestVLong.java:127), org.apache.hadoop.io.file.tfile.TestVLong.testVLong8Bytes(TestVLong.java:144), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestVLong/testVLong8Bytes/campaign/failures/debug_000003	{"io.file.buffer.size": "1717986803", "file.stream-buffer-size": "620732575"}	["debug_000003"]	org.apache.hadoop.fs.TestTrash#testTrash	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemTestHelper.writeFile(FileSystemTestHelper.java:190), org.apache.hadoop.fs.TestTrash.trashShell(TestTrash.java:161), org.apache.hadoop.fs.TestTrash.trashShell(TestTrash.java:121), org.apache.hadoop.fs.TestTrash.testTrash(TestTrash.java:573), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestTrash/testTrash/campaign/failures/debug_000002	{"file.stream-buffer-size": "1125337936", "io.file.buffer.size": "848375083"}	["debug_000002"]	org.apache.hadoop.security.token.TestDtUtilShell#testGetWithAliasFlag	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.token.DtFileOperations.doFormattedWrite(DtFileOperations.java:113), org.apache.hadoop.security.token.DtFileOperations.getTokenFile(DtFileOperations.java:219), org.apache.hadoop.security.token.DtUtilShell$Get.execute(DtUtilShell.java:243), org.apache.hadoop.tools.CommandShell.run(CommandShell.java:72), org.apache.hadoop.security.token.TestDtUtilShell.testGetWithAliasFlag(TestDtUtilShell.java:255), org.apache.hadoop.security.token.TestDtUtilShell.testGetWithAliasFlag$$CONFUZZ(TestDtUtilShell.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.token.TestDtUtilShell.makeTokenFile(TestDtUtilShell.java:124), org.apache.hadoop.security.token.TestDtUtilShell.setup(TestDtUtilShell.java:95), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.TestDtUtilShell/testGetWithAliasFlag/campaign/failures/debug_000001	{"file.stream-buffer-size": "1710745938", "io.file.buffer.size": "402395718"}	["debug_000001"]
			1	org.apache.hadoop.util.TestJsonSerialization#testFileSystemEmptyPath	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.ChecksumFileSystem.lambda$openFileWithOptions$0(ChecksumFileSystem.java:896), org.apache.hadoop.fs.ChecksumFileSystem$$Lambda$84/0x000000084015f040.call(Unknown Source), org.apache.hadoop.util.LambdaUtils.eval(LambdaUtils.java:52), org.apache.hadoop.fs.ChecksumFileSystem.openFileWithOptions(ChecksumFileSystem.java:894), org.apache.hadoop.fs.FileSystem$FSDataInputStreamBuilder.build(FileSystem.java:4768), org.apache.hadoop.util.JsonSerialization.load(JsonSerialization.java:271), org.apache.hadoop.util.JsonSerialization.load(JsonSerialization.java:245), org.apache.hadoop.util.TestJsonSerialization.lambda$testFileSystemEmptyPath$2(TestJsonSerialization.java:191), org.apache.hadoop.util.TestJsonSerialization$$Lambda$82/0x000000084015dc40.call(Unknown Source), org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:498), org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:384), org.apache.hadoop.util.TestJsonSerialization.testFileSystemEmptyPath(TestJsonSerialization.java:190), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.util.TestJsonSerialization/testFileSystemEmptyPath/campaign/failures/debug_000001	{"fs.defaultFS": "file:///", "hadoop.security.dns.log-slow-lookups.threshold.ms": "707564342", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "243", "hadoop.security.authentication": "kerberos", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "6s", "file.stream-buffer-size": "2332", "hadoop.security.groups.cache.background.reload.threads": "2038702488", "fs.local.block.size": "203949034", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "true", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "2130640638", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "440282813", "hadoop.security.groups.negative-cache.secs": "20456", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "fs.creation.parallel.count": "1285768169", "file.bytes-per-checksum": "778", "hadoop.security.groups.cache.warn.after.ms": "7444"}	["debug_000001"]																																																																																																																																																																																																																	
			3	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithoutKeyStorePassword	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStorePassword(TestSSLHttpServerConfigs.java:154), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStorePassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithoutKeyStorePassword/campaign/failures/debug_000005	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000005"]	org.apache.hadoop.http.TestHttpServerLifecycle#testStoppingTwiceServerIsAllowed	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.HttpServerFunctionalTest.createAndStartTestServer(HttpServerFunctionalTest.java:224), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppingTwiceServerIsAllowed(TestHttpServerLifecycle.java:121), org.apache.hadoop.http.TestHttpServerLifecycle.testStoppingTwiceServerIsAllowed$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testStoppingTwiceServerIsAllowed/campaign/failures/debug_000003	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000003"]	org.apache.hadoop.http.TestHttpServer#testBindAddress	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testBindAddress/campaign/failures/debug_000005	{"hadoop.prometheus.endpoint.enabled": "true"}	["debug_000005"]																																																																																																																																																																																											
	Bug-17	Repeated	4	org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays#testScan	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.setUp(TestTFileUnsortedByteArrays.java:74), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays/testScan/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "1828651540", "file.stream-buffer-size": "1208407129"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureNegativeOffset	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeOffset(TestTFileByteArrays.java:459), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureNegativeOffset$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureNegativeOffset/campaign/failures/debug_000001	{"file.stream-buffer-size": "740337837", "tfile.fs.output.buffer.size": "1534216767"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testNoEntry	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileStreams.closeOutput(TestTFileStreams.java:437), org.apache.hadoop.io.file.tfile.TestTFileStreams.testNoEntry(TestTFileStreams.java:96), org.apache.hadoop.io.file.tfile.TestTFileStreams.testNoEntry$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testNoEntry/campaign/failures/debug_000001	{"file.stream-buffer-size": "1502033632", "tfile.fs.output.buffer.size": "676554380"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureCompressionNotWorking	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureCompressionNotWorking(TestTFileByteArrays.java:550), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureCompressionNotWorking$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureCompressionNotWorking/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "1214908405", "file.stream-buffer-size": "1019487242"}	["debug_000001"]																																																																																																																																																																																
			1	org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays#testScan	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testScan(TestTFileUnsortedByteArrays.java:105), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testScan$$CONFUZZ(TestTFileUnsortedByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays/testScan/campaign/failures/debug_000001	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "72", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "8312s", "file.stream-buffer-size": "351825973", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "tfile.fs.input.buffer.size": "1359540569", "hadoop.kerberos.keytab.login.autorenewal.enabled": "true", "hadoop.security.groups.negative-cache.secs": "1452740596", "fs.creation.parallel.count": "1126187234", "file.bytes-per-checksum": "992", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "24665", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "837620873", "fs.local.block.size": "1118259416", "fs.file.impl.disable.cache": "true", "hadoop.security.token.service.use_ip": "true", "hadoop.kerberos.min.seconds.before.relogin": "560281462", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "tfile.fs.output.buffer.size": "21821", "hadoop.security.groups.cache.warn.after.ms": "26136"}	["debug_000001"]																																																																																																																																																																																																																	
	Bug-173	BUG	2	org.apache.hadoop.io.compress.TestCodec#testGzipCompatibility	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.GzipCodec.createInputStream(GzipCodec.java:182), org.apache.hadoop.io.compress.TestCodec.testGzipCompatibility(TestCodec.java:693), org.apache.hadoop.io.compress.TestCodec.testGzipCompatibility$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testGzipCompatibility/campaign/failures/debug_000000	{"io.file.buffer.size": "2130640638"}	["debug_000000"]	org.apache.hadoop.io.compress.TestCompressionStreamReuse#testGzipCompressStreamReuse	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.GzipCodec.createInputStream(GzipCodec.java:182), org.apache.hadoop.io.compress.CompressionCodec$Util.createInputStreamWithCodecPool(CompressionCodec.java:160), org.apache.hadoop.io.compress.GzipCodec.createInputStream(GzipCodec.java:171), org.apache.hadoop.io.compress.TestCompressionStreamReuse.resetStateTest(TestCompressionStreamReuse.java:153), org.apache.hadoop.io.compress.TestCompressionStreamReuse.testGzipCompressStreamReuse(TestCompressionStreamReuse.java:59), org.apache.hadoop.io.compress.TestCompressionStreamReuse.testGzipCompressStreamReuse$$CONFUZZ(TestCompressionStreamReuse.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCompressionStreamReuse/testGzipCompressStreamReuse/campaign/failures/debug_000000	{"io.file.buffer.size": "2147417854"}	["debug_000000"]																																																																																																																																																																																																						
			3	org.apache.hadoop.io.compress.TestCodec#testGzipCompatibility	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.GzipCodec.createInputStream(GzipCodec.java:182), org.apache.hadoop.io.compress.TestCodec.testGzipCompatibility(TestCodec.java:693), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testGzipCompatibility/campaign/failures/debug_000001	{"io.file.buffer.size": "2130673407"}	["debug_000001"]	org.apache.hadoop.io.TestSetFile#testSetFileAccessMethods	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2067), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:447), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.SetFile$Reader.<init>(SetFile.java:86), org.apache.hadoop.io.TestSetFile.createReader(TestSetFile.java:81), org.apache.hadoop.io.TestSetFile.testSetFileAccessMethods(TestSetFile.java:69), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSetFile/testSetFileAccessMethods/campaign/failures/debug_000002	{"io.file.buffer.size": "421137192"}	["debug_000002"]	org.apache.hadoop.io.compress.TestCompressionStreamReuse#testGzipCompressStreamReuse	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.GzipCodec.createInputStream(GzipCodec.java:182), org.apache.hadoop.io.compress.CompressionCodec$Util.createInputStreamWithCodecPool(CompressionCodec.java:160), org.apache.hadoop.io.compress.GzipCodec.createInputStream(GzipCodec.java:171), org.apache.hadoop.io.compress.TestCompressionStreamReuse.resetStateTest(TestCompressionStreamReuse.java:153), org.apache.hadoop.io.compress.TestCompressionStreamReuse.testGzipCompressStreamReuse(TestCompressionStreamReuse.java:59), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCompressionStreamReuse/testGzipCompressStreamReuse/campaign/failures/debug_000001	{"io.file.buffer.size": "2130640638"}	["debug_000001"]																																																																																																																																																																																											
	Bug-143	Repeated	1	org.apache.hadoop.fs.viewfs.TestViewFsOverloadSchemeListStatus#testListStatusACL	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.viewfs.ViewFileSystemOverloadScheme.initialize(ViewFileSystemOverloadScheme.java:161), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.TestViewFsOverloadSchemeListStatus.testListStatusACL(TestViewFsOverloadSchemeListStatus.java:92), org.apache.hadoop.fs.viewfs.TestViewFsOverloadSchemeListStatus.testListStatusACL$$CONFUZZ(TestViewFsOverloadSchemeListStatus.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsOverloadSchemeListStatus/testListStatusACL/campaign/failures/debug_000001	{"fs.file.impl.disable.cache": "true", "fs.viewfs.mounttable.default.name.key": "default"}	["debug_000001"]																																																																																																																																																																																																																	
	Bug-174	BUG	2	org.apache.hadoop.fs.TestHarFileSystemBasics#testPositiveListFilesNotEndInColon	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.util.LineReader.<init>(LineReader.java:82), org.apache.hadoop.util.LineReader.<init>(LineReader.java:95), org.apache.hadoop.fs.HarFileSystem$HarMetaData.parseMetaData(HarFileSystem.java:1176), org.apache.hadoop.fs.HarFileSystem$HarMetaData.access$000(HarFileSystem.java:1115), org.apache.hadoop.fs.HarFileSystem.initialize(HarFileSystem.java:172), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:93), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testPositiveListFilesNotEndInColon/campaign/failures/debug_000002	{"io.file.buffer.size": "1615330367"}	["debug_000002"]	org.apache.hadoop.fs.TestHarFileSystemBasics#testNegativeHarFsModifications	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.util.LineReader.<init>(LineReader.java:82), org.apache.hadoop.util.LineReader.<init>(LineReader.java:95), org.apache.hadoop.fs.HarFileSystem$HarMetaData.parseMetaData(HarFileSystem.java:1176), org.apache.hadoop.fs.HarFileSystem$HarMetaData.access$000(HarFileSystem.java:1115), org.apache.hadoop.fs.HarFileSystem.initialize(HarFileSystem.java:172), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:93), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testNegativeHarFsModifications/campaign/failures/debug_000000	{"io.file.buffer.size": "1546191928"}	["debug_000000", "debug_000001"]																																																																																																																																																																																																						
			2	org.apache.hadoop.fs.TestHarFileSystemBasics#testPositiveListFilesNotEndInColon	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.util.LineReader.<init>(LineReader.java:82), org.apache.hadoop.util.LineReader.<init>(LineReader.java:95), org.apache.hadoop.fs.HarFileSystem$HarMetaData.parseMetaData(HarFileSystem.java:1176), org.apache.hadoop.fs.HarFileSystem$HarMetaData.access$000(HarFileSystem.java:1115), org.apache.hadoop.fs.HarFileSystem.initialize(HarFileSystem.java:172), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:93), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testPositiveListFilesNotEndInColon/campaign/failures/debug_000003	{"io.file.buffer.size": "1544298726"}	["debug_000003"]	org.apache.hadoop.fs.TestHarFileSystemBasics#testListLocatedStatus	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.util.LineReader.<init>(LineReader.java:82), org.apache.hadoop.util.LineReader.<init>(LineReader.java:95), org.apache.hadoop.fs.HarFileSystem$HarMetaData.parseMetaData(HarFileSystem.java:1176), org.apache.hadoop.fs.HarFileSystem$HarMetaData.access$000(HarFileSystem.java:1115), org.apache.hadoop.fs.HarFileSystem.initialize(HarFileSystem.java:172), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:93), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testListLocatedStatus/campaign/failures/debug_000002	{"io.file.buffer.size": "1585508277"}	["debug_000002"]																																																																																																																																																																																																						
			5	org.apache.hadoop.fs.TestFsShellCopy#testRepresentsDir	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.create(CommandWithDestination.java:532), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:494), org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:417), org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:352), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.copyFileToTarget(CopyCommandWithMultiThread.java:144), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:287), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:272), org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:370), org.apache.hadoop.fs.shell.Command.processPaths(Command.java:333), org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:306), org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:267), org.apache.hadoop.fs.shell.Command.processArgument(Command.java:288), org.apache.hadoop.fs.shell.Command.processArguments(Command.java:272), org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:238), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.processArguments(CopyCommandWithMultiThread.java:89), org.apache.hadoop.fs.shell.CopyCommands$Put.processArguments(CopyCommands.java:312), org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:121), org.apache.hadoop.fs.shell.Command.run(Command.java:179), org.apache.hadoop.fs.FsShell.run(FsShell.java:327), org.apache.hadoop.fs.TestFsShellCopy.testRepresentsDir(TestFsShellCopy.java:297), org.apache.hadoop.fs.TestFsShellCopy.testRepresentsDir$$CONFUZZ(TestFsShellCopy.java),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:351), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.copyFileToTarget(CopyCommandWithMultiThread.java:144), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:287), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:272), org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:370), org.apache.hadoop.fs.shell.Command.processPaths(Command.java:333), org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:306), org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:267), org.apache.hadoop.fs.shell.Command.processArgument(Command.java:288), org.apache.hadoop.fs.shell.Command.processArguments(Command.java:272), org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:238), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.processArguments(CopyCommandWithMultiThread.java:89), org.apache.hadoop.fs.shell.CopyCommands$Put.processArguments(CopyCommands.java:312), org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:121), org.apache.hadoop.fs.shell.Command.run(Command.java:179), org.apache.hadoop.fs.FsShell.run(FsShell.java:327), org.apache.hadoop.fs.TestFsShellCopy.testRepresentsDir(TestFsShellCopy.java:297), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testRepresentsDir/campaign/failures/debug_000001	{"file.bytes-per-checksum": "964675248"}	["debug_000001"]	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testRenameSymlinkNonExistantDest	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testRenameSymlinkNonExistantDest(SymlinkBaseTest.java:1019), org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem.testRenameSymlinkNonExistantDest$$CONFUZZ(TestSymlinkLocalFSFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FileSystemTestWrapper.readFile(FileSystemTestWrapper.java:149), org.apache.hadoop.fs.SymlinkBaseTest.readFile(SymlinkBaseTest.java:70), org.apache.hadoop.fs.SymlinkBaseTest.testRenameSymlinkNonExistantDest(SymlinkBaseTest.java:1024), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testRenameSymlinkNonExistantDest/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1478226971"}	["debug_000000", "debug_000001"]	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testGetWrappedInputStream	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.testGetWrappedInputStream(FSMainOperationsBaseTest.java:1115), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testGetWrappedInputStream/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1443649548"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testOneDataEntry	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:612), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneDataEntry(TestTFileByteArrays.java:123), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneDataEntry$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:612), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneDataEntry(TestTFileByteArrays.java:123), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testOneDataEntry/campaign/failures/debug_000002	{"file.bytes-per-checksum": "997019068"}	["debug_000002"]	org.apache.hadoop.io.TestArrayFile#testEmptyFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:285), org.apache.hadoop.io.ArrayFile$Writer.<init>(ArrayFile.java:45), org.apache.hadoop.io.TestArrayFile.writeTest(TestArrayFile.java:88), org.apache.hadoop.io.TestArrayFile.testEmptyFile(TestArrayFile.java:62), org.apache.hadoop.io.TestArrayFile.testEmptyFile$$CONFUZZ(TestArrayFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.io.SequenceFile$Reader.openFile(SequenceFile.java:1962), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1882), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:447), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.ArrayFile$Reader.<init>(ArrayFile.java:75), org.apache.hadoop.io.TestArrayFile.testEmptyFile(TestArrayFile.java:63), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestArrayFile/testEmptyFile/campaign/failures/debug_000000	{"file.bytes-per-checksum": "514930708"}	["debug_000000"]																																																																																																																																																																					
			1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractMkdir#testMkdirOverParentFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.ContractTestUtils.createFile(ContractTestUtils.java:636), org.apache.hadoop.fs.contract.AbstractContractMkdirTest.testMkdirOverParentFile(AbstractContractMkdirTest.java:92), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractMkdir.testMkdirOverParentFile$$CONFUZZ(TestLocalFSContractMkdir.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractMkdir/testMkdirOverParentFile/campaign/failures/debug_000002	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "5877", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "2836m", "file.stream-buffer-size": "13228", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "1056", "fs.creation.parallel.count": "1913823550", "file.bytes-per-checksum": "15297", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "25957", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "15059", "fs.local.block.size": "104", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "1862841110", "hadoop.security.token.service.use_ip": "true", "hadoop.kerberos.min.seconds.before.relogin": "30586", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "771451838"}	["debug_000002"]																																																																																																																																																																																																																	
			12	org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs#testResolvePathDanglingLink	java.io.FileNotFoundException	File /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/Ka7p4LNCFE/missingTarget does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.DelegateToFileSystem.getFileStatus(DelegateToFileSystem.java:128), org.apache.hadoop.fs.FilterFs.getFileStatus(FilterFs.java:124), org.apache.hadoop.fs.viewfs.ChRootedFs.getFileStatus(ChRootedFs.java:205), org.apache.hadoop.fs.AbstractFileSystem.resolvePath(AbstractFileSystem.java:509), org.apache.hadoop.fs.viewfs.ViewFs.resolvePath(ViewFs.java:334), org.apache.hadoop.fs.FileContext$25.next(FileContext.java:2305), org.apache.hadoop.fs.FileContext$25.next(FileContext.java:2301), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.resolve(FileContext.java:2307), org.apache.hadoop.fs.FileContext.resolvePath(FileContext.java:616), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testResolvePathDanglingLink(ViewFsBaseTest.java:661), org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs.testResolvePathDanglingLink$$CONFUZZ(TestViewFsWithAuthorityLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs/testResolvePathDanglingLink/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsLocalFs#testResolvePathMissingThroughMountPoints2	java.io.FileNotFoundException	File /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/As8JUtshpV/user/dirX/nonExisting does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.DelegateToFileSystem.getFileStatus(DelegateToFileSystem.java:128), org.apache.hadoop.fs.FilterFs.getFileStatus(FilterFs.java:124), org.apache.hadoop.fs.viewfs.ChRootedFs.getFileStatus(ChRootedFs.java:205), org.apache.hadoop.fs.AbstractFileSystem.resolvePath(AbstractFileSystem.java:509), org.apache.hadoop.fs.viewfs.ViewFs.resolvePath(ViewFs.java:334), org.apache.hadoop.fs.FileContext$25.next(FileContext.java:2305), org.apache.hadoop.fs.FileContext$25.next(FileContext.java:2301), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.resolve(FileContext.java:2307), org.apache.hadoop.fs.FileContext.resolvePath(FileContext.java:616), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testResolvePathMissingThroughMountPoints2(ViewFsBaseTest.java:675), org.apache.hadoop.fs.viewfs.TestViewFsLocalFs.testResolvePathMissingThroughMountPoints2$$CONFUZZ(TestViewFsLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsLocalFs/testResolvePathMissingThroughMountPoints2/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsLocalFs#testResolvePathMissingThroughMountPoints	java.io.FileNotFoundException	File /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/ezWhzbNHlU/user/nonExisting does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.DelegateToFileSystem.getFileStatus(DelegateToFileSystem.java:128), org.apache.hadoop.fs.FilterFs.getFileStatus(FilterFs.java:124), org.apache.hadoop.fs.viewfs.ChRootedFs.getFileStatus(ChRootedFs.java:205), org.apache.hadoop.fs.AbstractFileSystem.resolvePath(AbstractFileSystem.java:509), org.apache.hadoop.fs.viewfs.ViewFs.resolvePath(ViewFs.java:334), org.apache.hadoop.fs.FileContext$25.next(FileContext.java:2305), org.apache.hadoop.fs.FileContext$25.next(FileContext.java:2301), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.resolve(FileContext.java:2307), org.apache.hadoop.fs.FileContext.resolvePath(FileContext.java:616), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testResolvePathMissingThroughMountPoints(ViewFsBaseTest.java:666), org.apache.hadoop.fs.viewfs.TestViewFsLocalFs.testResolvePathMissingThroughMountPoints$$CONFUZZ(TestViewFsLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsLocalFs/testResolvePathMissingThroughMountPoints/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs#testResolvePathMissingThroughMountPoints2	java.io.FileNotFoundException	File /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/jPXi1EShKf/user/dirX/nonExisting does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.DelegateToFileSystem.getFileStatus(DelegateToFileSystem.java:128), org.apache.hadoop.fs.FilterFs.getFileStatus(FilterFs.java:124), org.apache.hadoop.fs.viewfs.ChRootedFs.getFileStatus(ChRootedFs.java:205), org.apache.hadoop.fs.AbstractFileSystem.resolvePath(AbstractFileSystem.java:509), org.apache.hadoop.fs.viewfs.ViewFs.resolvePath(ViewFs.java:334), org.apache.hadoop.fs.FileContext$25.next(FileContext.java:2305), org.apache.hadoop.fs.FileContext$25.next(FileContext.java:2301), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.resolve(FileContext.java:2307), org.apache.hadoop.fs.FileContext.resolvePath(FileContext.java:616), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testResolvePathMissingThroughMountPoints2(ViewFsBaseTest.java:675), org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs.testResolvePathMissingThroughMountPoints2$$CONFUZZ(TestViewFsWithAuthorityLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs/testResolvePathMissingThroughMountPoints2/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testResolvePathMissingThroughMountPoints	java.io.FileNotFoundException	File /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/u0sQBeu2AR/user/nonExisting does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.FileSystem.resolvePath(FileSystem.java:958), org.apache.hadoop.fs.FilterFileSystem.resolvePath(FilterFileSystem.java:159), org.apache.hadoop.fs.FilterFileSystem.resolvePath(FilterFileSystem.java:159), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.resolvePath(ChRootedFileSystem.java:419), org.apache.hadoop.fs.viewfs.ViewFileSystem.resolvePath(ViewFileSystem.java:407), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testResolvePathMissingThroughMountPoints(ViewFileSystemBaseTest.java:688), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testResolvePathMissingThroughMountPoints$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testResolvePathMissingThroughMountPoints/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs#testResolvePathMissingThroughMountPoints	java.io.FileNotFoundException	File /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/LbRj6iOso1/user/nonExisting does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.DelegateToFileSystem.getFileStatus(DelegateToFileSystem.java:128), org.apache.hadoop.fs.FilterFs.getFileStatus(FilterFs.java:124), org.apache.hadoop.fs.viewfs.ChRootedFs.getFileStatus(ChRootedFs.java:205), org.apache.hadoop.fs.AbstractFileSystem.resolvePath(AbstractFileSystem.java:509), org.apache.hadoop.fs.viewfs.ViewFs.resolvePath(ViewFs.java:334), org.apache.hadoop.fs.FileContext$25.next(FileContext.java:2305), org.apache.hadoop.fs.FileContext$25.next(FileContext.java:2301), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.resolve(FileContext.java:2307), org.apache.hadoop.fs.FileContext.resolvePath(FileContext.java:616), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testResolvePathMissingThroughMountPoints(ViewFsBaseTest.java:666), org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs.testResolvePathMissingThroughMountPoints$$CONFUZZ(TestViewFsWithAuthorityLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs/testResolvePathMissingThroughMountPoints/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testResolvePathDanglingLink	java.io.FileNotFoundException	File /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/K9yPkxAfG2/missingTarget does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.FileSystem.resolvePath(FileSystem.java:958), org.apache.hadoop.fs.FilterFileSystem.resolvePath(FilterFileSystem.java:159), org.apache.hadoop.fs.FilterFileSystem.resolvePath(FilterFileSystem.java:159), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.resolvePath(ChRootedFileSystem.java:419), org.apache.hadoop.fs.viewfs.ViewFileSystem.resolvePath(ViewFileSystem.java:407), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testResolvePathDanglingLink(ViewFileSystemBaseTest.java:683), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testResolvePathDanglingLink$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testResolvePathDanglingLink/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testResolvePathMissingThroughMountPoints2	java.io.FileNotFoundException	File /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/DW1LsiA7xu/user/dirX/nonExisting does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.FileSystem.resolvePath(FileSystem.java:958), org.apache.hadoop.fs.FilterFileSystem.resolvePath(FilterFileSystem.java:159), org.apache.hadoop.fs.FilterFileSystem.resolvePath(FilterFileSystem.java:159), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.resolvePath(ChRootedFileSystem.java:419), org.apache.hadoop.fs.viewfs.ViewFileSystem.resolvePath(ViewFileSystem.java:407), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testResolvePathMissingThroughMountPoints2(ViewFileSystemBaseTest.java:696), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testResolvePathMissingThroughMountPoints2$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testResolvePathMissingThroughMountPoints2/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testgetFSonDanglingLink	java.io.FileNotFoundException	File /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/tf1Ow8JeQb/missingTarget does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462), org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.getFileStatus(ChRootedFileSystem.java:245), org.apache.hadoop.fs.viewfs.ViewFileSystem.getFileStatus(ViewFileSystem.java:560), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testgetFSonDanglingLink(ViewFileSystemBaseTest.java:632), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testgetFSonDanglingLink$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testgetFSonDanglingLink/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsLocalFs#testgetFSonDanglingLink	java.io.FileNotFoundException	File /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/wMFTfCrA8Z/missingTarget does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.DelegateToFileSystem.getFileStatus(DelegateToFileSystem.java:128), org.apache.hadoop.fs.FilterFs.getFileStatus(FilterFs.java:124), org.apache.hadoop.fs.viewfs.ChRootedFs.getFileStatus(ChRootedFs.java:205), org.apache.hadoop.fs.viewfs.ViewFs.getFileStatus(ViewFs.java:422), org.apache.hadoop.fs.FileContext$15.next(FileContext.java:1247), org.apache.hadoop.fs.FileContext$15.next(FileContext.java:1243), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.getFileStatus(FileContext.java:1249), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testgetFSonDanglingLink(ViewFsBaseTest.java:564), org.apache.hadoop.fs.viewfs.TestViewFsLocalFs.testgetFSonDanglingLink$$CONFUZZ(TestViewFsLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsLocalFs/testgetFSonDanglingLink/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testgetFSonDanglingLink	java.io.FileNotFoundException	File /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/9cHsNgARw4/missingTarget does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462), org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.getFileStatus(ChRootedFileSystem.java:245), org.apache.hadoop.fs.viewfs.ViewFileSystem.getFileStatus(ViewFileSystem.java:560), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testgetFSonDanglingLink(ViewFileSystemBaseTest.java:632), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testgetFSonDanglingLink$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testgetFSonDanglingLink/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsLocalFs#testResolvePathDanglingLink	java.io.FileNotFoundException	File /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/tuiY0Mi4tH/missingTarget does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.DelegateToFileSystem.getFileStatus(DelegateToFileSystem.java:128), org.apache.hadoop.fs.FilterFs.getFileStatus(FilterFs.java:124), org.apache.hadoop.fs.viewfs.ChRootedFs.getFileStatus(ChRootedFs.java:205), org.apache.hadoop.fs.AbstractFileSystem.resolvePath(AbstractFileSystem.java:509), org.apache.hadoop.fs.viewfs.ViewFs.resolvePath(ViewFs.java:334), org.apache.hadoop.fs.FileContext$25.next(FileContext.java:2305), org.apache.hadoop.fs.FileContext$25.next(FileContext.java:2301), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.resolve(FileContext.java:2307), org.apache.hadoop.fs.FileContext.resolvePath(FileContext.java:616), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testResolvePathDanglingLink(ViewFsBaseTest.java:661), org.apache.hadoop.fs.viewfs.TestViewFsLocalFs.testResolvePathDanglingLink$$CONFUZZ(TestViewFsLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsLocalFs/testResolvePathDanglingLink/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																								
			1	org.apache.hadoop.ipc.TestIPCServerResponder#testResponseBuffer	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1240), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.Server.<init>(Server.java:3046), org.apache.hadoop.ipc.TestIPCServerResponder$TestServer.<init>(TestIPCServerResponder.java:85), org.apache.hadoop.ipc.TestIPCServerResponder.checkServerResponder(TestIPCServerResponder.java:158), org.apache.hadoop.ipc.TestIPCServerResponder.testResponseBuffer(TestIPCServerResponder.java:142), org.apache.hadoop.ipc.TestIPCServerResponder.testResponseBuffer$$CONFUZZ(TestIPCServerResponder.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPCServerResponder/testResponseBuffer/campaign/failures/debug_000000	{"hadoop.security.dns.log-slow-lookups.enabled": "false", "ipc.client.kill.max": "0", "ipc.0.scheduler.priority.levels": "14930", "ipc.client.ping": "true", "ipc.client.idlethreshold": "659"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.ipc.TestIPCServerResponder#testResponseBuffer	java.lang.OutOfMemoryError	Java heap space		PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPCServerResponder/testResponseBuffer/campaign/failures/debug_000001	{"hadoop.security.authentication": "simple", "ipc.client.fallback-to-simple-auth-allowed": "false", "ipc.client.connect.max.retries": "639", "ipc.server.log.slow.rpc": "false", "ipc.client.low-latency": "true", "ipc.client.idlethreshold": "18382", "ipc.client.connect.retry.interval": "931", "ipc.client.connect.max.retries.on.sasl": "2130640638", "ipc.client.kill.max": "84512655", "ipc.client.connection.maxidletime": "127", "ipc.server.max.connections": "425", "ipc.client.connect.max.retries.on.timeouts": "5478", "ipc.client.tcpnodelay": "true"}	["debug_000001"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testClientRetriesWithSSLHandshakeExceptionFailsAtEveryAttempt	org.junit.runners.model.TestTimedOutException	test timed out after 30000 milliseconds	java.base@11.0.19/java.lang.Thread.sleep(Native Method), app//org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.doOp(LoadBalancingKMSClientProvider.java:220), app//org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.createKey(LoadBalancingKMSClientProvider.java:481), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.lambda$testClientRetriesWithSSLHandshakeExceptionFailsAtEveryAttempt$0(TestLoadBalancingKMSClientProvider.java:761), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$$Lambda$96/0x000000084021f840.call(Unknown Source), app//org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:498), app//org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:384), app//org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:453), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesWithSSLHandshakeExceptionFailsAtEveryAttempt(TestLoadBalancingKMSClientProvider.java:759), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesWithSSLHandshakeExceptionFailsAtEveryAttempt$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	FLAKY	org.junit.runners.model.TestTimedOutException	test timed out after 30000 milliseconds	java.base@11.0.19/java.lang.Thread.sleep(Native Method), app//org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.doOp(LoadBalancingKMSClientProvider.java:220), app//org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.createKey(LoadBalancingKMSClientProvider.java:481), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.lambda$testClientRetriesWithSSLHandshakeExceptionFailsAtEveryAttempt$0(TestLoadBalancingKMSClientProvider.java:761), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider$$Lambda$32/0x000000084016e440.call(Unknown Source), app//org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:498), app//org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:384), app//org.apache.hadoop.test.LambdaTestUtils.intercept(LambdaTestUtils.java:453), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesWithSSLHandshakeExceptionFailsAtEveryAttempt(TestLoadBalancingKMSClientProvider.java:759), java.base@11.0.19/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base@11.0.19/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base@11.0.19/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testClientRetriesWithSSLHandshakeExceptionFailsAtEveryAttempt/campaign/failures/debug_000000	{"hadoop.security.crypto.jceks.key.serialfilter": "java.lang.Enum;java.security.KeyRep;java.security.KeyRep$Type;javax.crypto.spec.SecretKeySpec;org.apache.hadoop.crypto.key.JavaKeyStoreProvider$KeyMetadata;!*", "hadoop.security.token.service.use_ip": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "15580", "hadoop.security.kms.client.failover.sleep.max.millis": "28767", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.key.default.cipher": "AES/CTR/NoPadding", "hadoop.security.key.default.bitlength": "1316332904", "hadoop.security.kms.client.failover.sleep.base.millis": "1252045731"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.crypto.key.kms.TestKMSClientProvider#testURLSelectToken	java.lang.NoSuchMethodError	void org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testURLSelectToken()'	org.apache.hadoop.crypto.key.kms.TestKMSClientProvider.testURLSelectToken$$CONFUZZ(TestKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestKMSClientProvider/testURLSelectToken/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
		FP	4	org.apache.hadoop.security.TestKDiag#testFileOutput	java.lang.ClassNotFoundException	Class (unset) not found	org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2662), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2756), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2782), org.apache.hadoop.security.KDiag.validateSasl(KDiag.java:737), org.apache.hadoop.security.KDiag.execute(KDiag.java:389), org.apache.hadoop.security.KDiag.run(KDiag.java:242), org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:81), org.apache.hadoop.security.KDiag.exec(KDiag.java:1053), org.apache.hadoop.security.TestKDiag.kdiag(TestKDiag.java:120), org.apache.hadoop.security.TestKDiag.testFileOutput(TestKDiag.java:187), org.apache.hadoop.security.TestKDiag.testFileOutput$$CONFUZZ(TestKDiag.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestKDiag/testFileOutput/campaign/failures/debug_000000	{"dfs.data.transfer.saslproperties.resolver.class": "(unset)"}	["debug_000000"]	org.apache.hadoop.security.TestKDiag#testKeytabNoPrincipal	java.lang.ClassNotFoundException	Class (unset) not found	org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2662), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2756), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2782), org.apache.hadoop.security.KDiag.validateSasl(KDiag.java:737), org.apache.hadoop.security.KDiag.execute(KDiag.java:389), org.apache.hadoop.security.KDiag.run(KDiag.java:242), org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:81), org.apache.hadoop.security.KDiag.exec(KDiag.java:1053), org.apache.hadoop.security.TestKDiag.kdiagFailure(TestKDiag.java:107), org.apache.hadoop.security.TestKDiag.testKeytabNoPrincipal(TestKDiag.java:151), org.apache.hadoop.security.TestKDiag.testKeytabNoPrincipal$$CONFUZZ(TestKDiag.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestKDiag/testKeytabNoPrincipal/campaign/failures/debug_000000	{"dfs.data.transfer.saslproperties.resolver.class": "(unset)"}	["debug_000000"]	org.apache.hadoop.security.TestKDiag#testKeytabAndPrincipal	java.lang.ClassNotFoundException	Class (unset) not found	org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2662), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2756), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2782), org.apache.hadoop.security.KDiag.validateSasl(KDiag.java:737), org.apache.hadoop.security.KDiag.execute(KDiag.java:389), org.apache.hadoop.security.KDiag.run(KDiag.java:242), org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:81), org.apache.hadoop.security.KDiag.exec(KDiag.java:1053), org.apache.hadoop.security.TestKDiag.kdiag(TestKDiag.java:120), org.apache.hadoop.security.TestKDiag.testKeytabAndPrincipal(TestKDiag.java:163), org.apache.hadoop.security.TestKDiag.testKeytabAndPrincipal$$CONFUZZ(TestKDiag.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestKDiag/testKeytabAndPrincipal/campaign/failures/debug_000001	{"dfs.data.transfer.saslproperties.resolver.class": "(unset)"}	["debug_000001"]	org.apache.hadoop.security.TestKDiag#testBasicLoginSkipped	java.lang.ClassNotFoundException	Class (unset) not found	org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2662), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2756), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2782), org.apache.hadoop.security.KDiag.validateSasl(KDiag.java:737), org.apache.hadoop.security.KDiag.execute(KDiag.java:389), org.apache.hadoop.security.KDiag.run(KDiag.java:242), org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:81), org.apache.hadoop.security.KDiag.exec(KDiag.java:1053), org.apache.hadoop.security.TestKDiag.kdiagFailure(TestKDiag.java:107), org.apache.hadoop.security.TestKDiag.testBasicLoginSkipped(TestKDiag.java:130), org.apache.hadoop.security.TestKDiag.testBasicLoginSkipped$$CONFUZZ(TestKDiag.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestKDiag/testBasicLoginSkipped/campaign/failures/debug_000000	{"dfs.data.transfer.saslproperties.resolver.class": "(unset)"}	["debug_000000"]																																																																																																																																																																																
		FP	4	org.apache.hadoop.security.TestKDiag#testFileOutput	java.lang.ClassNotFoundException	Class (unset) not found	org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2662), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2756), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2782), org.apache.hadoop.security.KDiag.validateSasl(KDiag.java:737), org.apache.hadoop.security.KDiag.execute(KDiag.java:387), org.apache.hadoop.security.KDiag.run(KDiag.java:242), org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:81), org.apache.hadoop.security.KDiag.exec(KDiag.java:1053), org.apache.hadoop.security.TestKDiag.kdiag(TestKDiag.java:120), org.apache.hadoop.security.TestKDiag.testFileOutput(TestKDiag.java:187), org.apache.hadoop.security.TestKDiag.testFileOutput$$CONFUZZ(TestKDiag.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestKDiag/testFileOutput/campaign/failures/debug_000001	{"hadoop.security.saslproperties.resolver.class": "(unset)"}	["debug_000001"]	org.apache.hadoop.security.TestKDiag#testKeytabNoPrincipal	java.lang.ClassNotFoundException	Class (unset) not found	org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2662), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2756), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2782), org.apache.hadoop.security.KDiag.validateSasl(KDiag.java:737), org.apache.hadoop.security.KDiag.execute(KDiag.java:387), org.apache.hadoop.security.KDiag.run(KDiag.java:242), org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:81), org.apache.hadoop.security.KDiag.exec(KDiag.java:1053), org.apache.hadoop.security.TestKDiag.kdiagFailure(TestKDiag.java:107), org.apache.hadoop.security.TestKDiag.testKeytabNoPrincipal(TestKDiag.java:151), org.apache.hadoop.security.TestKDiag.testKeytabNoPrincipal$$CONFUZZ(TestKDiag.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestKDiag/testKeytabNoPrincipal/campaign/failures/debug_000001	{"hadoop.security.saslproperties.resolver.class": "(unset)"}	["debug_000001"]	org.apache.hadoop.security.TestKDiag#testKeytabAndPrincipal	java.lang.ClassNotFoundException	Class (unset) not found	org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2662), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2756), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2782), org.apache.hadoop.security.KDiag.validateSasl(KDiag.java:737), org.apache.hadoop.security.KDiag.execute(KDiag.java:387), org.apache.hadoop.security.KDiag.run(KDiag.java:242), org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:81), org.apache.hadoop.security.KDiag.exec(KDiag.java:1053), org.apache.hadoop.security.TestKDiag.kdiag(TestKDiag.java:120), org.apache.hadoop.security.TestKDiag.testKeytabAndPrincipal(TestKDiag.java:163), org.apache.hadoop.security.TestKDiag.testKeytabAndPrincipal$$CONFUZZ(TestKDiag.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestKDiag/testKeytabAndPrincipal/campaign/failures/debug_000000	{"hadoop.security.saslproperties.resolver.class": "(unset)"}	["debug_000000"]	org.apache.hadoop.security.TestKDiag#testBasicLoginSkipped	java.lang.ClassNotFoundException	Class (unset) not found	org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2662), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2756), org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2782), org.apache.hadoop.security.KDiag.validateSasl(KDiag.java:737), org.apache.hadoop.security.KDiag.execute(KDiag.java:387), org.apache.hadoop.security.KDiag.run(KDiag.java:242), org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:81), org.apache.hadoop.security.KDiag.exec(KDiag.java:1053), org.apache.hadoop.security.TestKDiag.kdiagFailure(TestKDiag.java:107), org.apache.hadoop.security.TestKDiag.testBasicLoginSkipped(TestKDiag.java:130), org.apache.hadoop.security.TestKDiag.testBasicLoginSkipped$$CONFUZZ(TestKDiag.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestKDiag/testBasicLoginSkipped/campaign/failures/debug_000001	{"hadoop.security.saslproperties.resolver.class": "(unset)"}	["debug_000001"]																																																																																																																																																																																
	Bug-94	Repeated	3	org.apache.hadoop.http.TestHttpServerLifecycle#testCreatedServerIsNotAlive	java.lang.IllegalStateException	Insufficient configured threads: required=0 < max=0 for QueuedThreadPool[qtp1022473723]@3cf1b5fb{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.QueuedThreadPool.setMaxThreads(QueuedThreadPool.java:364), org.apache.hadoop.http.HttpServer2.initializeWebServer(HttpServer2.java:703), org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:687), org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:129), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:468), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:158), org.apache.hadoop.http.HttpServerFunctionalTest.createTestServer(HttpServerFunctionalTest.java:77), org.apache.hadoop.http.TestHttpServerLifecycle.testCreatedServerIsNotAlive(TestHttpServerLifecycle.java:47), org.apache.hadoop.http.TestHttpServerLifecycle.testCreatedServerIsNotAlive$$CONFUZZ(TestHttpServerLifecycle.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerLifecycle/testCreatedServerIsNotAlive/campaign/failures/debug_000003	{"hadoop.http.max.threads": "0"}	["debug_000003"]	org.apache.hadoop.http.TestHttpServerWebapps#testValidServerResource	java.lang.IllegalStateException	Insufficient configured threads: required=0 < max=0 for QueuedThreadPool[qtp261855196]@f9b97dc{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.QueuedThreadPool.setMaxThreads(QueuedThreadPool.java:364), org.apache.hadoop.http.HttpServer2.initializeWebServer(HttpServer2.java:703), org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:687), org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:129), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:468), org.apache.hadoop.http.HttpServerFunctionalTest.createServer(HttpServerFunctionalTest.java:158), org.apache.hadoop.http.TestHttpServerWebapps.testValidServerResource(TestHttpServerWebapps.java:42), org.apache.hadoop.http.TestHttpServerWebapps.testValidServerResource$$CONFUZZ(TestHttpServerWebapps.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerWebapps/testValidServerResource/campaign/failures/debug_000003	{"hadoop.http.max.threads": "0"}	["debug_000003"]	org.apache.hadoop.http.TestHttpServerWithSpnego#testAuthenticationWithProxyUser	java.lang.IllegalStateException	Insufficient configured threads: required=0 < max=0 for QueuedThreadPool[qtp2012831257]@77f95e19{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.QueuedThreadPool.setMaxThreads(QueuedThreadPool.java:364), org.apache.hadoop.http.HttpServer2.initializeWebServer(HttpServer2.java:703), org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:687), org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:129), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:468), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser(TestHttpServerWithSpnego.java:135), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser$$CONFUZZ(TestHttpServerWithSpnego.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerWithSpnego/testAuthenticationWithProxyUser/campaign/failures/debug_000006	{"hadoop.http.max.threads": "0"}	["debug_000006"]																																																																																																																																																																																											
			2	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testGetDelegationTokens	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testGetDelegationTokens/campaign/failures/debug_000003	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testCloseChildrenFileSystem	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testCloseChildrenFileSystem/campaign/failures/debug_000004	{"fs.viewfs.mounttable.default.name.key": "default"}	["debug_000004"]																																																																																																																																																																																																						
			1	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testTrashRoot	java.io.IOException	ViewFs: Cannot initialize: Invalid entry in Mount table in config: name.key	org.apache.hadoop.fs.viewfs.InodeTree.<init>(InodeTree.java:587), org.apache.hadoop.fs.viewfs.ViewFileSystem$1.<init>(ViewFileSystem.java:321), org.apache.hadoop.fs.viewfs.ViewFileSystem.initialize(ViewFileSystem.java:320), org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3469), org.apache.hadoop.fs.FileSystem.get(FileSystem.java:537), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:140), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testTrashRoot/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "1051263483", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "40937171h", "file.stream-buffer-size": "8297", "fs.viewfs.mount.links.as.symlinks": "false", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "10922", "fs.trash.checkpoint.interval": "5543", "fs.creation.parallel.count": "22322", "file.bytes-per-checksum": "1784186053", "fs.viewfs.rename.strategy": "SAME_FILESYSTEM_ACROSS_MOUNTPOINT", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "680", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "916", "fs.local.block.size": "11553", "fs.file.impl.disable.cache": "false", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "14564", "fs.viewfs.mounttable.default.name.key": "default", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "fs.viewfs.enable.inner.cache": "false", "hadoop.security.groups.cache.warn.after.ms": "2649"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testTrashRoot	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testTrashRoot/campaign/failures/debug_000002	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "1566210177", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "08497600s", "file.stream-buffer-size": "30330", "fs.viewfs.mount.links.as.symlinks": "true", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "646316367", "fs.trash.checkpoint.interval": "21937", "fs.creation.parallel.count": "802", "file.bytes-per-checksum": "1624065200", "fs.viewfs.rename.strategy": "SAME_TARGET_URI_ACROSS_MOUNTPOINT", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "11", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "646", "fs.local.block.size": "21", "fs.file.impl.disable.cache": "true", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "26908", "fs.viewfs.mounttable.default.name.key": "default", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "fs.viewfs.enable.inner.cache": "true", "hadoop.security.groups.cache.warn.after.ms": "584047582"}	["debug_000002"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testTrashRoot	java.lang.NegativeArraySizeException	-604355476	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testTrashRoot/campaign/failures/debug_000001	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "1997597804", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "0158354h", "file.stream-buffer-size": "648827397", "fs.viewfs.mount.links.as.symlinks": "true", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "309", "fs.trash.checkpoint.interval": "681", "fs.creation.parallel.count": "293330193", "file.bytes-per-checksum": "410067980", "fs.viewfs.rename.strategy": "SAME_MOUNTPOINT", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "485388069", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "21574", "fs.local.block.size": "342", "fs.file.impl.disable.cache": "true", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "745048523", "fs.viewfs.mounttable.default.name.key": "default", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "fs.viewfs.enable.inner.cache": "false", "hadoop.security.groups.cache.warn.after.ms": "410440231"}	["debug_000001"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testTrashRoot	java.lang.OutOfMemoryError	Java heap space		POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testTrashRoot/campaign/failures/debug_000004	{"hadoop.security.dns.log-slow-lookups.enabled": "true", "hadoop.service.shutdown.timeout": "0854474s", "file.stream-buffer-size": "767", "fs.file.impl.disable.cache": "true", "file.bytes-per-checksum": "1578095633"}	["debug_000004"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testTrashRoot	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testTrashRoot/campaign/failures/debug_000003	{"hadoop.security.token.service.use_ip": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "1073906431", "hadoop.security.authentication": "simple", "fs.client.resolve.remote.symlinks": "false", "file.stream-buffer-size": "6324739", "fs.local.block.size": "18496", "fs.viewfs.enable.inner.cache": "true", "fs.file.impl.disable.cache": "true", "file.bytes-per-checksum": "2139095166"}	["debug_000003"]																																																																																																																																																																																																																	
			8	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testCreateNonRecursive	java.lang.NegativeArraySizeException	-657757489	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.createNonRecursive(ChecksumFileSystem.java:565), org.apache.hadoop.fs.FilterFileSystem.createNonRecursive(FilterFileSystem.java:227), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.createNonRecursive(ChRootedFileSystem.java:206), org.apache.hadoop.fs.viewfs.ViewFileSystem.createNonRecursive(ViewFileSystem.java:454), org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1401), org.apache.hadoop.fs.FileSystem.createNonRecursive(FileSystem.java:1379), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testCreateNonRecursive(ViewFileSystemBaseTest.java:827), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testCreateNonRecursive$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-657757489	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testCreateNonRecursive/campaign/failures/debug_000003	{"file.bytes-per-checksum": "404134423"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testNflyWriteSimple	java.lang.NegativeArraySizeException	-1869263113	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.NflyFSystem$NflyOutputStream.<init>(NflyFSystem.java:301), org.apache.hadoop.fs.viewfs.NflyFSystem$NflyOutputStream.<init>(NflyFSystem.java:283), org.apache.hadoop.fs.viewfs.NflyFSystem.create(NflyFSystem.java:727), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testNflyWriteSimple(TestViewFileSystemLocalFileSystem.java:78), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testNflyWriteSimple$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-1869263113	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testNflyWriteSimple/campaign/failures/debug_000001	{"file.bytes-per-checksum": "269522687"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testRenameAcrossMounts2	java.lang.NegativeArraySizeException	-1738320892	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:163), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testRenameAcrossMounts2(ViewFileSystemBaseTest.java:404), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testRenameAcrossMounts2$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-1738320892	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testRenameAcrossMounts2/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1715727588"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testRenameAcrossMounts2	java.lang.NegativeArraySizeException	-2030805229	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:163), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testRenameAcrossMounts2(ViewFileSystemBaseTest.java:404), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testRenameAcrossMounts2$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-2030805229	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testRenameAcrossMounts2/campaign/failures/debug_000005	{"file.bytes-per-checksum": "251573563"}	["debug_000005"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testGetContentSummary	java.lang.NegativeArraySizeException	-106914158	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testGetContentSummary(ViewFileSystemBaseTest.java:1393), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testGetContentSummary$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-106914158	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testGetContentSummary/campaign/failures/debug_000004	{"file.bytes-per-checksum": "942557826"}	["debug_000004"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testGetContentSummary	java.lang.NegativeArraySizeException	-1170908054	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testGetContentSummary(ViewFileSystemBaseTest.java:1393), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testGetContentSummary$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-1170908054	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testGetContentSummary/campaign/failures/debug_000003	{"file.bytes-per-checksum": "824336282"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testResolvePathThroughMountPoints	java.lang.NegativeArraySizeException	-496094953	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:163), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testResolvePathThroughMountPoints(ViewFileSystemBaseTest.java:665), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testResolvePathThroughMountPoints$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-496094953	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.setUp(TestViewFileSystemLocalFileSystem.java:60), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testResolvePathThroughMountPoints/campaign/failures/debug_000001	{"file.bytes-per-checksum": "422096927"}	["debug_000001"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testRenameAcrossMounts1	java.lang.NegativeArraySizeException	-804400221	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.create(ChRootedFileSystem.java:197), org.apache.hadoop.fs.viewfs.ViewFileSystem.create(ViewFileSystem.java:469), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:163), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testRenameAcrossMounts1(ViewFileSystemBaseTest.java:387), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testRenameAcrossMounts1$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-804400221	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:136), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:129), org.apache.hadoop.fs.FileSystemTestHelper.createFile(FileSystemTestHelper.java:157), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.setUp(ViewFileSystemBaseTest.java:131), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.setUp(TestViewFileSystemWithAuthorityLocalFileSystem.java:50), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testRenameAcrossMounts1/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1342277963"}	["debug_000001"]																																																																																																																																				
			3	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testNullCreateFlag	org.apache.hadoop.HadoopIllegalArgumentException	null does not specify any options	org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:151), org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:174), org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1294), org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102), org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:353), org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400), org.apache.hadoop.fs.viewfs.ChRootedFs.createInternal(ChRootedFs.java:179), org.apache.hadoop.fs.viewfs.ViewFs.createInternal(ViewFs.java:358), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testNullCreateFlag(FileContextMainOperationsBaseTest.java:779), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.testNullCreateFlag$$CONFUZZ(TestFcMainOperationsLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testNullCreateFlag/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.TestLocalFSFileContextMainOperations#testEmptyCreateFlag	org.apache.hadoop.HadoopIllegalArgumentException	[] does not specify any options	org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:151), org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:174), org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1294), org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102), org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:353), org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testEmptyCreateFlag(FileContextMainOperationsBaseTest.java:786), org.apache.hadoop.fs.TestLocalFSFileContextMainOperations.testEmptyCreateFlag$$CONFUZZ(TestLocalFSFileContextMainOperations.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSFileContextMainOperations/testEmptyCreateFlag/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.TestLocalFSFileContextMainOperations#testNullCreateFlag	org.apache.hadoop.HadoopIllegalArgumentException	null does not specify any options	org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:151), org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:174), org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1294), org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102), org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:353), org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testNullCreateFlag(FileContextMainOperationsBaseTest.java:779), org.apache.hadoop.fs.TestLocalFSFileContextMainOperations.testNullCreateFlag$$CONFUZZ(TestLocalFSFileContextMainOperations.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSFileContextMainOperations/testNullCreateFlag/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																											
		FP	1	org.apache.hadoop.ipc.TestIPC#testIOEOnWriteAfterPingClient	java.lang.AssertionError	Exception should contain substring 'Injected fault':java.io.IOException: DestHost:destPort 98c8cbfde33e:35531 , LocalHost:localPort 98c8cbfde33e/172.17.0.2:0. Failed on local exception: java.io.IOException: org.apache.hadoop.ipc.RpcException: RPC response exceeds maximum data length at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) at java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490) at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:913) at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:888) at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1616) at org.apache.hadoop.ipc.Client.call(Client.java:1558) at org.apache.hadoop.ipc.Client.call(Client.java:1477) at org.apache.hadoop.ipc.TestIPC.call(TestIPC.java:177) at org.apache.hadoop.ipc.TestIPC.doErrorTest(TestIPC.java:528) at org.apache.hadoop.ipc.TestIPC.testIOEOnWriteAfterPingClient(TestIPC.java:632) at org.apache.hadoop.ipc.TestIPC.testIOEOnWriteAfterPingClient$$CONFUZZ(TestIPC.java) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56) at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65) at edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100) at edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144) at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63) at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329) at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293) at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306) at org.junit.runners.ParentRunner.run(ParentRunner.java:413) at org.junit.runner.JUnitCore.run(JUnitCore.java:137) at edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208) at edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39)Caused by: java.io.IOException: org.apache.hadoop.ipc.RpcException: RPC response exceeds maximum data length at org.apache.hadoop.ipc.Client$Connection$1.run(Client.java:798) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Client$Connection.handleSaslConnectionFailure(Client.java:752) at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:856) at org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414) at org.apache.hadoop.ipc.Client.getConnection(Client.java:1677) at org.apache.hadoop.ipc.Client.call(Client.java:1502) ... 32 moreCaused by: org.apache.hadoop.ipc.RpcException: RPC response exceeds maximum data length at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936) at org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367) at org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623) at org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414) at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843) at org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839) at java.base/java.security.AccessController.doPrivileged(Native Method) at java.base/javax.security.auth.Subject.doAs(Subject.java:423) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839) ... 35 more	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.ipc.TestIPC.assertExceptionContains(TestIPC.java:644), org.apache.hadoop.ipc.TestIPC.doErrorTest(TestIPC.java:531), org.apache.hadoop.ipc.TestIPC.testIOEOnWriteAfterPingClient(TestIPC.java:632), org.apache.hadoop.ipc.TestIPC.testIOEOnWriteAfterPingClient$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testIOEOnWriteAfterPingClient/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	3	org.apache.hadoop.fs.shell.TestPathData#testRelativeGlob	org.junit.ComparisonFailure	expected:<[0:<d1/f1>, 1:<d1/f1.1>]> but was:<[]>	org.junit.Assert.assertEquals(Assert.java:117), org.junit.Assert.assertEquals(Assert.java:146), org.apache.hadoop.fs.shell.TestPathData.testRelativeGlob(TestPathData.java:206), org.apache.hadoop.fs.shell.TestPathData.testRelativeGlob$$CONFUZZ(TestPathData.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestPathData/testRelativeGlob/campaign/failures/debug_000001	{"fs.file.impl.disable.cache": "true"}	["debug_000001"]	org.apache.hadoop.fs.shell.TestPathData#testRelativeGlobBack	org.junit.ComparisonFailure	expected:<[0:<../d2/f3>]> but was:<[]>	org.junit.Assert.assertEquals(Assert.java:117), org.junit.Assert.assertEquals(Assert.java:146), org.apache.hadoop.fs.shell.TestPathData.testRelativeGlobBack(TestPathData.java:216), org.apache.hadoop.fs.shell.TestPathData.testRelativeGlobBack$$CONFUZZ(TestPathData.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestPathData/testRelativeGlobBack/campaign/failures/debug_000000	{"fs.file.impl.disable.cache": "true"}	["debug_000000"]	org.apache.hadoop.fs.shell.TestPathData#testCwdContents	org.junit.ComparisonFailure	expected:<0:<[d1>, 1:<d2]>> but was:<0:<[HadoopCommon.cmake>, 1:<HadoopJNI.cmake>, 2:<code-compile.sh>, 3:<dev-support>, 4:<pom.xml>, 5:<src>, 6:<target>, 7:<test-compile.sh]>>	org.junit.Assert.assertEquals(Assert.java:117), org.junit.Assert.assertEquals(Assert.java:146), org.apache.hadoop.fs.shell.TestPathData.testCwdContents(TestPathData.java:114), org.apache.hadoop.fs.shell.TestPathData.testCwdContents$$CONFUZZ(TestPathData.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestPathData/testCwdContents/campaign/failures/debug_000001	{"fs.file.impl.disable.cache": "true"}	["debug_000001"]																																																																																																																																																																																											
			1	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testListOnMountTargetDirsInternal	java.lang.NoSuchMethodError	void org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testListOnMountTargetDirsInternal()'	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testListOnMountTargetDirsInternal$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testListOnMountTargetDirsInternal/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractLoaded#testContractWorks	java.lang.AssertionError	not true: fs.contract.supports-atomic-rename	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractLoaded.testContractWorks(TestLocalFSContractLoaded.java:42), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractLoaded.testContractWorks$$CONFUZZ(TestLocalFSContractLoaded.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractLoaded/testContractWorks/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.dns.log-slow-lookups.threshold.ms": "12752", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "1547465725", "hadoop.security.authentication": "simple", "fs.client.resolve.remote.symlinks": "false", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.service.shutdown.timeout": "22h", "hadoop.security.groups.cache.background.reload.threads": "593", "fs.local.block.size": "1635233783", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "fs.file.impl.disable.cache": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.security.token.service.use_ip": "true", "hadoop.kerberos.min.seconds.before.relogin": "8934", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "fs.contract.supports-atomic-rename": "false", "hadoop.security.groups.negative-cache.secs": "2105472836", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "fs.creation.parallel.count": "1131599842", "file.bytes-per-checksum": "1956493800", "fs.automatic.close": "false", "hadoop.security.groups.cache.warn.after.ms": "27126"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	7	org.apache.hadoop.ha.TestZKFailoverController#testGracefulFailoverFailBecomingActive	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /shuai/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:93), org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailoverFailBecomingActive(TestZKFailoverController.java:552), org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailoverFailBecomingActive$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testGracefulFailoverFailBecomingActive/campaign/failures/debug_000000	{"hadoop.security.credential.clear-text-fallback": "false"}	["debug_000000"]	org.apache.hadoop.ha.TestZKFailoverController#testCedeActive	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /shuai/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:93), org.apache.hadoop.ha.TestZKFailoverController.testCedeActive(TestZKFailoverController.java:451), org.apache.hadoop.ha.TestZKFailoverController.testCedeActive$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testCedeActive/campaign/failures/debug_000000	{"hadoop.security.credential.clear-text-fallback": "false"}	["debug_000000"]	org.apache.hadoop.ha.TestZKFailoverController#testDontFailoverToUnhealthyNode	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /hadoop-ha/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:93), org.apache.hadoop.ha.TestZKFailoverController.testDontFailoverToUnhealthyNode(TestZKFailoverController.java:336), org.apache.hadoop.ha.TestZKFailoverController.testDontFailoverToUnhealthyNode$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testDontFailoverToUnhealthyNode/campaign/failures/debug_000000	{"hadoop.security.credential.clear-text-fallback": "false"}	["debug_000000"]	org.apache.hadoop.ha.TestZKFailoverController#testAutoFailoverOnBadHealth	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /shuai/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:93), org.apache.hadoop.ha.TestZKFailoverController.testAutoFailoverOnBadHealth(TestZKFailoverController.java:258), org.apache.hadoop.ha.TestZKFailoverController.testAutoFailoverOnBadHealth$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testAutoFailoverOnBadHealth/campaign/failures/debug_000001	{"hadoop.security.credential.clear-text-fallback": "false"}	["debug_000001"]	org.apache.hadoop.ha.TestZKFailoverController#testGracefulFailoverToUnhealthy	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /hadoop-ha/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:93), org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailoverToUnhealthy(TestZKFailoverController.java:505), org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailoverToUnhealthy$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testGracefulFailoverToUnhealthy/campaign/failures/debug_000000	{"hadoop.security.credential.clear-text-fallback": "false"}	["debug_000000"]	org.apache.hadoop.ha.TestZKFailoverController#testGracefulFailoverFailBecomingStandby	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /shuai/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:93), org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailoverFailBecomingStandby(TestZKFailoverController.java:579), org.apache.hadoop.ha.TestZKFailoverController.testGracefulFailoverFailBecomingStandby$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testGracefulFailoverFailBecomingStandby/campaign/failures/debug_000000	{"hadoop.security.credential.clear-text-fallback": "false"}	["debug_000000"]	org.apache.hadoop.ha.TestZKFailoverController#testFormatOneClusterLeavesOtherClustersAlone	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /hadoop-ha/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.TestZKFailoverController.runFC(TestZKFailoverController.java:717), org.apache.hadoop.ha.TestZKFailoverController.testFormatOneClusterLeavesOtherClustersAlone(TestZKFailoverController.java:163), org.apache.hadoop.ha.TestZKFailoverController.testFormatOneClusterLeavesOtherClustersAlone$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testFormatOneClusterLeavesOtherClustersAlone/campaign/failures/debug_000000	{"hadoop.security.credential.clear-text-fallback": "false"}	["debug_000000"]																																																																																																																																															
			1	org.apache.hadoop.ha.TestZKFailoverController#testGracefulFailoverFailBecomingActive	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	DIFFERENT	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:361), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1855), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:501), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testGracefulFailoverFailBecomingActive/campaign/failures/debug_000001	{"hadoop.security.authentication": "kerberos", "ipc.server.read.threadpool.size": "2139095054"}	["debug_000001"]																																																																																																																																																																																																																	
	Bug-17	Repeated	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testNoDataEntry	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testNoDataEntry(TestTFileByteArrays.java:108), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testNoDataEntry$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testNoDataEntry/campaign/failures/debug_000000	{"io.file.buffer.size": "1297292705", "tfile.fs.output.buffer.size": "2011763356"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testNoDataEntry	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.setUp(TestTFileNoneCodecsByteArrays.java:29), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testNoDataEntry/campaign/failures/debug_000002	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "62", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "166s", "file.stream-buffer-size": "2042276520", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "tfile.fs.input.buffer.size": "861", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "60", "fs.creation.parallel.count": "14151"}	["debug_000002"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testClientRetriesIfMaxAttemptsNotSet	org.junit.runners.model.TestTimedOutException	test timed out after 30000 milliseconds	java.base@11.0.19/java.lang.Thread.sleep(Native Method), app//org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.doOp(LoadBalancingKMSClientProvider.java:220), app//org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.createKey(LoadBalancingKMSClientProvider.java:481), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet(TestLoadBalancingKMSClientProvider.java:654), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testClientRetriesIfMaxAttemptsNotSet/campaign/failures/debug_000000	{"hadoop.security.kms.client.failover.max.retries": "445"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testClientRetriesIfMaxAttemptsNotSet	org.mockito.exceptions.verification.TooManyActualInvocations	kMSClientProvider.createKey(    "test3",    <any org.apache.hadoop.crypto.key.KeyProvider.Options>);Wanted 2 times:-> at org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet(TestLoadBalancingKMSClientProvider.java:659)But was 16 times:-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet(TestLoadBalancingKMSClientProvider.java:659), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testClientRetriesIfMaxAttemptsNotSet/campaign/failures/debug_000001	{"hadoop.security.kms.client.failover.max.retries": "31"}	["debug_000001"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.security.authorize.TestProxyUsers#testNullUser	java.lang.IllegalArgumentException	user is null.	org.apache.hadoop.security.authorize.DefaultImpersonationProvider.authorize(DefaultImpersonationProvider.java:113), org.apache.hadoop.security.authorize.ImpersonationProvider.authorize(ImpersonationProvider.java:54), org.apache.hadoop.security.authorize.ProxyUsers.authorize(ProxyUsers.java:101), org.apache.hadoop.security.authorize.TestProxyUsers.testNullUser(TestProxyUsers.java:357), org.apache.hadoop.security.authorize.TestProxyUsers.testNullUser$$CONFUZZ(TestProxyUsers.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.authorize.TestProxyUsers/testNullUser/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.service.launcher.TestServiceConf#testConfPropagationOverInitBindings	org.apache.hadoop.service.launcher.ServiceLaunchException	service LaunchableRunningService failed	org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:521), org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:469), org.apache.hadoop.service.launcher.ServiceLauncher.launchServiceAndExit(ServiceLauncher.java:302), org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1070), org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1052), org.apache.hadoop.service.launcher.AbstractServiceLauncherTestBase.assertLaunchOutcome(AbstractServiceLauncherTestBase.java:162), org.apache.hadoop.service.launcher.TestServiceConf.testConfPropagationOverInitBindings(TestServiceConf.java:46), org.apache.hadoop.service.launcher.TestServiceConf.testConfPropagationOverInitBindings$$CONFUZZ(TestServiceConf.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.service.launcher.TestServiceConf/testConfPropagationOverInitBindings/campaign/failures/debug_000000	{"exit.code": "5320"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.service.launcher.TestServiceConf#testConfPropagationOverInitBindings	org.apache.hadoop.service.launcher.ServiceLaunchException	service LaunchableRunningService succeeded	org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:517), org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:469), org.apache.hadoop.service.launcher.ServiceLauncher.launchServiceAndExit(ServiceLauncher.java:302), org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1070), org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1052), org.apache.hadoop.service.launcher.AbstractServiceLauncherTestBase.assertLaunchOutcome(AbstractServiceLauncherTestBase.java:162), org.apache.hadoop.service.launcher.TestServiceConf.testConfPropagationOverInitBindings(TestServiceConf.java:46), org.apache.hadoop.service.launcher.TestServiceConf.testConfPropagationOverInitBindings$$CONFUZZ(TestServiceConf.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.service.launcher.TestServiceConf/testConfPropagationOverInitBindings/campaign/failures/debug_000002	{"exit.code": "0"}	["debug_000002"]																																																																																																																																																																																																																	
		FP	2	org.apache.hadoop.service.launcher.TestServiceConf#testConfPropagationOverInitBindings	org.junit.runners.model.TestTimedOutException	test timed out after 15000 milliseconds	java.base@11.0.19/java.lang.Thread.sleep(Native Method), app//org.apache.hadoop.service.launcher.testservices.LaunchableRunningService.execute(LaunchableRunningService.java:97), app//org.apache.hadoop.service.launcher.ServiceLauncher.coreServiceLaunch(ServiceLauncher.java:627), app//org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:495), app//org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:469), app//org.apache.hadoop.service.launcher.ServiceLauncher.launchServiceAndExit(ServiceLauncher.java:302), app//org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1070), app//org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1052), app//org.apache.hadoop.service.launcher.AbstractServiceLauncherTestBase.assertLaunchOutcome(AbstractServiceLauncherTestBase.java:162), app//org.apache.hadoop.service.launcher.TestServiceConf.testConfPropagationOverInitBindings(TestServiceConf.java:46), app//org.apache.hadoop.service.launcher.TestServiceConf.testConfPropagationOverInitBindings$$CONFUZZ(TestServiceConf.java), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), app//org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.service.launcher.TestServiceConf/testConfPropagationOverInitBindings/campaign/failures/debug_000001	{"delay.time": "33653072"}	["debug_000001"]	org.apache.hadoop.service.launcher.TestServiceConf#testRunService	org.junit.runners.model.TestTimedOutException	test timed out after 15000 milliseconds	java.base@11.0.19/java.lang.Thread.sleep(Native Method), app//org.apache.hadoop.service.launcher.testservices.LaunchableRunningService.execute(LaunchableRunningService.java:97), app//org.apache.hadoop.service.launcher.ServiceLauncher.coreServiceLaunch(ServiceLauncher.java:627), app//org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:495), app//org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:469), app//org.apache.hadoop.service.launcher.ServiceLauncher.launchServiceAndExit(ServiceLauncher.java:302), app//org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1070), app//org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1052), app//org.apache.hadoop.service.launcher.AbstractServiceLauncherTestBase.assertLaunchOutcome(AbstractServiceLauncherTestBase.java:162), app//org.apache.hadoop.service.launcher.AbstractServiceLauncherTestBase.assertRuns(AbstractServiceLauncherTestBase.java:173), app//org.apache.hadoop.service.launcher.TestServiceConf.testRunService(TestServiceConf.java:40), app//org.apache.hadoop.service.launcher.TestServiceConf.testRunService$$CONFUZZ(TestServiceConf.java), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), app//org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.service.launcher.TestServiceConf/testRunService/campaign/failures/debug_000000	{"delay.time": "91149023"}	["debug_000000"]																																																																																																																																																																																																						
			1	org.apache.hadoop.http.TestSSLHttpServerConfigs#testKeyStoreSetupWithoutKeyStorePassword	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutKeyStorePassword(TestSSLHttpServerConfigs.java:230), org.apache.hadoop.http.TestSSLHttpServerConfigs.testKeyStoreSetupWithoutKeyStorePassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testKeyStoreSetupWithoutKeyStorePassword/campaign/failures/debug_000005	{"hadoop.http.logs.enabled": "false", "hadoop.prometheus.endpoint.enabled": "true", "hadoop.http.max.request.header.size": "16493"}	["debug_000005"]																																																																																																																																																																																																																	
			2	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testTwoDataEntries	java.lang.ArrayIndexOutOfBoundsException	Index 0 out of bounds for length 0	org.apache.hadoop.io.file.tfile.SimpleBufferedOutputStream.write(SimpleBufferedOutputStream.java:50), java.base/java.io.DataOutputStream.writeByte(DataOutputStream.java:153), org.apache.hadoop.io.file.tfile.Utils.writeVLong(Utils.java:103), org.apache.hadoop.io.file.tfile.Utils.writeVInt(Utils.java:56), org.apache.hadoop.io.file.tfile.TFile$Writer$KeyRegister.close(TFile.java:450), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:399), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:136), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testTwoDataEntries$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.setUp(TestTFileNoneCodecsByteArrays.java:29), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testTwoDataEntries/campaign/failures/debug_000004	{"file.stream-buffer-size": "2130640638"}	["debug_000004"]	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86), org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112), java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81), java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142), java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.writeBuffer(SequenceFile.java:1588), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.sync(SequenceFile.java:1605), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.append(SequenceFile.java:1663), org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1425), org.apache.hadoop.io.MapFile$Writer.append(MapFile.java:327), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:638), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1170), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:634), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000005	{"file.stream-buffer-size": "2114934851"}	["debug_000005"]																																																																																																																																																																																																						
		FP	1	org.apache.hadoop.fs.ftp.TestFTPFileSystem#testCreateWithWritePermissions	java.io.IOException	Unable to create file: test1.txt, Aborting	org.apache.hadoop.fs.ftp.FTPFileSystem.create(FTPFileSystem.java:356), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.ftp.TestFTPFileSystem.testCreateWithWritePermissions(TestFTPFileSystem.java:95), org.apache.hadoop.fs.ftp.TestFTPFileSystem.testCreateWithWritePermissions$$CONFUZZ(TestFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.ftp.TestFTPFileSystem/testCreateWithWritePermissions/campaign/failures/debug_000000	{"fs.ftp.data.connection.mode": "PASSIVE_REMOTE_DATA_CONNECTION_MODE"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.crypto.key.TestKeyProviderFactory#testUserProvider	java.io.IOException	Key key3 already exists in user:///	org.apache.hadoop.crypto.key.UserProvider.createKey(UserProvider.java:87), org.apache.hadoop.crypto.key.TestKeyProviderFactory.checkSpecificProvider(TestKeyProviderFactory.java:120), org.apache.hadoop.crypto.key.TestKeyProviderFactory.testUserProvider(TestKeyProviderFactory.java:204), org.apache.hadoop.crypto.key.TestKeyProviderFactory.testUserProvider$$CONFUZZ(TestKeyProviderFactory.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.TestKeyProviderFactory/testUserProvider/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testRenamingFileOntoExistingFile	java.io.IOException	Destination path /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/testsftp/testrenamingfileontoexistingfile$$confuzz2 already exist, cannot rename!	org.apache.hadoop.fs.sftp.SFTPFileSystem.rename(SFTPFileSystem.java:479), org.apache.hadoop.fs.sftp.SFTPFileSystem.rename(SFTPFileSystem.java:607), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testRenamingFileOntoExistingFile(TestSFTPFileSystem.java:336), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testRenamingFileOntoExistingFile$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testRenamingFileOntoExistingFile/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.fs.TestFsShellCopy#testCopyFileFromLocal	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertTrue(Assert.java:53), org.apache.hadoop.fs.TestFsShellCopy.checkPut(TestFsShellCopy.java:279), org.apache.hadoop.fs.TestFsShellCopy.checkPut(TestFsShellCopy.java:192), org.apache.hadoop.fs.TestFsShellCopy.testCopyFileFromLocal(TestFsShellCopy.java:132), org.apache.hadoop.fs.TestFsShellCopy.testCopyFileFromLocal$$CONFUZZ(TestFsShellCopy.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testCopyFileFromLocal/campaign/failures/debug_000000	{"fs.file.impl.disable.cache": "true"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestFsShellCopy#testCopyFileFromLocal	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.TestFsShellCopy.prepFiles(TestFsShellCopy.java:74), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testCopyFileFromLocal/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1475730312", "hadoop.kerberos.min.seconds.before.relogin": "19288"}	["debug_000003"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testViewFileSystemUtil	org.apache.hadoop.fs.viewfs.NotInMountpointException	getStatus on path `/non-existing' is not within a mount point	org.apache.hadoop.fs.viewfs.ViewFileSystemUtil.getStatus(ViewFileSystemUtil.java:155), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testViewFileSystemUtil(ViewFileSystemBaseTest.java:1167), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testViewFileSystemUtil$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testViewFileSystemUtil/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestFileContextResolveAfs#testFileContextResolveAfs	java.io.IOException	Error 1 creating symlink file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/TestFileContextResolveAfs2 to /home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/TestFileContextResolveAfs1	org.apache.hadoop.fs.RawLocalFileSystem.createSymlink(RawLocalFileSystem.java:1061), org.apache.hadoop.fs.DelegateToFileSystem.createSymlink(DelegateToFileSystem.java:249), org.apache.hadoop.fs.FilterFs.createSymlink(FilterFs.java:304), org.apache.hadoop.fs.FileContext$21.next(FileContext.java:1575), org.apache.hadoop.fs.FileContext$21.next(FileContext.java:1571), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.createSymlink(FileContext.java:1578), org.apache.hadoop.fs.TestFileContextResolveAfs.testFileContextResolveAfs(TestFileContextResolveAfs.java:61), org.apache.hadoop.fs.TestFileContextResolveAfs.testFileContextResolveAfs$$CONFUZZ(TestFileContextResolveAfs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFileContextResolveAfs/testFileContextResolveAfs/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.service.launcher.TestServiceConf#testRunService	org.apache.hadoop.service.launcher.ServiceLaunchException	service LaunchableRunningService failed	org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:521), org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:469), org.apache.hadoop.service.launcher.ServiceLauncher.launchServiceAndExit(ServiceLauncher.java:302), org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1070), org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1052), org.apache.hadoop.service.launcher.AbstractServiceLauncherTestBase.assertLaunchOutcome(AbstractServiceLauncherTestBase.java:162), org.apache.hadoop.service.launcher.AbstractServiceLauncherTestBase.assertRuns(AbstractServiceLauncherTestBase.java:173), org.apache.hadoop.service.launcher.TestServiceConf.testRunService(TestServiceConf.java:40), org.apache.hadoop.service.launcher.TestServiceConf.testRunService$$CONFUZZ(TestServiceConf.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.service.launcher.TestServiceConf/testRunService/campaign/failures/debug_000001	{"fail.runnable": "true"}	["debug_000001"]																																																																																																																																																																																																																	
	Bug-113	Repeated	1	org.apache.hadoop.util.TestShutdownHookManager#testDuplicateRegistration	java.lang.AssertionError	timeout of hook. Actual: 1	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failEquals(Assert.java:187), org.junit.Assert.assertNotEquals(Assert.java:201), org.apache.hadoop.util.TestShutdownHookManager.testDuplicateRegistration(TestShutdownHookManager.java:215), org.apache.hadoop.util.TestShutdownHookManager.testDuplicateRegistration$$CONFUZZ(TestShutdownHookManager.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.util.TestShutdownHookManager/testDuplicateRegistration/campaign/failures/debug_000000	{"hadoop.service.shutdown.timeout": "0m"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	3	org.apache.hadoop.ipc.TestRPC#testRPCInterrupted	java.lang.AssertionError	rpc got exception org.apache.hadoop.thirdparty.protobuf.ServiceException: java.io.IOException: DestHost:destPort be4b4abb826e:38779 , LocalHost:localPort be4b4abb826e/172.17.0.2:0. Failed on local exception: java.io.IOException: org.apache.hadoop.security.AccessControlException: Client cannot authenticate via:[KERBEROS]	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.ipc.TestRPC.testRPCInterrupted(TestRPC.java:983), org.apache.hadoop.ipc.TestRPC.testRPCInterrupted$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testRPCInterrupted/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos"}	["debug_000000"]	org.apache.hadoop.ipc.TestRPC#testClientRpcTimeout	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertTrue(Assert.java:53), org.apache.hadoop.ipc.TestRPC.testClientRpcTimeout(TestRPC.java:1562), org.apache.hadoop.ipc.TestRPC.testClientRpcTimeout$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testClientRpcTimeout/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos"}	["debug_000000"]	org.apache.hadoop.security.TestDoAsEffectiveUser#testRealUserSetup	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.fail(Assert.java:96), org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserSetup(TestDoAsEffectiveUser.java:206), org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserSetup$$CONFUZZ(TestDoAsEffectiveUser.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestDoAsEffectiveUser/testRealUserSetup/campaign/failures/debug_000002	{"hadoop.security.authentication": "kerberos"}	["debug_000002"]																																																																																																																																																																																											
	Bug-90	Repeated	5	org.apache.hadoop.ipc.TestRPC#testRPCInterrupted	java.lang.IllegalArgumentException		java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRPC.testRPCInterrupted(TestRPC.java:931), org.apache.hadoop.ipc.TestRPC.testRPCInterrupted$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testRPCInterrupted/campaign/failures/debug_000001	{"ipc.server.handler.queue.size": "477900862"}	["debug_000001"]	org.apache.hadoop.ipc.TestRPC#testRpcMetricsInNanos	java.lang.IllegalArgumentException		java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos(TestRPC.java:1861), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testRpcMetricsInNanos/campaign/failures/debug_000004	{"ipc.server.handler.queue.size": "665646144"}	["debug_000004"]	org.apache.hadoop.ipc.TestRPC#testServerAddress	java.lang.IllegalArgumentException		java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.ipc.TestRPC.testServerAddress(TestRPC.java:646), org.apache.hadoop.ipc.TestRPC.testServerAddress$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testServerAddress/campaign/failures/debug_000000	{"ipc.server.handler.queue.size": "455276241"}	["debug_000000"]	org.apache.hadoop.ipc.TestRPC#testConnectionPing	java.lang.IllegalArgumentException		java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.ipc.TestRPC.testConnectionPing(TestRPC.java:997), org.apache.hadoop.ipc.TestRPC.testConnectionPing$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testConnectionPing/campaign/failures/debug_000004	{"ipc.server.handler.queue.size": "1666628020"}	["debug_000004"]	org.apache.hadoop.security.TestDoAsEffectiveUser#testRealUserSetup	java.lang.IllegalArgumentException		java.base/java.util.concurrent.LinkedBlockingQueue.<init>(LinkedBlockingQueue.java:254), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.ipc.CallQueueManager.createCallQueueInstance(CallQueueManager.java:168), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:81), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserSetup(TestDoAsEffectiveUser.java:192), org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserSetup$$CONFUZZ(TestDoAsEffectiveUser.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestDoAsEffectiveUser/testRealUserSetup/campaign/failures/debug_000000	{"ipc.server.handler.queue.size": "818319942"}	["debug_000000"]																																																																																																																																																																					
			1	org.apache.hadoop.fs.TestLocalFSFileContextMainOperations#testCreateFlagCreateExistingFile	org.apache.hadoop.fs.FileAlreadyExistsException	File already exists: file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/lb1R3f4q5e/test/testCreateFlagCreateExistingFile. Append or overwrite option must be specified in [CREATE]	org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:180), org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1294), org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102), org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:353), org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testCreateFlagCreateExistingFile(FileContextMainOperationsBaseTest.java:794), org.apache.hadoop.fs.TestLocalFSFileContextMainOperations.testCreateFlagCreateExistingFile$$CONFUZZ(TestLocalFSFileContextMainOperations.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSFileContextMainOperations/testCreateFlagCreateExistingFile/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			2	org.apache.hadoop.ha.TestZKFailoverController#testDontFailoverToUnhealthyNode	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	DIFFERENT	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:361), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1855), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:501), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testDontFailoverToUnhealthyNode/campaign/failures/debug_000002	{"hadoop.security.authorization": "true", "hadoop.security.authentication": "kerberos"}	["debug_000002"]	org.apache.hadoop.ha.TestZKFailoverController#testGracefulFailoverToUnhealthy	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	DIFFERENT	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:361), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1855), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:501), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testGracefulFailoverToUnhealthy/campaign/failures/debug_000001	{"hadoop.security.authorization": "true", "hadoop.security.authentication": "kerberos"}	["debug_000001"]																																																																																																																																																																																																						
		FP	1	org.apache.hadoop.ipc.TestWeightedTimeCostProvider#testGetCostConfiguredWeights	java.lang.AssertionError	expected:<754100> but was:<13792765916>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestWeightedTimeCostProvider.testGetCostConfiguredWeights(TestWeightedTimeCostProvider.java:84), org.apache.hadoop.ipc.TestWeightedTimeCostProvider.testGetCostConfiguredWeights$$CONFUZZ(TestWeightedTimeCostProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestWeightedTimeCostProvider/testGetCostConfiguredWeights/campaign/failures/debug_000000	{"foo.weighted-cost.lockexclusive": "1253819356"}	["debug_000000"]																																																																																																																																																																																																																	
			8	org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs#testInternalCreateMissingDir2	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation create not permitted on path viewfs://mycluster/missingDir/miss2/foo.	org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:177), org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:183), org.apache.hadoop.fs.viewfs.ViewFs.createInternal(ViewFs.java:352), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextTestHelper.createFile(FileContextTestHelper.java:110), org.apache.hadoop.fs.FileContextTestHelper.createFile(FileContextTestHelper.java:124), org.apache.hadoop.fs.FileContextTestHelper.createFile(FileContextTestHelper.java:129), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testInternalCreateMissingDir2(ViewFsBaseTest.java:736), org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs.testInternalCreateMissingDir2$$CONFUZZ(TestViewFsWithAuthorityLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs/testInternalCreateMissingDir2/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs#testInternalMkdirNew2	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation mkdir not permitted on path /dirNew.	org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:177), org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:183), org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs.mkdir(ViewFs.java:1287), org.apache.hadoop.fs.viewfs.ViewFs.mkdir(ViewFs.java:545), org.apache.hadoop.fs.FileContext$4.next(FileContext.java:809), org.apache.hadoop.fs.FileContext$4.next(FileContext.java:805), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:812), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testInternalMkdirNew2(ViewFsBaseTest.java:713), org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs.testInternalMkdirNew2$$CONFUZZ(TestViewFsWithAuthorityLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs/testInternalMkdirNew2/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs#testInternalCreateMissingDir	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation create not permitted on path viewfs://mycluster/missingDir/foo.	org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:177), org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:183), org.apache.hadoop.fs.viewfs.ViewFs.createInternal(ViewFs.java:352), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextTestHelper.createFile(FileContextTestHelper.java:110), org.apache.hadoop.fs.FileContextTestHelper.createFile(FileContextTestHelper.java:124), org.apache.hadoop.fs.FileContextTestHelper.createFile(FileContextTestHelper.java:129), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testInternalCreateMissingDir(ViewFsBaseTest.java:731), org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs.testInternalCreateMissingDir$$CONFUZZ(TestViewFsWithAuthorityLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs/testInternalCreateMissingDir/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs#testInternalMkdirSlash	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation mkdir not permitted on path /.	org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:177), org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:183), org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs.mkdir(ViewFs.java:1287), org.apache.hadoop.fs.viewfs.ViewFs.mkdir(ViewFs.java:545), org.apache.hadoop.fs.FileContext$4.next(FileContext.java:809), org.apache.hadoop.fs.FileContext$4.next(FileContext.java:805), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:812), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testInternalMkdirSlash(ViewFsBaseTest.java:691), org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs.testInternalMkdirSlash$$CONFUZZ(TestViewFsWithAuthorityLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs/testInternalMkdirSlash/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs#testInternalMkdirExisting2	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation mkdir not permitted on path /linkToDir2.	org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:177), org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:183), org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs.mkdir(ViewFs.java:1287), org.apache.hadoop.fs.viewfs.ViewFs.mkdir(ViewFs.java:545), org.apache.hadoop.fs.FileContext$4.next(FileContext.java:809), org.apache.hadoop.fs.FileContext$4.next(FileContext.java:805), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:812), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testInternalMkdirExisting2(ViewFsBaseTest.java:702), org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs.testInternalMkdirExisting2$$CONFUZZ(TestViewFsWithAuthorityLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs/testInternalMkdirExisting2/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs#testInternalMkdirExisting1	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation mkdir not permitted on path /internalDir.	org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:177), org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:183), org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs.mkdir(ViewFs.java:1287), org.apache.hadoop.fs.viewfs.ViewFs.mkdir(ViewFs.java:545), org.apache.hadoop.fs.FileContext$4.next(FileContext.java:809), org.apache.hadoop.fs.FileContext$4.next(FileContext.java:805), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:812), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testInternalMkdirExisting1(ViewFsBaseTest.java:697), org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs.testInternalMkdirExisting1$$CONFUZZ(TestViewFsWithAuthorityLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs/testInternalMkdirExisting1/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsLocalFs#testInternalMkdirNew	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation mkdir not permitted on path /dirNew.	org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:177), org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:183), org.apache.hadoop.fs.viewfs.ViewFs$InternalDirOfViewFs.mkdir(ViewFs.java:1287), org.apache.hadoop.fs.viewfs.ViewFs.mkdir(ViewFs.java:545), org.apache.hadoop.fs.FileContext$4.next(FileContext.java:809), org.apache.hadoop.fs.FileContext$4.next(FileContext.java:805), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.mkdir(FileContext.java:812), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testInternalMkdirNew(ViewFsBaseTest.java:708), org.apache.hadoop.fs.viewfs.TestViewFsLocalFs.testInternalMkdirNew$$CONFUZZ(TestViewFsLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsLocalFs/testInternalMkdirNew/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFsLocalFs#testInternalCreateMissingDir2	org.apache.hadoop.security.AccessControlException	InternalDir of ViewFileSystem is readonly, operation create not permitted on path viewfs:/missingDir/miss2/foo.	org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:177), org.apache.hadoop.fs.viewfs.ViewFs.readOnlyMountTable(ViewFs.java:183), org.apache.hadoop.fs.viewfs.ViewFs.createInternal(ViewFs.java:352), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextTestHelper.createFile(FileContextTestHelper.java:110), org.apache.hadoop.fs.FileContextTestHelper.createFile(FileContextTestHelper.java:124), org.apache.hadoop.fs.FileContextTestHelper.createFile(FileContextTestHelper.java:129), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testInternalCreateMissingDir2(ViewFsBaseTest.java:736), org.apache.hadoop.fs.viewfs.TestViewFsLocalFs.testInternalCreateMissingDir2$$CONFUZZ(TestViewFsLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsLocalFs/testInternalCreateMissingDir2/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																				
		FP	1	org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs#testRenameAcrossMounts2	java.lang.AssertionError	IOException is not thrown on rename operation	org.junit.Assert.fail(Assert.java:89), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testRenameAcrossMounts2(ViewFsBaseTest.java:380), org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs.testRenameAcrossMounts2$$CONFUZZ(TestViewFsWithAuthorityLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs/testRenameAcrossMounts2/campaign/failures/debug_000000	{"fs.viewfs.rename.strategy": "SAME_FILESYSTEM_ACROSS_MOUNTPOINT"}	["debug_000000"]																																																																																																																																																																																																																	
	Bug-155	Repeated	6	org.apache.hadoop.io.TestSetFile#testSetFileAccessMethods	java.lang.AssertionError	testSetFileWithConstruction error !!!	org.junit.Assert.fail(Assert.java:89), org.apache.hadoop.io.TestSetFile.testSetFileAccessMethods(TestSetFile.java:75), org.apache.hadoop.io.TestSetFile.testSetFileAccessMethods$$CONFUZZ(TestSetFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestSetFile/testSetFileAccessMethods/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1793308334"}	["debug_000003"]	org.apache.hadoop.security.alias.TestCredShell#testCredentialSuccessfulLifecycle	java.lang.AssertionError	WARNING: You have accepted the use of the default provider passwordby not configuring a password in one of the two following locations:    * In the environment variable HADOOP_CREDSTORE_PASSWORD    * In a file referred to by the configuration entry      hadoop.security.credstore.java-keystore-provider.password-file.Please review the documentation regarding provider passwords inthe keystore passwords section of the Credential Provider APIContinuing with the default provider password.create <alias> [-value alias-value] [-provider provider-path] [-strict]:The create subcommand creates a new credential for the namespecified as the <alias> argument within the provider indicatedthrough the -provider argument. If -strict is supplied, failimmediately if the provider requires a password and none is given.If -value is provided, use that for the value of the credentialinstead of prompting the user. expected:<0> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.apache.hadoop.security.alias.TestCredShell.testCredentialSuccessfulLifecycle(TestCredShell.java:70), org.apache.hadoop.security.alias.TestCredShell.testCredentialSuccessfulLifecycle$$CONFUZZ(TestCredShell.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.alias.TestCredShell/testCredentialSuccessfulLifecycle/campaign/failures/debug_000001	{"file.bytes-per-checksum": "472441256"}	["debug_000001"]	org.apache.hadoop.io.TestMapFile#testMainMethodMapFile	java.lang.AssertionError	testMainMethodMapFile error !!!	org.junit.Assert.fail(Assert.java:89), org.apache.hadoop.io.TestMapFile.testMainMethodMapFile(TestMapFile.java:679), org.apache.hadoop.io.TestMapFile.testMainMethodMapFile$$CONFUZZ(TestMapFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestMapFile/testMainMethodMapFile/campaign/failures/debug_000003	{"file.bytes-per-checksum": "290096650"}	["debug_000003"]	org.apache.hadoop.security.alias.TestCredShell#testPromptForCredential	java.lang.AssertionError	expected:<0> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.security.alias.TestCredShell.testPromptForCredential(TestCredShell.java:180), org.apache.hadoop.security.alias.TestCredShell.testPromptForCredential$$CONFUZZ(TestCredShell.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.alias.TestCredShell/testPromptForCredential/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1316189454"}	["debug_000001"]	org.apache.hadoop.fs.TestChecksumFileSystem#testVerifyChecksum	java.lang.AssertionError	error reading	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.fs.TestChecksumFileSystem.testVerifyChecksum(TestChecksumFileSystem.java:104), org.apache.hadoop.fs.TestChecksumFileSystem.testVerifyChecksum$$CONFUZZ(TestChecksumFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestChecksumFileSystem/testVerifyChecksum/campaign/failures/debug_000003	{"file.bytes-per-checksum": "7"}	["debug_000003"]	org.apache.hadoop.fs.TestChecksumFileSystem#testCorruptedChecksum	java.lang.AssertionError	got checksum error	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertNotNull(Assert.java:713), org.apache.hadoop.fs.TestChecksumFileSystem.testCorruptedChecksum(TestChecksumFileSystem.java:232), org.apache.hadoop.fs.TestChecksumFileSystem.testCorruptedChecksum$$CONFUZZ(TestChecksumFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestChecksumFileSystem/testCorruptedChecksum/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1035645884"}	["debug_000003"]																																																																																																																																																										
	Bug-99	Repeated	1	org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager#testRenewTokenSingleManager	org.apache.zookeeper.KeeperException$NodeExistsException	KeeperErrorCode = NodeExists for /testPath/ZKDTSMRoot/ZKDTSMTokensRoot/DT_1	org.apache.zookeeper.KeeperException.create(KeeperException.java:126), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1637), org.apache.curator.framework.imps.CreateBuilderImpl$17.call(CreateBuilderImpl.java:1180), org.apache.curator.framework.imps.CreateBuilderImpl$17.call(CreateBuilderImpl.java:1156), org.apache.curator.connection.StandardConnectionHandlingPolicy.callWithRetry(StandardConnectionHandlingPolicy.java:64), org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:100), org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:1153), org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:607), org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:597), org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:51), org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager.addOrUpdateToken(ZKDelegationTokenSecretManager.java:931), org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager.storeToken(ZKDelegationTokenSecretManager.java:839), org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.createPassword(AbstractDelegationTokenSecretManager.java:420), org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.createPassword(AbstractDelegationTokenSecretManager.java:48), org.apache.hadoop.security.token.Token.<init>(Token.java:65), org.apache.hadoop.security.token.delegation.web.DelegationTokenManager.createToken(DelegationTokenManager.java:183), org.apache.hadoop.security.token.delegation.web.DelegationTokenManager.createToken(DelegationTokenManager.java:163), org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testRenewTokenSingleManager(TestZKDelegationTokenSecretManager.java:284), org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testRenewTokenSingleManager$$CONFUZZ(TestZKDelegationTokenSecretManager.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager/testRenewTokenSingleManager/campaign/failures/debug_000000	{"zk-dt-secret-manager.token.seqnum.batch.size": "0"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager#testRenewTokenSingleManager	org.junit.runners.model.TestTimedOutException	test timed out after 300000 milliseconds	java.base@11.0.19/java.lang.Object.wait(Native Method), java.base@11.0.19/java.lang.Object.wait(Object.java:328), app//org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1529), app//org.apache.zookeeper.ClientCnxn.submitRequest(ClientCnxn.java:1512), app//org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:2016), app//org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:2049), app//org.apache.curator.utils.ZKPaths.mkdirs(ZKPaths.java:291), app//org.apache.curator.framework.imps.NamespaceImpl$1.call(NamespaceImpl.java:90), app//org.apache.curator.connection.StandardConnectionHandlingPolicy.callWithRetry(StandardConnectionHandlingPolicy.java:64), app//org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:100), app//org.apache.curator.framework.imps.NamespaceImpl.fixForNamespace(NamespaceImpl.java:83), app//org.apache.curator.framework.imps.CuratorFrameworkImpl.fixForNamespace(CuratorFrameworkImpl.java:736), app//org.apache.curator.framework.imps.WatcherRemovalFacade.fixForNamespace(WatcherRemovalFacade.java:176), app//org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:586), app//org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:457), app//org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:393), app//org.apache.curator.framework.recipes.shared.SharedValue.start(SharedValue.java:256), app//org.apache.curator.framework.recipes.shared.SharedCount.start(SharedCount.java:163), app//org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager.startThreads(ZKDelegationTokenSecretManager.java:332), app//org.apache.hadoop.security.token.delegation.web.DelegationTokenManager.init(DelegationTokenManager.java:146), app//org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testRenewTokenSingleManager(TestZKDelegationTokenSecretManager.java:280), app//org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testRenewTokenSingleManager$$CONFUZZ(TestZKDelegationTokenSecretManager.java), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	TIMEOUT	java.util.concurrent.TimeoutException	TIMEOUT	edu.illinois.confuzz.DebugUtil.runWithNewJVM(DebugUtil.java:148), edu.illinois.confuzz.DebugUtil.getReproduceResult(DebugUtil.java:73), edu.illinois.confuzz.DebugUtil.getReproduceStatus(DebugUtil.java:60), edu.illinois.confuzz.ConfigurationDebugNewJvmMojo.deltaDebug(ConfigurationDebugNewJvmMojo.java:240), edu.illinois.confuzz.ConfigurationDebugNewJvmMojo.execute(ConfigurationDebugNewJvmMojo.java:66), org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137), org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2(MojoExecutor.java:370), org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:351), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:215), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:171), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:163), org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117), org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81), org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56), org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128), org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294), org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192), org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105), org.apache.maven.cli.MavenCli.execute(MavenCli.java:960), org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293), org.apache.maven.cli.MavenCli.main(MavenCli.java:196), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282), org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225), org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406), org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager/testRenewTokenSingleManager/campaign/failures/debug_000002	{"hadoop.security.dns.log-slow-lookups.threshold.ms": "874", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "645", "zk-dt-secret-manager.zkNumRetries": "19570", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "true", "hadoop.security.groups.cache.background.reload.threads": "9418", "zk-dt-secret-manager.zkConnectionTimeout": "15074", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "true", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "zk-dt-secret-manager.zkSessionTimeout": "11", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "692874099", "zk-dt-secret-manager.token.seqnum.batch.size": "32074", "hadoop.security.groups.negative-cache.secs": "122452659", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "7180"}	["debug_000002"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager#testRenewTokenSingleManager	org.junit.runners.model.TestTimedOutException	test timed out after 300000 milliseconds	java.base@11.0.19/jdk.internal.misc.Unsafe.park(Native Method), java.base@11.0.19/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:234), java.base@11.0.19/java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1079), java.base@11.0.19/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1369), java.base@11.0.19/java.util.concurrent.CountDownLatch.await(CountDownLatch.java:278), app//org.apache.curator.CuratorZookeeperClient.internalBlockUntilConnectedOrTimedOut(CuratorZookeeperClient.java:434), app//org.apache.curator.connection.StandardConnectionHandlingPolicy.callWithRetry(StandardConnectionHandlingPolicy.java:56), app//org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:100), app//org.apache.curator.framework.imps.NamespaceImpl.fixForNamespace(NamespaceImpl.java:83), app//org.apache.curator.framework.imps.CuratorFrameworkImpl.fixForNamespace(CuratorFrameworkImpl.java:736), app//org.apache.curator.framework.imps.WatcherRemovalFacade.fixForNamespace(WatcherRemovalFacade.java:176), app//org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:586), app//org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:457), app//org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:393), app//org.apache.curator.framework.recipes.shared.SharedValue.start(SharedValue.java:256), app//org.apache.curator.framework.recipes.shared.SharedCount.start(SharedCount.java:163), app//org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager.startThreads(ZKDelegationTokenSecretManager.java:332), app//org.apache.hadoop.security.token.delegation.web.DelegationTokenManager.init(DelegationTokenManager.java:146), app//org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testRenewTokenSingleManager(TestZKDelegationTokenSecretManager.java:280), app//org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testRenewTokenSingleManager$$CONFUZZ(TestZKDelegationTokenSecretManager.java), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	TIMEOUT	java.util.concurrent.TimeoutException	TIMEOUT	edu.illinois.confuzz.DebugUtil.runWithNewJVM(DebugUtil.java:148), edu.illinois.confuzz.DebugUtil.getReproduceResult(DebugUtil.java:73), edu.illinois.confuzz.DebugUtil.getReproduceStatus(DebugUtil.java:60), edu.illinois.confuzz.ConfigurationDebugNewJvmMojo.deltaDebug(ConfigurationDebugNewJvmMojo.java:240), edu.illinois.confuzz.ConfigurationDebugNewJvmMojo.execute(ConfigurationDebugNewJvmMojo.java:66), org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137), org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2(MojoExecutor.java:370), org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:351), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:215), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:171), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:163), org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117), org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81), org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56), org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128), org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294), org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192), org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105), org.apache.maven.cli.MavenCli.execute(MavenCli.java:960), org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293), org.apache.maven.cli.MavenCli.main(MavenCli.java:196), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282), org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225), org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406), org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager/testRenewTokenSingleManager/campaign/failures/debug_000001	{"zk-dt-secret-manager.zkSessionTimeout": "0", "hadoop.security.auth_to_local.mechanism": "hadoop", "zk-dt-secret-manager.token.seqnum.batch.size": "12794", "hadoop.security.groups.cache.background.reload.threads": "2130640638", "zk-dt-secret-manager.zkConnectionTimeout": "806395647"}	["debug_000001"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs#testListLocatedStatus	org.mockito.exceptions.verification.TooManyActualInvocations	abstractFileSystem.listLocatedStatus(/foo);Wanted 1 time:-> at org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testListLocatedStatus(ViewFsBaseTest.java:971)But was 2 times:-> at org.apache.hadoop.fs.viewfs.ChRootedFs.listLocatedStatus(ChRootedFs.java:255)-> at org.apache.hadoop.fs.viewfs.ChRootedFs.listLocatedStatus(ChRootedFs.java:255)	org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testListLocatedStatus(ViewFsBaseTest.java:971), org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs.testListLocatedStatus$$CONFUZZ(TestViewFsWithAuthorityLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsWithAuthorityLocalFs/testListLocatedStatus/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.service.launcher.TestServiceConf#testConfPropagation	org.junit.runners.model.TestTimedOutException	test timed out after 15000 milliseconds	java.base@11.0.19/java.lang.Object.wait(Native Method), app//org.apache.hadoop.service.AbstractService.waitForServiceToStop(AbstractService.java:279), app//org.apache.hadoop.service.launcher.ServiceLauncher.coreServiceLaunch(ServiceLauncher.java:638), app//org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:495), app//org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:469), app//org.apache.hadoop.service.launcher.ServiceLauncher.launchServiceAndExit(ServiceLauncher.java:302), app//org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1070), app//org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1052), app//org.apache.hadoop.service.launcher.AbstractServiceLauncherTestBase.assertLaunchOutcome(AbstractServiceLauncherTestBase.java:162), app//org.apache.hadoop.service.launcher.TestServiceConf.testConfPropagation(TestServiceConf.java:73), app//org.apache.hadoop.service.launcher.TestServiceConf.testConfPropagation$$CONFUZZ(TestServiceConf.java), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), app//org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.service.launcher.TestServiceConf/testConfPropagation/campaign/failures/debug_000000	{"delay.time": "14998"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.service.launcher.TestServiceConf#testConfPropagation	org.apache.hadoop.service.launcher.ServiceLaunchException	service RunningService succeeded	org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:517), org.apache.hadoop.service.launcher.ServiceLauncher.launchService(ServiceLauncher.java:469), org.apache.hadoop.service.launcher.ServiceLauncher.launchServiceAndExit(ServiceLauncher.java:302), org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1070), org.apache.hadoop.service.launcher.ServiceLauncher.serviceMain(ServiceLauncher.java:1052), org.apache.hadoop.service.launcher.AbstractServiceLauncherTestBase.assertLaunchOutcome(AbstractServiceLauncherTestBase.java:162), org.apache.hadoop.service.launcher.TestServiceConf.testConfPropagation(TestServiceConf.java:73), org.apache.hadoop.service.launcher.TestServiceConf.testConfPropagation$$CONFUZZ(TestServiceConf.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.service.launcher.TestServiceConf/testConfPropagation/campaign/failures/debug_000001	{"hadoop.service.shutdown.timeout": "719226m", "delay.time": "1023"}	["debug_000001"]																																																																																																																																																																																																																	
			9	org.apache.hadoop.io.file.tfile.TestTFileStreams#testNoEntry	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileStreams.closeOutput(TestTFileStreams.java:437), org.apache.hadoop.io.file.tfile.TestTFileStreams.testNoEntry(TestTFileStreams.java:96), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testNoEntry/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "1695521720", "file.stream-buffer-size": "752449680"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureWriteMetaBlocksWithSameName	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteMetaBlocksWithSameName(TestTFileByteArrays.java:271), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureWriteMetaBlocksWithSameName/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "793302709", "file.stream-buffer-size": "1664982939"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureFileWriteNotAt0Position	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureFileWriteNotAt0Position(TestTFileByteArrays.java:561), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureFileWriteNotAt0Position/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "1236185652", "file.stream-buffer-size": "823220956"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureOutOfOrderKeys	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOutOfOrderKeys(TestTFileByteArrays.java:438), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureOutOfOrderKeys/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "1227640663", "file.stream-buffer-size": "1858919481"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testOneDataEntry	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:575), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testOneDataEntry(TestTFileByteArrays.java:122), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testOneDataEntry/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "1246619504", "file.stream-buffer-size": "1833737369"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays#testFailureSeek	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.setUp(TestTFileUnsortedByteArrays.java:74), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays/testFailureSeek/campaign/failures/debug_000001	{"file.stream-buffer-size": "1979471021", "tfile.fs.output.buffer.size": "1702158139"}	["debug_000001"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureOpenEmptyFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenEmptyFile(TestTFileByteArrays.java:381), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureOpenEmptyFile/campaign/failures/debug_000002	{"file.stream-buffer-size": "1953083219", "tfile.fs.output.buffer.size": "1207041233"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureNegativeLength	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeLength(TestTFileByteArrays.java:492), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureNegativeLength/campaign/failures/debug_000002	{"file.stream-buffer-size": "1561274614", "tfile.fs.output.buffer.size": "884301507"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureNegativeLength	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeLength(TestTFileByteArrays.java:492), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureNegativeLength/campaign/failures/debug_000001	{"file.stream-buffer-size": "1469192871", "tfile.fs.output.buffer.size": "1759457972"}	["debug_000001"]																																																																																																																									
			1	org.apache.hadoop.fs.TestHarFileSystemBasics#testNegativeHarFsModifications	java.lang.OutOfMemoryError	Java heap space		PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testNegativeHarFsModifications/campaign/failures/debug_000002	{"fs.creation.parallel.count": "36355"}	["debug_000002"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestFileSystemInitialization#testNewInstanceFailure	org.junit.ComparisonFailure	[init count] expected:<[1]> but was:<[2]>	org.apache.hadoop.fs.TestFileSystemInitialization.testNewInstanceFailure(TestFileSystemInitialization.java:75), org.apache.hadoop.fs.TestFileSystemInitialization.testNewInstanceFailure$$CONFUZZ(TestFileSystemInitialization.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFileSystemInitialization/testNewInstanceFailure/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			8	org.apache.hadoop.security.TestUserGroupInformation#testUGITokens	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1524), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1518), org.apache.hadoop.security.UserGroupInformation.createUserForTesting(UserGroupInformation.java:1558), org.apache.hadoop.security.TestUserGroupInformation.testUGITokens(TestUserGroupInformation.java:664), org.apache.hadoop.security.TestUserGroupInformation.testUGITokens$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:451), org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:338), org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:366), org.apache.hadoop.security.TestUserGroupInformation.setupUgi(TestUserGroupInformation.java:152), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testUGITokens/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000000"]	org.apache.hadoop.security.TestUserGroupInformation#testEqualsWithRealUser	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1524), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1518), org.apache.hadoop.security.UserGroupInformation.createUserForTesting(UserGroupInformation.java:1558), org.apache.hadoop.security.TestUserGroupInformation.testEqualsWithRealUser(TestUserGroupInformation.java:500), org.apache.hadoop.security.TestUserGroupInformation.testEqualsWithRealUser$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:451), org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:338), org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:366), org.apache.hadoop.security.TestUserGroupInformation.setupUgi(TestUserGroupInformation.java:152), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testEqualsWithRealUser/campaign/failures/debug_000001	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000001"]	org.apache.hadoop.security.TestUserGroupInformation#testConstructorWithRules	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1524), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1518), org.apache.hadoop.security.UserGroupInformation.createUserForTesting(UserGroupInformation.java:1558), org.apache.hadoop.security.TestUserGroupInformation.testConstructorSuccess(TestUserGroupInformation.java:412), org.apache.hadoop.security.TestUserGroupInformation.testConstructorWithRules(TestUserGroupInformation.java:335), org.apache.hadoop.security.TestUserGroupInformation.testConstructorWithRules$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:451), org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:338), org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:366), org.apache.hadoop.security.TestUserGroupInformation.setupUgi(TestUserGroupInformation.java:152), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testConstructorWithRules/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000000"]	org.apache.hadoop.security.TestUserGroupInformation#testTokenRaceCondition	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1524), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1518), org.apache.hadoop.security.UserGroupInformation.createUserForTesting(UserGroupInformation.java:1558), org.apache.hadoop.security.TestUserGroupInformation.testTokenRaceCondition(TestUserGroupInformation.java:967), org.apache.hadoop.security.TestUserGroupInformation.testTokenRaceCondition$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:451), org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:338), org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:366), org.apache.hadoop.security.TestUserGroupInformation.setupUgi(TestUserGroupInformation.java:152), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testTokenRaceCondition/campaign/failures/debug_000001	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000001"]	org.apache.hadoop.security.TestUserGroupInformation#testTokenIdentifiers	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1524), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1518), org.apache.hadoop.security.UserGroupInformation.createUserForTesting(UserGroupInformation.java:1558), org.apache.hadoop.security.TestUserGroupInformation.testTokenIdentifiers(TestUserGroupInformation.java:709), org.apache.hadoop.security.TestUserGroupInformation.testTokenIdentifiers$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:451), org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:338), org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:366), org.apache.hadoop.security.TestUserGroupInformation.setupUgi(TestUserGroupInformation.java:152), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testTokenIdentifiers/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000000"]	org.apache.hadoop.security.TestUserGroupInformation#testSetConfigWithRules	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1524), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1518), org.apache.hadoop.security.UserGroupInformation.createUserForTesting(UserGroupInformation.java:1558), org.apache.hadoop.security.TestUserGroupInformation.testSetConfigWithRules(TestUserGroupInformation.java:443), org.apache.hadoop.security.TestUserGroupInformation.testSetConfigWithRules$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:451), org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:338), org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:366), org.apache.hadoop.security.TestUserGroupInformation.setupUgi(TestUserGroupInformation.java:152), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testSetConfigWithRules/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000000"]	org.apache.hadoop.security.TestUserGroupInformation#testPrivateTokenExclusion	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1524), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1518), org.apache.hadoop.security.UserGroupInformation.createUserForTesting(UserGroupInformation.java:1558), org.apache.hadoop.security.TestUserGroupInformation.testPrivateTokenExclusion(TestUserGroupInformation.java:935), org.apache.hadoop.security.TestUserGroupInformation.testPrivateTokenExclusion$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:451), org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:338), org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:366), org.apache.hadoop.security.TestUserGroupInformation.setupUgi(TestUserGroupInformation.java:152), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testPrivateTokenExclusion/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000000"]	org.apache.hadoop.security.TestUserGroupInformation#testEnsureInitWithRules	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1524), org.apache.hadoop.security.UserGroupInformation$TestingGroups.<init>(UserGroupInformation.java:1518), org.apache.hadoop.security.UserGroupInformation.createUserForTesting(UserGroupInformation.java:1558), org.apache.hadoop.security.TestUserGroupInformation.testEnsureInitWithRules(TestUserGroupInformation.java:468), org.apache.hadoop.security.TestUserGroupInformation.testEnsureInitWithRules$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.Groups.<init>(Groups.java:102), org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:451), org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:338), org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:366), org.apache.hadoop.security.TestUserGroupInformation.setupUgi(TestUserGroupInformation.java:152), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testEnsureInitWithRules/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0", "hadoop.security.groups.cache.background.reload": "true"}	["debug_000000"]																																																																																																																																				
			1	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testSourceIsDirectoryAndDestinationIsFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:419), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2482), org.apache.hadoop.fs.FilterFileSystem.copyFromLocalFile(FilterFileSystem.java:376), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:303), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:296), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testSourceIsDirectoryAndDestinationIsFile(AbstractContractCopyFromLocalTest.java:271), org.apache.hadoop.fs.TestLocalFSCopyFromLocal.testSourceIsDirectoryAndDestinationIsFile$$CONFUZZ(TestLocalFSCopyFromLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testSourceIsDirectoryAndDestinationIsFile/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "5529", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "237057s", "file.stream-buffer-size": "32160", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "382", "fs.creation.parallel.count": "869635003", "file.bytes-per-checksum": "692", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "6772", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "30805", "fs.local.block.size": "535", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "611864476", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "648", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "259"}	["debug_000000"]																																																																																																																																																																																																																	
			3	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testSourceIsDirectoryAndDestinationIsFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:419), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2482), org.apache.hadoop.fs.FilterFileSystem.copyFromLocalFile(FilterFileSystem.java:376), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:303), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:296), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testSourceIsDirectoryAndDestinationIsFile(AbstractContractCopyFromLocalTest.java:271), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testSourceIsDirectoryAndDestinationIsFile/campaign/failures/debug_000002	{"io.file.buffer.size": "857499767"}	["debug_000002"]	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testSrcIsDirWithFilesAndCopySuccessful	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:129), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:419), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:409), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2482), org.apache.hadoop.fs.FilterFileSystem.copyFromLocalFile(FilterFileSystem.java:376), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:303), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:296), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testSrcIsDirWithFilesAndCopySuccessful(AbstractContractCopyFromLocalTest.java:165), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testSrcIsDirWithFilesAndCopySuccessful/campaign/failures/debug_000002	{"io.file.buffer.size": "858315987"}	["debug_000002"]	org.apache.hadoop.fs.TestFileUtil#testCopy5	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:93), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:68), org.apache.hadoop.io.IOUtils.copyBytes(IOUtils.java:114), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:502), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:482), org.apache.hadoop.fs.TestFileUtil.testCopy5(TestFileUtil.java:819), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFileUtil/testCopy5/campaign/failures/debug_000002	{"io.file.buffer.size": "1535472883"}	["debug_000002"]																																																																																																																																																																																											
			3	org.apache.hadoop.security.token.TestDtUtilShell#testGet	java.lang.AssertionError	test mocked get exit code expected:<0> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.apache.hadoop.security.token.TestDtUtilShell.testGet(TestDtUtilShell.java:225), org.apache.hadoop.security.token.TestDtUtilShell.testGet$$CONFUZZ(TestDtUtilShell.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-730751156	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.token.TestDtUtilShell.makeTokenFile(TestDtUtilShell.java:124), org.apache.hadoop.security.token.TestDtUtilShell.setup(TestDtUtilShell.java:95), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.TestDtUtilShell/testGet/campaign/failures/debug_000001	{"file.bytes-per-checksum": "873242604"}	["debug_000001"]	org.apache.hadoop.security.token.TestDtUtilShell#testGetWithServiceFlag	java.lang.AssertionError	test mocked get with service flag exit code expected:<0> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.apache.hadoop.security.token.TestDtUtilShell.testGetWithServiceFlag(TestDtUtilShell.java:241), org.apache.hadoop.security.token.TestDtUtilShell.testGetWithServiceFlag$$CONFUZZ(TestDtUtilShell.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-1177449947	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.token.TestDtUtilShell.makeTokenFile(TestDtUtilShell.java:124), org.apache.hadoop.security.token.TestDtUtilShell.setup(TestDtUtilShell.java:95), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.TestDtUtilShell/testGetWithServiceFlag/campaign/failures/debug_000001	{"file.bytes-per-checksum": "823609405"}	["debug_000001"]	org.apache.hadoop.security.token.TestDtUtilShell#testGetWithAliasFlag	java.lang.AssertionError	test mocked get with alias flag exit code expected:<0> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.apache.hadoop.security.token.TestDtUtilShell.testGetWithAliasFlag(TestDtUtilShell.java:256), org.apache.hadoop.security.token.TestDtUtilShell.testGetWithAliasFlag$$CONFUZZ(TestDtUtilShell.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NegativeArraySizeException	-1779338491	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.token.TestDtUtilShell.makeTokenFile(TestDtUtilShell.java:124), org.apache.hadoop.security.token.TestDtUtilShell.setup(TestDtUtilShell.java:95), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.TestDtUtilShell/testGetWithAliasFlag/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1711170077"}	["debug_000003"]																																																																																																																																																																																											
			1	org.apache.hadoop.security.token.TestDtUtilShell#testGet	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.security.Credentials.writeTokenStorageFile(Credentials.java:331), org.apache.hadoop.security.token.TestDtUtilShell.makeTokenFile(TestDtUtilShell.java:124), org.apache.hadoop.security.token.TestDtUtilShell.setup(TestDtUtilShell.java:95), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.TestDtUtilShell/testGet/campaign/failures/debug_000003	{"hadoop.security.dns.log-slow-lookups.threshold.ms": "31469", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "172498434", "hadoop.security.authentication": "kerberos", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "520h", "hadoop.security.groups.cache.background.reload.threads": "554", "fs.local.block.size": "0", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "2069566698", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.security.token.service.use_ip": "true", "hadoop.kerberos.min.seconds.before.relogin": "312986136", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "379", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "fs.creation.parallel.count": "4968", "file.bytes-per-checksum": "13390", "fs.automatic.close": "false", "hadoop.security.groups.cache.warn.after.ms": "1731242161"}	["debug_000003"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ha.TestFailoverController#testFailoverFromNonExistantServiceWithFencer	org.mockito.exceptions.verification.junit.ArgumentsAreDifferent	Argument(s) are different! Wanted:dummyHAService.getProxy(    <any>,    5000);-> at org.apache.hadoop.ha.TestFailoverController.testFailoverFromNonExistantServiceWithFencer(TestFailoverController.java:256)Actual invocations have different arguments:dummyHAService.getFencer(    );-> at org.apache.hadoop.ha.FailoverController.failover(FailoverController.java:203)dummyHAService.getAddress(    );-> at org.apache.hadoop.ha.FailoverController.preFailoverChecks(FailoverController.java:116)dummyHAService.getProxy(    Configuration: core-default.xml, core-site.xml, ctest.xml,    1074036736);-> at org.apache.hadoop.ha.FailoverController.tryGracefulFence(FailoverController.java:171)dummyHAService.getFencer(    );-> at org.apache.hadoop.ha.FailoverController.failover(FailoverController.java:216)	org.apache.hadoop.ha.TestFailoverController.testFailoverFromNonExistantServiceWithFencer(TestFailoverController.java:256), org.apache.hadoop.ha.TestFailoverController.testFailoverFromNonExistantServiceWithFencer$$CONFUZZ(TestFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestFailoverController/testFailoverFromNonExistantServiceWithFencer/campaign/failures/debug_000000	{"ha.failover-controller.graceful-fence.rpc-timeout.ms": "1074036736"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate#testOverwriteExistingFile	java.lang.OutOfMemoryError	Java heap space		PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate/testOverwriteExistingFile/campaign/failures/debug_000001	{"fs.defaultFS": "file:///", "hadoop.security.dns.log-slow-lookups.threshold.ms": "1864508540", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "414", "hadoop.security.authentication": "simple", "fs.client.resolve.remote.symlinks": "true", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.service.shutdown.timeout": "1167s", "hadoop.security.groups.cache.background.reload.threads": "362", "fs.local.block.size": "843483682", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "2037127144", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.security.token.service.use_ip": "true", "hadoop.kerberos.min.seconds.before.relogin": "679", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "21285", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "fs.creation.parallel.count": "750375806", "file.bytes-per-checksum": "224", "fs.automatic.close": "false", "hadoop.security.groups.cache.warn.after.ms": "23426"}	["debug_000001"]																																																																																																																																																																																																																	
	Bug-43	Repeated	2	org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager#testMultiNodeOperations	java.lang.ArithmeticException	/ by zero	org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager.<init>(ZKDelegationTokenSecretManager.java:210), org.apache.hadoop.security.token.delegation.web.DelegationTokenManager$ZKSecretManager.<init>(DelegationTokenManager.java:99), org.apache.hadoop.security.token.delegation.web.DelegationTokenManager.<init>(DelegationTokenManager.java:120), org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testMultiNodeOperations(TestZKDelegationTokenSecretManager.java:109), org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testMultiNodeOperations$$CONFUZZ(TestZKDelegationTokenSecretManager.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager/testMultiNodeOperations/campaign/failures/debug_000000	{"zk-dt-secret-manager.zkNumRetries": "0"}	["debug_000000"]	org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager#testNodeUpAferAWhile	java.lang.ArithmeticException	/ by zero	org.apache.hadoop.security.token.delegation.ZKDelegationTokenSecretManager.<init>(ZKDelegationTokenSecretManager.java:210), org.apache.hadoop.security.token.delegation.web.DelegationTokenManager$ZKSecretManager.<init>(DelegationTokenManager.java:99), org.apache.hadoop.security.token.delegation.web.DelegationTokenManager.<init>(DelegationTokenManager.java:120), org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testNodeUpAferAWhile(TestZKDelegationTokenSecretManager.java:153), org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager.testNodeUpAferAWhile$$CONFUZZ(TestZKDelegationTokenSecretManager.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.delegation.TestZKDelegationTokenSecretManager/testNodeUpAferAWhile/campaign/failures/debug_000000	{"zk-dt-secret-manager.zkNumRetries": "0"}	["debug_000000"]																																																																																																																																																																																																						
		FP	2	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testRenameAcrossMounts2	java.lang.AssertionError	IOException is not thrown on rename operation	org.junit.Assert.fail(Assert.java:89), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testRenameAcrossMounts2(ViewFileSystemBaseTest.java:407), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testRenameAcrossMounts2$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testRenameAcrossMounts2/campaign/failures/debug_000005	{"fs.viewfs.rename.strategy": "SAME_FILESYSTEM_ACROSS_MOUNTPOINT"}	["debug_000005"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testRenameAcrossMounts2	java.lang.AssertionError	IOException is not thrown on rename operation	org.junit.Assert.fail(Assert.java:89), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testRenameAcrossMounts2(ViewFileSystemBaseTest.java:407), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testRenameAcrossMounts2$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testRenameAcrossMounts2/campaign/failures/debug_000000	{"fs.viewfs.rename.strategy": "SAME_FILESYSTEM_ACROSS_MOUNTPOINT"}	["debug_000000"]																																																																																																																																																																																																						
			1	org.apache.hadoop.fs.TestHarFileSystemBasics#testPositiveLruMetadataCacheFs	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.NegativeArraySizeException	-601072258	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1134), org.apache.hadoop.fs.FileSystem.createNewFile(FileSystem.java:1439), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:84), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testPositiveLruMetadataCacheFs/campaign/failures/debug_000001	{}	["debug_000001"]																																																																																																																																																																																																																	
			5	org.apache.hadoop.ha.TestZKFailoverController#testVerifyObserverState	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /uiuc/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.TestZKFailoverController.testVerifyObserverState(TestZKFailoverController.java:321), org.apache.hadoop.ha.TestZKFailoverController.testVerifyObserverState$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	DIFFERENT	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /uiuc/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:361), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1855), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:501), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.TestZKFailoverController.testVerifyObserverState(TestZKFailoverController.java:321), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.apache.zookeeper.JUnit4ZKTestRunner$LoggedInvokeMethod.evaluate(JUnit4ZKTestRunner.java:80), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testVerifyObserverState/campaign/failures/debug_000000	{"hadoop.security.credential.clear-text-fallback": "false", "hadoop.security.authentication": "kerberos"}	["debug_000000"]	org.apache.hadoop.ha.TestZKFailoverController#testObserverExitGracefulFailover	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /uiuc/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.TestZKFailoverController.testObserverExitGracefulFailover(TestZKFailoverController.java:526), org.apache.hadoop.ha.TestZKFailoverController.testObserverExitGracefulFailover$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	DIFFERENT	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /uiuc/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:361), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1855), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:501), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.TestZKFailoverController.testObserverExitGracefulFailover(TestZKFailoverController.java:526), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.apache.zookeeper.JUnit4ZKTestRunner$LoggedInvokeMethod.evaluate(JUnit4ZKTestRunner.java:80), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testObserverExitGracefulFailover/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos", "hadoop.security.credential.clear-text-fallback": "false"}	["debug_000000"]	org.apache.hadoop.ha.TestZKFailoverController#testFormatSetsAcls	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /hadoop-ha/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.TestZKFailoverController.runFC(TestZKFailoverController.java:717), org.apache.hadoop.ha.TestZKFailoverController.testFormatSetsAcls(TestZKFailoverController.java:203), org.apache.hadoop.ha.TestZKFailoverController.testFormatSetsAcls$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	DIFFERENT	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /hadoop-ha/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:361), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1855), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:501), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.TestZKFailoverController.runFC(TestZKFailoverController.java:717), org.apache.hadoop.ha.TestZKFailoverController.testFormatSetsAcls(TestZKFailoverController.java:203), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.apache.zookeeper.JUnit4ZKTestRunner$LoggedInvokeMethod.evaluate(JUnit4ZKTestRunner.java:80), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testFormatSetsAcls/campaign/failures/debug_000002	{"hadoop.security.authentication": "kerberos", "hadoop.security.credential.clear-text-fallback": "false"}	["debug_000002"]	org.apache.hadoop.ha.TestZKFailoverController#testZooKeeperFailure	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /hadoop-ha/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:93), org.apache.hadoop.ha.TestZKFailoverController.testZooKeeperFailure(TestZKFailoverController.java:407), org.apache.hadoop.ha.TestZKFailoverController.testZooKeeperFailure$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	DIFFERENT	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /hadoop-ha/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:361), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1855), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:501), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:93), org.apache.hadoop.ha.TestZKFailoverController.testZooKeeperFailure(TestZKFailoverController.java:407), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.apache.zookeeper.JUnit4ZKTestRunner$LoggedInvokeMethod.evaluate(JUnit4ZKTestRunner.java:80), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testZooKeeperFailure/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos", "hadoop.security.credential.clear-text-fallback": "false"}	["debug_000000"]	org.apache.hadoop.ha.TestZKFailoverController#testAutoFailoverOnLostZKSession	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /hadoop-ha/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:93), org.apache.hadoop.ha.TestZKFailoverController.testAutoFailoverOnLostZKSession(TestZKFailoverController.java:298), org.apache.hadoop.ha.TestZKFailoverController.testAutoFailoverOnLostZKSession$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	DIFFERENT	org.apache.zookeeper.KeeperException$NoAuthException	KeeperErrorCode = NoAuth for /hadoop-ha/dummy-cluster	org.apache.zookeeper.KeeperException.create(KeeperException.java:120), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:1538), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1041), org.apache.hadoop.ha.ActiveStandbyElector$3.run(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1103), org.apache.hadoop.ha.ActiveStandbyElector.zkDoWithRetries(ActiveStandbyElector.java:1095), org.apache.hadoop.ha.ActiveStandbyElector.createWithRetries(ActiveStandbyElector.java:1038), org.apache.hadoop.ha.ActiveStandbyElector.ensureParentZNode(ActiveStandbyElector.java:350), org.apache.hadoop.ha.ZKFailoverController.formatZK(ZKFailoverController.java:292), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:222), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:361), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1855), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:501), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:93), org.apache.hadoop.ha.TestZKFailoverController.testAutoFailoverOnLostZKSession(TestZKFailoverController.java:298), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.apache.zookeeper.JUnit4ZKTestRunner$LoggedInvokeMethod.evaluate(JUnit4ZKTestRunner.java:80), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testAutoFailoverOnLostZKSession/campaign/failures/debug_000000	{"hadoop.security.credential.clear-text-fallback": "false", "hadoop.security.authentication": "kerberos"}	["debug_000000"]																																																																																																																																																																					
		FP	3	org.apache.hadoop.ha.TestZKFailoverController#testVerifyObserverState	java.lang.AssertionError	expected:<0> but was:<6>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.TestZKFailoverController.testVerifyObserverState(TestZKFailoverController.java:321), org.apache.hadoop.ha.TestZKFailoverController.testVerifyObserverState$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testVerifyObserverState/campaign/failures/debug_000002	{"ha.zookeeper.session-timeout.ms": "3"}	["debug_000002"]	org.apache.hadoop.ha.TestZKFailoverController#testObserverExitGracefulFailover	java.lang.AssertionError	expected:<0> but was:<6>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.TestZKFailoverController.testObserverExitGracefulFailover(TestZKFailoverController.java:526), org.apache.hadoop.ha.TestZKFailoverController.testObserverExitGracefulFailover$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testObserverExitGracefulFailover/campaign/failures/debug_000002	{"ha.zookeeper.session-timeout.ms": "15"}	["debug_000002"]	org.apache.hadoop.ha.TestZKFailoverController#testZooKeeperFailure	java.lang.AssertionError	expected:<0> but was:<6>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:116), org.apache.hadoop.ha.MiniZKFCCluster.start(MiniZKFCCluster.java:93), org.apache.hadoop.ha.TestZKFailoverController.testZooKeeperFailure(TestZKFailoverController.java:407), org.apache.hadoop.ha.TestZKFailoverController.testZooKeeperFailure$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testZooKeeperFailure/campaign/failures/debug_000002	{"ha.zookeeper.session-timeout.ms": "13"}	["debug_000002"]																																																																																																																																																																																											
	Bug-62	Repeated	4	org.apache.hadoop.ha.TestZKFailoverController#testVerifyObserverState	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testVerifyObserverState/campaign/failures/debug_000001	{"hadoop.security.authorization": "true"}	["debug_000001"]	org.apache.hadoop.ha.TestZKFailoverController#testAutoFailoverOnBadHealth	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testAutoFailoverOnBadHealth/campaign/failures/debug_000000	{"hadoop.security.authorization": "true"}	["debug_000000"]	org.apache.hadoop.ha.TestZKFailoverController#testObserverExitGracefulFailover	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testObserverExitGracefulFailover/campaign/failures/debug_000001	{"hadoop.security.authorization": "true"}	["debug_000001"]	org.apache.hadoop.ha.TestZKFailoverController#testZooKeeperFailure	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testZooKeeperFailure/campaign/failures/debug_000001	{"hadoop.security.authorization": "true"}	["debug_000001"]																																																																																																																																																																																
			1	org.apache.hadoop.ipc.TestAsyncIPC#testCallGetReturnRpcResponseMultipleTimes	org.apache.hadoop.ipc.RemoteException	SIMPLE authentication is not enabled.  Available:[KERBEROS]	org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612), org.apache.hadoop.ipc.Client.access$3500(Client.java:88), org.apache.hadoop.ipc.Client$2.get(Client.java:1533), org.apache.hadoop.ipc.Client$2.get(Client.java:1527), org.apache.hadoop.util.concurrent.AsyncGetFuture.callAsyncGet(AsyncGetFuture.java:45), org.apache.hadoop.util.concurrent.AsyncGetFuture.get(AsyncGetFuture.java:58), org.apache.hadoop.ipc.TestAsyncIPC$AsyncCaller.assertReturnValues(TestAsyncIPC.java:117), org.apache.hadoop.ipc.TestAsyncIPC.testCallGetReturnRpcResponseMultipleTimes(TestAsyncIPC.java:305), org.apache.hadoop.ipc.TestAsyncIPC.testCallGetReturnRpcResponseMultipleTimes$$CONFUZZ(TestAsyncIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	org.apache.hadoop.security.AccessControlException	Client cannot authenticate via:[KERBEROS]	org.apache.hadoop.security.SaslRpcClient.selectSaslClient(SaslRpcClient.java:179), org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:392), org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623), org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414), org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843), org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839), org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414), org.apache.hadoop.ipc.Client.getConnection(Client.java:1677), org.apache.hadoop.ipc.Client.call(Client.java:1502), org.apache.hadoop.ipc.Client.call(Client.java:1477), org.apache.hadoop.ipc.TestIPC.call(TestIPC.java:177), org.apache.hadoop.ipc.TestIPC.call(TestIPC.java:170), org.apache.hadoop.ipc.TestAsyncIPC$AsyncCaller.run(TestAsyncIPC.java:105), org.apache.hadoop.ipc.TestAsyncIPC.testCallGetReturnRpcResponseMultipleTimes(TestAsyncIPC.java:304), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestAsyncIPC/testCallGetReturnRpcResponseMultipleTimes/campaign/failures/debug_000002	{"hadoop.security.authentication": "kerberos"}	["debug_000002"]																																																																																																																																																																																																																	
		FP	2	org.apache.hadoop.ipc.TestAsyncIPC#testCallGetReturnRpcResponseMultipleTimes	org.apache.hadoop.ipc.RpcException	RPC response exceeds maximum data length	org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936), org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238), org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestAsyncIPC/testCallGetReturnRpcResponseMultipleTimes/campaign/failures/debug_000001	{"ipc.maximum.response.length": "7"}	["debug_000001"]	org.apache.hadoop.ipc.TestRPC#testRpcMetricsInNanos	org.apache.hadoop.ipc.RpcException	RPC response exceeds maximum data length	org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936), org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238), org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testRpcMetricsInNanos/campaign/failures/debug_000007	{"ipc.maximum.response.length": "12"}	["debug_000007"]																																																																																																																																																																																																						
			1	org.apache.hadoop.ha.TestZKFailoverController#testNoZK	org.junit.runners.model.TestTimedOutException	test timed out after 180000 milliseconds	java.base@11.0.19/jdk.internal.misc.Unsafe.park(Native Method), java.base@11.0.19/java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:234), java.base@11.0.19/java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedNanos(AbstractQueuedSynchronizer.java:1079), java.base@11.0.19/java.util.concurrent.locks.AbstractQueuedSynchronizer.tryAcquireSharedNanos(AbstractQueuedSynchronizer.java:1369), java.base@11.0.19/java.util.concurrent.CountDownLatch.await(CountDownLatch.java:278), app//org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef.waitForZKConnectionEvent(ActiveStandbyElector.java:1166), app//org.apache.hadoop.ha.ActiveStandbyElector$WatcherWithClientRef.access$400(ActiveStandbyElector.java:1141), app//org.apache.hadoop.ha.ActiveStandbyElector.connectToZooKeeper(ActiveStandbyElector.java:704), app//org.apache.hadoop.ha.ActiveStandbyElector.createConnection(ActiveStandbyElector.java:858), app//org.apache.hadoop.ha.ActiveStandbyElector.<init>(ActiveStandbyElector.java:272), app//org.apache.hadoop.ha.ActiveStandbyElector.<init>(ActiveStandbyElector.java:215), app//org.apache.hadoop.ha.ZKFailoverController.initZK(ZKFailoverController.java:374), app//org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:200), app//org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), app//org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), app//org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), app//org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), app//org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), app//org.apache.hadoop.ha.TestZKFailoverController.runFC(TestZKFailoverController.java:717), app//org.apache.hadoop.ha.TestZKFailoverController.testNoZK(TestZKFailoverController.java:143), app//org.apache.hadoop.ha.TestZKFailoverController.testNoZK$$CONFUZZ(TestZKFailoverController.java), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	TIMEOUT	java.util.concurrent.TimeoutException	TIMEOUT	edu.illinois.confuzz.DebugUtil.runWithNewJVM(DebugUtil.java:148), edu.illinois.confuzz.DebugUtil.getReproduceResult(DebugUtil.java:73), edu.illinois.confuzz.DebugUtil.getReproduceStatus(DebugUtil.java:60), edu.illinois.confuzz.ConfigurationDebugNewJvmMojo.deltaDebug(ConfigurationDebugNewJvmMojo.java:240), edu.illinois.confuzz.ConfigurationDebugNewJvmMojo.execute(ConfigurationDebugNewJvmMojo.java:66), org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137), org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2(MojoExecutor.java:370), org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:351), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:215), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:171), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:163), org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117), org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81), org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56), org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128), org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294), org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192), org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105), org.apache.maven.cli.MavenCli.execute(MavenCli.java:960), org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293), org.apache.maven.cli.MavenCli.main(MavenCli.java:196), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282), org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225), org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406), org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testNoZK/campaign/failures/debug_000000	{"hadoop.security.dns.log-slow-lookups.threshold.ms": "16181", "hadoop.security.auth_to_local.mechanism": "hadoop", "ha.zookeeper.parent-znode": "/uiuc", "hadoop.security.groups.cache.secs": "1087384286", "ha.failover-controller.active-standby-elector.zk.op.retries": "147722060", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "1968172814", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.security.credential.clear-text-fallback": "false", "hadoop.security.token.service.use_ip": "true", "hadoop.kerberos.min.seconds.before.relogin": "849916625", "ha.zookeeper.session-timeout.ms": "444934708", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "416", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "fs.creation.parallel.count": "313", "hadoop.security.groups.cache.warn.after.ms": "432"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testRenameNonExistFile	java.io.IOException	Source path file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/testsftp/testrenamenonexistfile$$confuzz1 does not exist	org.apache.hadoop.fs.sftp.SFTPFileSystem.rename(SFTPFileSystem.java:476), org.apache.hadoop.fs.sftp.SFTPFileSystem.rename(SFTPFileSystem.java:607), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testRenameNonExistFile(TestSFTPFileSystem.java:324), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testRenameNonExistFile$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testRenameNonExistFile/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
	Bug-175	BUG	2	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testSeekFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testSeekFile(AbstractContractSeekTest.java:203), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek.testSeekFile$$CONFUZZ(TestLocalFSContractSeek.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testSeekFile/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1448626211"}	["debug_000001"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testBlockReadZeroByteFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testBlockReadZeroByteFile(AbstractContractSeekTest.java:118), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek.testBlockReadZeroByteFile$$CONFUZZ(TestLocalFSContractSeek.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testBlockReadZeroByteFile/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1432215361"}	["debug_000000"]																																																																																																																																																																																																						
			1	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testStatFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.touch(TestSFTPFileSystem.java:173), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testStatFile(TestSFTPFileSystem.java:250), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testStatFile$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testStatFile/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "460593651", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "1356s", "file.stream-buffer-size": "233", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "true", "hadoop.security.groups.negative-cache.secs": "35", "fs.creation.parallel.count": "20081", "file.bytes-per-checksum": "576", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "772", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "803", "fs.local.block.size": "135478003", "fs.sftp.connection.max": "22258", "fs.file.impl.disable.cache": "false", "io.file.buffer.size": "2042983402", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "7273", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "402946490"}	["debug_000000"]																																																																																																																																																																																																																	
	Bug-74	Repeated	2	org.apache.hadoop.security.TestGroupsCaching#testEntriesExpireIfBackgroundRefreshFails	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.TestGroupsCaching.testEntriesExpireIfBackgroundRefreshFails(TestGroupsCaching.java:679), org.apache.hadoop.security.TestGroupsCaching.testEntriesExpireIfBackgroundRefreshFails$$CONFUZZ(TestGroupsCaching.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupsCaching/testEntriesExpireIfBackgroundRefreshFails/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "0"}	["debug_000000"]	org.apache.hadoop.security.TestGroupsCaching#testExceptionOnBackgroundRefreshHandled	java.lang.IllegalArgumentException		java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1293), java.base/java.util.concurrent.ThreadPoolExecutor.<init>(ThreadPoolExecutor.java:1215), org.apache.hadoop.security.Groups$GroupCacheLoader.<init>(Groups.java:285), org.apache.hadoop.security.Groups.<init>(Groups.java:139), org.apache.hadoop.security.TestGroupsCaching.testExceptionOnBackgroundRefreshHandled(TestGroupsCaching.java:627), org.apache.hadoop.security.TestGroupsCaching.testExceptionOnBackgroundRefreshHandled$$CONFUZZ(TestGroupsCaching.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupsCaching/testExceptionOnBackgroundRefreshHandled/campaign/failures/debug_000001	{"hadoop.security.groups.cache.background.reload.threads": "0"}	["debug_000001"]																																																																																																																																																																																																						
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<2> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:312), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000006	{"ipc.15.weighted-cost.lockexclusive": "65", "ipc.15.weighted-cost.lockfree": "256"}	["debug_000006"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<19220> but was:<708>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:316), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000008	{"ipc.15.faircallqueue.decay-scheduler.period-ms": "1"}	["debug_000008"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.IllegalStateException	The mock object was garbage collected. This should not happen in normal circumstances when using public API. Typically, the test class keeps strong reference to the mock object and it prevents getting the mock collected. Mockito internally needs to keep weak references to mock objects to avoid memory leaks for certain types of MockMaker implementations. If you see this exception using Mockito public API, please file a bug. For more information see issue #1313.	org.mockito.internal.invocation.mockref.MockWeakReference.get(MockWeakReference.java:32), org.mockito.internal.invocation.InterceptedInvocation.getMock(InterceptedInvocation.java:106), org.mockito.internal.stubbing.InvocationContainerImpl.invokedMock(InvocationContainerImpl.java:157), org.mockito.internal.stubbing.OngoingStubbingImpl.<init>(OngoingStubbingImpl.java:22), org.mockito.internal.handler.MockHandlerImpl.handle(MockHandlerImpl.java:83), org.mockito.internal.handler.NullResultGuardian.handle(NullResultGuardian.java:29), org.mockito.internal.handler.InvocationNotifierHandler.handle(InvocationNotifierHandler.java:35), org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:61), org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:49), org.mockito.internal.creation.bytebuddy.MockMethodInterceptor$DispatcherDefaultingToRealMethod.interceptAbstract(MockMethodInterceptor.java:126), org.apache.hadoop.ipc.Schedulable$MockitoMock$786571835.getUserGroupInformation(Unknown Source), org.apache.hadoop.ipc.UserIdentityProvider.makeIdentity(UserIdentityProvider.java:29), org.apache.hadoop.ipc.DecayRpcScheduler.getIdentity(DecayRpcScheduler.java:595), org.apache.hadoop.ipc.DecayRpcScheduler.getPriorityLevel(DecayRpcScheduler.java:611), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:311), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000009	{"ipc.15.decay-scheduler.backoff.responsetime.enable": "false"}	["debug_000009"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<1> but was:<0>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:311), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000000	{"ipc.15.weighted-cost.lockexclusive": "1655940276"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.getSchedulerWithWeightedTimeCostProvider(TestDecayRpcScheduler.java:390), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:290), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000002	{"ipc.15.faircallqueue.decay-scheduler.decay-factor": "-0.3469524383544922"}	["debug_000002"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<0> but was:<2>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:310), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000001	{"ipc.15.weighted-cost.lockfree": "557059"}	["debug_000001"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<3> but was:<2>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:314), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000007	{"ipc.15.faircallqueue.decay-scheduler.period-ms": "1"}	["debug_000007"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<1> but was:<0>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:322), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000004	{"ipc.15.decay-scheduler.decay-factor": "3.7550926208496094E-6"}	["debug_000004"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<3> but was:<2>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:325), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000003	{"ipc.15.faircallqueue.decay-scheduler.decay-factor": "0.03125053644180298"}	["debug_000003"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureOneEntryKnownLength	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureOneEntryKnownLength(TestTFileStreams.java:189), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureOneEntryKnownLength/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "202492806", "io.file.buffer.size": "1927899958"}	["debug_000003"]																																																																																																																																																																																																																	
		Filtered	1	org.apache.hadoop.security.TestAuthenticationFilter#testConfiguration	org.junit.ComparisonFailure	expected:<[36000]> but was:<[2563]>	org.junit.Assert.assertEquals(Assert.java:117), org.junit.Assert.assertEquals(Assert.java:146), org.apache.hadoop.security.TestAuthenticationFilter$1.answer(TestAuthenticationFilter.java:60), org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:39), org.mockito.internal.handler.MockHandlerImpl.handle(MockHandlerImpl.java:96), org.mockito.internal.handler.NullResultGuardian.handle(NullResultGuardian.java:29), org.mockito.internal.handler.InvocationNotifierHandler.handle(InvocationNotifierHandler.java:35), org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:61), org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:49), org.mockito.internal.creation.bytebuddy.MockMethodInterceptor$DispatcherDefaultingToRealMethod.interceptAbstract(MockMethodInterceptor.java:126), org.apache.hadoop.http.FilterContainer$MockitoMock$1729625386.addFilter(Unknown Source), org.apache.hadoop.security.AuthenticationFilterInitializer.initFilter(AuthenticationFilterInitializer.java:61), org.apache.hadoop.security.TestAuthenticationFilter.testConfiguration(TestAuthenticationFilter.java:73), org.apache.hadoop.security.TestAuthenticationFilter.testConfiguration$$CONFUZZ(TestAuthenticationFilter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestAuthenticationFilter/testConfiguration/campaign/failures/debug_000000	{"hadoop.http.authentication.token.validity": "2563"}	["debug_000000"]																																																																																																																																																																																																																	
		Filtered	1	org.apache.hadoop.security.TestAuthenticationFilter#testConfiguration	org.junit.ComparisonFailure	expected:<[tru]e> but was:<[fals]e>	org.junit.Assert.assertEquals(Assert.java:117), org.junit.Assert.assertEquals(Assert.java:146), org.apache.hadoop.security.TestAuthenticationFilter$1.answer(TestAuthenticationFilter.java:62), org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:39), org.mockito.internal.handler.MockHandlerImpl.handle(MockHandlerImpl.java:96), org.mockito.internal.handler.NullResultGuardian.handle(NullResultGuardian.java:29), org.mockito.internal.handler.InvocationNotifierHandler.handle(InvocationNotifierHandler.java:35), org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:61), org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:49), org.mockito.internal.creation.bytebuddy.MockMethodInterceptor$DispatcherDefaultingToRealMethod.interceptAbstract(MockMethodInterceptor.java:126), org.apache.hadoop.http.FilterContainer$MockitoMock$1729625386.addFilter(Unknown Source), org.apache.hadoop.security.AuthenticationFilterInitializer.initFilter(AuthenticationFilterInitializer.java:61), org.apache.hadoop.security.TestAuthenticationFilter.testConfiguration(TestAuthenticationFilter.java:73), org.apache.hadoop.security.TestAuthenticationFilter.testConfiguration$$CONFUZZ(TestAuthenticationFilter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestAuthenticationFilter/testConfiguration/campaign/failures/debug_000002	{"hadoop.http.authentication.simple.anonymous.allowed": "false"}	["debug_000002"]																																																																																																																																																																																																																	
		Filtered	1	org.apache.hadoop.security.TestAuthenticationFilter#testConfiguration	org.junit.ComparisonFailure	expected:<[simple]> but was:<[kerberos]>	org.junit.Assert.assertEquals(Assert.java:117), org.junit.Assert.assertEquals(Assert.java:146), org.apache.hadoop.security.TestAuthenticationFilter$1.answer(TestAuthenticationFilter.java:59), org.mockito.internal.stubbing.StubbedInvocationMatcher.answer(StubbedInvocationMatcher.java:39), org.mockito.internal.handler.MockHandlerImpl.handle(MockHandlerImpl.java:96), org.mockito.internal.handler.NullResultGuardian.handle(NullResultGuardian.java:29), org.mockito.internal.handler.InvocationNotifierHandler.handle(InvocationNotifierHandler.java:35), org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:61), org.mockito.internal.creation.bytebuddy.MockMethodInterceptor.doIntercept(MockMethodInterceptor.java:49), org.mockito.internal.creation.bytebuddy.MockMethodInterceptor$DispatcherDefaultingToRealMethod.interceptAbstract(MockMethodInterceptor.java:126), org.apache.hadoop.http.FilterContainer$MockitoMock$1729625386.addFilter(Unknown Source), org.apache.hadoop.security.AuthenticationFilterInitializer.initFilter(AuthenticationFilterInitializer.java:61), org.apache.hadoop.security.TestAuthenticationFilter.testConfiguration(TestAuthenticationFilter.java:73), org.apache.hadoop.security.TestAuthenticationFilter.testConfiguration$$CONFUZZ(TestAuthenticationFilter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestAuthenticationFilter/testConfiguration/campaign/failures/debug_000001	{"hadoop.http.authentication.type": "kerberos"}	["debug_000001"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseFactor	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseFactor(TestDecayRpcScheduler.java:89), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseFactor$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseFactor/campaign/failures/debug_000000	{"ipc.3.faircallqueue.decay-scheduler.decay-factor": "-0.2308964729309082"}	["debug_000000"]																																																																																																																																																																																																																	
		Filtered	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseFactor	java.lang.IllegalArgumentException	Period millis must be >= 0	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayPeriodMillis(DecayRpcScheduler.java:332), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:228), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseFactor(TestDecayRpcScheduler.java:97), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseFactor$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseFactor/campaign/failures/debug_000002	{"ipc.4.decay-scheduler.period-ms": "0"}	["debug_000002", "debug_000003"]																																																																																																																																																																																																																	
		Filtered	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseFactor	java.lang.AssertionError	expected:<0.5> but was:<0.18357843160629272>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:555), org.junit.Assert.assertEquals(Assert.java:685), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseFactor(TestDecayRpcScheduler.java:90), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseFactor$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseFactor/campaign/failures/debug_000001	{"ipc.3.decay-scheduler.decay-factor": "0.18357843160629272"}	["debug_000001"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testListOnMountTargetDirsInternal	java.lang.NoSuchMethodError	void org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testListOnMountTargetDirsInternal()'	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testListOnMountTargetDirsInternal$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testListOnMountTargetDirsInternal/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestFsShellList#testListWithUGI	java.lang.IllegalArgumentException	Invalid attribute value for hadoop.security.authentication of DUMMYAUTH	org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:720), org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:312), org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:366), org.apache.hadoop.fs.FsShell.init(FsShell.java:102), org.apache.hadoop.fs.FsShell.run(FsShell.java:303), org.apache.hadoop.fs.TestFsShellList.testListWithUGI(TestFsShellList.java:90), org.apache.hadoop.fs.TestFsShellList.testListWithUGI$$CONFUZZ(TestFsShellList.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellList/testListWithUGI/campaign/failures/debug_000000	{}	["debug_000000", "debug_000001"]																																																																																																																																																																																																																	
			2	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate#testOverwriteEmptyDirectory	java.io.FileNotFoundException	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/wxYCeqwAjp/testOverwriteEmptyDirectory (Is a directory)	java.base/java.io.FileOutputStream.open0(Native Method), java.base/java.io.FileOutputStream.open(FileOutputStream.java:298), java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237), org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:321), org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294), org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testOverwriteEmptyDirectory(AbstractContractCreateTest.java:143), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testOverwriteEmptyDirectory(AbstractContractCreateTest.java:160), org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate.testOverwriteEmptyDirectory$$CONFUZZ(TestRawlocalContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate/testOverwriteEmptyDirectory/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "91740806", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "23225141s", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "630871809", "fs.creation.parallel.count": "29327", "file.bytes-per-checksum": "710", "fs.automatic.close": "false", "fs.contract.supports-strict-exceptions": "true", "hadoop.security.dns.log-slow-lookups.threshold.ms": "310", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "true", "hadoop.security.groups.cache.background.reload.threads": "558", "fs.local.block.size": "700", "fs.file.impl.disable.cache": "false", "io.file.buffer.size": "19416", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "649", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "292"}	["debug_000000"]	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate#testOverwriteNonEmptyDirectory	java.io.FileNotFoundException	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/dCzTYRsMjy/testOverwriteNonEmptyDirectory (Is a directory)	java.base/java.io.FileOutputStream.open0(Native Method), java.base/java.io.FileOutputStream.open(FileOutputStream.java:298), java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237), org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:321), org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294), org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testOverwriteNonEmptyDirectory(AbstractContractCreateTest.java:184), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testOverwriteNonEmptyDirectory(AbstractContractCreateTest.java:209), org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate.testOverwriteNonEmptyDirectory$$CONFUZZ(TestRawlocalContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate/testOverwriteNonEmptyDirectory/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "311699540", "fs.client.resolve.remote.symlinks": "true", "hadoop.service.shutdown.timeout": "79433s", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "1604543072", "fs.creation.parallel.count": "738", "file.bytes-per-checksum": "20306", "fs.automatic.close": "false", "fs.contract.supports-strict-exceptions": "true", "hadoop.security.dns.log-slow-lookups.threshold.ms": "460", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "1151456929", "fs.local.block.size": "29199", "fs.file.impl.disable.cache": "false", "io.file.buffer.size": "24559", "hadoop.security.token.service.use_ip": "true", "hadoop.kerberos.min.seconds.before.relogin": "572", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "16880"}	["debug_000000"]																																																																																																																																																																																																						
			1	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testOperationsThroughMountLinksInternal	java.lang.NoSuchMethodError	void org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testOperationsThroughMountLinksInternal()'	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testOperationsThroughMountLinksInternal$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testOperationsThroughMountLinksInternal/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			2	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testCreateNewFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.contract.ContractTestUtils.readDataset(ContractTestUtils.java:214), org.apache.hadoop.fs.contract.ContractTestUtils.verifyFileContents(ContractTestUtils.java:240), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreateNewFile(AbstractContractCreateTest.java:72), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreateNewFile(AbstractContractCreateTest.java:77), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testCreateNewFile/campaign/failures/debug_000002	{"io.file.buffer.size": "849120106", "file.stream-buffer-size": "2006670299"}	["debug_000002"]	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteHalfABlock	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:692), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteHalfABlock(FSMainOperationsBaseTest.java:659), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testWriteReadAndDeleteHalfABlock$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:692), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteHalfABlock(FSMainOperationsBaseTest.java:659), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteHalfABlock/campaign/failures/debug_000002	{"file.stream-buffer-size": "1101413872", "io.file.buffer.size": "1900575808"}	["debug_000002"]																																																																																																																																																																																																						
		FP	2	org.apache.hadoop.security.TestRuleBasedLdapGroupsMapping#testGetGroupsInvalidRule	java.lang.AssertionError	expected:<[group1, GROUP2]> but was:<[]>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:120), org.junit.Assert.assertEquals(Assert.java:146), org.apache.hadoop.security.TestRuleBasedLdapGroupsMapping.testGetGroupsInvalidRule(TestRuleBasedLdapGroupsMapping.java:96), org.apache.hadoop.security.TestRuleBasedLdapGroupsMapping.testGetGroupsInvalidRule$$CONFUZZ(TestRuleBasedLdapGroupsMapping.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestRuleBasedLdapGroupsMapping/testGetGroupsInvalidRule/campaign/failures/debug_000000	{"hadoop.security.group.mapping.ldap.num.attempts": "0"}	["debug_000000"]	org.apache.hadoop.security.TestRuleBasedLdapGroupsMapping#testGetGroupsToLower	java.lang.AssertionError	expected:<[group1, group2]> but was:<[]>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:120), org.junit.Assert.assertEquals(Assert.java:146), org.apache.hadoop.security.TestRuleBasedLdapGroupsMapping.testGetGroupsToLower(TestRuleBasedLdapGroupsMapping.java:78), org.apache.hadoop.security.TestRuleBasedLdapGroupsMapping.testGetGroupsToLower$$CONFUZZ(TestRuleBasedLdapGroupsMapping.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestRuleBasedLdapGroupsMapping/testGetGroupsToLower/campaign/failures/debug_000000	{"hadoop.security.group.mapping.ldap.num.attempts": "0"}	["debug_000000"]																																																																																																																																																																																																						
		FP	1	org.apache.hadoop.ipc.TestIPC#testRTEOnServerReadParam	java.lang.AssertionError	Exception should contain substring 'Injected fault':org.apache.hadoop.ipc.RpcException: RPC response exceeds maximum data length at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936) at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238) at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.ipc.TestIPC.assertExceptionContains(TestIPC.java:644), org.apache.hadoop.ipc.TestIPC.doErrorTest(TestIPC.java:531), org.apache.hadoop.ipc.TestIPC.testRTEOnServerReadParam(TestIPC.java:581), org.apache.hadoop.ipc.TestIPC.testRTEOnServerReadParam$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testRTEOnServerReadParam/campaign/failures/debug_000000	{"ipc.maximum.response.length": "33"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testOverwriteNonEmptyDirectory	java.io.FileNotFoundException	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/7C1wqKI6sU/testOverwriteNonEmptyDirectory (Is a directory)	java.base/java.io.FileOutputStream.open0(Native Method), java.base/java.io.FileOutputStream.open(FileOutputStream.java:298), java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237), org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:321), org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294), org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testOverwriteNonEmptyDirectory(AbstractContractCreateTest.java:184), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testOverwriteNonEmptyDirectory(AbstractContractCreateTest.java:209), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testOverwriteNonEmptyDirectory$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testOverwriteNonEmptyDirectory/campaign/failures/debug_000001	{"hadoop.security.dns.log-slow-lookups.threshold.ms": "985", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.background.reload.threads": "515", "fs.contract.supports-strict-exceptions": "true"}	["debug_000001"]																																																																																																																																																																																																																	
	Bug-144	Repeated	3	org.apache.hadoop.security.TestLdapGroupsMapping#testGetGroups	java.lang.NullPointerException		org.apache.hadoop.security.LdapGroupsMapping.goUpGroupHierarchy(LdapGroupsMapping.java:612), org.apache.hadoop.security.LdapGroupsMapping.lookupGroup(LdapGroupsMapping.java:489), org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:552), org.apache.hadoop.security.LdapGroupsMapping.getGroups(LdapGroupsMapping.java:365), org.apache.hadoop.security.TestLdapGroupsMapping.doTestGetGroups(TestLdapGroupsMapping.java:211), org.apache.hadoop.security.TestLdapGroupsMapping.testGetGroups(TestLdapGroupsMapping.java:101), org.apache.hadoop.security.TestLdapGroupsMapping.testGetGroups$$CONFUZZ(TestLdapGroupsMapping.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestLdapGroupsMapping/testGetGroups/campaign/failures/debug_000000	{"hadoop.security.group.mapping.ldap.search.group.hierarchy.levels": "3"}	["debug_000000"]	org.apache.hadoop.security.TestLdapGroupsMapping#testGetGroupsWithConnectionClosed	java.lang.NullPointerException		org.apache.hadoop.security.LdapGroupsMapping.goUpGroupHierarchy(LdapGroupsMapping.java:612), org.apache.hadoop.security.LdapGroupsMapping.lookupGroup(LdapGroupsMapping.java:489), org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:552), org.apache.hadoop.security.LdapGroupsMapping.getGroups(LdapGroupsMapping.java:365), org.apache.hadoop.security.TestLdapGroupsMapping.doTestGetGroups(TestLdapGroupsMapping.java:211), org.apache.hadoop.security.TestLdapGroupsMapping.testGetGroupsWithConnectionClosed(TestLdapGroupsMapping.java:188), org.apache.hadoop.security.TestLdapGroupsMapping.testGetGroupsWithConnectionClosed$$CONFUZZ(TestLdapGroupsMapping.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestLdapGroupsMapping/testGetGroupsWithConnectionClosed/campaign/failures/debug_000000	{"hadoop.security.group.mapping.ldap.search.group.hierarchy.levels": "440"}	["debug_000000"]	org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch#testBindUserSwitchPasswordFromAlias	java.lang.NullPointerException		org.apache.hadoop.security.LdapGroupsMapping.goUpGroupHierarchy(LdapGroupsMapping.java:612), org.apache.hadoop.security.LdapGroupsMapping.lookupGroup(LdapGroupsMapping.java:489), org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:552), org.apache.hadoop.security.LdapGroupsMapping.getGroups(LdapGroupsMapping.java:365), org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch.doTestBindUserSwitch(TestLdapGroupsMappingWithBindUserSwitch.java:237), org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch.doTestBindUserSwitch(TestLdapGroupsMappingWithBindUserSwitch.java:193), org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch.testBindUserSwitchPasswordFromAlias(TestLdapGroupsMappingWithBindUserSwitch.java:122), org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch.testBindUserSwitchPasswordFromAlias$$CONFUZZ(TestLdapGroupsMappingWithBindUserSwitch.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch/testBindUserSwitchPasswordFromAlias/campaign/failures/debug_000000	{"hadoop.security.group.mapping.ldap.search.group.hierarchy.levels": "214"}	["debug_000000"]																																																																																																																																																																																											
			1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testPositionedBulkReadDoesntChangePosition	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testPositionedBulkReadDoesntChangePosition(AbstractContractSeekTest.java:320), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek.testPositionedBulkReadDoesntChangePosition$$CONFUZZ(TestLocalFSContractSeek.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testPositionedBulkReadDoesntChangePosition(AbstractContractSeekTest.java:320), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testPositionedBulkReadDoesntChangePosition/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "1417681885", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "132685752h", "file.stream-buffer-size": "555291923", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "fs.contract.supports-seek": "true", "hadoop.kerberos.keytab.login.autorenewal.enabled": "true", "hadoop.security.groups.negative-cache.secs": "517", "fs.creation.parallel.count": "780", "file.bytes-per-checksum": "533978826", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "490", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "32", "fs.local.block.size": "7157", "fs.file.impl.disable.cache": "true", "fs.contract.supports-positioned-readable": "true", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "7208", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "44"}	["debug_000000"]																																																																																																																																																																																																																	
			2	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testPositionedBulkReadDoesntChangePosition	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testPositionedBulkReadDoesntChangePosition(AbstractContractSeekTest.java:320), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testPositionedBulkReadDoesntChangePosition/campaign/failures/debug_000002	{"file.stream-buffer-size": "555291923", "file.bytes-per-checksum": "533978826"}	["debug_000002"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testPositionedBulkReadDoesntChangePosition	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testPositionedBulkReadDoesntChangePosition(AbstractContractSeekTest.java:320), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek.testPositionedBulkReadDoesntChangePosition$$CONFUZZ(TestLocalFSContractSeek.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testPositionedBulkReadDoesntChangePosition(AbstractContractSeekTest.java:320), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testPositionedBulkReadDoesntChangePosition/campaign/failures/debug_000001	{"file.bytes-per-checksum": "533978826", "file.stream-buffer-size": "555291923"}	["debug_000001"]																																																																																																																																																																																																						
			4	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testTwoBlocks	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:612), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoBlocks(TestTFileByteArrays.java:176), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testTwoBlocks/campaign/failures/debug_000003	{"tfile.fs.input.buffer.size": "2140147454"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryUnknownLength	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryUnknownLength(TestTFileStreams.java:117), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryUnknownLength/campaign/failures/debug_000003	{"tfile.fs.input.buffer.size": "2130640638"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryMixedLengths2	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths2(TestTFileStreams.java:137), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryMixedLengths2/campaign/failures/debug_000003	{"tfile.fs.input.buffer.size": "2130640638"}	["debug_000003"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testLocate	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testLocate(TestTFileByteArrays.java:239), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testLocate/campaign/failures/debug_000003	{"tfile.fs.input.buffer.size": "2086700504"}	["debug_000003"]																																																																																																																																																																																
			2	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testTargetFileSystemLazyInitialization	java.lang.AssertionError	expected:<4> but was:<3>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testTargetFileSystemLazyInitialization(ViewFileSystemBaseTest.java:1465), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testTargetFileSystemLazyInitialization$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testTargetFileSystemLazyInitialization/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testTargetFileSystemLazyInitialization	java.lang.AssertionError	expected:<4> but was:<3>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testTargetFileSystemLazyInitialization(ViewFileSystemBaseTest.java:1465), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testTargetFileSystemLazyInitialization$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testTargetFileSystemLazyInitialization/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																						
		FP	1	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testClientRetriesSpecifiedNumberOfTimes	org.junit.runners.model.TestTimedOutException	test timed out after 30000 milliseconds	java.base@11.0.19/java.lang.Thread.sleep(Native Method), app//org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.doOp(LoadBalancingKMSClientProvider.java:220), app//org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.createKey(LoadBalancingKMSClientProvider.java:481), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesSpecifiedNumberOfTimes(TestLoadBalancingKMSClientProvider.java:622), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesSpecifiedNumberOfTimes$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testClientRetriesSpecifiedNumberOfTimes/campaign/failures/debug_000000	{"hadoop.security.kms.client.failover.sleep.max.millis": "466482598"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestHarFileSystemBasics#testHarFsWithoutAuthority	java.lang.OutOfMemoryError	Java heap space		PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testHarFsWithoutAuthority/campaign/failures/debug_000003	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "15168", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "136092h", "file.stream-buffer-size": "1170245342", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "30924", "fs.creation.parallel.count": "904146878", "file.bytes-per-checksum": "742", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "295", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "453135642", "fs.har.metadatacache.entries": "313", "fs.local.block.size": "1624531159", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "118828053", "fs.AbstractFileSystem.har.impl": "org.apache.hadoop.fs.HarFs", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "425464631", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "736"}	["debug_000003"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename#testRenameWithNonEmptySubDir	java.io.FileNotFoundException	File file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/Z4hP7Xfi1e/testRenameWithNonEmptySubDir/dest/src1/source.txt does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462), org.apache.hadoop.fs.contract.ContractTestUtils.verifyPathExists(ContractTestUtils.java:961), org.apache.hadoop.fs.contract.ContractTestUtils.assertPathExists(ContractTestUtils.java:945), org.apache.hadoop.fs.contract.AbstractFSContractTestBase.assertPathExists(AbstractFSContractTestBase.java:317), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameWithNonEmptySubDir(AbstractContractRenameTest.java:234), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename.testRenameWithNonEmptySubDir$$CONFUZZ(TestLocalFSContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractRename/testRenameWithNonEmptySubDir/campaign/failures/debug_000000	{"hadoop.security.dns.log-slow-lookups.threshold.ms": "2049", "hadoop.security.groups.cache.secs": "7748", "fs.contract.rename-remove-dest-if-empty-dir": "false", "fs.local.block.size": "0"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.shell.TestPathData#testAbsoluteGlob	java.lang.OutOfMemoryError	Java heap space		PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestPathData/testAbsoluteGlob/campaign/failures/debug_000002	{"file.stream-buffer-size": "286", "hadoop.security.groups.negative-cache.secs": "1042393665", "file.bytes-per-checksum": "1432731711", "io.file.buffer.size": "523", "fs.automatic.close": "false"}	["debug_000002"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.ipc.TestRPC#testRpcMetricsInNanos	java.net.SocketTimeoutException	770 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:52176 remote=42302f3193c0/172.17.0.2:35295]	org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163), org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161), org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131), java.base/java.io.FilterInputStream.read(FilterInputStream.java:133), java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252), java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271), java.base/java.io.DataInputStream.readInt(DataInputStream.java:392), org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922), org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367), org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623), org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414), org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843), org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839), org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414), org.apache.hadoop.ipc.Client.getConnection(Client.java:1677), org.apache.hadoop.ipc.Client.call(Client.java:1502), org.apache.hadoop.ipc.Client.call(Client.java:1455), org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242), org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129), com.sun.proxy.$Proxy22.ping(Unknown Source), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos(TestRPC.java:1878), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	TIMEOUT					{"hadoop.security.groups.cache.secs": "888", "ipc.client.async.calls.max": "1022434123", "ipc.server.tcpnodelay": "false", "ipc.0.callqueue.overflow.trigger.failover": "true", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "ipc.client.low-latency": "false", "ipc.client.idlethreshold": "123", "ipc.server.max.response.size": "150", "ipc.client.connection.idle-scan-interval.ms": "14460", "ipc.ping.interval": "770", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "ipc.server.handler.queue.size": "2040160726", "hadoop.security.authorization": "false", "ipc.client.connection.maxidletime": "668", "ipc.server.read.connection-queue.size": "27313", "hadoop.rpc.socket.factory.class.default": "org.apache.hadoop.net.StandardSocketFactory", "ipc.client.tcpnodelay": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "591", "ipc.client.connect.timeout": "29286", "hadoop.security.authentication": "kerberos", "hadoop.security.groups.cache.background.reload.threads": "29312", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "15927", "ipc.server.reuseaddr": "true", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "1403775288", "ipc.server.read.threadpool.size": "54", "hadoop.security.auth_to_local.mechanism": "MIT", "ipc.client.rpc-timeout.ms": "1476636777", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "ipc.maximum.data.length": "6200", "ipc.client.connect.max.retries.on.sasl": "15032", "ipc.client.bind.wildcard.addr": "false", "hadoop.security.groups.negative-cache.secs": "437", "ipc.client.kill.max": "865", "ipc.0.faircallqueue.priority-levels": "817", "ipc.server.listen.queue.size": "7884", "ipc.0.backoff.enable": "true", "ipc.client.connect.max.retries.on.timeouts": "1307364693", "hadoop.security.dns.log-slow-lookups.enabled": "true", "ipc.client.fallback-to-simple-auth-allowed": "false", "ipc.client.connect.max.retries": "921", "ipc.server.log.slow.rpc": "true", "ipc.client.ping": "true", "ipc.client.connect.retry.interval": "5060", "hadoop.rpc.protection": "authentication,authentication,integrity,integrity,privacy,integrity,privacy,integrity,authentication,authentication,integrity,authentication,privacy,integrity,privacy,privacy,authentication,integrity,privacy,authentication,privacy,authentication,authentication,authentication,integrity,privacy,privacy,integrity,authentication,authentication,integrity,authentication,authentication,privacy,integrity,authentication,authentication,integrity", "ipc.server.purge.interval": "241", "ipc.0.scheduler.priority.levels": "728809837", "ipc.server.max.connections": "525212051", "ipc.maximum.response.length": "221110571"}	["debug_000006"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.ipc.TestRPC#testRpcMetricsInNanos	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertTrue(Assert.java:53), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos(TestRPC.java:1902), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testRpcMetricsInNanos/campaign/failures/debug_000009	{"ipc.client.connect.timeout": "767", "ipc.client.connect.retry.interval": "688822999", "hadoop.security.authentication": "simple", "hadoop.rpc.protection": "privacy,integrity,authentication,integrity,authentication,privacy,privacy,authentication,privacy,authentication,authentication,authentication,privacy,privacy,privacy,integrity,integrity,integrity,authentication,integrity,privacy,integrity,privacy,integrity,integrity,privacy,authentication,privacy,authentication,authentication,authentication,integrity,authentication,authentication,integrity,integrity,authentication,integrity,integrity,authentication,privacy,integrity,authentication,integrity,authentication,integrity,privacy,privacy,privacy,authentication,authentication,privacy,authentication,integrity,privacy,integrity,authentication,integrity,integrity,authentication,integrity,authentication,authentication,privacy,authentication,authentication,authentication,authentication,privacy,privacy,authentication,authentication,authentication,authentication,integrity,authentication,privacy,integrity,authentication,authentication,integrity,integrity,integrity,privacy,authentication,integrity,privacy,privacy,authentication,authentication,authentication,privacy,authentication,privacy,privacy,privacy", "ipc.client.kill.max": "23"}	["debug_000009"]																																																																																																																																																																																																																	
	Bug-89	Repeated	2	org.apache.hadoop.ipc.TestRPC#testRpcMetricsInNanos	java.io.EOFException		java.base/java.io.DataInputStream.readInt(DataInputStream.java:397), org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922), org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238), org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testRpcMetricsInNanos/campaign/failures/debug_000000	{"ipc.maximum.data.length": "1"}	["debug_000000"]	org.apache.hadoop.ipc.TestRPC#testConnectionPing	java.io.EOFException		java.base/java.io.DataInputStream.readInt(DataInputStream.java:397), org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922), org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238), org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testConnectionPing/campaign/failures/debug_000005	{"ipc.maximum.data.length": "1"}	["debug_000005"]																																																																																																																																																																																																						
		FP	3	org.apache.hadoop.ipc.TestRPC#testRpcMetricsInNanos	org.apache.hadoop.security.AccessControlException	Client cannot authenticate via:[KERBEROS]	org.apache.hadoop.security.SaslRpcClient.selectSaslClient(SaslRpcClient.java:179), org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:392), org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623), org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414), org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843), org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839), org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414), org.apache.hadoop.ipc.Client.getConnection(Client.java:1677), org.apache.hadoop.ipc.Client.call(Client.java:1502), org.apache.hadoop.ipc.Client.call(Client.java:1455), org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242), org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129), com.sun.proxy.$Proxy22.ping(Unknown Source), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos(TestRPC.java:1878), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testRpcMetricsInNanos/campaign/failures/debug_000002	{"hadoop.security.authentication": "kerberos"}	["debug_000002"]	org.apache.hadoop.ipc.TestIPC#testRTEDuringConnectionSetup	org.apache.hadoop.security.AccessControlException	Client cannot authenticate via:[KERBEROS]	org.apache.hadoop.security.SaslRpcClient.selectSaslClient(SaslRpcClient.java:179), org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:392), org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623), org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414), org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843), org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839), org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414), org.apache.hadoop.ipc.Client.getConnection(Client.java:1677), org.apache.hadoop.ipc.Client.call(Client.java:1502), org.apache.hadoop.ipc.Client.call(Client.java:1477), org.apache.hadoop.ipc.TestIPC.call(TestIPC.java:177), org.apache.hadoop.ipc.TestIPC.call(TestIPC.java:170), org.apache.hadoop.ipc.TestIPC.testRTEDuringConnectionSetup(TestIPC.java:716), org.apache.hadoop.ipc.TestIPC.testRTEDuringConnectionSetup$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testRTEDuringConnectionSetup/campaign/failures/debug_000002	{"hadoop.security.authentication": "kerberos"}	["debug_000002"]	org.apache.hadoop.ipc.TestRPC#testConnectionPing	org.apache.hadoop.security.AccessControlException	Client cannot authenticate via:[KERBEROS]	org.apache.hadoop.security.SaslRpcClient.selectSaslClient(SaslRpcClient.java:179), org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:392), org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623), org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414), org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843), org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839), org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414), org.apache.hadoop.ipc.Client.getConnection(Client.java:1677), org.apache.hadoop.ipc.Client.call(Client.java:1502), org.apache.hadoop.ipc.Client.call(Client.java:1455), org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242), org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129), com.sun.proxy.$Proxy22.sleep(Unknown Source), org.apache.hadoop.ipc.TestRPC.testConnectionPing(TestRPC.java:1002), org.apache.hadoop.ipc.TestRPC.testConnectionPing$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testConnectionPing/campaign/failures/debug_000001	{"hadoop.security.authentication": "kerberos"}	["debug_000001"]																																																																																																																																																																																											
		FP	3	org.apache.hadoop.ipc.TestRPC#testRpcMetricsInNanos	org.apache.hadoop.ipc.RemoteException	Protocol interface org.apache.hadoop.ipc.TestRpcBase$TestRpcService is not known.	org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612), org.apache.hadoop.ipc.Client.call(Client.java:1558), org.apache.hadoop.ipc.Client.call(Client.java:1455), org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242), org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129), com.sun.proxy.$Proxy22.ping(Unknown Source), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos(TestRPC.java:1878), org.apache.hadoop.ipc.TestRPC.testRpcMetricsInNanos$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testRpcMetricsInNanos/campaign/failures/debug_000003	{"hadoop.security.authorization": "true"}	["debug_000003"]	org.apache.hadoop.ipc.TestIPC#testRTEDuringConnectionSetup	org.apache.hadoop.ipc.RemoteException	Null protocol not authorized	org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612), org.apache.hadoop.ipc.Client.call(Client.java:1558), org.apache.hadoop.ipc.Client.call(Client.java:1477), org.apache.hadoop.ipc.TestIPC.call(TestIPC.java:177), org.apache.hadoop.ipc.TestIPC.call(TestIPC.java:170), org.apache.hadoop.ipc.TestIPC.testRTEDuringConnectionSetup(TestIPC.java:716), org.apache.hadoop.ipc.TestIPC.testRTEDuringConnectionSetup$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testRTEDuringConnectionSetup/campaign/failures/debug_000000	{"hadoop.security.authorization": "true"}	["debug_000000"]	org.apache.hadoop.ipc.TestRPC#testConnectionPing	org.apache.hadoop.ipc.RemoteException	Protocol interface org.apache.hadoop.ipc.TestRpcBase$TestRpcService is not known.	org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612), org.apache.hadoop.ipc.Client.call(Client.java:1558), org.apache.hadoop.ipc.Client.call(Client.java:1455), org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242), org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129), com.sun.proxy.$Proxy22.sleep(Unknown Source), org.apache.hadoop.ipc.TestRPC.testConnectionPing(TestRPC.java:1002), org.apache.hadoop.ipc.TestRPC.testConnectionPing$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testConnectionPing/campaign/failures/debug_000000	{"hadoop.security.authorization": "true"}	["debug_000000"]																																																																																																																																																																																											
			1	org.apache.hadoop.ha.TestZKFailoverController#testObserverExitGracefulFailover	org.junit.runners.model.TestTimedOutException	test timed out after 180000 milliseconds	java.base@11.0.19/java.lang.Thread.sleep(Native Method), app//org.apache.hadoop.ha.ActiveStandbyElectorTestUtil.waitForActiveLockData(ActiveStandbyElectorTestUtil.java:68), app//org.apache.hadoop.ha.MiniZKFCCluster.waitForActiveLockHolder(MiniZKFCCluster.java:260), app//org.apache.hadoop.ha.TestZKFailoverController.testObserverExitGracefulFailover(TestZKFailoverController.java:528), app//org.apache.hadoop.ha.TestZKFailoverController.testObserverExitGracefulFailover$$CONFUZZ(TestZKFailoverController.java), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), app//org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	TIMEOUT	java.util.concurrent.TimeoutException	TIMEOUT	edu.illinois.confuzz.DebugUtil.runWithNewJVM(DebugUtil.java:148), edu.illinois.confuzz.DebugUtil.getReproduceResult(DebugUtil.java:73), edu.illinois.confuzz.DebugUtil.getReproduceStatus(DebugUtil.java:60), edu.illinois.confuzz.ConfigurationDebugNewJvmMojo.deltaDebug(ConfigurationDebugNewJvmMojo.java:240), edu.illinois.confuzz.ConfigurationDebugNewJvmMojo.execute(ConfigurationDebugNewJvmMojo.java:66), org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137), org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2(MojoExecutor.java:370), org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:351), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:215), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:171), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:163), org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117), org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81), org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56), org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128), org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294), org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192), org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105), org.apache.maven.cli.MavenCli.execute(MavenCli.java:960), org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293), org.apache.maven.cli.MavenCli.main(MavenCli.java:196), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282), org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225), org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406), org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testObserverExitGracefulFailover/campaign/failures/debug_000003	{"hadoop.security.auth_to_local.mechanism": "MIT", "ha.zookeeper.parent-znode": "/shuai", "ha.failover-controller.active-standby-elector.zk.op.retries": "18484", "hadoop.security.authentication": "kerberos", "security.service.authorization.default.acl": "*", "security.service.authorization.default.hosts.blocked": "", "ipc.0.callqueue.overflow.trigger.failover": "true", "ipc.maximum.data.length": "650", "security.service.authorization.default.hosts": "*", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "23242", "ipc.client.connection.idle-scan-interval.ms": "26796", "ha.zookeeper.session-timeout.ms": "229", "ha.health-monitor.rpc.connect.max.retries": "1", "security.service.authorization.default.acl.blocked": "", "ipc.server.handler.queue.size": "571", "hadoop.security.authorization": "false"}	["debug_000003"]																																																																																																																																																																																																																	
	Bug-171	BUG	1	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testGetWrappedInputStream	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.testGetWrappedInputStream(FSMainOperationsBaseTest.java:1115), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testGetWrappedInputStream$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testGetWrappedInputStream/campaign/failures/debug_000000	{"io.file.buffer.size": "562813169", "file.stream-buffer-size": "1800914559"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ha.TestZKFailoverController#testFormatSetsAcls	org.apache.zookeeper.KeeperException$NoNodeException	KeeperErrorCode = NoNode for /hadoop-ha	org.apache.zookeeper.KeeperException.create(KeeperException.java:118), org.apache.zookeeper.KeeperException.create(KeeperException.java:54), org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:2131), org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:2160), org.apache.hadoop.ha.TestZKFailoverController.testFormatSetsAcls(TestZKFailoverController.java:209), org.apache.hadoop.ha.TestZKFailoverController.testFormatSetsAcls$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testFormatSetsAcls/campaign/failures/debug_000000	{"ha.zookeeper.parent-znode": "/uiuc"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	2	org.apache.hadoop.ha.TestZKFailoverController#testFormatSetsAcls	java.lang.AssertionError	expected:<0> but was:<6>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ha.TestZKFailoverController.testFormatSetsAcls(TestZKFailoverController.java:203), org.apache.hadoop.ha.TestZKFailoverController.testFormatSetsAcls$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testFormatSetsAcls/campaign/failures/debug_000001	{"ha.zookeeper.session-timeout.ms": "1"}	["debug_000001"]	org.apache.hadoop.ha.TestZKFailoverController#testFormatOneClusterLeavesOtherClustersAlone	java.lang.AssertionError	expected:<3> but was:<6>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ha.TestZKFailoverController.testFormatOneClusterLeavesOtherClustersAlone(TestZKFailoverController.java:159), org.apache.hadoop.ha.TestZKFailoverController.testFormatOneClusterLeavesOtherClustersAlone$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testFormatOneClusterLeavesOtherClustersAlone/campaign/failures/debug_000001	{"ha.zookeeper.session-timeout.ms": "15"}	["debug_000001"]																																																																																																																																																																																																						
		Filtered	2	org.apache.hadoop.ha.TestZKFailoverController#testFormatSetsAcls	java.lang.IllegalArgumentException	Invalid ZK session timeout 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:192), org.apache.hadoop.ha.ZKFailoverController.initZK(ZKFailoverController.java:367), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:200), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.TestZKFailoverController.runFC(TestZKFailoverController.java:717), org.apache.hadoop.ha.TestZKFailoverController.testFormatSetsAcls(TestZKFailoverController.java:203), org.apache.hadoop.ha.TestZKFailoverController.testFormatSetsAcls$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testFormatSetsAcls/campaign/failures/debug_000003	{"ha.zookeeper.session-timeout.ms": "0"}	["debug_000003"]	org.apache.hadoop.ha.TestZKFailoverController#testFormatOneClusterLeavesOtherClustersAlone	java.lang.IllegalArgumentException	Invalid ZK session timeout 0	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:192), org.apache.hadoop.ha.ZKFailoverController.initZK(ZKFailoverController.java:367), org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:200), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.TestZKFailoverController.runFC(TestZKFailoverController.java:717), org.apache.hadoop.ha.TestZKFailoverController.testFormatOneClusterLeavesOtherClustersAlone(TestZKFailoverController.java:160), org.apache.hadoop.ha.TestZKFailoverController.testFormatOneClusterLeavesOtherClustersAlone$$CONFUZZ(TestZKFailoverController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testFormatOneClusterLeavesOtherClustersAlone/campaign/failures/debug_000002	{"ha.zookeeper.session-timeout.ms": "0"}	["debug_000002"]																																																																																																																																																																																																						
			1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureKeyLongerThan64K	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileStreams.setUp(TestTFileStreams.java:76), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.setUp(TestTFileNoneCodecsStreams.java:30), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureKeyLongerThan64K/campaign/failures/debug_000002	{"io.file.buffer.size": "1133784394", "file.bytes-per-checksum": "1053465519"}	["debug_000002"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProviderNoRequests	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.getSchedulerWithWeightedTimeCostProvider(TestDecayRpcScheduler.java:390), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProviderNoRequests(TestDecayRpcScheduler.java:374), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProviderNoRequests$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProviderNoRequests/campaign/failures/debug_000000	{"ipc.18.faircallqueue.decay-scheduler.decay-factor": "-0.31547367572784424"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.fs.TestFsShellReturnCode#testRmForceWithNonexistentGlob	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertTrue(Assert.java:53), org.apache.hadoop.fs.TestFsShellReturnCode.testRmForceWithNonexistentGlob(TestFsShellReturnCode.java:352), org.apache.hadoop.fs.TestFsShellReturnCode.testRmForceWithNonexistentGlob$$CONFUZZ(TestFsShellReturnCode.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellReturnCode/testRmForceWithNonexistentGlob/campaign/failures/debug_000000	{"hadoop.shell.missing.defaultFs.warning": "true"}	["debug_000000"]																																																																																																																																																																																																																	
			2	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteHalfABlock	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:692), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteHalfABlock(FSMainOperationsBaseTest.java:659), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testWriteReadAndDeleteHalfABlock$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:692), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteHalfABlock(FSMainOperationsBaseTest.java:659), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteHalfABlock/campaign/failures/debug_000000	{"file.bytes-per-checksum": "1015320444"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureOpenRandomFile	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenRandomFile(TestTFileByteArrays.java:411), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureOpenRandomFile/campaign/failures/debug_000002	{"file.bytes-per-checksum": "985833778"}	["debug_000002"]																																																																																																																																																																																																						
		Filtered	2	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteHalfABlock	java.lang.IllegalArgumentException	Buffer size <= 0	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:207), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:126), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:694), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteHalfABlock(FSMainOperationsBaseTest.java:659), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testWriteReadAndDeleteHalfABlock$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteHalfABlock/campaign/failures/debug_000004	{"file.stream-buffer-size": "0"}	["debug_000004"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteTwoBlocks	java.lang.IllegalArgumentException	Buffer size <= 0	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:207), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:126), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:694), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteTwoBlocks(FSMainOperationsBaseTest.java:675), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testWriteReadAndDeleteTwoBlocks$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteTwoBlocks/campaign/failures/debug_000005	{"file.stream-buffer-size": "0"}	["debug_000005"]																																																																																																																																																																																																						
			5	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteHalfABlock	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:692), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteHalfABlock(FSMainOperationsBaseTest.java:659), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteHalfABlock/campaign/failures/debug_000003	{"file.stream-buffer-size": "1241380702"}	["debug_000003"]	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteOneAndAHalfBlocks	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FilterFileSystem.open(FilterFileSystem.java:168), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.open(ChRootedFileSystem.java:290), org.apache.hadoop.fs.viewfs.ViewFileSystem.open(ViewFileSystem.java:678), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:692), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteOneAndAHalfBlocks(FSMainOperationsBaseTest.java:670), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteOneAndAHalfBlocks/campaign/failures/debug_000004	{"file.stream-buffer-size": "1080066055"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureWriterNotClosed	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriterNotClosed(TestTFileByteArrays.java:256), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureWriterNotClosed/campaign/failures/debug_000002	{"file.stream-buffer-size": "1057954249"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestVLong#testVLong5Bytes	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestVLong.writeAndVerify(TestVLong.java:87), org.apache.hadoop.io.file.tfile.TestVLong.testVLong5Bytes(TestVLong.java:121), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestVLong/testVLong5Bytes/campaign/failures/debug_000003	{"file.stream-buffer-size": "1651750348"}	["debug_000003"]	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testReadFullyPastEOF	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:126), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testReadFullyPastEOF(AbstractContractSeekTest.java:472), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testReadFullyPastEOF/campaign/failures/debug_000001	{"file.stream-buffer-size": "884714718"}	["debug_000001"]																																																																																																																																																																					
	Bug-16	Repeated	4	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureGetNonExistentMetaBlock	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock(TestTFileByteArrays.java:303), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock$$CONFUZZ(TestTFileByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureGetNonExistentMetaBlock/campaign/failures/debug_000002	{"tfile.fs.input.buffer.size": "1023917806", "file.stream-buffer-size": "955777206"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays#testScanRange	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testScanRange(TestTFileUnsortedByteArrays.java:140), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testScanRange$$CONFUZZ(TestTFileUnsortedByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays/testScanRange/campaign/failures/debug_000000	{"file.stream-buffer-size": "580251631", "tfile.fs.input.buffer.size": "1653090026"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryMixedLengths1	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths1(TestTFileStreams.java:127), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths1$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryMixedLengths1/campaign/failures/debug_000000	{"tfile.fs.input.buffer.size": "1381358238", "file.stream-buffer-size": "1902901223"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testLocate	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testLocate(TestTFileByteArrays.java:239), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testLocate$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testLocate/campaign/failures/debug_000001	{"file.stream-buffer-size": "691873811", "tfile.fs.input.buffer.size": "1975812765"}	["debug_000001"]																																																																																																																																																																																
			1	org.apache.hadoop.io.file.tfile.TestTFileByteArrays#testFailureGetNonExistentMetaBlock	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock(TestTFileByteArrays.java:303), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileByteArrays/testFailureGetNonExistentMetaBlock/campaign/failures/debug_000003	{"tfile.fs.input.buffer.size": "555029505", "tfile.fs.output.buffer.size": "1955306433"}	["debug_000003"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testOverwriteEmptyDirectory	java.io.FileNotFoundException	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/PuMnwcpvke/testOverwriteEmptyDirectory (Is a directory)	java.base/java.io.FileOutputStream.open0(Native Method), java.base/java.io.FileOutputStream.open(FileOutputStream.java:298), java.base/java.io.FileOutputStream.<init>(FileOutputStream.java:237), org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:321), org.apache.hadoop.fs.RawLocalFileSystem$LocalFSFileOutputStream.<init>(RawLocalFileSystem.java:294), org.apache.hadoop.fs.RawLocalFileSystem.createOutputStreamWithMode(RawLocalFileSystem.java:439), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testOverwriteEmptyDirectory(AbstractContractCreateTest.java:143), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testOverwriteEmptyDirectory(AbstractContractCreateTest.java:160), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testOverwriteEmptyDirectory$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testOverwriteEmptyDirectory/campaign/failures/debug_000000	{"fs.contract.supports-strict-exceptions": "true"}	["debug_000000"]																																																																																																																																																																																																																	
	Bug-131	Repeated	1	org.apache.hadoop.crypto.key.TestKeyProviderFactory#testJksProviderPasswordViaConfig	java.lang.AssertionError	could not create keystore with password file	org.junit.Assert.fail(Assert.java:89), org.apache.hadoop.crypto.key.TestKeyProviderFactory.testJksProviderPasswordViaConfig(TestKeyProviderFactory.java:396), org.apache.hadoop.crypto.key.TestKeyProviderFactory.testJksProviderPasswordViaConfig$$CONFUZZ(TestKeyProviderFactory.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.TestKeyProviderFactory/testJksProviderPasswordViaConfig/campaign/failures/debug_000000	{"hadoop.security.key.default.bitlength": "12769"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem#testWriteReadAndDeleteOneAndAHalfBlocks	java.lang.IllegalArgumentException	Buffer size <= 0	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:207), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:161), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:126), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:694), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteOneAndAHalfBlocks(FSMainOperationsBaseTest.java:670), org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem.testWriteReadAndDeleteOneAndAHalfBlocks$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FilterFileSystem.open(FilterFileSystem.java:168), org.apache.hadoop.fs.viewfs.ChRootedFileSystem.open(ChRootedFileSystem.java:290), org.apache.hadoop.fs.viewfs.ViewFileSystem.open(ViewFileSystem.java:678), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.writeReadAndDelete(FSMainOperationsBaseTest.java:692), org.apache.hadoop.fs.FSMainOperationsBaseTest.testWriteReadAndDeleteOneAndAHalfBlocks(FSMainOperationsBaseTest.java:670), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFSMainOperationsLocalFileSystem/testWriteReadAndDeleteOneAndAHalfBlocks/campaign/failures/debug_000005	{"file.bytes-per-checksum": "539787007"}	["debug_000005"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testClientRetriesSucceedsSecondTime	org.junit.runners.model.TestTimedOutException	test timed out after 30000 milliseconds	java.base@11.0.19/java.lang.Thread.sleep(Native Method), app//org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.doOp(LoadBalancingKMSClientProvider.java:220), app//org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider.createKey(LoadBalancingKMSClientProvider.java:481), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesSucceedsSecondTime(TestLoadBalancingKMSClientProvider.java:590), app//org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesSucceedsSecondTime$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testClientRetriesSucceedsSecondTime/campaign/failures/debug_000000	{"hadoop.security.kms.client.failover.sleep.max.millis": "773002770", "hadoop.security.kms.client.failover.sleep.base.millis": "67421183"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureNegativeOffset	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeOffset(TestTFileByteArrays.java:459), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureNegativeOffset/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "1872969859", "file.bytes-per-checksum": "158548113"}	["debug_000002"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename#testRenameWithNonEmptySubDir	java.io.FileNotFoundException	File file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/uNGDPbJTn1/testRenameWithNonEmptySubDir/dest/src1/source.txt does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.contract.ContractTestUtils.verifyPathExists(ContractTestUtils.java:961), org.apache.hadoop.fs.contract.ContractTestUtils.assertPathExists(ContractTestUtils.java:945), org.apache.hadoop.fs.contract.AbstractFSContractTestBase.assertPathExists(AbstractFSContractTestBase.java:317), org.apache.hadoop.fs.contract.AbstractContractRenameTest.testRenameWithNonEmptySubDir(AbstractContractRenameTest.java:234), org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename.testRenameWithNonEmptySubDir$$CONFUZZ(TestRawlocalContractRename.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractRename/testRenameWithNonEmptySubDir/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "420", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "80493h", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "1768829705", "fs.creation.parallel.count": "9208", "file.bytes-per-checksum": "31741", "fs.automatic.close": "true", "hadoop.security.dns.log-slow-lookups.threshold.ms": "640", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "true", "hadoop.security.groups.cache.background.reload.threads": "1865109890", "fs.contract.rename-remove-dest-if-empty-dir": "false", "fs.local.block.size": "551659115", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "11695", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "23274", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "1902936996"}	["debug_000000"]																																																																																																																																																																																																																	
	Bug-14	Repeated	1	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryUnknownLength	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendValue(TFile.java:565), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:415), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryUnknownLength(TestTFileStreams.java:113), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryUnknownLength$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryUnknownLength/campaign/failures/debug_000000	{"tfile.io.chunk.size": "2123116822"}	["debug_000000"]																																																																																																																																																																																																																	
	Bug-163	Repeated	2	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryUnknownLength	java.lang.RuntimeException	Value length unknown.	org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry.getValueLength(TFile.java:1820), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:633), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryUnknownLength(TestTFileStreams.java:117), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryUnknownLength$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryUnknownLength/campaign/failures/debug_000004	{"tfile.io.chunk.size": "2"}	["debug_000004"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryMixedLengths1	java.lang.RuntimeException	Value length unknown.	org.apache.hadoop.io.file.tfile.TFile$Reader$Scanner$Entry.getValueLength(TFile.java:1820), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:633), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths1(TestTFileStreams.java:127), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths1$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryMixedLengths1/campaign/failures/debug_000001	{"tfile.io.chunk.size": "3"}	["debug_000001"]																																																																																																																																																																																																						
	Bug-173	BUG	2	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryMixedLengths2	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths2(TestTFileStreams.java:137), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths2$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryMixedLengths2/campaign/failures/debug_000000	{"tfile.fs.input.buffer.size": "2130640638"}	["debug_000000"]	org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays#testFailureSeek	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testFailureSeek(TestTFileUnsortedByteArrays.java:176), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testFailureSeek$$CONFUZZ(TestTFileUnsortedByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays/testFailureSeek/campaign/failures/debug_000000	{"tfile.fs.input.buffer.size": "2073722079"}	["debug_000000"]																																																																																																																																																																																																						
			2	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryMixedLengths2	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:410), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths2(TestTFileStreams.java:135), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryMixedLengths2/campaign/failures/debug_000002	{"file.stream-buffer-size": "1762323515", "tfile.fs.output.buffer.size": "960507097"}	["debug_000002"]	org.apache.hadoop.io.file.tfile.TestTFileStreams#testFailureAddKeyWithoutValue	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureAddKeyWithoutValue(TestTFileStreams.java:154), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testFailureAddKeyWithoutValue/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "1204542422", "file.stream-buffer-size": "2017040537"}	["debug_000003"]																																																																																																																																																																																																						
			1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testReadAtExactEOF	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testReadAtExactEOF(AbstractContractSeekTest.java:586), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek.testReadAtExactEOF$$CONFUZZ(TestLocalFSContractSeek.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testReadAtExactEOF/campaign/failures/debug_000001	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "122052165", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "60200s", "file.stream-buffer-size": "409", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "true", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "fs.contract.supports-seek": "true", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "901", "fs.creation.parallel.count": "644318964", "file.bytes-per-checksum": "1030547134", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "589", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "780", "fs.local.block.size": "1718770354", "fs.file.impl.disable.cache": "true", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "1517265176", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "589"}	["debug_000001"]																																																																																																																																																																																																																	
	Bug-16	Repeated	1	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureGetNonExistentMetaBlock	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock(TestTFileByteArrays.java:303), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureGetNonExistentMetaBlock$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureGetNonExistentMetaBlock/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "1713972512", "tfile.fs.input.buffer.size": "1805675763"}	["debug_000000"]																																																																																																																																																																																																																	
	Bug-171	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureGetNonExistentMetaBlock	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock(TestTFileByteArrays.java:303), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.testFailureGetNonExistentMetaBlock$$CONFUZZ(TestTFileJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureGetNonExistentMetaBlock/campaign/failures/debug_000001	{"file.bytes-per-checksum": "1471406676"}	["debug_000001"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureCompressionNotWorking2	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.OutOfMemoryError(Java heap space)  java.lang.OutOfMemoryError(Java heap space)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:410), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureCompressionNotWorking2(TestTFileStreams.java:397), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureCompressionNotWorking2/campaign/failures/debug_000002	{"tfile.fs.output.buffer.size": "1974620812", "file.bytes-per-checksum": "56201838"}	["debug_000002"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestHarFileSystemBasics#testMakeQualifiedPath	java.lang.OutOfMemoryError	Java heap space		PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testMakeQualifiedPath/campaign/failures/debug_000002	{"hadoop.kerberos.keytab.login.autorenewal.enabled": "false"}	["debug_000002"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetup	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetup(TestSSLHttpServerConfigs.java:142), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetup$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetup/campaign/failures/debug_000004	{"hadoop.prometheus.endpoint.enabled": "true", "hadoop.http.sni.host.check.enabled": "true"}	["debug_000004"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.security.alias.TestCredentialProviderFactory#testUserProvider	java.io.IOException	Credential pass already exists in user:///	org.apache.hadoop.security.alias.UserProvider.createCredentialEntry(UserProvider.java:69), org.apache.hadoop.security.alias.TestCredentialProviderFactory.checkSpecificProvider(TestCredentialProviderFactory.java:136), org.apache.hadoop.security.alias.TestCredentialProviderFactory.testUserProvider(TestCredentialProviderFactory.java:196), org.apache.hadoop.security.alias.TestCredentialProviderFactory.testUserProvider$$CONFUZZ(TestCredentialProviderFactory.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.alias.TestCredentialProviderFactory/testUserProvider/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.sftp.TestSFTPFileSystem#testDeleteNonEmptyDir	java.io.IOException	Directory: file:/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/test/data/testsftp is not empty.	org.apache.hadoop.fs.sftp.SFTPFileSystem.delete(SFTPFileSystem.java:400), org.apache.hadoop.fs.sftp.SFTPFileSystem.delete(SFTPFileSystem.java:618), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testDeleteNonEmptyDir(TestSFTPFileSystem.java:273), org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testDeleteNonEmptyDir$$CONFUZZ(TestSFTPFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.sftp.TestSFTPFileSystem/testDeleteNonEmptyDir/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			3	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testCreateFlagAppendCreateOverwrite	org.apache.hadoop.HadoopIllegalArgumentException	[CREATE, OVERWRITE, APPEND]Both append and overwrite options cannot be enabled.	org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:159), org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:174), org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1294), org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102), org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:353), org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400), org.apache.hadoop.fs.viewfs.ChRootedFs.createInternal(ChRootedFs.java:179), org.apache.hadoop.fs.viewfs.ViewFs.createInternal(ViewFs.java:358), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testCreateFlagAppendCreateOverwrite(FileContextMainOperationsBaseTest.java:853), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.testCreateFlagAppendCreateOverwrite$$CONFUZZ(TestFcMainOperationsLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testCreateFlagAppendCreateOverwrite/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs#testCreateFlagAppendOverwrite	org.apache.hadoop.HadoopIllegalArgumentException	[OVERWRITE, APPEND]Both append and overwrite options cannot be enabled.	org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:159), org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:174), org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1294), org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102), org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:353), org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400), org.apache.hadoop.fs.viewfs.ChRootedFs.createInternal(ChRootedFs.java:179), org.apache.hadoop.fs.viewfs.ViewFs.createInternal(ViewFs.java:358), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testCreateFlagAppendOverwrite(FileContextMainOperationsBaseTest.java:846), org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.testCreateFlagAppendOverwrite$$CONFUZZ(TestFcMainOperationsLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs/testCreateFlagAppendOverwrite/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.TestLocalFSFileContextMainOperations#testCreateFlagAppendCreateOverwrite	org.apache.hadoop.HadoopIllegalArgumentException	[CREATE, OVERWRITE, APPEND]Both append and overwrite options cannot be enabled.	org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:159), org.apache.hadoop.fs.CreateFlag.validate(CreateFlag.java:174), org.apache.hadoop.fs.FileSystem.primitiveCreate(FileSystem.java:1294), org.apache.hadoop.fs.DelegateToFileSystem.createInternal(DelegateToFileSystem.java:102), org.apache.hadoop.fs.ChecksumFs$ChecksumFSOutputSummer.<init>(ChecksumFs.java:353), org.apache.hadoop.fs.ChecksumFs.createInternal(ChecksumFs.java:400), org.apache.hadoop.fs.AbstractFileSystem.create(AbstractFileSystem.java:626), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:701), org.apache.hadoop.fs.FileContext$3.next(FileContext.java:697), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.create(FileContext.java:703), org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testCreateFlagAppendCreateOverwrite(FileContextMainOperationsBaseTest.java:853), org.apache.hadoop.fs.TestLocalFSFileContextMainOperations.testCreateFlagAppendCreateOverwrite$$CONFUZZ(TestLocalFSFileContextMainOperations.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSFileContextMainOperations/testCreateFlagAppendCreateOverwrite/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																											
			1	org.apache.hadoop.security.TestGroupsCaching#testExceptionOnBackgroundRefreshHandled	org.junit.ComparisonFailure	expected:<[2]> but was:<[3]>	org.apache.hadoop.security.TestGroupsCaching.testExceptionOnBackgroundRefreshHandled(TestGroupsCaching.java:660), org.apache.hadoop.security.TestGroupsCaching.testExceptionOnBackgroundRefreshHandled$$CONFUZZ(TestGroupsCaching.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupsCaching/testExceptionOnBackgroundRefreshHandled/campaign/failures/debug_000000	{"hadoop.security.groups.cache.background.reload.threads": "499653648"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.security.TestGroupsCaching#testExceptionOnBackgroundRefreshHandled	org.junit.ComparisonFailure	expected:<[3]> but was:<[2]>	org.apache.hadoop.security.TestGroupsCaching.testExceptionOnBackgroundRefreshHandled(TestGroupsCaching.java:667), org.apache.hadoop.security.TestGroupsCaching.testExceptionOnBackgroundRefreshHandled$$CONFUZZ(TestGroupsCaching.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupsCaching/testExceptionOnBackgroundRefreshHandled/campaign/failures/debug_000002	{"hadoop.security.groups.negative-cache.secs": "1811589642"}	["debug_000002"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testStatNonLinks	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystemTestWrapper.create(FileSystemTestWrapper.java:292), org.apache.hadoop.fs.FileSystemTestWrapper.createFile(FileSystemTestWrapper.java:70), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:65), org.apache.hadoop.fs.SymlinkBaseTest.createAndWriteFile(SymlinkBaseTest.java:60), org.apache.hadoop.fs.SymlinkBaseTest.testStatNonLinks(SymlinkBaseTest.java:319), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testStatNonLinks/campaign/failures/debug_000001	{"hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "fs.defaultFS": "file:///", "file.stream-buffer-size": "2066760987", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.threshold.ms": "778980450", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "538", "hadoop.security.groups.cache.warn.after.ms": "1717421571", "fs.creation.parallel.count": "28492", "fs.client.resolve.remote.symlinks": "false", "hadoop.security.groups.negative-cache.secs": "832898890", "hadoop.security.groups.cache.secs": "474"}	["debug_000001"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.crypto.TestCryptoOutputStreamClosing#testOutputStreamNotClosing	java.lang.IllegalArgumentException	Minimum value of buffer size is 512.	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:144), org.apache.hadoop.crypto.CryptoStreamUtils.checkBufferSize(CryptoStreamUtils.java:70), org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:104), org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:134), org.apache.hadoop.crypto.TestCryptoOutputStreamClosing.testOutputStreamNotClosing(TestCryptoOutputStreamClosing.java:51), org.apache.hadoop.crypto.TestCryptoOutputStreamClosing.testOutputStreamNotClosing$$CONFUZZ(TestCryptoOutputStreamClosing.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.TestCryptoOutputStreamClosing/testOutputStreamNotClosing/campaign/failures/debug_000000	{"hadoop.security.crypto.buffer.size": "3"}	["debug_000000"]																																																																																																																																																																																																																	
	Bug-21	Repeated	2	org.apache.hadoop.crypto.TestCryptoOutputStreamClosing#testOutputStreamNotClosing	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:109), org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:134), org.apache.hadoop.crypto.TestCryptoOutputStreamClosing.testOutputStreamNotClosing(TestCryptoOutputStreamClosing.java:51), org.apache.hadoop.crypto.TestCryptoOutputStreamClosing.testOutputStreamNotClosing$$CONFUZZ(TestCryptoOutputStreamClosing.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.TestCryptoOutputStreamClosing/testOutputStreamNotClosing/campaign/failures/debug_000002	{"hadoop.security.crypto.buffer.size": "2130640638"}	["debug_000002"]	org.apache.hadoop.crypto.TestCryptoOutputStreamClosing#testOutputStreamNotClosing	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:110), org.apache.hadoop.crypto.CryptoOutputStream.<init>(CryptoOutputStream.java:134), org.apache.hadoop.crypto.TestCryptoOutputStreamClosing.testOutputStreamNotClosing(TestCryptoOutputStreamClosing.java:51), org.apache.hadoop.crypto.TestCryptoOutputStreamClosing.testOutputStreamNotClosing$$CONFUZZ(TestCryptoOutputStreamClosing.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.TestCryptoOutputStreamClosing/testOutputStreamNotClosing/campaign/failures/debug_000001	{"hadoop.security.crypto.buffer.size": "1625172721"}	["debug_000001"]																																																																																																																																																																																																						
			1	org.apache.hadoop.io.file.tfile.TestTFileStreams#testFailureAddKeyWithoutValue	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureAddKeyWithoutValue(TestTFileStreams.java:154), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureAddKeyWithoutValue$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testFailureAddKeyWithoutValue/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "1905862947", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "59h", "file.stream-buffer-size": "8359", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "1679743398", "fs.creation.parallel.count": "1315546816", "file.bytes-per-checksum": "12", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "1255858803", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "true", "hadoop.security.groups.cache.background.reload.threads": "1651", "fs.local.block.size": "429", "fs.file.impl.disable.cache": "false", "hadoop.security.token.service.use_ip": "true", "hadoop.kerberos.min.seconds.before.relogin": "24298", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "tfile.fs.output.buffer.size": "1960756279", "hadoop.security.groups.cache.warn.after.ms": "1399080253"}	["debug_000000"]																																																																																																																																																																																																																	
			3	org.apache.hadoop.fs.shell.TestCopy#testInterruptedCopyBytes	org.mockito.exceptions.verification.WantedButNotInvoked	Wanted but not invoked:fileSystem.delete(    mockfs:/file._COPYING_,    <any boolean>);-> at org.apache.hadoop.fs.shell.TestCopy.testInterruptedCopyBytes(TestCopy.java:165)Actually, there were zero interactions with this mock.	org.apache.hadoop.fs.shell.TestCopy.testInterruptedCopyBytes(TestCopy.java:165), org.apache.hadoop.fs.shell.TestCopy.testInterruptedCopyBytes$$CONFUZZ(TestCopy.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestCopy/testInterruptedCopyBytes/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.shell.TestCopy#testInterruptedRename	org.mockito.exceptions.verification.WantedButNotInvoked	Wanted but not invoked:fileSystem.delete(    mockfs:/file._COPYING_,    <any boolean>);-> at org.apache.hadoop.fs.shell.TestCopy.testInterruptedRename(TestCopy.java:182)Actually, there were zero interactions with this mock.	org.apache.hadoop.fs.shell.TestCopy.testInterruptedRename(TestCopy.java:182), org.apache.hadoop.fs.shell.TestCopy.testInterruptedRename$$CONFUZZ(TestCopy.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestCopy/testInterruptedRename/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.fs.shell.TestCopy#testCopyStreamTargetExists	org.mockito.exceptions.verification.WantedButNotInvoked	Wanted but not invoked:fileSystem.delete(    mockfs:/file,    <any boolean>);-> at org.apache.hadoop.fs.shell.TestCopy.testCopyStreamTargetExists(TestCopy.java:110)Actually, there were zero interactions with this mock.	org.apache.hadoop.fs.shell.TestCopy.testCopyStreamTargetExists(TestCopy.java:110), org.apache.hadoop.fs.shell.TestCopy.testCopyStreamTargetExists$$CONFUZZ(TestCopy.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestCopy/testCopyStreamTargetExists/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																											
		FP	1	org.apache.hadoop.http.TestHttpServer#testDisabledAuthorizationOfDefaultServlets	java.net.SocketException	Unexpected end of file from server	java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:899), java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:722), java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:896), java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:722), java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1615), java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1520), java.base/java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:527), org.apache.hadoop.http.TestHttpServer.getHttpStatusCode(TestHttpServer.java:396), org.apache.hadoop.http.TestHttpServer.testDisabledAuthorizationOfDefaultServlets(TestHttpServer.java:444), org.apache.hadoop.http.TestHttpServer.testDisabledAuthorizationOfDefaultServlets$$CONFUZZ(TestHttpServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testDisabledAuthorizationOfDefaultServlets/campaign/failures/debug_000008	{"hadoop.http.idle_timeout.ms": "1"}	["debug_000008"]																																																																																																																																																																																																																	
		FP	3	org.apache.hadoop.http.TestHttpServer#testDisabledAuthorizationOfDefaultServlets	java.lang.AssertionError	expected:<200> but was:<404>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.http.TestHttpServer.testDisabledAuthorizationOfDefaultServlets(TestHttpServer.java:444), org.apache.hadoop.http.TestHttpServer.testDisabledAuthorizationOfDefaultServlets$$CONFUZZ(TestHttpServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testDisabledAuthorizationOfDefaultServlets/campaign/failures/debug_000002	{"hadoop.http.logs.enabled": "false"}	["debug_000002"]	org.apache.hadoop.http.TestHttpServerWithSpnego#testAuthenticationWithProxyUser	java.lang.AssertionError	expected:<200> but was:<404>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser(TestHttpServerWithSpnego.java:176), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser$$CONFUZZ(TestHttpServerWithSpnego.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerWithSpnego/testAuthenticationWithProxyUser/campaign/failures/debug_000004	{"hadoop.http.logs.enabled": "false"}	["debug_000004"]	org.apache.hadoop.http.TestHttpServer#testAuthorizationOfDefaultServlets	java.lang.AssertionError	expected:<200> but was:<404>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.http.TestHttpServer.testAuthorizationOfDefaultServlets(TestHttpServer.java:488), org.apache.hadoop.http.TestHttpServer.testAuthorizationOfDefaultServlets$$CONFUZZ(TestHttpServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testAuthorizationOfDefaultServlets/campaign/failures/debug_000005	{"hadoop.http.logs.enabled": "false"}	["debug_000005"]																																																																																																																																																																																											
			1	org.apache.hadoop.io.file.tfile.TestTFileSeek#testSeeks	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileSeek.seekTFile(TestTFileSeek.java:151), org.apache.hadoop.io.file.tfile.TestTFileSeek.testSeeks(TestTFileSeek.java:205), org.apache.hadoop.io.file.tfile.TestTFileSeek.testSeeks$$CONFUZZ(TestTFileSeek.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	TIMEOUT	java.util.concurrent.TimeoutException	TIMEOUT	edu.illinois.confuzz.DebugUtil.runWithNewJVM(DebugUtil.java:148), edu.illinois.confuzz.DebugUtil.getReproduceResult(DebugUtil.java:73), edu.illinois.confuzz.DebugUtil.getReproduceStatus(DebugUtil.java:60), edu.illinois.confuzz.ConfigurationDebugNewJvmMojo.deltaDebug(ConfigurationDebugNewJvmMojo.java:240), edu.illinois.confuzz.ConfigurationDebugNewJvmMojo.execute(ConfigurationDebugNewJvmMojo.java:66), org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:137), org.apache.maven.lifecycle.internal.MojoExecutor.doExecute2(MojoExecutor.java:370), org.apache.maven.lifecycle.internal.MojoExecutor.doExecute(MojoExecutor.java:351), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:215), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:171), org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:163), org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:117), org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:81), org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:56), org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128), org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:294), org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:192), org.apache.maven.DefaultMaven.execute(DefaultMaven.java:105), org.apache.maven.cli.MavenCli.execute(MavenCli.java:960), org.apache.maven.cli.MavenCli.doMain(MavenCli.java:293), org.apache.maven.cli.MavenCli.main(MavenCli.java:196), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:282), org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:225), org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:406), org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:347),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileSeek/testSeeks/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "127", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "5268h", "file.stream-buffer-size": "6724", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "true", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "638510088", "fs.creation.parallel.count": "11374", "file.bytes-per-checksum": "1035507990", "fs.automatic.close": "true", "hadoop.security.dns.log-slow-lookups.threshold.ms": "722858472", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "true", "hadoop.security.groups.cache.background.reload.threads": "296777365", "zlib.compress.level": "DEFAULT_COMPRESSION", "fs.local.block.size": "673", "test.reload.lzo.codec": "false", "fs.file.impl.disable.cache": "true", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "10446", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "2129833018"}	["debug_000000"]																																																																																																																																																																																																																	
			2	org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegation#testAclMethods	org.mockito.exceptions.verification.TooManyActualInvocations	fileSystem.modifyAclEntries(/d/e/f, []);Wanted 1 time:-> at org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegation.testAclMethods(TestViewFileSystemDelegation.java:113)But was 2 times:-> at org.apache.hadoop.fs.FilterFileSystem.modifyAclEntries(FilterFileSystem.java:594)-> at org.apache.hadoop.fs.FilterFileSystem.modifyAclEntries(FilterFileSystem.java:594)	org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegation.testAclMethods(TestViewFileSystemDelegation.java:113), org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegation.testAclMethods$$CONFUZZ(TestViewFileSystemDelegation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegation/testAclMethods/campaign/failures/debug_000002	{"fs.mockfs2.impl.disable.cache": "false", "fs.viewfs.enable.inner.cache": "false", "fs.mockfs1.impl.disable.cache": "true"}	["debug_000002"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegation#testAclMethods	org.mockito.exceptions.verification.TooManyActualInvocations	fileSystem.modifyAclEntries(/a/b/c, []);Wanted 1 time:-> at org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegation.testAclMethods(TestViewFileSystemDelegation.java:111)But was 2 times:-> at org.apache.hadoop.fs.FilterFileSystem.modifyAclEntries(FilterFileSystem.java:594)-> at org.apache.hadoop.fs.FilterFileSystem.modifyAclEntries(FilterFileSystem.java:594)	org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegation.testAclMethods(TestViewFileSystemDelegation.java:111), org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegation.testAclMethods$$CONFUZZ(TestViewFileSystemDelegation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemDelegation/testAclMethods/campaign/failures/debug_000001	{"fs.mockfs2.impl.disable.cache": "false", "fs.viewfs.enable.inner.cache": "false", "fs.mockfs1.impl.disable.cache": "false"}	["debug_000001"]																																																																																																																																																																																																						
		FP	2	org.apache.hadoop.security.authorize.TestServiceAuthorization#testDefaultMachineList	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.fail(Assert.java:96), org.apache.hadoop.security.authorize.TestServiceAuthorization.testDefaultMachineList(TestServiceAuthorization.java:286), org.apache.hadoop.security.authorize.TestServiceAuthorization.testDefaultMachineList$$CONFUZZ(TestServiceAuthorization.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.authorize.TestServiceAuthorization/testDefaultMachineList/campaign/failures/debug_000000	{"test.protocol.hosts": "10.222.0.0/16,10.113.221.221"}	["debug_000000"]	org.apache.hadoop.security.authorize.TestServiceAuthorization#testDefaultMachineList	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.fail(Assert.java:96), org.apache.hadoop.security.authorize.TestServiceAuthorization.testDefaultMachineList(TestServiceAuthorization.java:296), org.apache.hadoop.security.authorize.TestServiceAuthorization.testDefaultMachineList$$CONFUZZ(TestServiceAuthorization.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.authorize.TestServiceAuthorization/testDefaultMachineList/campaign/failures/debug_000001	{"test.protocol.hosts": "*"}	["debug_000001"]																																																																																																																																																																																																						
			1	org.apache.hadoop.fs.TestHarFileSystemBasics#testPositiveInitWithoutUnderlyingFS	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.util.LineReader.<init>(LineReader.java:82), org.apache.hadoop.util.LineReader.<init>(LineReader.java:95), org.apache.hadoop.fs.HarFileSystem$HarMetaData.parseMetaData(HarFileSystem.java:1176), org.apache.hadoop.fs.HarFileSystem$HarMetaData.access$000(HarFileSystem.java:1115), org.apache.hadoop.fs.HarFileSystem.initialize(HarFileSystem.java:172), org.apache.hadoop.fs.TestHarFileSystemBasics.createHarFileSystem(TestHarFileSystemBasics.java:93), org.apache.hadoop.fs.TestHarFileSystemBasics.before(TestHarFileSystemBasics.java:137), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testPositiveInitWithoutUnderlyingFS/campaign/failures/debug_000002	{"fs.file.impl.disable.cache": "false"}	["debug_000002", "debug_000001"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestHarFileSystemBasics#testPositiveInitWithoutUnderlyingFS	java.lang.OutOfMemoryError	Java heap space		PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestHarFileSystemBasics/testPositiveInitWithoutUnderlyingFS/campaign/failures/debug_000003	{"hadoop.security.groups.cache.background.reload.threads": "1028"}	["debug_000003"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.security.TestLdapGroupsMapping#testLdapConnectionTimeout	java.net.SocketTimeoutException	Read timed out	java.base/java.net.SocketInputStream.socketRead0(Native Method), java.base/java.net.SocketInputStream.socketRead(SocketInputStream.java:115), java.base/java.net.SocketInputStream.read(SocketInputStream.java:168), java.base/java.net.SocketInputStream.read(SocketInputStream.java:140), java.base/sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:484), java.base/sun.security.ssl.SSLSocketInputRecord.readHeader(SSLSocketInputRecord.java:478), java.base/sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:160), java.base/sun.security.ssl.SSLTransport.decode(SSLTransport.java:111), java.base/sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1507), java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(SSLSocketImpl.java:1417), java.base/sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:456), java.base/sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:427), java.naming/com.sun.jndi.ldap.Connection.createSocket(Connection.java:364), java.naming/com.sun.jndi.ldap.Connection.<init>(Connection.java:231), java.naming/com.sun.jndi.ldap.LdapClient.<init>(LdapClient.java:137), java.naming/com.sun.jndi.ldap.LdapClient.getInstance(LdapClient.java:1616), java.naming/com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2847), java.naming/com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:348), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:266), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:226), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:284), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:185), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:115), java.naming/javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:730), java.naming/javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:305), java.naming/javax.naming.InitialContext.init(InitialContext.java:236), java.naming/javax.naming.ldap.InitialLdapContext.<init>(InitialLdapContext.java:154), org.apache.hadoop.security.TestLdapGroupsMappingBase$DummyLdapCtxFactory.getInitialContext(TestLdapGroupsMappingBase.java:241), java.naming/javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:730), java.naming/javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:305), java.naming/javax.naming.InitialContext.init(InitialContext.java:236), java.naming/javax.naming.InitialContext.<init>(InitialContext.java:208), java.naming/javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101), org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:701), org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:512), org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout(TestLdapGroupsMapping.java:388), org.apache.hadoop.security.TestLdapGroupsMapping.testLdapConnectionTimeout$$CONFUZZ(TestLdapGroupsMapping.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	TIMEOUT					{"hadoop.security.group.mapping.ldap.read.timeout.ms": "287", "hadoop.security.group.mapping.ldap.userbase": "", "hadoop.security.group.mapping.ldap.base": "", "hadoop.security.group.mapping.ldap.num.attempts.before.failover": "6014", "hadoop.security.group.mapping.ldap.bind.password": "LH9bhpnA5qD85uy6BUriXGqkkGNr0uSybjFZMExCH9EtvNGvZBRUHeZ3mSyYA3pPDJhc5DQoyPBsxNsiAqptTFSTS3JjhCh2", "hadoop.security.group.mapping.ldap.directory.search.timeout": "79", "hadoop.security.group.mapping.ldap.ssl": "true", "hadoop.security.credential.clear-text-fallback": "true", "hadoop.security.group.mapping.ldap.search.group.hierarchy.levels": "570457987", "hadoop.security.group.mapping.ldap.num.attempts": "1856"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem#testInputStreamClosedTwice	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.fs.FSMainOperationsBaseTest.testInputStreamClosedTwice(FSMainOperationsBaseTest.java:1093), org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem.testInputStreamClosedTwice$$CONFUZZ(TestFSMainOperationsLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFSMainOperationsLocalFileSystem/testInputStreamClosedTwice/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "962", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "804500373s", "file.stream-buffer-size": "712", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "true", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "1270901394", "fs.creation.parallel.count": "56", "file.bytes-per-checksum": "481745396", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "375", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "354148474", "fs.local.block.size": "951", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "843330506", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "1174255336", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "1792918587"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.IllegalArgumentException	newLimit > capacity: (76 > 73)	java.base/java.nio.Buffer.createLimitException(Buffer.java:372), java.base/java.nio.Buffer.limit(Buffer.java:346), java.base/java.nio.ByteBuffer.limit(ByteBuffer.java:1107), java.base/java.nio.MappedByteBuffer.limit(MappedByteBuffer.java:235), java.base/java.nio.MappedByteBuffer.limit(MappedByteBuffer.java:67), org.xerial.snappy.Snappy.compress(Snappy.java:156), org.apache.hadoop.io.compress.snappy.SnappyCompressor.compressDirectBuf(SnappyCompressor.java:282), org.apache.hadoop.io.compress.snappy.SnappyCompressor.compress(SnappyCompressor.java:210), org.apache.hadoop.io.compress.BlockCompressorStream.compress(BlockCompressorStream.java:149), org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:131), java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81), java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142), java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.writeBuffer(SequenceFile.java:1588), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.sync(SequenceFile.java:1606), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.close(SequenceFile.java:1629), org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:640), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000012	{"hadoop.security.auth_to_local.mechanism": "MIT"}	["debug_000012"]																																																																																																																																																																																																																	
			5	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.snappy.SnappyDecompressor.<init>(SnappyDecompressor.java:57), org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:172), org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:183), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2075), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:621), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.snappy.SnappyDecompressor.<init>(SnappyDecompressor.java:57), org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:172), org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:183), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2071), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:621), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000015	{"io.compression.codec.snappy.buffersize": "268992515"}	["debug_000015"]	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.snappy.SnappyDecompressor.<init>(SnappyDecompressor.java:57), org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:172), org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:183), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2071), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:621), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.snappy.SnappyDecompressor.<init>(SnappyDecompressor.java:57), org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:172), org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:183), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2066), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:621), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000016	{"io.compression.codec.snappy.buffersize": "387968755"}	["debug_000016"]	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.snappy.SnappyDecompressor.<init>(SnappyDecompressor.java:56), org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:172), org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:183), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2075), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:621), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.snappy.SnappyDecompressor.<init>(SnappyDecompressor.java:56), org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:172), org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:183), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2071), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:621), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000013	{"io.compression.codec.snappy.buffersize": "327499355"}	["debug_000013"]	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.snappy.SnappyDecompressor.<init>(SnappyDecompressor.java:56), org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:172), org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:183), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2071), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:621), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.snappy.SnappyDecompressor.<init>(SnappyDecompressor.java:56), org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:172), org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:183), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2066), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:621), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000007	{"io.compression.codec.snappy.buffersize": "466786701"}	["debug_000007"]	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.snappy.SnappyDecompressor.<init>(SnappyDecompressor.java:56), org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:172), org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:183), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2066), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:621), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.snappy.SnappyDecompressor.<init>(SnappyDecompressor.java:56), org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:172), org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:183), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2054), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:621), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000011	{"io.compression.codec.snappy.buffersize": "997658558"}	["debug_000011"]																																																																																																																																																																					
			1	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.IllegalArgumentException	newLimit > capacity: (130 > 127)	java.base/java.nio.Buffer.createLimitException(Buffer.java:372), java.base/java.nio.Buffer.limit(Buffer.java:346), java.base/java.nio.ByteBuffer.limit(ByteBuffer.java:1107), java.base/java.nio.MappedByteBuffer.limit(MappedByteBuffer.java:235), java.base/java.nio.MappedByteBuffer.limit(MappedByteBuffer.java:67), org.xerial.snappy.Snappy.compress(Snappy.java:156), org.apache.hadoop.io.compress.snappy.SnappyCompressor.compressDirectBuf(SnappyCompressor.java:282), org.apache.hadoop.io.compress.snappy.SnappyCompressor.compress(SnappyCompressor.java:210), org.apache.hadoop.io.compress.BlockCompressorStream.compress(BlockCompressorStream.java:149), org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:131), java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81), java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142), java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.writeBuffer(SequenceFile.java:1588), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.sync(SequenceFile.java:1606), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.append(SequenceFile.java:1663), org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1425), org.apache.hadoop.io.MapFile$Writer.append(MapFile.java:327), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:638), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000017	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "329", "fs.client.resolve.remote.symlinks": "true", "hadoop.service.shutdown.timeout": "81191m", "file.stream-buffer-size": "775", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "453", "fs.creation.parallel.count": "29336", "file.bytes-per-checksum": "29749", "fs.automatic.close": "true", "io.map.index.interval": "10163", "io.seqfile.compress.blocksize": "566", "hadoop.security.dns.log-slow-lookups.threshold.ms": "89", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "true", "hadoop.security.groups.cache.background.reload.threads": "189", "io.map.index.skip": "1442181082", "fs.local.block.size": "17243", "io.compression.codec.snappy.buffersize": "578", "fs.file.impl.disable.cache": "false", "io.file.buffer.size": "10068", "hadoop.security.token.service.use_ip": "true", "hadoop.kerberos.min.seconds.before.relogin": "201", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "456", "io.serializations": "org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization"}	["debug_000017"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.IllegalArgumentException	Illegal bufferSize	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42), org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56), org.apache.hadoop.io.compress.SnappyCodec.createOutputStream(SnappyCodec.java:92), org.apache.hadoop.io.SequenceFile$Writer.init(SequenceFile.java:1307), org.apache.hadoop.io.SequenceFile$Writer.<init>(SequenceFile.java:1194), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.<init>(SequenceFile.java:1569), org.apache.hadoop.io.SequenceFile.createWriter(SequenceFile.java:290), org.apache.hadoop.io.MapFile$Writer.<init>(MapFile.java:278), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:634), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000008	{"io.compression.codec.snappy.buffersize": "0"}	["debug_000008"]																																																																																																																																																																																																																	
	Bug-20	Repeated	1	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.snappy.SnappyDecompressor.<init>(SnappyDecompressor.java:56), org.apache.hadoop.io.compress.SnappyCodec.createDecompressor(SnappyCodec.java:172), org.apache.hadoop.io.compress.CodecPool.getDecompressor(CodecPool.java:183), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2054), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.createDataFileReader(MapFile.java:460), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:433), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:621), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000014	{"io.compression.codec.snappy.buffersize": "724338661"}	["debug_000014"]																																																																																																																																																																																																																	
	Bug-52	Repeated	1	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86), org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112), java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81), java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142), java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.writeBuffer(SequenceFile.java:1588), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.sync(SequenceFile.java:1605), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.close(SequenceFile.java:1629), org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:640), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000009	{"io.compression.codec.snappy.buffersize": "7"}	["debug_000009"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.IllegalArgumentException	newLimit > capacity: (130 > 127)	java.base/java.nio.Buffer.createLimitException(Buffer.java:372), java.base/java.nio.Buffer.limit(Buffer.java:346), java.base/java.nio.ByteBuffer.limit(ByteBuffer.java:1107), java.base/java.nio.MappedByteBuffer.limit(MappedByteBuffer.java:235), java.base/java.nio.MappedByteBuffer.limit(MappedByteBuffer.java:67), org.xerial.snappy.Snappy.compress(Snappy.java:156), org.apache.hadoop.io.compress.snappy.SnappyCompressor.compressDirectBuf(SnappyCompressor.java:282), org.apache.hadoop.io.compress.snappy.SnappyCompressor.compress(SnappyCompressor.java:210), org.apache.hadoop.io.compress.BlockCompressorStream.compress(BlockCompressorStream.java:149), org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:115), java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81), java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142), java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.writeBuffer(SequenceFile.java:1588), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.sync(SequenceFile.java:1606), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.close(SequenceFile.java:1629), org.apache.hadoop.io.MapFile$Writer.close(MapFile.java:306), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:640), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000018	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "9308", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "4407494h", "file.stream-buffer-size": "19444", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "1011505922", "fs.creation.parallel.count": "839", "file.bytes-per-checksum": "2263", "fs.automatic.close": "false", "io.map.index.interval": "884", "io.seqfile.compress.blocksize": "1007477473", "hadoop.security.dns.log-slow-lookups.threshold.ms": "383", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "10682", "zlib.compress.level": "DEFAULT_COMPRESSION", "io.map.index.skip": "28414", "fs.local.block.size": "11622", "io.compression.codec.snappy.buffersize": "256", "fs.file.impl.disable.cache": "false", "io.file.buffer.size": "299", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "8636", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "53318723", "io.serializations": "org.apache.hadoop.io.serializer.WritableSerialization, org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization, org.apache.hadoop.io.serializer.avro.AvroReflectSerialization"}	["debug_000018"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.viewfs.TestViewFsLocalFs#testInternalRename2	org.apache.hadoop.security.AccessControlException	Cannot Rename within internal dirs of mount table: src=/internalDir/linkToDir2 is readOnly	org.apache.hadoop.fs.viewfs.ViewFs.renameInternal(ViewFs.java:578), org.apache.hadoop.fs.AbstractFileSystem.rename(AbstractFileSystem.java:720), org.apache.hadoop.fs.FileContext.rename(FileContext.java:1036), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testInternalRename2(ViewFsBaseTest.java:777), org.apache.hadoop.fs.viewfs.TestViewFsLocalFs.testInternalRename2$$CONFUZZ(TestViewFsLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsLocalFs/testInternalRename2/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.security.TestSecurityUtil#testAuthPlainPasswordProperty	java.lang.AssertionError	expected:<1> but was:<0>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.security.TestSecurityUtil.testAuthPlainPasswordProperty(TestSecurityUtil.java:436), org.apache.hadoop.security.TestSecurityUtil.testAuthPlainPasswordProperty$$CONFUZZ(TestSecurityUtil.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestSecurityUtil/testAuthPlainPasswordProperty/campaign/failures/debug_000000	{"hadoop.security.credential.clear-text-fallback": "false"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryMixedLengths1	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendValue(TFile.java:565), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:415), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:432), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths1(TestTFileStreams.java:125), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryMixedLengths1/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1444243788", "tfile.io.chunk.size": "1223353056"}	["debug_000003"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureNegativeOffset	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileStreams.setUp(TestTFileStreams.java:76), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.setUp(TestTFileNoneCodecsStreams.java:30), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureNegativeOffset/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "475", "fs.client.resolve.remote.symlinks": "true", "hadoop.service.shutdown.timeout": "051459970s", "file.stream-buffer-size": "1601929777", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "tfile.fs.input.buffer.size": "368", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "395", "fs.creation.parallel.count": "768", "file.bytes-per-checksum": "22316", "fs.automatic.close": "true", "hadoop.security.dns.log-slow-lookups.threshold.ms": "994", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "938495255", "fs.local.block.size": "621", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "281707939", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "719", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "tfile.fs.output.buffer.size": "994", "hadoop.security.groups.cache.warn.after.ms": "31965"}	["debug_000000"]																																																																																																																																																																																																																	
	Bug-52	Repeated	1	org.apache.hadoop.io.compress.TestCodec#testLz4Codec	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.io.compress.lz4.Lz4Compressor.setInput(Lz4Compressor.java:114), org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112), java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:123), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.compress.TestCodec.codecTest(TestCodec.java:204), org.apache.hadoop.io.compress.TestCodec.testLz4Codec(TestCodec.java:146), org.apache.hadoop.io.compress.TestCodec.testLz4Codec$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testLz4Codec/campaign/failures/debug_000006	{"io.compression.codec.lz4.buffersize": "1"}	["debug_000006"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.io.compress.TestCodec#testLz4Codec	java.lang.IllegalArgumentException	Illegal bufferSize	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:42), org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56), org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:92), org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134), org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70), org.apache.hadoop.io.compress.TestCodec.codecTest(TestCodec.java:201), org.apache.hadoop.io.compress.TestCodec.testLz4Codec(TestCodec.java:145), org.apache.hadoop.io.compress.TestCodec.testLz4Codec$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testLz4Codec/campaign/failures/debug_000005	{"io.compression.codec.lz4.buffersize": "0"}	["debug_000005"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.compress.TestCodec#testLz4Codec	net.jpountz.lz4.LZ4Exception	maxDestLen is too small	net.jpountz.lz4.LZ4JNICompressor.compress(LZ4JNICompressor.java:69), net.jpountz.lz4.LZ4Compressor.compress(LZ4Compressor.java:158), org.apache.hadoop.io.compress.lz4.Lz4Compressor.compressDirectBuf(Lz4Compressor.java:311), org.apache.hadoop.io.compress.lz4.Lz4Compressor.compress(Lz4Compressor.java:238), org.apache.hadoop.io.compress.BlockCompressorStream.compress(BlockCompressorStream.java:149), org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:115), java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:123), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.compress.TestCodec.codecTest(TestCodec.java:204), org.apache.hadoop.io.compress.TestCodec.testLz4Codec(TestCodec.java:146), org.apache.hadoop.io.compress.TestCodec.testLz4Codec$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testLz4Codec/campaign/failures/debug_000000	{"io.compression.codec.lz4.buffersize": "561161"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.compress.TestCodec#testLz4Codec	net.jpountz.lz4.LZ4Exception	maxDestLen is too small	net.jpountz.lz4.LZ4JNICompressor.compress(LZ4JNICompressor.java:69), net.jpountz.lz4.LZ4Compressor.compress(LZ4Compressor.java:158), org.apache.hadoop.io.compress.lz4.Lz4Compressor.compressDirectBuf(Lz4Compressor.java:311), org.apache.hadoop.io.compress.lz4.Lz4Compressor.compress(Lz4Compressor.java:238), org.apache.hadoop.io.compress.BlockCompressorStream.compress(BlockCompressorStream.java:149), org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:131), java.base/java.io.BufferedOutputStream.write(BufferedOutputStream.java:123), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.io.compress.TestCodec.codecTest(TestCodec.java:204), org.apache.hadoop.io.compress.TestCodec.testLz4Codec(TestCodec.java:146), org.apache.hadoop.io.compress.TestCodec.testLz4Codec$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:79), org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119), org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152), org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131), org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70), org.apache.hadoop.io.compress.TestCodec.codecTest(TestCodec.java:201), org.apache.hadoop.io.compress.TestCodec.testLz4Codec(TestCodec.java:145), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testLz4Codec/campaign/failures/debug_000002	{"io.compression.codec.lz4.buffersize": "1602274047"}	["debug_000002"]																																																																																																																																																																																																																	
			2	org.apache.hadoop.io.compress.TestCodec#testLz4Codec	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.CompressorStream.<init>(CompressorStream.java:46), org.apache.hadoop.io.compress.BlockCompressorStream.<init>(BlockCompressorStream.java:56), org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:92), org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:134), org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70), org.apache.hadoop.io.compress.TestCodec.codecTest(TestCodec.java:201), org.apache.hadoop.io.compress.TestCodec.testLz4Codec(TestCodec.java:145), org.apache.hadoop.io.compress.TestCodec.testLz4Codec$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	DIFFERENT	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:78), org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119), org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152), org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131), org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70), org.apache.hadoop.io.compress.TestCodec.codecTest(TestCodec.java:201), org.apache.hadoop.io.compress.TestCodec.testLz4Codec(TestCodec.java:145), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testLz4Codec/campaign/failures/debug_000001	{"io.compression.codec.lz4.buffersize": "2130640638"}	["debug_000001", "debug_000003"]	org.apache.hadoop.io.compress.TestCodec#testLz4Codec	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Direct buffer memory	java.base/java.nio.Bits.reserveMemory(Bits.java:175), java.base/java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:118), java.base/java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:317), org.apache.hadoop.io.compress.lz4.Lz4Compressor.<init>(Lz4Compressor.java:79), org.apache.hadoop.io.compress.Lz4Codec.createCompressor(Lz4Codec.java:119), org.apache.hadoop.io.compress.CodecPool.getCompressor(CodecPool.java:152), org.apache.hadoop.io.compress.CompressionCodec$Util.createOutputStreamWithCodecPool(CompressionCodec.java:131), org.apache.hadoop.io.compress.Lz4Codec.createOutputStream(Lz4Codec.java:70), org.apache.hadoop.io.compress.TestCodec.codecTest(TestCodec.java:201), org.apache.hadoop.io.compress.TestCodec.testLz4Codec(TestCodec.java:145), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testLz4Codec/campaign/failures/debug_000004	{"io.compression.codec.lz4.buffersize": "1762816961"}	["debug_000004"]																																																																																																																																																																																																						
		FP	1	org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch#testBindUserSwitchPasswordFromAlias	java.lang.AssertionError	expected:<[group1, group2]> but was:<[]>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:120), org.junit.Assert.assertEquals(Assert.java:146), org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch.doTestBindUserSwitch(TestLdapGroupsMappingWithBindUserSwitch.java:238), org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch.doTestBindUserSwitch(TestLdapGroupsMappingWithBindUserSwitch.java:193), org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch.testBindUserSwitchPasswordFromAlias(TestLdapGroupsMappingWithBindUserSwitch.java:122), org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch.testBindUserSwitchPasswordFromAlias$$CONFUZZ(TestLdapGroupsMappingWithBindUserSwitch.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestLdapGroupsMappingWithBindUserSwitch/testBindUserSwitchPasswordFromAlias/campaign/failures/debug_000003	{"hadoop.security.group.mapping.ldap.num.attempts": "1"}	["debug_000003"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.ipc.TestRPC#testConnectionPing	java.net.SocketTimeoutException	7 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/172.17.0.2:56432 remote=517426261c1f/172.17.0.2:44153]	org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163), org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161), org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131), java.base/java.io.FilterInputStream.read(FilterInputStream.java:133), java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252), java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:271), java.base/java.io.FilterInputStream.read(FilterInputStream.java:83), java.base/java.io.FilterInputStream.read(FilterInputStream.java:83), org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:563), java.base/java.io.DataInputStream.readInt(DataInputStream.java:392), org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922), org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238), org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134),	TIMEOUT					{"hadoop.security.token.service.use_ip": "false", "ipc.client.rpc-timeout.ms": "7", "hadoop.rpc.protection": "privacy,authentication,privacy,authentication,integrity,privacy,privacy,integrity,authentication,authentication,privacy,authentication,privacy,authentication,integrity,privacy,privacy,authentication,authentication,integrity,authentication,authentication,integrity,authentication,privacy,integrity,integrity,privacy,privacy,integrity,privacy,integrity,authentication,integrity,authentication,privacy,authentication,privacy,authentication,authentication,authentication,privacy,privacy,authentication", "ipc.client.kill.max": "0", "ipc.client.idlethreshold": "7951"}	["debug_000003"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testPriority	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.testPriority(TestDecayRpcScheduler.java:215), org.apache.hadoop.ipc.TestDecayRpcScheduler.testPriority$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testPriority/campaign/failures/debug_000000	{"ipc.12.faircallqueue.decay-scheduler.decay-factor": "-0.24803924560546875"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testPriority	java.lang.AssertionError	Get expected JMX for CallVolumeSummary after decay	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.ipc.TestDecayRpcScheduler.testPriority(TestDecayRpcScheduler.java:239), org.apache.hadoop.ipc.TestDecayRpcScheduler.testPriority$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testPriority/campaign/failures/debug_000001	{"ipc.12.decay-scheduler.decay-factor": "0.41765010356903076"}	["debug_000001"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.http.TestSSLHttpServerConfigs#testServerSetupWithoutKeyStoreKeyPassword	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerStart(TestSSLHttpServerConfigs.java:126), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStoreKeyPassword(TestSSLHttpServerConfigs.java:160), org.apache.hadoop.http.TestSSLHttpServerConfigs.testServerSetupWithoutKeyStoreKeyPassword$$CONFUZZ(TestSSLHttpServerConfigs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestSSLHttpServerConfigs/testServerSetupWithoutKeyStoreKeyPassword/campaign/failures/debug_000005	{"hadoop.http.idle_timeout.ms": "10042", "hadoop.http.authentication.token.validity": "2147451006", "hadoop.prometheus.endpoint.enabled": "true", "hadoop.security.dns.log-slow-lookups.enabled": "true", "hadoop.http.max.response.header.size": "767"}	["debug_000005"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.security.token.delegation.web.TestWebDelegationToken#testDelegationTokenAuthenticatedURLWithNoDT	java.lang.NoSuchMethodError	void org.apache.hadoop.security.token.delegation.web.TestWebDelegationToken.testDelegationTokenAuthenticatedURLWithNoDT()'	org.apache.hadoop.security.token.delegation.web.TestWebDelegationToken.testDelegationTokenAuthenticatedURLWithNoDT$$CONFUZZ(TestWebDelegationToken.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.token.delegation.web.TestWebDelegationToken/testDelegationTokenAuthenticatedURLWithNoDT/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			3	org.apache.hadoop.crypto.key.TestKeyShell#testTransientProviderWarning	java.lang.AssertionError	expected:<0> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.crypto.key.TestKeyShell.testTransientProviderWarning(TestKeyShell.java:228), org.apache.hadoop.crypto.key.TestKeyShell.testTransientProviderWarning$$CONFUZZ(TestKeyShell.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.TestKeyShell/testTransientProviderWarning/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.security.TestUserGroupInformation#testGetNextRetryTime	java.lang.AssertionError	expected:<0> but was:<5>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.security.TestUserGroupInformation.testGetNextRetryTime(TestUserGroupInformation.java:1105), org.apache.hadoop.security.TestUserGroupInformation.testGetNextRetryTime$$CONFUZZ(TestUserGroupInformation.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestUserGroupInformation/testGetNextRetryTime/campaign/failures/debug_000000	{}	["debug_000000"]	org.apache.hadoop.security.alias.TestCredShell#testTransientProviderWarning	java.lang.AssertionError	WARNING: you are modifying a transient provider.Credential credential1 has NOT been created. Credential credential1 already exists in user:///create <alias> [-value alias-value] [-provider provider-path] [-strict]:The create subcommand creates a new credential for the namespecified as the <alias> argument within the provider indicatedthrough the -provider argument. If -strict is supplied, failimmediately if the provider requires a password and none is given.If -value is provided, use that for the value of the credentialinstead of prompting the user. expected:<0> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.apache.hadoop.security.alias.TestCredShell.testTransientProviderWarning(TestCredShell.java:126), org.apache.hadoop.security.alias.TestCredShell.testTransientProviderWarning$$CONFUZZ(TestCredShell.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.alias.TestCredShell/testTransientProviderWarning/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																											
	Bug-67	Repeated	1	org.apache.hadoop.ha.TestZKFailoverController#testAutoFailoverOnLostZKSession	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testAutoFailoverOnLostZKSession/campaign/failures/debug_000001	{"ipc.server.handler.queue.size": "0"}	["debug_000001"]																																																																																																																																																																																																																	
		FP	2	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsXFrameOptions	java.lang.AssertionError	X-FRAME-OPTIONS is absent in the header	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.http.TestHttpServer.validateXFrameOption(TestHttpServer.java:297), org.apache.hadoop.http.TestHttpServer.testHttpResonseContainsXFrameOptions(TestHttpServer.java:275), org.apache.hadoop.http.TestHttpServer.testHttpResonseContainsXFrameOptions$$CONFUZZ(TestHttpServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsXFrameOptions/campaign/failures/debug_000005	{"hadoop.http.max.request.header.size": "20"}	["debug_000005"]	org.apache.hadoop.http.TestHttpServer#testHttpResonseContainsDeny	java.lang.AssertionError	X-FRAME-OPTIONS is absent in the header	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.http.TestHttpServer.validateXFrameOption(TestHttpServer.java:297), org.apache.hadoop.http.TestHttpServer.testHttpResonseContainsDeny(TestHttpServer.java:280), org.apache.hadoop.http.TestHttpServer.testHttpResonseContainsDeny$$CONFUZZ(TestHttpServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHttpResonseContainsDeny/campaign/failures/debug_000007	{"hadoop.http.max.request.header.size": "7"}	["debug_000007"]																																																																																																																																																																																																						
		FP	2	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testCloseChildrenFileSystem	java.lang.AssertionError	expected not same	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failSame(Assert.java:820), org.junit.Assert.assertNotSame(Assert.java:799), org.junit.Assert.assertNotSame(Assert.java:812), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testCloseChildrenFileSystem(ViewFileSystemBaseTest.java:1332), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testCloseChildrenFileSystem$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testCloseChildrenFileSystem/campaign/failures/debug_000000	{"fs.viewfs.enable.inner.cache": "false"}	["debug_000000"]	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testCloseChildrenFileSystem	java.lang.AssertionError	expected not same	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failSame(Assert.java:820), org.junit.Assert.assertNotSame(Assert.java:799), org.junit.Assert.assertNotSame(Assert.java:812), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testCloseChildrenFileSystem(ViewFileSystemBaseTest.java:1332), org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testCloseChildrenFileSystem$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testCloseChildrenFileSystem/campaign/failures/debug_000001	{"fs.viewfs.enable.inner.cache": "false"}	["debug_000001"]																																																																																																																																																																																																						
	Bug-178	BUG	1	org.apache.hadoop.ipc.TestAsyncIPC#testCallIdAndRetry	java.lang.NullPointerException		org.apache.hadoop.ipc.TestAsyncIPC$1.checkResponse(TestAsyncIPC.java:406), org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1242), org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestAsyncIPC/testCallIdAndRetry/campaign/failures/debug_000000	{"hadoop.security.authorization": "true"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.ipc.TestRPC#testAuthorization	java.io.IOException	protocolClass interface org.apache.hadoop.ipc.TestRpcBase$TestRpcService is not implemented by protocolImpl which is of class class org.apache.hadoop.ipc.protobuf.TestRpcServiceProtos$TestProtobufRpcProto$2	org.apache.hadoop.ipc.WritableRpcEngine$Server.<init>(WritableRpcEngine.java:460), org.apache.hadoop.ipc.WritableRpcEngine.getServer(WritableRpcEngine.java:332), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.ipc.TestRPC.doRPCs(TestRPC.java:604), org.apache.hadoop.ipc.TestRPC.testAuthorization(TestRPC.java:687), org.apache.hadoop.ipc.TestRPC.testAuthorization$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testAuthorization/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.fs.shell.TestPathData#testWithDirStringAndConf	java.lang.AssertionError	checking fs expected:<org.apache.hadoop.fs.LocalFileSystem@7b4b8199> but was:<org.apache.hadoop.fs.LocalFileSystem@4bbf20d1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:120), org.apache.hadoop.fs.shell.TestPathData.checkPathData(TestPathData.java:253), org.apache.hadoop.fs.shell.TestPathData.testWithDirStringAndConf(TestPathData.java:78), org.apache.hadoop.fs.shell.TestPathData.testWithDirStringAndConf$$CONFUZZ(TestPathData.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestPathData/testWithDirStringAndConf/campaign/failures/debug_000002	{"fs.file.impl.disable.cache": "true"}	["debug_000002"]																																																																																																																																																																																																																	
		Filtered	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseThresholds	java.lang.IllegalArgumentException	Period millis must be >= 0	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayPeriodMillis(DecayRpcScheduler.java:332), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:228), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds(TestDecayRpcScheduler.java:116), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseThresholds/campaign/failures/debug_000006	{"ipc.6.decay-scheduler.period-ms": "0"}	["debug_000006", "debug_000008", "debug_000009", "debug_000004"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseThresholds	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds(TestDecayRpcScheduler.java:129), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseThresholds/campaign/failures/debug_000005	{"ipc.9.faircallqueue.decay-scheduler.decay-factor": "-0.15781766176223755"}	["debug_000005", "debug_000000", "debug_000002", "debug_000001", "debug_000003"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.crypto.key.TestKeyProviderFactory#testJksProvider	java.io.IOException	Wrong key length. Required 906, but got 128	org.apache.hadoop.crypto.key.JavaKeyStoreProvider.createKey(JavaKeyStoreProvider.java:452), org.apache.hadoop.crypto.key.TestKeyProviderFactory.checkSpecificProvider(TestKeyProviderFactory.java:120), org.apache.hadoop.crypto.key.TestKeyProviderFactory.testJksProvider(TestKeyProviderFactory.java:224), org.apache.hadoop.crypto.key.TestKeyProviderFactory.testJksProvider$$CONFUZZ(TestKeyProviderFactory.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.TestKeyProviderFactory/testJksProvider/campaign/failures/debug_000000	{"hadoop.security.key.default.bitlength": "906"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFileStreams#testFailureCompressionNotWorking	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendValue(TFile.java:565), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:415), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureCompressionNotWorking(TestTFileStreams.java:386), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testFailureCompressionNotWorking/campaign/failures/debug_000003	{"tfile.io.chunk.size": "1575923140", "tfile.fs.output.buffer.size": "1519366679"}	["debug_000003"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem#testOperationsThroughMountLinksInternal	java.lang.NoSuchMethodError	void org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testOperationsThroughMountLinksInternal()'	org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem.testOperationsThroughMountLinksInternal$$CONFUZZ(TestViewFileSystemLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	POLLUTED				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem/testOperationsThroughMountLinksInternal/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestLocalFSCopyFromLocal#testCopyTreeDirectoryWithoutDelete	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:418), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:409), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:391), org.apache.hadoop.fs.FileSystem.copyFromLocalFile(FileSystem.java:2482), org.apache.hadoop.fs.FilterFileSystem.copyFromLocalFile(FilterFileSystem.java:376), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.copyFromLocal(AbstractContractCopyFromLocalTest.java:303), org.apache.hadoop.fs.contract.AbstractContractCopyFromLocalTest.testCopyTreeDirectoryWithoutDelete(AbstractContractCopyFromLocalTest.java:237), org.apache.hadoop.fs.TestLocalFSCopyFromLocal.testCopyTreeDirectoryWithoutDelete$$CONFUZZ(TestLocalFSCopyFromLocal.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	DIFFERENT				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFSCopyFromLocal/testCopyTreeDirectoryWithoutDelete/campaign/failures/debug_000001	{"io.file.buffer.size": "1699996266"}	["debug_000001"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.fs.TestFsShellCopy#testCopyMerge	java.io.FileNotFoundException	File out does not exist	org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:779), org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:1100), org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:769), org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:462), org.apache.hadoop.fs.TestFsShellCopy.readFile(TestFsShellCopy.java:606), org.apache.hadoop.fs.TestFsShellCopy.testCopyMerge(TestFsShellCopy.java:360), org.apache.hadoop.fs.TestFsShellCopy.testCopyMerge$$CONFUZZ(TestFsShellCopy.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testCopyMerge/campaign/failures/debug_000000	{"fs.file.impl.disable.cache": "true"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem#testRenameAcrossMounts1	java.lang.AssertionError	IOException is not thrown on rename operation	org.junit.Assert.fail(Assert.java:89), org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testRenameAcrossMounts1(ViewFileSystemBaseTest.java:390), org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem.testRenameAcrossMounts1$$CONFUZZ(TestViewFileSystemWithAuthorityLocalFileSystem.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem/testRenameAcrossMounts1/campaign/failures/debug_000004	{"fs.viewfs.rename.strategy": "SAME_TARGET_URI_ACROSS_MOUNTPOINT"}	["debug_000004"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.http.TestHttpServerWithSpnego#testAuthenticationWithProxyUser	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser(TestHttpServerWithSpnego.java:136), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser$$CONFUZZ(TestHttpServerWithSpnego.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.AssertionError	expected:<200> but was:<404>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser(TestHttpServerWithSpnego.java:176), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), org.junit.runner.JUnitCore.run(JUnitCore.java:115), edu.illinois.confuzz.internal.DebugForkMain.runTestWithConfig(DebugForkMain.java:47), edu.illinois.confuzz.internal.DebugForkMain.main(DebugForkMain.java:28),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerWithSpnego/testAuthenticationWithProxyUser/campaign/failures/debug_000008	{"hadoop.http.logs.enabled": "false"}	["debug_000008"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.http.TestHttpServerWithSpnego#testAuthenticationWithProxyUser	java.lang.AssertionError	expected:<200> but was:<403>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser(TestHttpServerWithSpnego.java:156), org.apache.hadoop.http.TestHttpServerWithSpnego.testAuthenticationWithProxyUser$$CONFUZZ(TestHttpServerWithSpnego.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServerWithSpnego/testAuthenticationWithProxyUser/campaign/failures/debug_000003	{"hadoop.security.instrumentation.requires.admin": "true"}	["debug_000003"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem#testCreateLinkToDotDotPrefix	java.lang.OutOfMemoryError	Java heap space		PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem/testCreateLinkToDotDotPrefix/campaign/failures/debug_000002	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "404360947", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "9122m", "file.stream-buffer-size": "32049", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "60", "fs.creation.parallel.count": "367379101", "file.bytes-per-checksum": "1472162515", "fs.automatic.close": "true", "hadoop.security.dns.log-slow-lookups.threshold.ms": "25874", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "2048287925", "fs.local.block.size": "14327", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "15771", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "221", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "1852388114"}	["debug_000002"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.ha.TestZKFailoverControllerStress#testRandomExpirations	org.junit.internal.runners.model.MultipleFailureException	There were 2 errors:  java.lang.RuntimeException(Deferred)  java.lang.RuntimeException(Deferred)	org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:102), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:361), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1855), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:501), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverControllerStress/testRandomExpirations/campaign/failures/debug_000000	{"ipc.server.read.threadpool.size": "1499850793", "hadoop.security.authentication": "kerberos"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.http.TestHttpServer#testBacklogSize	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testBacklogSize/campaign/failures/debug_000005	{"hadoop.prometheus.endpoint.enabled": "true", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.http.max.response.header.size": "189564292"}	["debug_000005"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testSyncable	java.lang.AssertionError	Should have capability: hflush in FSDataOutputStream{wrappedStream=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer@2291b593}	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.fs.contract.ContractTestUtils.assertCapabilities(ContractTestUtils.java:1545), org.apache.hadoop.fs.contract.AbstractContractCreateTest.validateSyncableSemantics(AbstractContractCreateTest.java:495), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testSyncable(AbstractContractCreateTest.java:459), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testSyncable$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testSyncable/campaign/failures/debug_000000	{"fs.contract.supports-hflush": "true"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testSyncable	java.lang.AssertionError	Should have capability: hsync in FSDataOutputStream{wrappedStream=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer@3191ef07}	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.fs.contract.ContractTestUtils.assertCapabilities(ContractTestUtils.java:1545), org.apache.hadoop.fs.contract.AbstractContractCreateTest.validateSyncableSemantics(AbstractContractCreateTest.java:500), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testSyncable(AbstractContractCreateTest.java:459), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testSyncable$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testSyncable/campaign/failures/debug_000001	{"fs.contract.supports-hsync": "true"}	["debug_000001"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate#testSyncable	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.contract.AbstractContractCreateTest.validateSyncableSemantics(AbstractContractCreateTest.java:483), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testSyncable(AbstractContractCreateTest.java:459), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate.testSyncable$$CONFUZZ(TestLocalFSContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	DIFFERENT	java.lang.AssertionError	Should have capability: hsync in FSDataOutputStream{wrappedStream=org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer@77fafff}	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.assertTrue(Assert.java:42), org.apache.hadoop.fs.contract.ContractTestUtils.assertCapabilities(ContractTestUtils.java:1545), org.apache.hadoop.fs.contract.AbstractContractCreateTest.validateSyncableSemantics(AbstractContractCreateTest.java:500), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testSyncable(AbstractContractCreateTest.java:459), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractCreate/testSyncable/campaign/failures/debug_000003	{"fs.contract.supports-hsync": "true"}	["debug_000003"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testOneEntryMixedLengths2	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths2(TestTFileStreams.java:137), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testOneEntryMixedLengths2$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	DIFFERENT				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testOneEntryMixedLengths2/campaign/failures/debug_000000	{"file.stream-buffer-size": "2047184157", "tfile.fs.input.buffer.size": "27847603"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.http.TestHttpServer#testHasAdministratorAccess	java.lang.NullPointerException	config	org.apache.hadoop.thirdparty.com.google.common.base.Preconditions.checkNotNull(Preconditions.java:899), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.registerSink(MetricsSystemImpl.java:298), org.apache.hadoop.metrics2.impl.MetricsSystemImpl.register(MetricsSystemImpl.java:277), org.apache.hadoop.http.HttpServer2.start(HttpServer2.java:1279), org.apache.hadoop.http.TestHttpServer.setup(TestHttpServer.java:156), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.http.TestHttpServer/testHasAdministratorAccess/campaign/failures/debug_000005	{"hadoop.security.dns.log-slow-lookups.threshold.ms": "68", "hadoop.prometheus.endpoint.enabled": "true", "hadoop.http.max.request.header.size": "4034", "hadoop.http.socket.backlog.size": "1077978145", "hadoop.http.sni.host.check.enabled": "false"}	["debug_000005"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestTrash#testExpungeWithFileSystem	java.lang.OutOfMemoryError	Java heap space		FLAKY	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.fs.FileSystemTestHelper.writeFile(FileSystemTestHelper.java:190), org.apache.hadoop.fs.TestTrash.testExpungeWithFileSystem(TestTrash.java:506), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestTrash/testExpungeWithFileSystem/campaign/failures/debug_000001	{"hadoop.shell.missing.defaultFs.warning": "false", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "410", "fs.testlfs.impl.disable.cache": "false", "fs.client.resolve.remote.symlinks": "false", "fs.incorrectfs.impl.disable.cache": "false", "hadoop.service.shutdown.timeout": "837h", "file.stream-buffer-size": "4750", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "1296777472", "fs.trash.checkpoint.interval": "788", "fs.creation.parallel.count": "504685124", "file.bytes-per-checksum": "9154", "fs.automatic.close": "true", "hadoop.security.dns.log-slow-lookups.threshold.ms": "373", "hadoop.security.authentication": "kerberos", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "1325177904", "fs.local.block.size": "676", "io.file.buffer.size": "2061396759", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "509", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "582316688"}	["debug_000001"]																																																																																																																																																																																																																	
	Bug-14	Repeated	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureCompressionNotWorking	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendValue(TFile.java:565), org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(TestTFileStreams.java:415), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureCompressionNotWorking(TestTFileStreams.java:386), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testFailureCompressionNotWorking$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureCompressionNotWorking/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "1656136169", "tfile.io.chunk.size": "1671047254"}	["debug_000000"]																																																																																																																																																																																																																	
		FP	1	org.apache.hadoop.fs.shell.TestPathData#testUnqualifiedUriContents	org.apache.hadoop.fs.PathNotFoundException	`d1': No such file or directory	org.apache.hadoop.fs.shell.PathData.checkIfExists(PathData.java:218), org.apache.hadoop.fs.shell.PathData.getDirectoryContents(PathData.java:270), org.apache.hadoop.fs.shell.TestPathData.testUnqualifiedUriContents(TestPathData.java:91), org.apache.hadoop.fs.shell.TestPathData.testUnqualifiedUriContents$$CONFUZZ(TestPathData.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.shell.TestPathData/testUnqualifiedUriContents/campaign/failures/debug_000000	{"fs.file.impl.disable.cache": "true"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.security.TestDoAsEffectiveUser#testRealUserSetup	java.lang.OutOfMemoryError	unable to create native thread: possibly out of memory or process/resource limits reached	java.base/java.lang.Thread.start0(Native Method), java.base/java.lang.Thread.start(Thread.java:798), org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1245), org.apache.hadoop.ipc.Server.<init>(Server.java:3127), org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserSetup(TestDoAsEffectiveUser.java:192), org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserSetup$$CONFUZZ(TestDoAsEffectiveUser.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	DIFFERENT	org.junit.runners.model.TestTimedOutException	test timed out after 4000 milliseconds	java.base@11.0.19/java.security.AccessController.getStackAccessControlContext(Native Method), java.base@11.0.19/java.security.AccessController.getContext(AccessController.java:833), java.base@11.0.19/java.lang.Thread.<init>(Thread.java:440), java.base@11.0.19/java.lang.Thread.<init>(Thread.java:704), java.base@11.0.19/java.lang.Thread.<init>(Thread.java:537), app//org.apache.hadoop.ipc.Server$Listener$Reader.<init>(Server.java:1264), app//org.apache.hadoop.ipc.Server$Listener.<init>(Server.java:1242), app//org.apache.hadoop.ipc.Server.<init>(Server.java:3127), app//org.apache.hadoop.ipc.RPC$Server.<init>(RPC.java:1062), app//org.apache.hadoop.ipc.ProtobufRpcEngine2$Server.<init>(ProtobufRpcEngine2.java:468), app//org.apache.hadoop.ipc.ProtobufRpcEngine2.getServer(ProtobufRpcEngine2.java:371), app//org.apache.hadoop.ipc.RPC$Builder.build(RPC.java:853), app//org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:126), app//org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:121), app//org.apache.hadoop.ipc.TestRpcBase.setupTestServer(TestRpcBase.java:104), app//org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserSetup(TestDoAsEffectiveUser.java:192), java.base@11.0.19/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base@11.0.19/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base@11.0.19/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestDoAsEffectiveUser/testRealUserSetup/campaign/failures/debug_000003	{"ipc.server.read.threadpool.size": "117407487"}	["debug_000003"]																																																																																																																																																																																																																	
	Bug-164	Repeated	1	org.apache.hadoop.security.TestLdapGroupsMapping#testLdapReadTimeout	javax.net.ssl.SSLException	Unsupported or unrecognized SSL message	java.base/sun.security.ssl.SSLSocketInputRecord.handleUnknownRecord(SSLSocketInputRecord.java:457), java.base/sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:175), java.base/sun.security.ssl.SSLTransport.decode(SSLTransport.java:111), java.base/sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1507), java.base/sun.security.ssl.SSLSocketImpl.readHandshakeRecord(SSLSocketImpl.java:1417), java.base/sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:456), java.base/sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:427), java.naming/com.sun.jndi.ldap.Connection.createSocket(Connection.java:364), java.naming/com.sun.jndi.ldap.Connection.<init>(Connection.java:231), java.naming/com.sun.jndi.ldap.LdapClient.<init>(LdapClient.java:137), java.naming/com.sun.jndi.ldap.LdapClient.getInstance(LdapClient.java:1616), java.naming/com.sun.jndi.ldap.LdapCtx.connect(LdapCtx.java:2847), java.naming/com.sun.jndi.ldap.LdapCtx.<init>(LdapCtx.java:348), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxFromUrl(LdapCtxFactory.java:266), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getUsingURL(LdapCtxFactory.java:226), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getUsingURLs(LdapCtxFactory.java:284), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getLdapCtxInstance(LdapCtxFactory.java:185), java.naming/com.sun.jndi.ldap.LdapCtxFactory.getInitialContext(LdapCtxFactory.java:115), java.naming/javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:730), java.naming/javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:305), java.naming/javax.naming.InitialContext.init(InitialContext.java:236), java.naming/javax.naming.ldap.InitialLdapContext.<init>(InitialLdapContext.java:154), org.apache.hadoop.security.TestLdapGroupsMappingBase$DummyLdapCtxFactory.getInitialContext(TestLdapGroupsMappingBase.java:241), java.naming/javax.naming.spi.NamingManager.getInitialContext(NamingManager.java:730), java.naming/javax.naming.InitialContext.getDefaultInitCtx(InitialContext.java:305), java.naming/javax.naming.InitialContext.init(InitialContext.java:236), java.naming/javax.naming.InitialContext.<init>(InitialContext.java:208), java.naming/javax.naming.directory.InitialDirContext.<init>(InitialDirContext.java:101), org.apache.hadoop.security.LdapGroupsMapping.getDirContext(LdapGroupsMapping.java:701), org.apache.hadoop.security.LdapGroupsMapping.doGetGroups(LdapGroupsMapping.java:512), org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout(TestLdapGroupsMapping.java:444), org.apache.hadoop.security.TestLdapGroupsMapping.testLdapReadTimeout$$CONFUZZ(TestLdapGroupsMapping.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestLdapGroupsMapping/testLdapReadTimeout/campaign/failures/debug_000000	{"hadoop.security.group.mapping.ldap.ssl": "true"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays#testFailureFileWriteNotAt0Position	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1052), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.setUp(TestTFileByteArrays.java:94), org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays.setUp(TestTFileJClassComparatorByteArrays.java:41), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileJClassComparatorByteArrays/testFailureFileWriteNotAt0Position/campaign/failures/debug_000000	{"hadoop.security.dns.log-slow-lookups.threshold.ms": "13504", "hadoop.security.authentication": "kerberos", "file.stream-buffer-size": "470124431", "fs.file.impl.disable.cache": "true", "file.bytes-per-checksum": "161558124"}	["debug_000000", "debug_000001"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestLocalFsFCStatistics#testStatistics	java.lang.AssertionError	expected:<0> but was:<1024>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.fs.FCStatisticsBaseTest.testStatistics(FCStatisticsBaseTest.java:98), org.apache.hadoop.fs.TestLocalFsFCStatistics.testStatistics$$CONFUZZ(TestLocalFsFCStatistics.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestLocalFsFCStatistics/testStatistics/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.TestFileSystemCaching#testCacheEnabledWithInitializeForeverFS	org.junit.runners.model.TestTimedOutException	test timed out after 100000 milliseconds	java.base@11.0.19/jdk.internal.misc.Unsafe.park(Native Method), java.base@11.0.19/java.util.concurrent.locks.LockSupport.park(LockSupport.java:194), java.base@11.0.19/java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:885), java.base@11.0.19/java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1039), java.base@11.0.19/java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1345), java.base@11.0.19/java.util.concurrent.Semaphore.acquire(Semaphore.java:318), app//org.apache.hadoop.fs.TestFileSystemCaching.testCacheEnabledWithInitializeForeverFS(TestFileSystemCaching.java:135), app//org.apache.hadoop.fs.TestFileSystemCaching.testCacheEnabledWithInitializeForeverFS$$CONFUZZ(TestFileSystemCaching.java), java.base@11.0.19/java.lang.reflect.Method.invoke(Method.java:566), app//org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), app//org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), app//org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), app//edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), app//org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), app//org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base@11.0.19/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base@11.0.19/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFileSystemCaching/testCacheEnabledWithInitializeForeverFS/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.util.TestRunJar#testClientClassLoaderSkipUnjar	java.lang.IllegalStateException	Shutdown in progress, cannot add a shutdownHook	org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:301), org.apache.hadoop.util.RunJar.run(RunJar.java:301), org.apache.hadoop.util.TestRunJar.testClientClassLoaderSkipUnjar(TestRunJar.java:256), org.apache.hadoop.util.TestRunJar.testClientClassLoaderSkipUnjar$$CONFUZZ(TestRunJar.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.util.TestRunJar/testClientClassLoaderSkipUnjar/campaign/failures/debug_000000	{"hadoop.security.dns.log-slow-lookups.threshold.ms": "865", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "30766", "hadoop.security.authentication": "kerberos", "fs.client.resolve.remote.symlinks": "true", "hadoop.service.shutdown.timeout": "9397h", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "2145706565", "fs.local.block.size": "264", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "fs.AbstractFileSystem.file.impl": "org.apache.hadoop.fs.local.LocalFs", "hadoop.security.token.service.use_ip": "true", "hadoop.kerberos.min.seconds.before.relogin": "60", "hadoop.kerberos.keytab.login.autorenewal.enabled": "true", "hadoop.security.groups.negative-cache.secs": "993", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "fs.creation.parallel.count": "923", "hadoop.security.groups.cache.warn.after.ms": "584587245"}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFileStreams#testFailureValueTooLong	java.lang.OutOfMemoryError	Java heap space		PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testFailureValueTooLong/campaign/failures/debug_000001	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "MIT", "hadoop.security.groups.cache.secs": "13469", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "202s", "file.stream-buffer-size": "2061628123", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "false", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "1495947950", "fs.creation.parallel.count": "474438252", "file.bytes-per-checksum": "390", "fs.automatic.close": "true", "hadoop.security.dns.log-slow-lookups.threshold.ms": "732", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "1476925916", "zlib.compress.level": "DEFAULT_COMPRESSION", "fs.local.block.size": "9864", "fs.file.impl.disable.cache": "true", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "7977", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "tfile.fs.output.buffer.size": "6055", "hadoop.security.groups.cache.warn.after.ms": "318"}	["debug_000001"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.viewfs.TestViewFsLocalFs#testInternalDeleteExisting2	org.apache.hadoop.security.AccessControlException	Cannot delete internal mount table directory: /internalDir/linkToDir2	org.apache.hadoop.fs.viewfs.ViewFs.delete(ViewFs.java:372), org.apache.hadoop.fs.FileContext$5.next(FileContext.java:845), org.apache.hadoop.fs.FileContext$5.next(FileContext.java:841), org.apache.hadoop.fs.FSLinkResolver.resolve(FSLinkResolver.java:90), org.apache.hadoop.fs.FileContext.delete(FileContext.java:847), org.apache.hadoop.fs.viewfs.ViewFsBaseTest.testInternalDeleteExisting2(ViewFsBaseTest.java:763), org.apache.hadoop.fs.viewfs.TestViewFsLocalFs.testInternalDeleteExisting2$$CONFUZZ(TestViewFsLocalFs.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:100), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:39),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.viewfs.TestViewFsLocalFs/testInternalDeleteExisting2/campaign/failures/debug_000000	{}	["debug_000000"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.io.file.tfile.TestTFileStreams#testTwoEntriesKnownLength	java.lang.OutOfMemoryError	Java heap space		DIFFERENT	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testTwoEntriesKnownLength(TestTFileStreams.java:146), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method), java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62), java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testTwoEntriesKnownLength/campaign/failures/debug_000002	{"file.stream-buffer-size": "1137727590", "tfile.fs.input.buffer.size": "1055381772"}	["debug_000002"]																																																																																																																																																																																																																	
			1	org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate#testCreateUnderFileSubdir	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:413), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:183), org.apache.hadoop.fs.contract.ContractTestUtils.writeDataset(ContractTestUtils.java:152), org.apache.hadoop.fs.contract.AbstractContractCreateTest.createFile(AbstractContractCreateTest.java:447), org.apache.hadoop.fs.contract.AbstractContractCreateTest.expectCreateUnderFileFails(AbstractContractCreateTest.java:413), org.apache.hadoop.fs.contract.AbstractContractCreateTest.testCreateUnderFileSubdir(AbstractContractCreateTest.java:365), org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate.testCreateUnderFileSubdir$$CONFUZZ(TestRawlocalContractCreate.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	PASS				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.rawlocal.TestRawlocalContractCreate/testCreateUnderFileSubdir/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "8183", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "94s", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "true", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "2313", "fs.creation.parallel.count": "22198", "file.bytes-per-checksum": "642", "fs.automatic.close": "false", "hadoop.security.dns.log-slow-lookups.threshold.ms": "2027503323", "fs.contract.create-file-under-file-allowed": "false", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "1088116677", "fs.local.block.size": "892", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "2069734866", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "1746936475", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "hadoop.security.groups.cache.warn.after.ms": "1928095846"}	["debug_000000"]																																																																																																																																																																																																																	
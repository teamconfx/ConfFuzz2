note	bugId	status	times	testName	failure	failureMessage	stackTrace	reproStatus	replayedFailure	replayedErrorMessage	replayedStackTrace	replayedFile	minConfig	debugFiles											
	Bug-252	BUG	1	org.apache.hadoop.hbase.io.hfile.TestHFile#testReaderWithCombinedBlockCache	java.lang.NullPointerException		org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithCombinedBlockCache(TestHFile.java:252), org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithCombinedBlockCache$$CONFUZZ(TestHFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.hfile.TestHFile/testReaderWithCombinedBlockCache/campaign/failures/debug_000003	{"hbase.lru.max.block.size": "825"}	["debug_000003"]											
	Bug-240	BUG	1	org.apache.hadoop.hbase.io.hfile.TestHFile#testReaderWithTinyLfuCombinedBlockCache	java.lang.NullPointerException		org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderCombinedCache(TestHFile.java:1060), org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithTinyLfuCombinedBlockCache(TestHFile.java:1011), org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithTinyLfuCombinedBlockCache$$CONFUZZ(TestHFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.hfile.TestHFile/testReaderWithTinyLfuCombinedBlockCache/campaign/failures/debug_000002	{"hbase.tinylfu.max.block.size": "511"}	["debug_000002"]											
	Bug-222	BUG	2	org.apache.hadoop.hbase.wal.TestWALMethods#testGetSplitEditFilesSorted	java.lang.ArithmeticException	/ by zero	org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.calculateMaxLogFiles(AbstractFSWAL.java:353), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.<init>(AbstractFSWAL.java:463), org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.<init>(AsyncFSWAL.java:218), org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:78), org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:49), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:157), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62), org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300), org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted(TestWALMethods.java:105), org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted$$CONFUZZ(TestWALMethods.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.wal.TestWALMethods/testGetSplitEditFilesSorted/campaign/failures/debug_000004	{"hbase.regionserver.logroll.multiplier": "0.0"}	["debug_000004"]	org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan#testReverseScanWithPadding	java.lang.ArithmeticException	/ by zero	org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.calculateMaxLogFiles(AbstractFSWAL.java:353), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.<init>(AbstractFSWAL.java:463), org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.<init>(AsyncFSWAL.java:218), org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:78), org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:49), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:157), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62), org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300), org.apache.hadoop.hbase.HBaseTestingUtility.createWal(HBaseTestingUtility.java:2579), org.apache.hadoop.hbase.HBaseTestingUtility.createRegionAndWAL(HBaseTestingUtility.java:2624), org.apache.hadoop.hbase.HBaseTestingUtility.createRegionAndWAL(HBaseTestingUtility.java:2588), org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan.setUp(TestSeekBeforeWithReverseScan.java:69), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan/testReverseScanWithPadding/campaign/failures/debug_000000	{"hbase.regionserver.logroll.multiplier": "0.0"}	["debug_000000"]
		FP	1	org.apache.hadoop.hbase.wal.TestWALMethods#testGetSplitEditFilesSorted	java.lang.NoSuchMethodException	org.apache.hadoop.hbase.codec.CellCodec.<init>(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.wal.CompressionContext)	java.base/java.lang.Class.getConstructor0(Class.java:3349), java.base/java.lang.Class.getDeclaredConstructor(Class.java:2553), org.apache.hadoop.hbase.util.ReflectionUtils.instantiateWithCustomCtor(ReflectionUtils.java:42), org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.create(WALCellCodec.java:102), org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.getCodec(AbstractProtobufLogWriter.java:75), org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.initAfterHeader0(AbstractProtobufLogWriter.java:208), org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.secureInitAfterHeader(AbstractProtobufLogWriter.java:231), org.apache.hadoop.hbase.regionserver.wal.SecureAsyncProtobufLogWriter.initAfterHeader(SecureAsyncProtobufLogWriter.java:63), org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.init(AbstractProtobufLogWriter.java:191), org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createAsyncWriter(AsyncFSWALProvider.java:117), org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:698), org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:128), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriterInternal(AbstractFSWAL.java:861), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.lambda$rollWriter$8(AbstractFSWAL.java:893), org.apache.hadoop.hbase.trace.TraceUtil.trace(TraceUtil.java:216), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:893), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:548), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.init(AbstractFSWAL.java:489), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:160), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62), org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300), org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted(TestWALMethods.java:105), org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted$$CONFUZZ(TestWALMethods.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.wal.TestWALMethods/testGetSplitEditFilesSorted/campaign/failures/debug_000003	{"hbase.regionserver.hlog.async.writer.impl": "org.apache.hadoop.hbase.regionserver.wal.SecureAsyncProtobufLogWriter", "hbase.regionserver.wal.codec": "org.apache.hadoop.hbase.codec.CellCodec"}	["debug_000003"]											
		FP	1	org.apache.hadoop.hbase.io.TestFileLink#testGetUnderlyingFSDataInputStream	org.apache.hadoop.ipc.RpcException	RPC response exceeds maximum data length	org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1935), org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238), org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.TestFileLink/testGetUnderlyingFSDataInputStream/campaign/failures/debug_000002	{"ipc.maximum.response.length": "756"}	["debug_000002"]											
		FP	1	org.apache.hadoop.hbase.procedure2.store.region.TestWALProcedurePrettyPrinter#test	java.lang.AssertionError	expected:<5> but was:<0>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.hbase.procedure2.store.region.TestWALProcedurePrettyPrinter.test(TestWALProcedurePrettyPrinter.java:102), org.apache.hadoop.hbase.procedure2.store.region.TestWALProcedurePrettyPrinter.test$$CONFUZZ(TestWALProcedurePrettyPrinter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.procedure2.store.region.TestWALProcedurePrettyPrinter/test/campaign/failures/debug_000005	{"hbase.table.max.rowsize": "120"}	["debug_000005"]											
		FP	1	org.apache.hadoop.hbase.mob.TestMobFileCache#testMobFileCache	java.lang.IllegalArgumentException	byteSize=70368744177664 too large for bitSize=15872, foldFactor=686	org.apache.hadoop.hbase.util.BloomFilterUtil.computeFoldableByteSize(BloomFilterUtil.java:134), org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.<init>(CompoundBloomFilterWriter.java:91), org.apache.hadoop.hbase.util.BloomFilterFactory.createDeleteBloomAtWrite(BloomFilterFactory.java:200), org.apache.hadoop.hbase.regionserver.StoreFileWriter.<init>(StoreFileWriter.java:160), org.apache.hadoop.hbase.regionserver.StoreFileWriter.<init>(StoreFileWriter.java:80), org.apache.hadoop.hbase.regionserver.StoreFileWriter$Builder.build(StoreFileWriter.java:577), org.apache.hadoop.hbase.mob.MobUtils.createWriter(MobUtils.java:635), org.apache.hadoop.hbase.regionserver.HMobStore.createWriterInTmp(HMobStore.java:244), org.apache.hadoop.hbase.regionserver.HMobStore.createWriterInTmp(HMobStore.java:227), org.apache.hadoop.hbase.regionserver.HMobStore.createWriterInTmp(HMobStore.java:187), org.apache.hadoop.hbase.mob.TestMobFileCache.createMobStoreFile(TestMobFileCache.java:148), org.apache.hadoop.hbase.mob.TestMobFileCache.createMobStoreFile(TestMobFileCache.java:130), org.apache.hadoop.hbase.mob.TestMobFileCache.createMobStoreFile(TestMobFileCache.java:120), org.apache.hadoop.hbase.mob.TestMobFileCache.testMobFileCache(TestMobFileCache.java:165), org.apache.hadoop.hbase.mob.TestMobFileCache.testMobFileCache$$CONFUZZ(TestMobFileCache.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.mob.TestMobFileCache/testMobFileCache/campaign/failures/debug_000002	{"io.storefile.bloom.block.size": "1984", "io.storefile.bloom.max.fold": "686"}	["debug_000002"]											
		FP	1	org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting#testBucketCache	java.lang.AssertionError	expected:<6> but was:<3>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.addDataAndHits(TestBlockCacheReporting.java:69), org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.testBucketCache(TestBlockCacheReporting.java:85), org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.testBucketCache$$CONFUZZ(TestBlockCacheReporting.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting/testBucketCache/campaign/failures/debug_000004	{"hbase.blockcache.minblocksize": "8"}	["debug_000004"]											
		FP	1	org.apache.hadoop.hbase.fs.TestBlockReorder#testBlockLocationReorder	org.apache.hadoop.ipc.RemoteException	File /user/root/hello could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and 3 node(s) are excluded in this operation.        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2276)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2820)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:910)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:577)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:549)        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:518)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2960)	org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612), org.apache.hadoop.ipc.Client.call(Client.java:1558), org.apache.hadoop.ipc.Client.call(Client.java:1455), org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:231), org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118), com.sun.proxy.$Proxy40.addBlock(Unknown Source), org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:520), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:433), org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:166), org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:158), org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:96), org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:362), com.sun.proxy.$Proxy41.addBlock(Unknown Source), org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1082), org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1898), org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1700), org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:707),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.fs.TestBlockReorder/testBlockLocationReorder/campaign/failures/debug_000002	{"dfs.namenode.block-placement-policy.default.prefer-local-node": "false", "dfs.namenode.redundancy.considerLoad.factor": "0.3987211585044861"}	["debug_000002"]											
		Not-Reproducible	1	org.apache.hadoop.hbase.ipc.TestBlockingIPC#testAsyncEcho	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertFalse(Assert.java:65), org.junit.Assert.assertFalse(Assert.java:75), org.apache.hadoop.hbase.ipc.AbstractTestIPC.testAsyncEcho(AbstractTestIPC.java:372), org.apache.hadoop.hbase.ipc.TestBlockingIPC.testAsyncEcho$$CONFUZZ(TestBlockingIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.ipc.TestBlockingIPC/testAsyncEcho/campaign/failures/debug_000000	{"hbase.ipc.server.max.callqueue.size": "728", "hbase.client.ipc.pool.size": "771686142"}	["debug_000000"]											
		FP	1	org.apache.hadoop.hbase.io.TestFileLink#testHDFSLinkReadDuringDelete	java.io.IOException	Timed out waiting for Mini HDFS Cluster to start	org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1488), org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:958), org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:849), org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:685), org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:665), org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:638), org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete(TestFileLink.java:259), org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete$$CONFUZZ(TestFileLink.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.TestFileLink/testHDFSLinkReadDuringDelete/campaign/failures/debug_000000	{"dfs.datanode.cache.revocation.timeout.ms": "767"}	["debug_000000"]											
		FP	1	org.apache.hadoop.hbase.TestHBaseTestingUtility#testMiniDFSCluster	java.io.EOFException		java.base/java.io.DataInputStream.readInt(DataInputStream.java:397), org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1921), org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238), org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.TestHBaseTestingUtility/testMiniDFSCluster/campaign/failures/debug_000006	{"ipc.maximum.data.length": "17"}	["debug_000006"]											
	Bug-222	BUG	1	org.apache.hadoop.hbase.wal.TestWALMethods#testGetSplitEditFilesSorted	java.lang.ArithmeticException	/ by zero	org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.calculateMaxLogFiles(AbstractFSWAL.java:353), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.<init>(AbstractFSWAL.java:463), org.apache.hadoop.hbase.regionserver.wal.FSHLog.<init>(FSHLog.java:246), org.apache.hadoop.hbase.wal.FSHLogProvider.createWAL(FSHLogProvider.java:101), org.apache.hadoop.hbase.wal.FSHLogProvider.createWAL(FSHLogProvider.java:38), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:157), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62), org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300), org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted(TestWALMethods.java:105), org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted$$CONFUZZ(TestWALMethods.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.wal.TestWALMethods/testGetSplitEditFilesSorted/campaign/failures/debug_000006	{"hbase.regionserver.logroll.multiplier": "-1.9073486328125E-6", "hbase.regionserver.hlog.blocksize": "906", "hbase.wal.provider": "filesystem"}	["debug_000006"]											
		FP	1	org.apache.hadoop.hbase.io.hfile.TestHFile#testReaderWithAdaptiveLruCombinedBlockCache	java.lang.IllegalArgumentException	Single, multi, and memory factors  should be non-negative and total 1.0	org.apache.hadoop.hbase.io.hfile.LruAdaptiveBlockCache.<init>(LruAdaptiveBlockCache.java:385), org.apache.hadoop.hbase.io.hfile.LruAdaptiveBlockCache.<init>(LruAdaptiveBlockCache.java:332), org.apache.hadoop.hbase.io.hfile.BlockCacheFactory.createFirstLevelCache(BlockCacheFactory.java:136), org.apache.hadoop.hbase.io.hfile.BlockCacheFactory.createBlockCache(BlockCacheFactory.java:98), org.apache.hadoop.hbase.io.hfile.TestHFile.initCombinedBlockCache(TestHFile.java:213), org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderCombinedCache(TestHFile.java:1037), org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithAdaptiveLruCombinedBlockCache(TestHFile.java:1019), org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithAdaptiveLruCombinedBlockCache$$CONFUZZ(TestHFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.hfile.TestHFile/testReaderWithAdaptiveLruCombinedBlockCache/campaign/failures/debug_000003	{"hbase.lru.blockcache.memory.percentage": "0.12107843160629272"}	["debug_000003"]											
	Bug-227	BUG	1	org.apache.hadoop.hbase.io.hfile.TestHFile#testReaderWithCombinedBlockCache	java.lang.NullPointerException		org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithCombinedBlockCache(TestHFile.java:252), org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithCombinedBlockCache$$CONFUZZ(TestHFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.hfile.TestHFile/testReaderWithCombinedBlockCache/campaign/failures/debug_000001	{"hfile.onheap.block.cache.fixed.size": "767"}	["debug_000001"]											
	Bug-257	BUG	1	org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter#test	java.lang.ArithmeticException	/ by zero	org.apache.hadoop.hbase.util.BloomFilterUtil.optimalFunctionCount(BloomFilterUtil.java:141), org.apache.hadoop.hbase.util.BloomFilterUtil.createBySize(BloomFilterUtil.java:164), org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.allocateNewChunk(CompoundBloomFilterWriter.java:188), org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.append(CompoundBloomFilterWriter.java:165), org.apache.hadoop.hbase.util.BloomContext.writeBloom(BloomContext.java:51), org.apache.hadoop.hbase.regionserver.StoreFileWriter.appendDeleteFamilyBloomFilter(StoreFileWriter.java:295), org.apache.hadoop.hbase.regionserver.StoreFileWriter.append(StoreFileWriter.java:302), org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(StoreFlusher.java:139), org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:65), org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:822), org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1963), org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2838), org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2580), org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2552), org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2422), org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2345), org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:2315), org.apache.hadoop.hbase.master.region.MasterRegion.flush(MasterRegion.java:166), org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test(TestHFileProcedurePrettyPrinter.java:103), org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test$$CONFUZZ(TestHFileProcedurePrettyPrinter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter/test/campaign/failures/debug_000003	{"io.storefile.bloom.max.fold": "767", "io.storefile.bloom.enabled": "false"}	["debug_000003"]											
		FP	1	org.apache.hadoop.hbase.io.TestFileLink#testHDFSLinkReadDuringRename	org.apache.hadoop.ipc.RemoteException	The maximum path component name limit of cf6d955d-1721-6e05-8c39-c19fe848f4ea in directory /user/root/test-data is exceeded: limit=30 length=36        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1216)        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1318)        at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.unprotectedMkdir(FSDirMkdirOp.java:215)        at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.createSingleDirectory(FSDirMkdirOp.java:168)        at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.createParentDirectories(FSDirMkdirOp.java:144)        at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.createAncestorDirectories(FSDirMkdirOp.java:106)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:395)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2567)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2464)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:809)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:478)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:549)        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:518)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2960)	org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612), org.apache.hadoop.ipc.Client.call(Client.java:1558), org.apache.hadoop.ipc.Client.call(Client.java:1455), org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:231), org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118), com.sun.proxy.$Proxy35.create(Unknown Source), org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:372), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:433), org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:166), org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:158), org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:96), org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:362), com.sun.proxy.$Proxy36.create(Unknown Source), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:361), com.sun.proxy.$Proxy39.create(Unknown Source), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:361), com.sun.proxy.$Proxy39.create(Unknown Source), org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276), org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1230), org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1209), org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1147), org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533), org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:530), org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81), org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:544), org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:471), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1125), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1105), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:994), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:982), org.apache.hadoop.hbase.io.TestFileLink.writeSomeData(TestFileLink.java:320), org.apache.hadoop.hbase.io.TestFileLink.testLinkReadDuringRename(TestFileLink.java:198), org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringRename(TestFileLink.java:142), org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringRename$$CONFUZZ(TestFileLink.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.TestFileLink/testHDFSLinkReadDuringRename/campaign/failures/debug_000002	{"dfs.namenode.fs-limits.max-component-length": "30"}	["debug_000002"]											
		FP	1	org.apache.hadoop.hbase.io.TestFileLink#testHDFSLinkReadDuringDelete	java.lang.AssertionError	expected:<1> but was:<0>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.hbase.io.TestFileLink.dataVerify(TestFileLink.java:337), org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete(TestFileLink.java:286), org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete$$CONFUZZ(TestFileLink.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.TestFileLink/testHDFSLinkReadDuringDelete/campaign/failures/debug_000003	{"dfs.datanode.transferTo.allowed": "false"}	["debug_000003"]											
	Bug-260	BUG	1	org.apache.hadoop.hbase.io.TestFileLink#testHDFSLinkReadDuringDelete	java.lang.NegativeArraySizeException	-1872267529	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:54), org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:191), org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:247), org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:313), org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1230), org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1209), org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1147), org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533), org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:530), org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81), org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:544), org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:471), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1125), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1105), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:994), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:982), org.apache.hadoop.hbase.io.TestFileLink.writeSomeData(TestFileLink.java:320), org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete(TestFileLink.java:268), org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete$$CONFUZZ(TestFileLink.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.TestFileLink/testHDFSLinkReadDuringDelete/campaign/failures/debug_000000	{"dfs.bytes-per-checksum": "269188863"}	["debug_000000"]											
		FP	1	org.apache.hadoop.hbase.TestHBaseTestingUtility#testMiniZooKeeperWithMultipleClientPorts	java.io.IOException	Waiting for startup of standalone server; server isRunning=true	org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(MiniZooKeeperCluster.java:265), org.apache.hadoop.hbase.HBaseZKTestingUtility.startMiniZKCluster(HBaseZKTestingUtility.java:129), org.apache.hadoop.hbase.HBaseZKTestingUtility.startMiniZKCluster(HBaseZKTestingUtility.java:102), org.apache.hadoop.hbase.TestHBaseTestingUtility.testMiniZooKeeperWithMultipleClientPorts(TestHBaseTestingUtility.java:341), org.apache.hadoop.hbase.TestHBaseTestingUtility.testMiniZooKeeperWithMultipleClientPorts$$CONFUZZ(TestHBaseTestingUtility.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.TestHBaseTestingUtility/testMiniZooKeeperWithMultipleClientPorts/campaign/failures/debug_000000	{"hbase.zookeeper.property.maxClientCnxns": "9096", "zookeeper.session.timeout.localHBaseCluster": "17"}	["debug_000000"]											
		Not-Reproducible	1	org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler#testHandlerIsolation	org.mockito.exceptions.verification.WantedButNotInvoked	Wanted but not invoked:callRunner.run();-> at org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation(TestSimpleRpcScheduler.java:221)However, there were exactly 2 interactions with this mock:callRunner.setStatus(    test: status=status unset, state=WAITING, startTime=1694834242521, completionTime=-1);-> at org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation(TestSimpleRpcScheduler.java:208)callRunner.getRpcCall();-> at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.dispatch(SimpleRpcScheduler.java:197)	org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation(TestSimpleRpcScheduler.java:221), org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation$$CONFUZZ(TestSimpleRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler/testHandlerIsolation/campaign/failures/debug_000000	{"hbase.ipc.server.callqueue.type": "fifo"}	["debug_000000"]											
	Bug-261	BUG	1	org.apache.hadoop.hbase.wal.TestWALMethods#testGetSplitEditFilesSorted	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.hbase.wal.BoundedGroupingStrategy.init(BoundedGroupingStrategy.java:65), org.apache.hadoop.hbase.wal.RegionGroupingProvider.getStrategy(RegionGroupingProvider.java:106), org.apache.hadoop.hbase.wal.RegionGroupingProvider.init(RegionGroupingProvider.java:159), org.apache.hadoop.hbase.wal.WALFactory.createProvider(WALFactory.java:165), org.apache.hadoop.hbase.wal.WALFactory.getProvider(WALFactory.java:180), org.apache.hadoop.hbase.wal.WALFactory.<init>(WALFactory.java:207), org.apache.hadoop.hbase.wal.WALFactory.<init>(WALFactory.java:186), org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted(TestWALMethods.java:105), org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted$$CONFUZZ(TestWALMethods.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.wal.TestWALMethods/testGetSplitEditFilesSorted/campaign/failures/debug_000004	{"hbase.wal.provider": "multiwal", "hbase.wal.regiongrouping.numgroups": "2130640638"}	["debug_000004"]											
		FP	1	org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter#test	java.lang.AssertionError	expected:<3> but was:<0>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test(TestHFileProcedurePrettyPrinter.java:148), org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test$$CONFUZZ(TestHFileProcedurePrettyPrinter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter/test/campaign/failures/debug_000004	{"hbase.master.store.region.flush.size": "767", "hbase.hregion.memstore.block.multiplier": "498"}	["debug_000004"]											
	Bug-263	BUG	1	org.apache.hadoop.hbase.ipc.TestBlockingIPC#testAsyncEcho	java.lang.OutOfMemoryError	Java heap space	java.base/java.util.ArrayDeque.<init>(ArrayDeque.java:196), org.apache.hadoop.hbase.ipc.BlockingRpcConnection$CallSender.<init>(BlockingRpcConnection.java:144), org.apache.hadoop.hbase.ipc.BlockingRpcConnection.<init>(BlockingRpcConnection.java:239), org.apache.hadoop.hbase.ipc.BlockingRpcClient.createConnection(BlockingRpcClient.java:67), org.apache.hadoop.hbase.ipc.BlockingRpcClient.createConnection(BlockingRpcClient.java:34), org.apache.hadoop.hbase.ipc.AbstractRpcClient.lambda$getConnection$0(AbstractRpcClient.java:364), org.apache.hadoop.hbase.ipc.AbstractRpcClient$$Lambda$207/0x0000000840337040.get(Unknown Source), org.apache.hadoop.hbase.util.PoolMap.createResource(PoolMap.java:127), org.apache.hadoop.hbase.util.PoolMap$RoundRobinPool.getOrCreate(PoolMap.java:211), org.apache.hadoop.hbase.util.PoolMap.getOrCreate(PoolMap.java:68), org.apache.hadoop.hbase.ipc.AbstractRpcClient.getConnection(AbstractRpcClient.java:364), org.apache.hadoop.hbase.ipc.AbstractRpcClient.callMethod(AbstractRpcClient.java:444), org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$300(AbstractRpcClient.java:92), org.apache.hadoop.hbase.ipc.AbstractRpcClient$RpcChannelImplementation.callMethod(AbstractRpcClient.java:618), org.apache.hadoop.hbase.shaded.ipc.protobuf.generated.TestRpcServiceProtos$TestProtobufRpcProto$Stub.echo(TestRpcServiceProtos.java:378), org.apache.hadoop.hbase.ipc.AbstractTestIPC.testAsyncEcho(AbstractTestIPC.java:366), org.apache.hadoop.hbase.ipc.TestBlockingIPC.testAsyncEcho$$CONFUZZ(TestBlockingIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.ipc.TestBlockingIPC/testAsyncEcho/campaign/failures/debug_000002	{"hbase.ipc.client.write.queueSize": "2083421821", "hbase.ipc.client.specificThreadForWriting": "true"}	["debug_000002"]											
		FP	1	org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter#test	java.lang.AssertionError	expected:<3> but was:<0>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test(TestHFileProcedurePrettyPrinter.java:148), org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test$$CONFUZZ(TestHFileProcedurePrettyPrinter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter/test/campaign/failures/debug_000001	{"hbase.master.store.region.flush.per.changes": "7"}	["debug_000001"]											
		FP	1	org.apache.hadoop.hbase.io.TestFileLink#testGetUnderlyingFSDataInputStream	org.apache.hadoop.ipc.RemoteException	Exceeded the configured number of objects 79 in the filesystem.        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkFsObjectLimit(FSNamesystem.java:4865)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.analyzeFileState(FSDirWriteFileOp.java:596)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.validateAddBlock(FSDirWriteFileOp.java:171)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2808)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:910)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:577)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:549)        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:518)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2960)	org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612), org.apache.hadoop.ipc.Client.call(Client.java:1558), org.apache.hadoop.ipc.Client.call(Client.java:1455), org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:231), org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118), com.sun.proxy.$Proxy35.addBlock(Unknown Source), org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:520), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:433), org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:166), org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:158), org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:96), org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:362), com.sun.proxy.$Proxy36.addBlock(Unknown Source), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:361), com.sun.proxy.$Proxy39.addBlock(Unknown Source), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:361), com.sun.proxy.$Proxy39.addBlock(Unknown Source), org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1082), org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1898), org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1700), org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:707),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.TestFileLink/testGetUnderlyingFSDataInputStream/campaign/failures/debug_000005	{"dfs.namenode.max.objects": "79"}	["debug_000005"]											
	Bug-187	BUG	1	org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidatorTest#testTableValidJar	java.lang.OutOfMemoryError	Requested array size exceeds VM limit	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:322), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:353), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:407), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:466), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:445), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1125), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1105), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:994), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:420), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:393), org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:343), org.apache.hadoop.fs.LocalFileSystem.copyToLocalFile(LocalFileSystem.java:88), org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2408), org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidator.createClassLoader(CoprocessorValidator.java:116), org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidator.validateTables(CoprocessorValidator.java:180), org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidatorTest.validateTable(CoprocessorValidatorTest.java:198), org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidatorTest.testTableValidJar(CoprocessorValidatorTest.java:250), org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidatorTest.testTableValidJar$$CONFUZZ(CoprocessorValidatorTest.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidatorTest/testTableValidJar/campaign/failures/debug_000003	{"file.stream-buffer-size": "2147483646"}	["debug_000003"]											
		FP	1	org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan#testReverseScanWithoutPadding	java.lang.IllegalArgumentException	hbase.hregion.memstore.mslab.max.allocation must be less than hbase.hregion.memstore.mslab.chunksize	org.apache.hbase.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:145), org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.<init>(MemStoreLABImpl.java:105), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:55), org.apache.hadoop.hbase.util.ReflectionUtils.instantiateWithCustomCtor(ReflectionUtils.java:43), org.apache.hadoop.hbase.regionserver.MemStoreLAB.newInstance(MemStoreLAB.java:116), org.apache.hadoop.hbase.regionserver.SegmentFactory.createMutableSegment(SegmentFactory.java:81), org.apache.hadoop.hbase.regionserver.AbstractMemStore.resetActive(AbstractMemStore.java:93), org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:83), org.apache.hadoop.hbase.regionserver.CompactingMemStore.<init>(CompactingMemStore.java:106), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:55), org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:92), org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:378), org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:280), org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:6359), org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1114), org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1111), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128), java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan/testReverseScanWithoutPadding/campaign/failures/debug_000010	{"hbase.hregion.memstore.mslab.max.allocation": "2130640638", "hbase.hregion.compacting.memstore.type": "eager"}	["debug_000010"]											
		FP	1	org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler#testHandlerIsolation	org.mockito.exceptions.verification.WantedButNotInvoked	Wanted but not invoked:callRunner.run();-> at org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation(TestSimpleRpcScheduler.java:221)However, there were exactly 2 interactions with this mock:callRunner.setStatus(    test: status=status unset, state=WAITING, startTime=1694795796396, completionTime=-1);-> at org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation(TestSimpleRpcScheduler.java:208)callRunner.getRpcCall();-> at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.dispatch(SimpleRpcScheduler.java:197)	org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation(TestSimpleRpcScheduler.java:221), org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation$$CONFUZZ(TestSimpleRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler/testHandlerIsolation/campaign/failures/debug_000000	{"hbase.ipc.server.metacallqueue.read.ratio": "-0.06771010160446167"}	["debug_000000"]											
		FP	1	org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan#testReverseScanWithPadding	java.lang.IllegalArgumentException	Invalid hbase.busy.wait.duration (0) or hbase.busy.wait.multiplier.max (2). Their product should be positive	org.apache.hadoop.hbase.regionserver.HRegion.<init>(HRegion.java:819), org.apache.hadoop.hbase.regionserver.HRegion.<init>(HRegion.java:734), java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490), org.apache.hadoop.hbase.regionserver.HRegion.newHRegion(HRegion.java:6969), org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:7008), org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:6987), org.apache.hadoop.hbase.HBaseTestingUtility.createRegionAndWAL(HBaseTestingUtility.java:2625), org.apache.hadoop.hbase.HBaseTestingUtility.createRegionAndWAL(HBaseTestingUtility.java:2588), org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan.setUp(TestSeekBeforeWithReverseScan.java:69), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan/testReverseScanWithPadding/campaign/failures/debug_000005	{"hbase.busy.wait.duration": "0"}	["debug_000005"]											
	Bug-169	BUG	1	org.apache.hadoop.hbase.wal.TestWALMethods#testGetSplitEditFilesSorted	java.lang.ArithmeticException	/ by zero	org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.calculateMaxLogFiles(AbstractFSWAL.java:353), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.<init>(AbstractFSWAL.java:463), org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.<init>(AsyncFSWAL.java:218), org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:78), org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:49), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:157), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62), org.apache.hadoop.hbase.wal.RegionGroupingProvider.getWAL(RegionGroupingProvider.java:195), org.apache.hadoop.hbase.wal.RegionGroupingProvider.getWAL(RegionGroupingProvider.java:215), org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300), org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted(TestWALMethods.java:105), org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted$$CONFUZZ(TestWALMethods.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.wal.TestWALMethods/testGetSplitEditFilesSorted/campaign/failures/debug_000006	{"hbase.regionserver.hlog.blocksize": "0", "hbase.wal.provider": "multiwal"}	["debug_000006"]											
	Bug-265	BUG	1	org.apache.hadoop.hbase.io.hfile.TestHFileSeek#testSeeks	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.seek(FSInputChecker.java:441), org.apache.hadoop.fs.FSDataInputStream.seek(FSDataInputStream.java:65), org.apache.hadoop.fs.ChecksumFileSystem$FSDataBoundedInputStream.seek(ChecksumFileSystem.java:333), org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.readFromStream(FixedFileTrailer.java:391), org.apache.hadoop.hbase.io.hfile.HFileInfo.initTrailerAndContext(HFileInfo.java:339), org.apache.hadoop.hbase.io.hfile.HFileInfo.<init>(HFileInfo.java:123), org.apache.hadoop.hbase.io.hfile.TestHFile.createReaderFromStream(TestHFile.java:125), org.apache.hadoop.hbase.io.hfile.TestHFileSeek.seekTFile(TestHFileSeek.java:175), org.apache.hadoop.hbase.io.hfile.TestHFileSeek.testSeeks(TestHFileSeek.java:210), org.apache.hadoop.hbase.io.hfile.TestHFileSeek.testSeeks$$CONFUZZ(TestHFileSeek.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.hfile.TestHFileSeek/testSeeks/campaign/failures/debug_000004	{"file.bytes-per-checksum": "2144534922"}	["debug_000004"]											
		FP	1	org.apache.hadoop.hbase.io.TestFileLink#testHDFSLinkReadDuringDelete	java.io.IOException	Unexpected configuration parameters: dfs.namenode.replication.min = 234 > dfs.replication.max = 2	org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:510), org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:831), org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:767), org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1209), org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:427), org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:260), org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1117), org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1001), org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:933), org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:849), org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:685), org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:665), org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:638), org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete(TestFileLink.java:259), org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete$$CONFUZZ(TestFileLink.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.TestFileLink/testHDFSLinkReadDuringDelete/campaign/failures/debug_000006	{"dfs.namenode.replication.min": "234", "dfs.replication.max": "2"}	["debug_000006"]											
		Not-Reproducible	1	org.apache.hadoop.hbase.filter.TestDependentColumnFilter#testToStringWithNullComparator	java.lang.RuntimeException		org.apache.hadoop.hbase.regionserver.wal.AsyncProtobufLogWriter.writeWALMetadata(AsyncProtobufLogWriter.java:219), org.apache.hadoop.hbase.regionserver.wal.AsyncProtobufLogWriter.writeMagicAndWALHeader(AsyncProtobufLogWriter.java:225), org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.init(AbstractProtobufLogWriter.java:188), org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createAsyncWriter(AsyncFSWALProvider.java:117), org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:698), org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:128), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriterInternal(AbstractFSWAL.java:861), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.lambda$rollWriter$8(AbstractFSWAL.java:893), org.apache.hadoop.hbase.trace.TraceUtil.trace(TraceUtil.java:216), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:893), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:548), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.init(AbstractFSWAL.java:489), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:160), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62), org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300), org.apache.hadoop.hbase.HBaseTestingUtility.createWal(HBaseTestingUtility.java:2579), org.apache.hadoop.hbase.HBaseTestingUtility.createRegionAndWAL(HBaseTestingUtility.java:2624), org.apache.hadoop.hbase.HBaseTestingUtility.createRegionAndWAL(HBaseTestingUtility.java:2588), org.apache.hadoop.hbase.filter.TestDependentColumnFilter.setUp(TestDependentColumnFilter.java:89), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.filter.TestDependentColumnFilter/testToStringWithNullComparator/campaign/failures/debug_000000	{"hbase.hfile.drop.behind.compaction": "false", "hbase.regionserver.logroll.wait.timeout.ms": "0"}	["debug_000000"]											
	Bug-266	BUG	1	org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter#test	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.hbase.io.ByteArrayOutputStream.checkSizeAndGrow(ByteArrayOutputStream.java:93), org.apache.hadoop.hbase.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:74), java.base/java.io.DataOutputStream.write(DataOutputStream.java:107), org.apache.hadoop.hbase.util.BloomFilterChunk.writeBloom(BloomFilterChunk.java:290), org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.writeInlineBlock(CompoundBloomFilterWriter.java:210), org.apache.hadoop.hbase.io.hfile.HFileWriterImpl.writeInlineBlocks(HFileWriterImpl.java:522), org.apache.hadoop.hbase.io.hfile.HFileWriterImpl.close(HFileWriterImpl.java:599), org.apache.hadoop.hbase.regionserver.StoreFileWriter.close(StoreFileWriter.java:378), org.apache.hadoop.hbase.regionserver.StoreFlusher.finalizeWriter(StoreFlusher.java:69), org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:74), org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:822), org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1963), org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2838), org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2580), org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2552), org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2422), org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2345), org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:2315), org.apache.hadoop.hbase.master.region.MasterRegion.flush(MasterRegion.java:166), org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test(TestHFileProcedurePrettyPrinter.java:97), org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test$$CONFUZZ(TestHFileProcedurePrettyPrinter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter/test/campaign/failures/debug_000003	{"io.storefile.bloom.block.size": "1913015228", "io.storefile.bloom.error.rate": "0.2502479553222656"}	["debug_000003"]											
		FP	1	org.apache.hadoop.hbase.wal.TestWALMethods#testGetSplitEditFilesSorted	java.lang.NoSuchMethodException	org.apache.hadoop.hbase.codec.KeyValueCodec.<init>(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.wal.CompressionContext)	java.base/java.lang.Class.getConstructor0(Class.java:3349), java.base/java.lang.Class.getDeclaredConstructor(Class.java:2553), org.apache.hadoop.hbase.util.ReflectionUtils.instantiateWithCustomCtor(ReflectionUtils.java:42), org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.create(WALCellCodec.java:102), org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.getCodec(AbstractProtobufLogWriter.java:75), org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.initAfterHeader0(AbstractProtobufLogWriter.java:208), org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.secureInitAfterHeader(AbstractProtobufLogWriter.java:231), org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter.initAfterHeader(SecureProtobufLogWriter.java:46), org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.init(AbstractProtobufLogWriter.java:191), org.apache.hadoop.hbase.wal.FSHLogProvider.createWriter(FSHLogProvider.java:79), org.apache.hadoop.hbase.regionserver.wal.FSHLog.createWriterInstance(FSHLog.java:310), org.apache.hadoop.hbase.regionserver.wal.FSHLog.createWriterInstance(FSHLog.java:71), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriterInternal(AbstractFSWAL.java:861), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.lambda$rollWriter$8(AbstractFSWAL.java:893), org.apache.hadoop.hbase.trace.TraceUtil.trace(TraceUtil.java:216), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:893), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:548), org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.init(AbstractFSWAL.java:489), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:160), org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62), org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300), org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted(TestWALMethods.java:105), org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted$$CONFUZZ(TestWALMethods.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.wal.TestWALMethods/testGetSplitEditFilesSorted/campaign/failures/debug_000003	{"hbase.regionserver.hlog.writer.impl": "org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter", "hbase.wal.provider": "filesystem", "hbase.regionserver.wal.codec": "org.apache.hadoop.hbase.codec.KeyValueCodec"}	["debug_000003"]											
	Bug-267	BUG	1	org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter#test	java.lang.ArithmeticException	/ by zero	org.apache.hadoop.hbase.util.BloomFilterUtil.optimalFunctionCount(BloomFilterUtil.java:141), org.apache.hadoop.hbase.util.BloomFilterUtil.createBySize(BloomFilterUtil.java:164), org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.allocateNewChunk(CompoundBloomFilterWriter.java:188), org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.append(CompoundBloomFilterWriter.java:165), org.apache.hadoop.hbase.util.BloomContext.writeBloom(BloomContext.java:51), org.apache.hadoop.hbase.regionserver.StoreFileWriter.appendDeleteFamilyBloomFilter(StoreFileWriter.java:295), org.apache.hadoop.hbase.regionserver.StoreFileWriter.append(StoreFileWriter.java:302), org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(StoreFlusher.java:139), org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:65), org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:822), org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1963), org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2838), org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2580), org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2552), org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2422), org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2345), org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:2315), org.apache.hadoop.hbase.master.region.MasterRegion.flush(MasterRegion.java:166), org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test(TestHFileProcedurePrettyPrinter.java:103), org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test$$CONFUZZ(TestHFileProcedurePrettyPrinter.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter/test/campaign/failures/debug_000003	{"io.storefile.bloom.error.rate": "-0.36717891693115234", "io.storefile.bloom.enabled": "false"}	["debug_000003"]											
		FP	1	org.apache.hadoop.hbase.fs.TestBlockReorder#testBlockLocationReorder	java.io.IOException	Timed out waiting for Mini HDFS Cluster to start	org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1488), org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:958), org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:849), org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:685), org.apache.hadoop.hbase.fs.TestBlockReorder.setUp(TestBlockReorder.java:84), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.fs.TestBlockReorder/testBlockLocationReorder/campaign/failures/debug_000002	{"dfs.datanode.directoryscan.interval": "10795057"}	["debug_000002"]											
	Bug-129	BUG	1	org.apache.hadoop.hbase.io.hfile.TestHFile#testReaderWithTinyLfuCombinedBlockCache	java.lang.NullPointerException		org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderCombinedCache(TestHFile.java:1060), org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithTinyLfuCombinedBlockCache(TestHFile.java:1011), org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithTinyLfuCombinedBlockCache$$CONFUZZ(TestHFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.hfile.TestHFile/testReaderWithTinyLfuCombinedBlockCache/campaign/failures/debug_000008	{"hbase.writer.unified.encoded.blocksize.ratio": "0.0"}	["debug_000008"]											
	Bug-263	BUG	1	org.apache.hadoop.hbase.ipc.TestBlockingIPC#testAsyncEcho	java.lang.OutOfMemoryError	Java heap space	java.base/java.util.ArrayDeque.<init>(ArrayDeque.java:196), org.apache.hadoop.hbase.ipc.BlockingRpcConnection$CallSender.<init>(BlockingRpcConnection.java:144), org.apache.hadoop.hbase.ipc.BlockingRpcConnection.<init>(BlockingRpcConnection.java:239), org.apache.hadoop.hbase.ipc.BlockingRpcClient.createConnection(BlockingRpcClient.java:67), org.apache.hadoop.hbase.ipc.BlockingRpcClient.createConnection(BlockingRpcClient.java:34), org.apache.hadoop.hbase.ipc.AbstractRpcClient.lambda$getConnection$0(AbstractRpcClient.java:364), org.apache.hadoop.hbase.ipc.AbstractRpcClient$$Lambda$207/0x0000000840337040.get(Unknown Source), org.apache.hadoop.hbase.util.PoolMap.createResource(PoolMap.java:127), org.apache.hadoop.hbase.util.PoolMap$ThreadLocalPool.getOrCreate(PoolMap.java:268), org.apache.hadoop.hbase.util.PoolMap.getOrCreate(PoolMap.java:68), org.apache.hadoop.hbase.ipc.AbstractRpcClient.getConnection(AbstractRpcClient.java:364), org.apache.hadoop.hbase.ipc.AbstractRpcClient.callMethod(AbstractRpcClient.java:444), org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$300(AbstractRpcClient.java:92), org.apache.hadoop.hbase.ipc.AbstractRpcClient$RpcChannelImplementation.callMethod(AbstractRpcClient.java:618), org.apache.hadoop.hbase.shaded.ipc.protobuf.generated.TestRpcServiceProtos$TestProtobufRpcProto$Stub.echo(TestRpcServiceProtos.java:378), org.apache.hadoop.hbase.ipc.AbstractTestIPC.testAsyncEcho(AbstractTestIPC.java:366), org.apache.hadoop.hbase.ipc.TestBlockingIPC.testAsyncEcho$$CONFUZZ(TestBlockingIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.ipc.TestBlockingIPC/testAsyncEcho/campaign/failures/debug_000003	{"hbase.ipc.client.specificThreadForWriting": "true", "hbase.client.ipc.pool.type": "thread-local", "hbase.ipc.client.write.queueSize": "1855534301"}	["debug_000003"]											
		FP	1	org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan#testReverseScanWithPadding	org.apache.hadoop.hbase.RegionTooBusyException	Over memstore limit=0, regionName=5b9f2d5b640f2969d309ad528a401005, server=unknown	org.apache.hadoop.hbase.regionserver.HRegion.checkResources(HRegion.java:4966), org.apache.hadoop.hbase.regionserver.HRegion.lambda$put$7(HRegion.java:3137), org.apache.hadoop.hbase.trace.TraceUtil.trace(TraceUtil.java:216), org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3130), org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan.testReverseScanWithPadding(TestSeekBeforeWithReverseScan.java:129), org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan.testReverseScanWithPadding$$CONFUZZ(TestSeekBeforeWithReverseScan.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan/testReverseScanWithPadding/campaign/failures/debug_000005	{"hbase.hregion.memstore.block.multiplier": "0"}	["debug_000005"]											
	Bug-268	BUG	1	org.apache.hadoop.hbase.io.TestFileLink#testHDFSLinkReadDuringDelete	java.lang.OutOfMemoryError	Java heap space	java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270), java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254), org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5089), org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:587), org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:831), org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:767), org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1209), org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:427), org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:260), org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1117), org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1001), org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:933), org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:849), org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:685), org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:665), org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:638), org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete(TestFileLink.java:259), org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete$$CONFUZZ(TestFileLink.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hbase/hbase-server/target/meringue/org.apache.hadoop.hbase.io.TestFileLink/testHDFSLinkReadDuringDelete/campaign/failures/debug_000008	{"dfs.namenode.blocks.per.postponedblocks.rescan": "595821979", "dfs.namenode.blockreport.queue.size": "1208011039"}	["debug_000008"]											
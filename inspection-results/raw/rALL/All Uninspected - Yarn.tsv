note	bugId	status	times	testName	failure	failureMessage	stackTrace	reproStatus	replayedFailure	replayedErrorMessage	replayedStackTrace	replayedFile	minConfig	debugFiles																						
	Bug-11	BUG	2	org.apache.hadoop.yarn.webapp.TestWebApp#testDefaultRoutes	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.yarn.webapp.WebApps$Builder.build(WebApps.java:372), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:465), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:461), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:457), org.apache.hadoop.yarn.webapp.TestWebApp.testDefaultRoutes(TestWebApp.java:221), org.apache.hadoop.yarn.webapp.TestWebApp.testDefaultRoutes$$CONFUZZ(TestWebApp.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.webapp.TestWebApp/testDefaultRoutes/campaign/failures/debug_000001	{"yarn.http.policy": "HTTPS_ONLY", "hadoop.http.selector.count": "1797431237"}	["debug_000001"]	org.apache.hadoop.yarn.webapp.TestWebApp#testCreateWithPort	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.yarn.webapp.WebApps$Builder.build(WebApps.java:372), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:465), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:461), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:457), org.apache.hadoop.yarn.webapp.TestWebApp.testCreateWithPort(TestWebApp.java:160), org.apache.hadoop.yarn.webapp.TestWebApp.testCreateWithPort$$CONFUZZ(TestWebApp.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.webapp.TestWebApp/testCreateWithPort/campaign/failures/debug_000003	{"yarn.http.policy": "HTTPS_ONLY", "hadoop.http.selector.count": "1935643601"}	["debug_000003"]											
	Hardcode Assertion	FP	1	org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC#testHadoopProtoRPCTimeout	org.junit.ComparisonFailure	Error, exception is not: java.net.SocketTimeoutException expected:<[java.net.SocketTimeout]Exception> but was:<[org.apache.hadoop.security.AccessControl]Exception>	org.junit.Assert.assertEquals(Assert.java:117), org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testRPCTimeout(TestContainerResourceIncreaseRPC.java:125), org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testHadoopProtoRPCTimeout(TestContainerResourceIncreaseRPC.java:82), org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testHadoopProtoRPCTimeout$$CONFUZZ(TestContainerResourceIncreaseRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC/testHadoopProtoRPCTimeout/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos"}	["debug_000000"]																						
	Hardcode Assertion	FP	2	org.apache.hadoop.yarn.util.resource.TestResourceUtils#testGetResourceTypesConfigs	java.lang.AssertionError	expected:<2> but was:<3>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.yarn.util.resource.TestResourceUtils.testGetResourceTypesConfigs(TestResourceUtils.java:186), org.apache.hadoop.yarn.util.resource.TestResourceUtils.testGetResourceTypesConfigs$$CONFUZZ(TestResourceUtils.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:258), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.util.resource.TestResourceUtils/testGetResourceTypesConfigs/campaign/failures/debug_000001	{"yarn.resource-types": "resource1"}	["debug_000001"]	org.apache.hadoop.yarn.util.resource.TestResources#testCompareToWithUnboundedResource	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertTrue(Assert.java:53), org.apache.hadoop.yarn.util.resource.TestResources.testCompareToWithUnboundedResource(TestResources.java:103), org.apache.hadoop.yarn.util.resource.TestResources.testCompareToWithUnboundedResource$$CONFUZZ(TestResources.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.util.resource.TestResources/testCompareToWithUnboundedResource/campaign/failures/debug_000000	{"yarn.resource-types": "resource2"}	["debug_000000"]											
	Bug-204	BUG	3	org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat#testReadAcontainerLogs1	java.lang.OutOfMemoryError	Requested array size exceeds VM limit	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogWriter.writeVersion(AggregatedLogFormat.java:499), org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogWriter.initialize(AggregatedLogFormat.java:490), org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat.testReadAcontainerLog(TestAggregatedLogFormat.java:237), org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat.testReadAcontainerLogs1(TestAggregatedLogFormat.java:203), org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat.testReadAcontainerLogs1$$CONFUZZ(TestAggregatedLogFormat.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat/testReadAcontainerLogs1/campaign/failures/debug_000000	{"tfile.fs.output.buffer.size": "2147483646"}	["debug_000000"]	org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock#testAccessDenied	java.lang.OutOfMemoryError	Requested array size exceeds VM limit	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogWriter.close(AggregatedLogFormat.java:547), org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController.closeWriter(LogAggregationTFileController.java:99), org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.writeLog(TestAggregatedLogsBlock.java:354), org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testAccessDenied(TestAggregatedLogsBlock.java:83), org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testAccessDenied$$CONFUZZ(TestAggregatedLogsBlock.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock/testAccessDenied/campaign/failures/debug_000003	{"tfile.fs.output.buffer.size": "2147483646"}	["debug_000003"]	org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock#testNoLogs	java.lang.OutOfMemoryError	Requested array size exceeds VM limit	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.yarn.logaggregation.AggregatedLogFormat$LogWriter.close(AggregatedLogFormat.java:547), org.apache.hadoop.yarn.logaggregation.filecontroller.tfile.LogAggregationTFileController.closeWriter(LogAggregationTFileController.java:99), org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.writeLog(TestAggregatedLogsBlock.java:354), org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testNoLogs(TestAggregatedLogsBlock.java:250), org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testNoLogs$$CONFUZZ(TestAggregatedLogsBlock.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock/testNoLogs/campaign/failures/debug_000001	{"tfile.fs.output.buffer.size": "2147483646"}	["debug_000001"]
	Hardcode Assertion	FP	1	org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5#testPostEntities	java.lang.AssertionError		 	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5/testPostEntities/campaign/failures/debug_000001	{"yarn.timeline-service.entity-group-fs-store.with-user-dir": "true"}	["debug_000001"]																						
	Bug-8	BUG	1	org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5#testPutDomain	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$DomainLogFD.<init>(FileSystemTimelineWriter.java:298), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeDomainLog(FileSystemTimelineWriter.java:753), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.writeDomain(FileSystemTimelineWriter.java:291), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putDomain(FileSystemTimelineWriter.java:255), org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putDomain(TimelineClientImpl.java:426),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5/testPutDomain/campaign/failures/debug_000002	{"yarn.timeline-service.client.internal-attempt-dir-cache-size": "1010569524", "file.stream-buffer-size": "1973613242"}	["debug_000002"]																						
	Hardcode Assertion	FP	1	org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5#testPutDomain	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertTrue(Assert.java:53), org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.verifyForPutDomain(TestTimelineClientForATS1_5.java:203), org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPutDomain(TestTimelineClientForATS1_5.java:176), org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPutDomain$$CONFUZZ(TestTimelineClientForATS1_5.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5/testPutDomain/campaign/failures/debug_000001	{"yarn.timeline-service.entity-group-fs-store.with-user-dir": "true"}	["debug_000001"]																						
	Bug-7	BUG	1	org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5#testPutDomain	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$DomainLogFD.<init>(FileSystemTimelineWriter.java:298), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeDomainLog(FileSystemTimelineWriter.java:753), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.writeDomain(FileSystemTimelineWriter.java:291), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putDomain(FileSystemTimelineWriter.java:255), org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putDomain(TimelineClientImpl.java:426),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5/testPutDomain/campaign/failures/debug_000003	{"yarn.timeline-service.client.internal-attempt-dir-cache-size": "760520203", "io.file.buffer.size": "2130640638"}	["debug_000003"]																						
	Bug-118	BUG	1	org.apache.hadoop.yarn.nodelabels.TestCommonNodeLabelsManager#testAddReplaceRemoveLabelsOnNodes	java.lang.NullPointerException		org.apache.hadoop.yarn.nodelabels.NodeLabelTestBase.assertMapEquals(NodeLabelTestBase.java:38), org.apache.hadoop.yarn.nodelabels.TestCommonNodeLabelsManager.testAddReplaceRemoveLabelsOnNodes(TestCommonNodeLabelsManager.java:230), org.apache.hadoop.yarn.nodelabels.TestCommonNodeLabelsManager.testAddReplaceRemoveLabelsOnNodes$$CONFUZZ(TestCommonNodeLabelsManager.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.nodelabels.TestCommonNodeLabelsManager/testAddReplaceRemoveLabelsOnNodes/campaign/failures/debug_000000	{"yarn.node-labels.configuration-type": "delegated-centralized"}	["debug_000000"]																						
	Bug-175	BUG	1	org.apache.hadoop.yarn.webapp.util.TestWebAppUtils#testGetPassword	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.security.alias.KeyStoreProvider.getInputStreamForFile(KeyStoreProvider.java:65), org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.locateKeystore(AbstractJavaKeyStoreProvider.java:325), org.apache.hadoop.security.alias.AbstractJavaKeyStoreProvider.<init>(AbstractJavaKeyStoreProvider.java:86), org.apache.hadoop.security.alias.KeyStoreProvider.<init>(KeyStoreProvider.java:49), org.apache.hadoop.security.alias.JavaKeyStoreProvider.<init>(JavaKeyStoreProvider.java:42), org.apache.hadoop.security.alias.JavaKeyStoreProvider.<init>(JavaKeyStoreProvider.java:35), org.apache.hadoop.security.alias.JavaKeyStoreProvider$Factory.createProvider(JavaKeyStoreProvider.java:68), org.apache.hadoop.security.alias.CredentialProviderFactory.getProviders(CredentialProviderFactory.java:91), org.apache.hadoop.conf.Configuration.getPasswordFromCredentialProviders(Configuration.java:2506), org.apache.hadoop.conf.Configuration.getPassword(Configuration.java:2444), org.apache.hadoop.yarn.webapp.util.WebAppUtils.getPassword(WebAppUtils.java:489), org.apache.hadoop.yarn.webapp.util.TestWebAppUtils.testGetPassword(TestWebAppUtils.java:99), org.apache.hadoop.yarn.webapp.util.TestWebAppUtils.testGetPassword$$CONFUZZ(TestWebAppUtils.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.webapp.util.TestWebAppUtils/testGetPassword/campaign/failures/debug_000001	{"file.bytes-per-checksum": "2029551709", "io.file.buffer.size": "1327544759"}	["debug_000001"]																						
	Hardcode Assertion	FP	1	org.apache.hadoop.yarn.TestContainerLaunchRPC#testHadoopProtoRPCTimeout	org.junit.ComparisonFailure	Error, exception is not: java.net.SocketTimeoutException expected:<[java.net.SocketTimeout]Exception> but was:<[org.apache.hadoop.security.AccessControl]Exception>	org.junit.Assert.assertEquals(Assert.java:117), org.apache.hadoop.yarn.TestContainerLaunchRPC.testRPCTimeout(TestContainerLaunchRPC.java:139), org.apache.hadoop.yarn.TestContainerLaunchRPC.testHadoopProtoRPCTimeout(TestContainerLaunchRPC.java:90), org.apache.hadoop.yarn.TestContainerLaunchRPC.testHadoopProtoRPCTimeout$$CONFUZZ(TestContainerLaunchRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.TestContainerLaunchRPC/testHadoopProtoRPCTimeout/campaign/failures/debug_000000	{"hadoop.security.authentication": "kerberos"}	["debug_000000"]																						
	Hardcode Assertion	FP	1	org.apache.hadoop.yarn.client.TestClientRMProxy#testProxyUserCorrectUGI	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertNotNull(Assert.java:713), org.junit.Assert.assertNotNull(Assert.java:723), org.apache.hadoop.yarn.client.TestClientRMProxy.assertUGI(TestClientRMProxy.java:164), org.apache.hadoop.yarn.client.TestClientRMProxy.testProxyUserCorrectUGI(TestClientRMProxy.java:158), org.apache.hadoop.yarn.client.TestClientRMProxy.testProxyUserCorrectUGI$$CONFUZZ(TestClientRMProxy.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.TestClientRMProxy/testProxyUserCorrectUGI/campaign/failures/debug_000000	{"yarn.client.failover-proxy-provider": "org.apache.hadoop.yarn.client.DefaultNoHARMFailoverProxyProvider"}	["debug_000000"]																						
	Hardcode Assertion	FP	1	org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5#testPostEntitiesToKeepUnderUserDir	java.lang.AssertionError	Exception is not expected. java.lang.IllegalArgumentException: Non-positive period.	org.junit.Assert.fail(Assert.java:89), org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.verifyForPostEntities(TestTimelineClientForATS1_5.java:169), org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPostEntitiesToKeepUnderUserDir(TestTimelineClientForATS1_5.java:109), org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPostEntitiesToKeepUnderUserDir$$CONFUZZ(TestTimelineClientForATS1_5.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5/testPostEntitiesToKeepUnderUserDir/campaign/failures/debug_000000	{"yarn.timeline-service.client.fd-clean-interval-secs": "0"}	["debug_000000"]																						
	invalid value	FP	1	org.apache.hadoop.yarn.webapp.TestWebApp#testYARNWebAppContext	java.lang.AssertionError	expected:<404> but was:<431>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.yarn.webapp.TestWebApp.testYARNWebAppContext(TestWebApp.java:333), org.apache.hadoop.yarn.webapp.TestWebApp.testYARNWebAppContext$$CONFUZZ(TestWebApp.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.webapp.TestWebApp/testYARNWebAppContext/campaign/failures/debug_000003	{"hadoop.http.max.request.header.size": "97"}	["debug_000003"]																						
	Bug-7, Bug-200	BUG	1	org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5#testPostEntities	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$EntityLogFD.<init>(FileSystemTimelineWriter.java:311), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.createSummaryFDAndWrite(FileSystemTimelineWriter.java:879), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeSummmaryEntityLogs(FileSystemTimelineWriter.java:863), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeSummaryEntityLogs(FileSystemTimelineWriter.java:842), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putEntities(FileSystemTimelineWriter.java:229),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5/testPostEntities/campaign/failures/debug_000002	{"io.file.buffer.size": "1474707349", "file.bytes-per-checksum": "1470175729"}	["debug_000002"]																						
	Bug-86	BUG	1	org.apache.hadoop.yarn.webapp.TestWebApp#testYARNWebAppContext	java.lang.IllegalStateException	Insufficient configured threads: required=0 < max=0 for QueuedThreadPool[qtp1741095319]@67c70197{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY]	org.eclipse.jetty.util.thread.ThreadPoolBudget.check(ThreadPoolBudget.java:165), org.eclipse.jetty.util.thread.QueuedThreadPool.setMaxThreads(QueuedThreadPool.java:364), org.apache.hadoop.http.HttpServer2.initializeWebServer(HttpServer2.java:703), org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:687), org.apache.hadoop.http.HttpServer2.<init>(HttpServer2.java:129), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:468), org.apache.hadoop.yarn.webapp.WebApps$Builder.build(WebApps.java:372), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:465), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:461), org.apache.hadoop.yarn.webapp.TestWebApp.testYARNWebAppContext(TestWebApp.java:325), org.apache.hadoop.yarn.webapp.TestWebApp.testYARNWebAppContext$$CONFUZZ(TestWebApp.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.webapp.TestWebApp/testYARNWebAppContext/campaign/failures/debug_000006	{"hadoop.http.max.threads": "0"}	["debug_000006"]																						
	Bug-2	BUG	1	org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5#testPostEntities	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$EntityLogFD.<init>(FileSystemTimelineWriter.java:311), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.createSummaryFDAndWrite(FileSystemTimelineWriter.java:879), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeSummmaryEntityLogs(FileSystemTimelineWriter.java:863), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeSummaryEntityLogs(FileSystemTimelineWriter.java:842), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putEntities(FileSystemTimelineWriter.java:229), org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities(TimelineClientImpl.java:416), org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.verifyForPostEntities(TestTimelineClientForATS1_5.java:151), org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPostEntities(TestTimelineClientForATS1_5.java:99),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5/testPostEntities/campaign/failures/debug_000002	{"yarn.timeline-service.client.internal-attempt-dir-cache-size": "1552703431", "file.bytes-per-checksum": "193025984"}	["debug_000002"]																						
	Hardcode Assertion	FP	1	org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC#testHadoopProtoRPCTimeout	org.junit.ComparisonFailure	Error, exception is not: java.net.SocketTimeoutException expected:<[java.net.SocketTimeout]Exception> but was:<[org.apache.hadoop.security.authorize.Authorization]Exception>	org.junit.Assert.assertEquals(Assert.java:117), org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testRPCTimeout(TestContainerResourceIncreaseRPC.java:125), org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testHadoopProtoRPCTimeout(TestContainerResourceIncreaseRPC.java:82), org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testHadoopProtoRPCTimeout$$CONFUZZ(TestContainerResourceIncreaseRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC/testHadoopProtoRPCTimeout/campaign/failures/debug_000000	{"hadoop.security.authorization": "true"}	["debug_000000"]																						
	Bug-2	BUG	1	org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5#testPostEntities	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$EntityLogFD.<init>(FileSystemTimelineWriter.java:311), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.createEntityFDandWrite(FileSystemTimelineWriter.java:817), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeEntityLogs(FileSystemTimelineWriter.java:795), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeEntityLogs(FileSystemTimelineWriter.java:767), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putEntities(FileSystemTimelineWriter.java:237), org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities(TimelineClientImpl.java:416), org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.verifyForPostEntities(TestTimelineClientForATS1_5.java:151), org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPostEntities(TestTimelineClientForATS1_5.java:99),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5/testPostEntities/campaign/failures/debug_000002	{"file.bytes-per-checksum": "689862716"}	["debug_000002"]																						
	Bug-10, Bug-11	BUG	1	org.apache.hadoop.yarn.webapp.TestWebApp#testYARNWebAppContext	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.createHttpsChannelConnector(HttpServer2.java:552), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:514), org.apache.hadoop.yarn.webapp.WebApps$Builder.build(WebApps.java:372), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:465), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:461), org.apache.hadoop.yarn.webapp.TestWebApp.testYARNWebAppContext(TestWebApp.java:325), org.apache.hadoop.yarn.webapp.TestWebApp.testYARNWebAppContext$$CONFUZZ(TestWebApp.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.webapp.TestWebApp/testYARNWebAppContext/campaign/failures/debug_000002	{"yarn.http.policy": "HTTPS_ONLY", "hadoop.http.selector.count": "1460953568", "hadoop.http.acceptor.count": "634100972"}	["debug_000002"]																						
	Bug-7, Bug-200	BUG	1	org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5#testPutDomain	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$DomainLogFD.<init>(FileSystemTimelineWriter.java:298), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeDomainLog(FileSystemTimelineWriter.java:753), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.writeDomain(FileSystemTimelineWriter.java:291), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putDomain(FileSystemTimelineWriter.java:255), org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putDomain(TimelineClientImpl.java:426),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5/testPutDomain/campaign/failures/debug_000002	{"yarn.timeline-service.client.internal-attempt-dir-cache-size": "1874873744", "io.file.buffer.size": "1801117294", "file.bytes-per-checksum": "130094302"}	["debug_000002"]																						
	Bug-200	BUG	1	org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5#testPutDomainToKeepUnderUserDir	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$DomainLogFD.<init>(FileSystemTimelineWriter.java:298), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeDomainLog(FileSystemTimelineWriter.java:753), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.writeDomain(FileSystemTimelineWriter.java:291), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putDomain(FileSystemTimelineWriter.java:255), org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putDomain(TimelineClientImpl.java:426),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5/testPutDomainToKeepUnderUserDir/campaign/failures/debug_000003	{"file.bytes-per-checksum": "1144894387", "yarn.timeline-service.client.internal-attempt-dir-cache-size": "752055985"}	["debug_000003"]																						
	Hardcode Assertion	FP	1	org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC#testHadoopProtoRPCTimeout	org.junit.ComparisonFailure	Error, exception is not: java.net.SocketTimeoutException expected:<java.[net.SocketTimeout]Exception> but was:<java.[io.EOF]Exception>	org.junit.Assert.assertEquals(Assert.java:117), org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testRPCTimeout(TestContainerResourceIncreaseRPC.java:125), org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testHadoopProtoRPCTimeout(TestContainerResourceIncreaseRPC.java:82), org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC.testHadoopProtoRPCTimeout$$CONFUZZ(TestContainerResourceIncreaseRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.TestContainerResourceIncreaseRPC/testHadoopProtoRPCTimeout/campaign/failures/debug_000001	{"ipc.maximum.data.length": "183"}	["debug_000001"]																						
	Bug-10, Bug-11	BUG	2	org.apache.hadoop.yarn.webapp.TestWebApp#testCreateWithNonZeroPort	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.yarn.webapp.WebApps$Builder.build(WebApps.java:372), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:465), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:461), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:457), org.apache.hadoop.yarn.webapp.TestWebApp.testCreateWithNonZeroPort(TestWebApp.java:184), org.apache.hadoop.yarn.webapp.TestWebApp.testCreateWithNonZeroPort$$CONFUZZ(TestWebApp.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.webapp.TestWebApp/testCreateWithNonZeroPort/campaign/failures/debug_000002	{"hadoop.http.selector.count": "1595403199", "hadoop.http.acceptor.count": "663921885"}	["debug_000002"]	org.apache.hadoop.yarn.webapp.TestWebApp#testServePaths	java.lang.OutOfMemoryError	Java heap space	org.eclipse.jetty.io.SelectorManager.<init>(SelectorManager.java:99), org.eclipse.jetty.server.ServerConnector$ServerConnectorManager.<init>(ServerConnector.java:600), org.eclipse.jetty.server.ServerConnector.newSelectorManager(ServerConnector.java:223), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:216), org.eclipse.jetty.server.ServerConnector.<init>(ServerConnector.java:114), org.apache.hadoop.http.HttpServer2$Builder.createHttpChannelConnector(HttpServer2.java:534), org.apache.hadoop.http.HttpServer2$Builder.build(HttpServer2.java:511), org.apache.hadoop.yarn.webapp.WebApps$Builder.build(WebApps.java:372), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:465), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:461), org.apache.hadoop.yarn.webapp.WebApps$Builder.start(WebApps.java:457), org.apache.hadoop.yarn.webapp.TestWebApp.testServePaths(TestWebApp.java:195), org.apache.hadoop.yarn.webapp.TestWebApp.testServePaths$$CONFUZZ(TestWebApp.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.webapp.TestWebApp/testServePaths/campaign/failures/debug_000000	{"hadoop.http.acceptor.count": "769531098", "hadoop.http.selector.count": "1584072720"}	["debug_000000"]											
	Bug-2	BUG	1	org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5#testPostEntities	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:55), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:430), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$EntityLogFD.<init>(FileSystemTimelineWriter.java:311), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.createSummaryFDAndWrite(FileSystemTimelineWriter.java:879), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeSummmaryEntityLogs(FileSystemTimelineWriter.java:863), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeSummaryEntityLogs(FileSystemTimelineWriter.java:842), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putEntities(FileSystemTimelineWriter.java:229), org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putEntities(TimelineClientImpl.java:416), org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.verifyForPostEntities(TestTimelineClientForATS1_5.java:151), org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5.testPostEntities(TestTimelineClientForATS1_5.java:99),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5/testPostEntities/campaign/failures/debug_000000	{"yarn.http.policy": "HTTPS_ONLY", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "file.stream-buffer-size": "2017561428", "file.bytes-per-checksum": "1660781381", "fs.client.resolve.remote.symlinks": "false"}	["debug_000000"]																						
	Bug-226	BUG	1	org.apache.hadoop.yarn.util.TestFSDownload#testDownload	java.lang.OutOfMemoryError	Java heap space		REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.util.TestFSDownload/testDownload/campaign/failures/debug_000001	{"file.stream-buffer-size": "2082207443", "io.file.buffer.size": "1166572912"}	["debug_000001"]																						
	Bug-7, Bug-8	BUG	1	org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5#testPutDomainToKeepUnderUserDir	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:437), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.createLogFileStream(FileSystemTimelineWriter.java:388), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.prepareForWrite(FileSystemTimelineWriter.java:367), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFD.<init>(FileSystemTimelineWriter.java:343), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$DomainLogFD.<init>(FileSystemTimelineWriter.java:298), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter$LogFDsCache.writeDomainLog(FileSystemTimelineWriter.java:753), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.writeDomain(FileSystemTimelineWriter.java:291), org.apache.hadoop.yarn.client.api.impl.FileSystemTimelineWriter.putDomain(FileSystemTimelineWriter.java:255), org.apache.hadoop.yarn.client.api.impl.TimelineClientImpl.putDomain(TimelineClientImpl.java:426),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.client.api.impl.TestTimelineClientForATS1_5/testPutDomainToKeepUnderUserDir/campaign/failures/debug_000000	{"file.stream-buffer-size": "1584506966", "yarn.timeline-service.client.internal-attempt-dir-cache-size": "1240621380", "io.file.buffer.size": "1454086926"}	["debug_000000"]																						
	Hardcode Assertion	FP	1	org.apache.hadoop.yarn.webapp.TestWebApp#testDefaultRoutes	java.net.SocketException	Unexpected end of file from server	java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:899), java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:722), java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:896), java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:722), java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1615), java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1520), org.apache.hadoop.yarn.webapp.TestWebApp.getContent(TestWebApp.java:392), org.apache.hadoop.yarn.webapp.TestWebApp.testDefaultRoutes(TestWebApp.java:224), org.apache.hadoop.yarn.webapp.TestWebApp.testDefaultRoutes$$CONFUZZ(TestWebApp.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.webapp.TestWebApp/testDefaultRoutes/campaign/failures/debug_000001	{"hadoop.http.max.threads": "16039", "yarn.http.policy": "HTTPS_ONLY"}	["debug_000001"]																						
	Bug-208	BUG	2	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexedFileController#testFetchApplictionLogsHar	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.readAggregatedLogs(LogAggregationIndexedFileController.java:587), org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexedFileController.testFetchApplictionLogsHar(TestLogAggregationIndexedFileController.java:425), org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexedFileController.testFetchApplictionLogsHar$$CONFUZZ(TestLogAggregationIndexedFileController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexedFileController/testFetchApplictionLogsHar/campaign/failures/debug_000002	{"indexedFile.fs.input.buffer.size": "1666091541", "file.bytes-per-checksum": "1536933200"}	["debug_000002"]	org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexedFileController#testLogAggregationIndexFileFormat	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController.readAggregatedLogs(LogAggregationIndexedFileController.java:587), org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexedFileController.testLogAggregationIndexFileFormat(TestLogAggregationIndexedFileController.java:313), org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexedFileController.testLogAggregationIndexFileFormat$$CONFUZZ(TestLogAggregationIndexedFileController.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/target/meringue/org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.TestLogAggregationIndexedFileController/testLogAggregationIndexFileFormat/campaign/failures/debug_000002	{"indexedFile.fs.input.buffer.size": "1863426621", "file.bytes-per-checksum": "1130276856"}	["debug_000002"]											
[
    {
        "status": "BUG",
        "bugId": [
            "Bug-252"
        ],
        "testClass": "org.apache.hadoop.hbase.io.hfile.TestHFile",
        "testMethod": "testReaderWithCombinedBlockCache",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithCombinedBlockCache(TestHFile.java:252)",
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithCombinedBlockCache$$CONFUZZ(TestHFile.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.lru.max.block.size": "825"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-240"
        ],
        "testClass": "org.apache.hadoop.hbase.io.hfile.TestHFile",
        "testMethod": "testReaderWithTinyLfuCombinedBlockCache",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderCombinedCache(TestHFile.java:1060)",
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithTinyLfuCombinedBlockCache(TestHFile.java:1011)",
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithTinyLfuCombinedBlockCache$$CONFUZZ(TestHFile.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.tinylfu.max.block.size": "511"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-222"
        ],
        "testClass": "org.apache.hadoop.hbase.wal.TestWALMethods",
        "testMethod": "testGetSplitEditFilesSorted",
        "failure": "java.lang.ArithmeticException",
        "errorMessage": "/ by zero",
        "stackTrace": [
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.calculateMaxLogFiles(AbstractFSWAL.java:353)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.<init>(AbstractFSWAL.java:463)",
            "org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.<init>(AsyncFSWAL.java:218)",
            "org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:78)",
            "org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:49)",
            "org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:157)",
            "org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62)",
            "org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300)",
            "org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted(TestWALMethods.java:105)",
            "org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted$$CONFUZZ(TestWALMethods.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.regionserver.logroll.multiplier": "0.0"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.wal.TestWALMethods",
        "testMethod": "testGetSplitEditFilesSorted",
        "failure": "java.lang.NoSuchMethodException",
        "errorMessage": "org.apache.hadoop.hbase.codec.CellCodec.<init>(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.wal.CompressionContext)",
        "stackTrace": [
            "java.base/java.lang.Class.getConstructor0(Class.java:3349)",
            "java.base/java.lang.Class.getDeclaredConstructor(Class.java:2553)",
            "org.apache.hadoop.hbase.util.ReflectionUtils.instantiateWithCustomCtor(ReflectionUtils.java:42)",
            "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.create(WALCellCodec.java:102)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.getCodec(AbstractProtobufLogWriter.java:75)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.initAfterHeader0(AbstractProtobufLogWriter.java:208)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.secureInitAfterHeader(AbstractProtobufLogWriter.java:231)",
            "org.apache.hadoop.hbase.regionserver.wal.SecureAsyncProtobufLogWriter.initAfterHeader(SecureAsyncProtobufLogWriter.java:63)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.init(AbstractProtobufLogWriter.java:191)",
            "org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createAsyncWriter(AsyncFSWALProvider.java:117)",
            "org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:698)",
            "org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:128)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriterInternal(AbstractFSWAL.java:861)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.lambda$rollWriter$8(AbstractFSWAL.java:893)",
            "org.apache.hadoop.hbase.trace.TraceUtil.trace(TraceUtil.java:216)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:893)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:548)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.init(AbstractFSWAL.java:489)",
            "org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:160)",
            "org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62)",
            "org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300)",
            "org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted(TestWALMethods.java:105)",
            "org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted$$CONFUZZ(TestWALMethods.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.regionserver.hlog.async.writer.impl": "org.apache.hadoop.hbase.regionserver.wal.SecureAsyncProtobufLogWriter",
            "hbase.regionserver.wal.codec": "org.apache.hadoop.hbase.codec.CellCodec"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.io.TestFileLink",
        "testMethod": "testGetUnderlyingFSDataInputStream",
        "failure": "org.apache.hadoop.ipc.RpcException",
        "errorMessage": "RPC response exceeds maximum data length",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1935)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.response.length": "756"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.procedure2.store.region.TestWALProcedurePrettyPrinter",
        "testMethod": "test",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<5> but was:<0>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hbase.procedure2.store.region.TestWALProcedurePrettyPrinter.test(TestWALProcedurePrettyPrinter.java:102)",
            "org.apache.hadoop.hbase.procedure2.store.region.TestWALProcedurePrettyPrinter.test$$CONFUZZ(TestWALProcedurePrettyPrinter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.table.max.rowsize": "120"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.mob.TestMobFileCache",
        "testMethod": "testMobFileCache",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "byteSize=70368744177664 too large for bitSize=15872, foldFactor=686",
        "stackTrace": [
            "org.apache.hadoop.hbase.util.BloomFilterUtil.computeFoldableByteSize(BloomFilterUtil.java:134)",
            "org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.<init>(CompoundBloomFilterWriter.java:91)",
            "org.apache.hadoop.hbase.util.BloomFilterFactory.createDeleteBloomAtWrite(BloomFilterFactory.java:200)",
            "org.apache.hadoop.hbase.regionserver.StoreFileWriter.<init>(StoreFileWriter.java:160)",
            "org.apache.hadoop.hbase.regionserver.StoreFileWriter.<init>(StoreFileWriter.java:80)",
            "org.apache.hadoop.hbase.regionserver.StoreFileWriter$Builder.build(StoreFileWriter.java:577)",
            "org.apache.hadoop.hbase.mob.MobUtils.createWriter(MobUtils.java:635)",
            "org.apache.hadoop.hbase.regionserver.HMobStore.createWriterInTmp(HMobStore.java:244)",
            "org.apache.hadoop.hbase.regionserver.HMobStore.createWriterInTmp(HMobStore.java:227)",
            "org.apache.hadoop.hbase.regionserver.HMobStore.createWriterInTmp(HMobStore.java:187)",
            "org.apache.hadoop.hbase.mob.TestMobFileCache.createMobStoreFile(TestMobFileCache.java:148)",
            "org.apache.hadoop.hbase.mob.TestMobFileCache.createMobStoreFile(TestMobFileCache.java:130)",
            "org.apache.hadoop.hbase.mob.TestMobFileCache.createMobStoreFile(TestMobFileCache.java:120)",
            "org.apache.hadoop.hbase.mob.TestMobFileCache.testMobFileCache(TestMobFileCache.java:165)",
            "org.apache.hadoop.hbase.mob.TestMobFileCache.testMobFileCache$$CONFUZZ(TestMobFileCache.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.storefile.bloom.block.size": "1984",
            "io.storefile.bloom.max.fold": "686"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting",
        "testMethod": "testBucketCache",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<6> but was:<3>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.addDataAndHits(TestBlockCacheReporting.java:69)",
            "org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.testBucketCache(TestBlockCacheReporting.java:85)",
            "org.apache.hadoop.hbase.io.hfile.TestBlockCacheReporting.testBucketCache$$CONFUZZ(TestBlockCacheReporting.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.blockcache.minblocksize": "8"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.fs.TestBlockReorder",
        "testMethod": "testBlockLocationReorder",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "File /user/root/hello could only be written to 0 of the 1 minReplication nodes. There are 3 datanode(s) running and 3 node(s) are excluded in this operation.        at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2276)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2820)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:910)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:577)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:549)        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:518)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2960)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:231)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)",
            "com.sun.proxy.$Proxy40.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:520)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:433)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:166)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:158)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:96)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:362)",
            "com.sun.proxy.$Proxy41.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1082)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1898)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1700)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:707)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.block-placement-policy.default.prefer-local-node": "false",
            "dfs.namenode.redundancy.considerLoad.factor": "0.3987211585044861"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.ipc.TestBlockingIPC",
        "testMethod": "testAsyncEcho",
        "failure": "java.lang.AssertionError",
        "errorMessage": "",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:87)",
            "org.junit.Assert.assertTrue(Assert.java:42)",
            "org.junit.Assert.assertFalse(Assert.java:65)",
            "org.junit.Assert.assertFalse(Assert.java:75)",
            "org.apache.hadoop.hbase.ipc.AbstractTestIPC.testAsyncEcho(AbstractTestIPC.java:372)",
            "org.apache.hadoop.hbase.ipc.TestBlockingIPC.testAsyncEcho$$CONFUZZ(TestBlockingIPC.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.ipc.server.max.callqueue.size": "728",
            "hbase.client.ipc.pool.size": "771686142"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.io.TestFileLink",
        "testMethod": "testHDFSLinkReadDuringDelete",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1488)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:958)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:849)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:685)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:665)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:638)",
            "org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete(TestFileLink.java:259)",
            "org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete$$CONFUZZ(TestFileLink.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.cache.revocation.timeout.ms": "767"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.TestHBaseTestingUtility",
        "testMethod": "testMiniDFSCluster",
        "failure": "java.io.EOFException",
        "errorMessage": "",
        "stackTrace": [
            "java.base/java.io.DataInputStream.readInt(DataInputStream.java:397)",
            "org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1921)",
            "org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238)",
            "org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "ipc.maximum.data.length": "17"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-222"
        ],
        "testClass": "org.apache.hadoop.hbase.wal.TestWALMethods",
        "testMethod": "testGetSplitEditFilesSorted",
        "failure": "java.lang.ArithmeticException",
        "errorMessage": "/ by zero",
        "stackTrace": [
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.calculateMaxLogFiles(AbstractFSWAL.java:353)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.<init>(AbstractFSWAL.java:463)",
            "org.apache.hadoop.hbase.regionserver.wal.FSHLog.<init>(FSHLog.java:246)",
            "org.apache.hadoop.hbase.wal.FSHLogProvider.createWAL(FSHLogProvider.java:101)",
            "org.apache.hadoop.hbase.wal.FSHLogProvider.createWAL(FSHLogProvider.java:38)",
            "org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:157)",
            "org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62)",
            "org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300)",
            "org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted(TestWALMethods.java:105)",
            "org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted$$CONFUZZ(TestWALMethods.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.regionserver.logroll.multiplier": "-1.9073486328125E-6",
            "hbase.regionserver.hlog.blocksize": "906",
            "hbase.wal.provider": "filesystem"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.io.hfile.TestHFile",
        "testMethod": "testReaderWithAdaptiveLruCombinedBlockCache",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Single, multi, and memory factors  should be non-negative and total 1.0",
        "stackTrace": [
            "org.apache.hadoop.hbase.io.hfile.LruAdaptiveBlockCache.<init>(LruAdaptiveBlockCache.java:385)",
            "org.apache.hadoop.hbase.io.hfile.LruAdaptiveBlockCache.<init>(LruAdaptiveBlockCache.java:332)",
            "org.apache.hadoop.hbase.io.hfile.BlockCacheFactory.createFirstLevelCache(BlockCacheFactory.java:136)",
            "org.apache.hadoop.hbase.io.hfile.BlockCacheFactory.createBlockCache(BlockCacheFactory.java:98)",
            "org.apache.hadoop.hbase.io.hfile.TestHFile.initCombinedBlockCache(TestHFile.java:213)",
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderCombinedCache(TestHFile.java:1037)",
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithAdaptiveLruCombinedBlockCache(TestHFile.java:1019)",
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithAdaptiveLruCombinedBlockCache$$CONFUZZ(TestHFile.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.lru.blockcache.memory.percentage": "0.12107843160629272"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-227"
        ],
        "testClass": "org.apache.hadoop.hbase.io.hfile.TestHFile",
        "testMethod": "testReaderWithCombinedBlockCache",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithCombinedBlockCache(TestHFile.java:252)",
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithCombinedBlockCache$$CONFUZZ(TestHFile.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hfile.onheap.block.cache.fixed.size": "767"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-257"
        ],
        "testClass": "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter",
        "testMethod": "test",
        "failure": "java.lang.ArithmeticException",
        "errorMessage": "/ by zero",
        "stackTrace": [
            "org.apache.hadoop.hbase.util.BloomFilterUtil.optimalFunctionCount(BloomFilterUtil.java:141)",
            "org.apache.hadoop.hbase.util.BloomFilterUtil.createBySize(BloomFilterUtil.java:164)",
            "org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.allocateNewChunk(CompoundBloomFilterWriter.java:188)",
            "org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.append(CompoundBloomFilterWriter.java:165)",
            "org.apache.hadoop.hbase.util.BloomContext.writeBloom(BloomContext.java:51)",
            "org.apache.hadoop.hbase.regionserver.StoreFileWriter.appendDeleteFamilyBloomFilter(StoreFileWriter.java:295)",
            "org.apache.hadoop.hbase.regionserver.StoreFileWriter.append(StoreFileWriter.java:302)",
            "org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(StoreFlusher.java:139)",
            "org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:65)",
            "org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:822)",
            "org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1963)",
            "org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2838)",
            "org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2580)",
            "org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2552)",
            "org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2422)",
            "org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2345)",
            "org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:2315)",
            "org.apache.hadoop.hbase.master.region.MasterRegion.flush(MasterRegion.java:166)",
            "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test(TestHFileProcedurePrettyPrinter.java:103)",
            "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test$$CONFUZZ(TestHFileProcedurePrettyPrinter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.storefile.bloom.max.fold": "767",
            "io.storefile.bloom.enabled": "false"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.io.TestFileLink",
        "testMethod": "testHDFSLinkReadDuringRename",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "The maximum path component name limit of cf6d955d-1721-6e05-8c39-c19fe848f4ea in directory /user/root/test-data is exceeded: limit=30 length=36        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.verifyMaxComponentLength(FSDirectory.java:1216)        at org.apache.hadoop.hdfs.server.namenode.FSDirectory.addLastINode(FSDirectory.java:1318)        at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.unprotectedMkdir(FSDirMkdirOp.java:215)        at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.createSingleDirectory(FSDirMkdirOp.java:168)        at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.createParentDirectories(FSDirMkdirOp.java:144)        at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.createAncestorDirectories(FSDirMkdirOp.java:106)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.startFile(FSDirWriteFileOp.java:395)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFileInt(FSNamesystem.java:2567)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.startFile(FSNamesystem.java:2464)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.create(NameNodeRpcServer.java:809)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.create(ClientNamenodeProtocolServerSideTranslatorPB.java:478)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:549)        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:518)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2960)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:231)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)",
            "com.sun.proxy.$Proxy35.create(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.create(ClientNamenodeProtocolTranslatorPB.java:372)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:433)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:166)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:158)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:96)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:362)",
            "com.sun.proxy.$Proxy36.create(Unknown Source)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:361)",
            "com.sun.proxy.$Proxy39.create(Unknown Source)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:361)",
            "com.sun.proxy.$Proxy39.create(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:276)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1230)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1209)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1147)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:530)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:544)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:471)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1125)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1105)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:994)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:982)",
            "org.apache.hadoop.hbase.io.TestFileLink.writeSomeData(TestFileLink.java:320)",
            "org.apache.hadoop.hbase.io.TestFileLink.testLinkReadDuringRename(TestFileLink.java:198)",
            "org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringRename(TestFileLink.java:142)",
            "org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringRename$$CONFUZZ(TestFileLink.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.fs-limits.max-component-length": "30"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.io.TestFileLink",
        "testMethod": "testHDFSLinkReadDuringDelete",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<1> but was:<0>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hbase.io.TestFileLink.dataVerify(TestFileLink.java:337)",
            "org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete(TestFileLink.java:286)",
            "org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete$$CONFUZZ(TestFileLink.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.transferTo.allowed": "false"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-260"
        ],
        "testClass": "org.apache.hadoop.hbase.io.TestFileLink",
        "testMethod": "testHDFSLinkReadDuringDelete",
        "failure": "java.lang.NegativeArraySizeException",
        "errorMessage": "-1872267529",
        "stackTrace": [
            "org.apache.hadoop.fs.FSOutputSummer.<init>(FSOutputSummer.java:54)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:191)",
            "org.apache.hadoop.hdfs.DFSOutputStream.<init>(DFSOutputStream.java:247)",
            "org.apache.hadoop.hdfs.DFSOutputStream.newStreamForCreate(DFSOutputStream.java:313)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1230)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1209)",
            "org.apache.hadoop.hdfs.DFSClient.create(DFSClient.java:1147)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:533)",
            "org.apache.hadoop.hdfs.DistributedFileSystem$8.doCall(DistributedFileSystem.java:530)",
            "org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:544)",
            "org.apache.hadoop.hdfs.DistributedFileSystem.create(DistributedFileSystem.java:471)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1125)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1105)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:994)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:982)",
            "org.apache.hadoop.hbase.io.TestFileLink.writeSomeData(TestFileLink.java:320)",
            "org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete(TestFileLink.java:268)",
            "org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete$$CONFUZZ(TestFileLink.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.bytes-per-checksum": "269188863"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.TestHBaseTestingUtility",
        "testMethod": "testMiniZooKeeperWithMultipleClientPorts",
        "failure": "java.io.IOException",
        "errorMessage": "Waiting for startup of standalone server; server isRunning=true",
        "stackTrace": [
            "org.apache.hadoop.hbase.zookeeper.MiniZooKeeperCluster.startup(MiniZooKeeperCluster.java:265)",
            "org.apache.hadoop.hbase.HBaseZKTestingUtility.startMiniZKCluster(HBaseZKTestingUtility.java:129)",
            "org.apache.hadoop.hbase.HBaseZKTestingUtility.startMiniZKCluster(HBaseZKTestingUtility.java:102)",
            "org.apache.hadoop.hbase.TestHBaseTestingUtility.testMiniZooKeeperWithMultipleClientPorts(TestHBaseTestingUtility.java:341)",
            "org.apache.hadoop.hbase.TestHBaseTestingUtility.testMiniZooKeeperWithMultipleClientPorts$$CONFUZZ(TestHBaseTestingUtility.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.zookeeper.property.maxClientCnxns": "9096",
            "zookeeper.session.timeout.localHBaseCluster": "17"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler",
        "testMethod": "testHandlerIsolation",
        "failure": "org.mockito.exceptions.verification.WantedButNotInvoked",
        "errorMessage": "Wanted but not invoked:callRunner.run();-> at org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation(TestSimpleRpcScheduler.java:221)However, there were exactly 2 interactions with this mock:callRunner.setStatus(    test: status=status unset, state=WAITING, startTime=1694834242521, completionTime=-1);-> at org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation(TestSimpleRpcScheduler.java:208)callRunner.getRpcCall();-> at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.dispatch(SimpleRpcScheduler.java:197)",
        "stackTrace": [
            "org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation(TestSimpleRpcScheduler.java:221)",
            "org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation$$CONFUZZ(TestSimpleRpcScheduler.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.ipc.server.callqueue.type": "fifo"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-261"
        ],
        "testClass": "org.apache.hadoop.hbase.wal.TestWALMethods",
        "testMethod": "testGetSplitEditFilesSorted",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.hbase.wal.BoundedGroupingStrategy.init(BoundedGroupingStrategy.java:65)",
            "org.apache.hadoop.hbase.wal.RegionGroupingProvider.getStrategy(RegionGroupingProvider.java:106)",
            "org.apache.hadoop.hbase.wal.RegionGroupingProvider.init(RegionGroupingProvider.java:159)",
            "org.apache.hadoop.hbase.wal.WALFactory.createProvider(WALFactory.java:165)",
            "org.apache.hadoop.hbase.wal.WALFactory.getProvider(WALFactory.java:180)",
            "org.apache.hadoop.hbase.wal.WALFactory.<init>(WALFactory.java:207)",
            "org.apache.hadoop.hbase.wal.WALFactory.<init>(WALFactory.java:186)",
            "org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted(TestWALMethods.java:105)",
            "org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted$$CONFUZZ(TestWALMethods.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.wal.provider": "multiwal",
            "hbase.wal.regiongrouping.numgroups": "2130640638"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter",
        "testMethod": "test",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<3> but was:<0>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test(TestHFileProcedurePrettyPrinter.java:148)",
            "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test$$CONFUZZ(TestHFileProcedurePrettyPrinter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.master.store.region.flush.size": "767",
            "hbase.hregion.memstore.block.multiplier": "498"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-263"
        ],
        "testClass": "org.apache.hadoop.hbase.ipc.TestBlockingIPC",
        "testMethod": "testAsyncEcho",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayDeque.<init>(ArrayDeque.java:196)",
            "org.apache.hadoop.hbase.ipc.BlockingRpcConnection$CallSender.<init>(BlockingRpcConnection.java:144)",
            "org.apache.hadoop.hbase.ipc.BlockingRpcConnection.<init>(BlockingRpcConnection.java:239)",
            "org.apache.hadoop.hbase.ipc.BlockingRpcClient.createConnection(BlockingRpcClient.java:67)",
            "org.apache.hadoop.hbase.ipc.BlockingRpcClient.createConnection(BlockingRpcClient.java:34)",
            "org.apache.hadoop.hbase.ipc.AbstractRpcClient.lambda$getConnection$0(AbstractRpcClient.java:364)",
            "org.apache.hadoop.hbase.ipc.AbstractRpcClient$$Lambda$207/0x0000000840337040.get(Unknown Source)",
            "org.apache.hadoop.hbase.util.PoolMap.createResource(PoolMap.java:127)",
            "org.apache.hadoop.hbase.util.PoolMap$RoundRobinPool.getOrCreate(PoolMap.java:211)",
            "org.apache.hadoop.hbase.util.PoolMap.getOrCreate(PoolMap.java:68)",
            "org.apache.hadoop.hbase.ipc.AbstractRpcClient.getConnection(AbstractRpcClient.java:364)",
            "org.apache.hadoop.hbase.ipc.AbstractRpcClient.callMethod(AbstractRpcClient.java:444)",
            "org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$300(AbstractRpcClient.java:92)",
            "org.apache.hadoop.hbase.ipc.AbstractRpcClient$RpcChannelImplementation.callMethod(AbstractRpcClient.java:618)",
            "org.apache.hadoop.hbase.shaded.ipc.protobuf.generated.TestRpcServiceProtos$TestProtobufRpcProto$Stub.echo(TestRpcServiceProtos.java:378)",
            "org.apache.hadoop.hbase.ipc.AbstractTestIPC.testAsyncEcho(AbstractTestIPC.java:366)",
            "org.apache.hadoop.hbase.ipc.TestBlockingIPC.testAsyncEcho$$CONFUZZ(TestBlockingIPC.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.ipc.client.write.queueSize": "2083421821",
            "hbase.ipc.client.specificThreadForWriting": "true"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter",
        "testMethod": "test",
        "failure": "java.lang.AssertionError",
        "errorMessage": "expected:<3> but was:<0>",
        "stackTrace": [
            "org.junit.Assert.fail(Assert.java:89)",
            "org.junit.Assert.failNotEquals(Assert.java:835)",
            "org.junit.Assert.assertEquals(Assert.java:647)",
            "org.junit.Assert.assertEquals(Assert.java:633)",
            "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test(TestHFileProcedurePrettyPrinter.java:148)",
            "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test$$CONFUZZ(TestHFileProcedurePrettyPrinter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.master.store.region.flush.per.changes": "7"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.io.TestFileLink",
        "testMethod": "testGetUnderlyingFSDataInputStream",
        "failure": "org.apache.hadoop.ipc.RemoteException",
        "errorMessage": "Exceeded the configured number of objects 79 in the filesystem.        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkFsObjectLimit(FSNamesystem.java:4865)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.analyzeFileState(FSDirWriteFileOp.java:596)        at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.validateAddBlock(FSDirWriteFileOp.java:171)        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2808)        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:910)        at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:577)        at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:549)        at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:518)        at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1086)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1035)        at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:963)        at java.base/java.security.AccessController.doPrivileged(Native Method)        at java.base/javax.security.auth.Subject.doAs(Subject.java:423)        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1762)        at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2960)",
        "stackTrace": [
            "org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1612)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1558)",
            "org.apache.hadoop.ipc.Client.call(Client.java:1455)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:231)",
            "org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:118)",
            "com.sun.proxy.$Proxy35.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:520)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:433)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:166)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:158)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:96)",
            "org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:362)",
            "com.sun.proxy.$Proxy36.addBlock(Unknown Source)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:361)",
            "com.sun.proxy.$Proxy39.addBlock(Unknown Source)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.apache.hadoop.hbase.fs.HFileSystem$1.invoke(HFileSystem.java:361)",
            "com.sun.proxy.$Proxy39.addBlock(Unknown Source)",
            "org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1082)",
            "org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1898)",
            "org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1700)",
            "org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:707)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.max.objects": "79"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-187"
        ],
        "testClass": "org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidatorTest",
        "testMethod": "testTableValidJar",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Requested array size exceeds VM limit",
        "stackTrace": [
            "java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:322)",
            "org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:353)",
            "org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:407)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:466)",
            "org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:445)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1125)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1105)",
            "org.apache.hadoop.fs.FileSystem.create(FileSystem.java:994)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:420)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:393)",
            "org.apache.hadoop.fs.FileUtil.copy(FileUtil.java:343)",
            "org.apache.hadoop.fs.LocalFileSystem.copyToLocalFile(LocalFileSystem.java:88)",
            "org.apache.hadoop.fs.FileSystem.copyToLocalFile(FileSystem.java:2408)",
            "org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidator.createClassLoader(CoprocessorValidator.java:116)",
            "org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidator.validateTables(CoprocessorValidator.java:180)",
            "org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidatorTest.validateTable(CoprocessorValidatorTest.java:198)",
            "org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidatorTest.testTableValidJar(CoprocessorValidatorTest.java:250)",
            "org.apache.hadoop.hbase.tool.coprocessor.CoprocessorValidatorTest.testTableValidJar$$CONFUZZ(CoprocessorValidatorTest.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.stream-buffer-size": "2147483646"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan",
        "testMethod": "testReverseScanWithoutPadding",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "hbase.hregion.memstore.mslab.max.allocation must be less than hbase.hregion.memstore.mslab.chunksize",
        "stackTrace": [
            "org.apache.hbase.thirdparty.com.google.common.base.Preconditions.checkArgument(Preconditions.java:145)",
            "org.apache.hadoop.hbase.regionserver.MemStoreLABImpl.<init>(MemStoreLABImpl.java:105)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:55)",
            "org.apache.hadoop.hbase.util.ReflectionUtils.instantiateWithCustomCtor(ReflectionUtils.java:43)",
            "org.apache.hadoop.hbase.regionserver.MemStoreLAB.newInstance(MemStoreLAB.java:116)",
            "org.apache.hadoop.hbase.regionserver.SegmentFactory.createMutableSegment(SegmentFactory.java:81)",
            "org.apache.hadoop.hbase.regionserver.AbstractMemStore.resetActive(AbstractMemStore.java:93)",
            "org.apache.hadoop.hbase.regionserver.AbstractMemStore.<init>(AbstractMemStore.java:83)",
            "org.apache.hadoop.hbase.regionserver.CompactingMemStore.<init>(CompactingMemStore.java:106)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.hbase.util.ReflectionUtils.instantiate(ReflectionUtils.java:55)",
            "org.apache.hadoop.hbase.util.ReflectionUtils.newInstance(ReflectionUtils.java:92)",
            "org.apache.hadoop.hbase.regionserver.HStore.getMemstore(HStore.java:378)",
            "org.apache.hadoop.hbase.regionserver.HStore.<init>(HStore.java:280)",
            "org.apache.hadoop.hbase.regionserver.HRegion.instantiateHStore(HRegion.java:6359)",
            "org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1114)",
            "org.apache.hadoop.hbase.regionserver.HRegion$1.call(HRegion.java:1111)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)",
            "java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.hregion.memstore.mslab.max.allocation": "2130640638",
            "hbase.hregion.compacting.memstore.type": "eager"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler",
        "testMethod": "testHandlerIsolation",
        "failure": "org.mockito.exceptions.verification.WantedButNotInvoked",
        "errorMessage": "Wanted but not invoked:callRunner.run();-> at org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation(TestSimpleRpcScheduler.java:221)However, there were exactly 2 interactions with this mock:callRunner.setStatus(    test: status=status unset, state=WAITING, startTime=1694795796396, completionTime=-1);-> at org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation(TestSimpleRpcScheduler.java:208)callRunner.getRpcCall();-> at org.apache.hadoop.hbase.ipc.SimpleRpcScheduler.dispatch(SimpleRpcScheduler.java:197)",
        "stackTrace": [
            "org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation(TestSimpleRpcScheduler.java:221)",
            "org.apache.hadoop.hbase.ipc.TestSimpleRpcScheduler.testHandlerIsolation$$CONFUZZ(TestSimpleRpcScheduler.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.ipc.server.metacallqueue.read.ratio": "-0.06771010160446167"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan",
        "testMethod": "testReverseScanWithPadding",
        "failure": "java.lang.IllegalArgumentException",
        "errorMessage": "Invalid hbase.busy.wait.duration (0) or hbase.busy.wait.multiplier.max (2). Their product should be positive",
        "stackTrace": [
            "org.apache.hadoop.hbase.regionserver.HRegion.<init>(HRegion.java:819)",
            "org.apache.hadoop.hbase.regionserver.HRegion.<init>(HRegion.java:734)",
            "java.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)",
            "org.apache.hadoop.hbase.regionserver.HRegion.newHRegion(HRegion.java:6969)",
            "org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:7008)",
            "org.apache.hadoop.hbase.regionserver.HRegion.createHRegion(HRegion.java:6987)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.createRegionAndWAL(HBaseTestingUtility.java:2625)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.createRegionAndWAL(HBaseTestingUtility.java:2588)",
            "org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan.setUp(TestSeekBeforeWithReverseScan.java:69)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.busy.wait.duration": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-169"
        ],
        "testClass": "org.apache.hadoop.hbase.wal.TestWALMethods",
        "testMethod": "testGetSplitEditFilesSorted",
        "failure": "java.lang.ArithmeticException",
        "errorMessage": "/ by zero",
        "stackTrace": [
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.calculateMaxLogFiles(AbstractFSWAL.java:353)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.<init>(AbstractFSWAL.java:463)",
            "org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.<init>(AsyncFSWAL.java:218)",
            "org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:78)",
            "org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createWAL(AsyncFSWALProvider.java:49)",
            "org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:157)",
            "org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62)",
            "org.apache.hadoop.hbase.wal.RegionGroupingProvider.getWAL(RegionGroupingProvider.java:195)",
            "org.apache.hadoop.hbase.wal.RegionGroupingProvider.getWAL(RegionGroupingProvider.java:215)",
            "org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300)",
            "org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted(TestWALMethods.java:105)",
            "org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted$$CONFUZZ(TestWALMethods.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.regionserver.hlog.blocksize": "0",
            "hbase.wal.provider": "multiwal"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-265"
        ],
        "testClass": "org.apache.hadoop.hbase.io.hfile.TestHFileSeek",
        "testMethod": "testSeeks",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.fs.FSInputChecker.seek(FSInputChecker.java:441)",
            "org.apache.hadoop.fs.FSDataInputStream.seek(FSDataInputStream.java:65)",
            "org.apache.hadoop.fs.ChecksumFileSystem$FSDataBoundedInputStream.seek(ChecksumFileSystem.java:333)",
            "org.apache.hadoop.hbase.io.hfile.FixedFileTrailer.readFromStream(FixedFileTrailer.java:391)",
            "org.apache.hadoop.hbase.io.hfile.HFileInfo.initTrailerAndContext(HFileInfo.java:339)",
            "org.apache.hadoop.hbase.io.hfile.HFileInfo.<init>(HFileInfo.java:123)",
            "org.apache.hadoop.hbase.io.hfile.TestHFile.createReaderFromStream(TestHFile.java:125)",
            "org.apache.hadoop.hbase.io.hfile.TestHFileSeek.seekTFile(TestHFileSeek.java:175)",
            "org.apache.hadoop.hbase.io.hfile.TestHFileSeek.testSeeks(TestHFileSeek.java:210)",
            "org.apache.hadoop.hbase.io.hfile.TestHFileSeek.testSeeks$$CONFUZZ(TestHFileSeek.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "file.bytes-per-checksum": "2144534922"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.io.TestFileLink",
        "testMethod": "testHDFSLinkReadDuringDelete",
        "failure": "java.io.IOException",
        "errorMessage": "Unexpected configuration parameters: dfs.namenode.replication.min = 234 > dfs.replication.max = 2",
        "stackTrace": [
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:510)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:831)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:767)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1209)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:427)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:260)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1117)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1001)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:933)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:849)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:685)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:665)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:638)",
            "org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete(TestFileLink.java:259)",
            "org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete$$CONFUZZ(TestFileLink.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.replication.min": "234",
            "dfs.replication.max": "2"
        }
    },
    {
        "status": "Not-Reproducible",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.filter.TestDependentColumnFilter",
        "testMethod": "testToStringWithNullComparator",
        "failure": "java.lang.RuntimeException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hbase.regionserver.wal.AsyncProtobufLogWriter.writeWALMetadata(AsyncProtobufLogWriter.java:219)",
            "org.apache.hadoop.hbase.regionserver.wal.AsyncProtobufLogWriter.writeMagicAndWALHeader(AsyncProtobufLogWriter.java:225)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.init(AbstractProtobufLogWriter.java:188)",
            "org.apache.hadoop.hbase.wal.AsyncFSWALProvider.createAsyncWriter(AsyncFSWALProvider.java:117)",
            "org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:698)",
            "org.apache.hadoop.hbase.regionserver.wal.AsyncFSWAL.createWriterInstance(AsyncFSWAL.java:128)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriterInternal(AbstractFSWAL.java:861)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.lambda$rollWriter$8(AbstractFSWAL.java:893)",
            "org.apache.hadoop.hbase.trace.TraceUtil.trace(TraceUtil.java:216)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:893)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:548)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.init(AbstractFSWAL.java:489)",
            "org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:160)",
            "org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62)",
            "org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.createWal(HBaseTestingUtility.java:2579)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.createRegionAndWAL(HBaseTestingUtility.java:2624)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.createRegionAndWAL(HBaseTestingUtility.java:2588)",
            "org.apache.hadoop.hbase.filter.TestDependentColumnFilter.setUp(TestDependentColumnFilter.java:89)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.hfile.drop.behind.compaction": "false",
            "hbase.regionserver.logroll.wait.timeout.ms": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-266"
        ],
        "testClass": "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter",
        "testMethod": "test",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "org.apache.hadoop.hbase.io.ByteArrayOutputStream.checkSizeAndGrow(ByteArrayOutputStream.java:93)",
            "org.apache.hadoop.hbase.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:74)",
            "java.base/java.io.DataOutputStream.write(DataOutputStream.java:107)",
            "org.apache.hadoop.hbase.util.BloomFilterChunk.writeBloom(BloomFilterChunk.java:290)",
            "org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.writeInlineBlock(CompoundBloomFilterWriter.java:210)",
            "org.apache.hadoop.hbase.io.hfile.HFileWriterImpl.writeInlineBlocks(HFileWriterImpl.java:522)",
            "org.apache.hadoop.hbase.io.hfile.HFileWriterImpl.close(HFileWriterImpl.java:599)",
            "org.apache.hadoop.hbase.regionserver.StoreFileWriter.close(StoreFileWriter.java:378)",
            "org.apache.hadoop.hbase.regionserver.StoreFlusher.finalizeWriter(StoreFlusher.java:69)",
            "org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:74)",
            "org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:822)",
            "org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1963)",
            "org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2838)",
            "org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2580)",
            "org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2552)",
            "org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2422)",
            "org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2345)",
            "org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:2315)",
            "org.apache.hadoop.hbase.master.region.MasterRegion.flush(MasterRegion.java:166)",
            "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test(TestHFileProcedurePrettyPrinter.java:97)",
            "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test$$CONFUZZ(TestHFileProcedurePrettyPrinter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.storefile.bloom.block.size": "1913015228",
            "io.storefile.bloom.error.rate": "0.2502479553222656"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.wal.TestWALMethods",
        "testMethod": "testGetSplitEditFilesSorted",
        "failure": "java.lang.NoSuchMethodException",
        "errorMessage": "org.apache.hadoop.hbase.codec.KeyValueCodec.<init>(org.apache.hadoop.conf.Configuration, org.apache.hadoop.hbase.regionserver.wal.CompressionContext)",
        "stackTrace": [
            "java.base/java.lang.Class.getConstructor0(Class.java:3349)",
            "java.base/java.lang.Class.getDeclaredConstructor(Class.java:2553)",
            "org.apache.hadoop.hbase.util.ReflectionUtils.instantiateWithCustomCtor(ReflectionUtils.java:42)",
            "org.apache.hadoop.hbase.regionserver.wal.WALCellCodec.create(WALCellCodec.java:102)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.getCodec(AbstractProtobufLogWriter.java:75)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.initAfterHeader0(AbstractProtobufLogWriter.java:208)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.secureInitAfterHeader(AbstractProtobufLogWriter.java:231)",
            "org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter.initAfterHeader(SecureProtobufLogWriter.java:46)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractProtobufLogWriter.init(AbstractProtobufLogWriter.java:191)",
            "org.apache.hadoop.hbase.wal.FSHLogProvider.createWriter(FSHLogProvider.java:79)",
            "org.apache.hadoop.hbase.regionserver.wal.FSHLog.createWriterInstance(FSHLog.java:310)",
            "org.apache.hadoop.hbase.regionserver.wal.FSHLog.createWriterInstance(FSHLog.java:71)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriterInternal(AbstractFSWAL.java:861)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.lambda$rollWriter$8(AbstractFSWAL.java:893)",
            "org.apache.hadoop.hbase.trace.TraceUtil.trace(TraceUtil.java:216)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:893)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.rollWriter(AbstractFSWAL.java:548)",
            "org.apache.hadoop.hbase.regionserver.wal.AbstractFSWAL.init(AbstractFSWAL.java:489)",
            "org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:160)",
            "org.apache.hadoop.hbase.wal.AbstractFSWALProvider.getWAL(AbstractFSWALProvider.java:62)",
            "org.apache.hadoop.hbase.wal.WALFactory.getWAL(WALFactory.java:300)",
            "org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted(TestWALMethods.java:105)",
            "org.apache.hadoop.hbase.wal.TestWALMethods.testGetSplitEditFilesSorted$$CONFUZZ(TestWALMethods.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.regionserver.hlog.writer.impl": "org.apache.hadoop.hbase.regionserver.wal.SecureProtobufLogWriter",
            "hbase.wal.provider": "filesystem",
            "hbase.regionserver.wal.codec": "org.apache.hadoop.hbase.codec.KeyValueCodec"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-267"
        ],
        "testClass": "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter",
        "testMethod": "test",
        "failure": "java.lang.ArithmeticException",
        "errorMessage": "/ by zero",
        "stackTrace": [
            "org.apache.hadoop.hbase.util.BloomFilterUtil.optimalFunctionCount(BloomFilterUtil.java:141)",
            "org.apache.hadoop.hbase.util.BloomFilterUtil.createBySize(BloomFilterUtil.java:164)",
            "org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.allocateNewChunk(CompoundBloomFilterWriter.java:188)",
            "org.apache.hadoop.hbase.io.hfile.CompoundBloomFilterWriter.append(CompoundBloomFilterWriter.java:165)",
            "org.apache.hadoop.hbase.util.BloomContext.writeBloom(BloomContext.java:51)",
            "org.apache.hadoop.hbase.regionserver.StoreFileWriter.appendDeleteFamilyBloomFilter(StoreFileWriter.java:295)",
            "org.apache.hadoop.hbase.regionserver.StoreFileWriter.append(StoreFileWriter.java:302)",
            "org.apache.hadoop.hbase.regionserver.StoreFlusher.performFlush(StoreFlusher.java:139)",
            "org.apache.hadoop.hbase.regionserver.DefaultStoreFlusher.flushSnapshot(DefaultStoreFlusher.java:65)",
            "org.apache.hadoop.hbase.regionserver.HStore.flushCache(HStore.java:822)",
            "org.apache.hadoop.hbase.regionserver.HStore$StoreFlusherImpl.flushCache(HStore.java:1963)",
            "org.apache.hadoop.hbase.regionserver.HRegion.internalFlushCacheAndCommit(HRegion.java:2838)",
            "org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2580)",
            "org.apache.hadoop.hbase.regionserver.HRegion.internalFlushcache(HRegion.java:2552)",
            "org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2422)",
            "org.apache.hadoop.hbase.regionserver.HRegion.flushcache(HRegion.java:2345)",
            "org.apache.hadoop.hbase.regionserver.HRegion.flush(HRegion.java:2315)",
            "org.apache.hadoop.hbase.master.region.MasterRegion.flush(MasterRegion.java:166)",
            "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test(TestHFileProcedurePrettyPrinter.java:103)",
            "org.apache.hadoop.hbase.procedure2.store.region.TestHFileProcedurePrettyPrinter.test$$CONFUZZ(TestHFileProcedurePrettyPrinter.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "io.storefile.bloom.error.rate": "-0.36717891693115234",
            "io.storefile.bloom.enabled": "false"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.fs.TestBlockReorder",
        "testMethod": "testBlockLocationReorder",
        "failure": "java.io.IOException",
        "errorMessage": "Timed out waiting for Mini HDFS Cluster to start",
        "stackTrace": [
            "org.apache.hadoop.hdfs.MiniDFSCluster.waitClusterUp(MiniDFSCluster.java:1488)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:958)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:849)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:685)",
            "org.apache.hadoop.hbase.fs.TestBlockReorder.setUp(TestBlockReorder.java:84)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "org.junit.internal.runners.statements.RunBefores.invokeMethod(RunBefores.java:33)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.datanode.directoryscan.interval": "10795057"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-129"
        ],
        "testClass": "org.apache.hadoop.hbase.io.hfile.TestHFile",
        "testMethod": "testReaderWithTinyLfuCombinedBlockCache",
        "failure": "java.lang.NullPointerException",
        "errorMessage": "",
        "stackTrace": [
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderCombinedCache(TestHFile.java:1060)",
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithTinyLfuCombinedBlockCache(TestHFile.java:1011)",
            "org.apache.hadoop.hbase.io.hfile.TestHFile.testReaderWithTinyLfuCombinedBlockCache$$CONFUZZ(TestHFile.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.writer.unified.encoded.blocksize.ratio": "0.0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-263"
        ],
        "testClass": "org.apache.hadoop.hbase.ipc.TestBlockingIPC",
        "testMethod": "testAsyncEcho",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.ArrayDeque.<init>(ArrayDeque.java:196)",
            "org.apache.hadoop.hbase.ipc.BlockingRpcConnection$CallSender.<init>(BlockingRpcConnection.java:144)",
            "org.apache.hadoop.hbase.ipc.BlockingRpcConnection.<init>(BlockingRpcConnection.java:239)",
            "org.apache.hadoop.hbase.ipc.BlockingRpcClient.createConnection(BlockingRpcClient.java:67)",
            "org.apache.hadoop.hbase.ipc.BlockingRpcClient.createConnection(BlockingRpcClient.java:34)",
            "org.apache.hadoop.hbase.ipc.AbstractRpcClient.lambda$getConnection$0(AbstractRpcClient.java:364)",
            "org.apache.hadoop.hbase.ipc.AbstractRpcClient$$Lambda$207/0x0000000840337040.get(Unknown Source)",
            "org.apache.hadoop.hbase.util.PoolMap.createResource(PoolMap.java:127)",
            "org.apache.hadoop.hbase.util.PoolMap$ThreadLocalPool.getOrCreate(PoolMap.java:268)",
            "org.apache.hadoop.hbase.util.PoolMap.getOrCreate(PoolMap.java:68)",
            "org.apache.hadoop.hbase.ipc.AbstractRpcClient.getConnection(AbstractRpcClient.java:364)",
            "org.apache.hadoop.hbase.ipc.AbstractRpcClient.callMethod(AbstractRpcClient.java:444)",
            "org.apache.hadoop.hbase.ipc.AbstractRpcClient.access$300(AbstractRpcClient.java:92)",
            "org.apache.hadoop.hbase.ipc.AbstractRpcClient$RpcChannelImplementation.callMethod(AbstractRpcClient.java:618)",
            "org.apache.hadoop.hbase.shaded.ipc.protobuf.generated.TestRpcServiceProtos$TestProtobufRpcProto$Stub.echo(TestRpcServiceProtos.java:378)",
            "org.apache.hadoop.hbase.ipc.AbstractTestIPC.testAsyncEcho(AbstractTestIPC.java:366)",
            "org.apache.hadoop.hbase.ipc.TestBlockingIPC.testAsyncEcho$$CONFUZZ(TestBlockingIPC.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:54)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.ipc.client.specificThreadForWriting": "true",
            "hbase.client.ipc.pool.type": "thread-local",
            "hbase.ipc.client.write.queueSize": "1855534301"
        }
    },
    {
        "status": "FP",
        "bugId": [],
        "testClass": "org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan",
        "testMethod": "testReverseScanWithPadding",
        "failure": "org.apache.hadoop.hbase.RegionTooBusyException",
        "errorMessage": "Over memstore limit=0, regionName=5b9f2d5b640f2969d309ad528a401005, server=unknown",
        "stackTrace": [
            "org.apache.hadoop.hbase.regionserver.HRegion.checkResources(HRegion.java:4966)",
            "org.apache.hadoop.hbase.regionserver.HRegion.lambda$put$7(HRegion.java:3137)",
            "org.apache.hadoop.hbase.trace.TraceUtil.trace(TraceUtil.java:216)",
            "org.apache.hadoop.hbase.regionserver.HRegion.put(HRegion.java:3130)",
            "org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan.testReverseScanWithPadding(TestSeekBeforeWithReverseScan.java:129)",
            "org.apache.hadoop.hbase.io.encoding.TestSeekBeforeWithReverseScan.testReverseScanWithPadding$$CONFUZZ(TestSeekBeforeWithReverseScan.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)",
            "org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)",
            "org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)",
            "org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)",
            "org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)",
            "org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)",
            "org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)",
            "org.apache.hadoop.hbase.SystemExitRule$1.evaluate(SystemExitRule.java:39)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299)",
            "org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293)",
            "java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)",
            "java.base/java.lang.Thread.run(Thread.java:829)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "hbase.hregion.memstore.block.multiplier": "0"
        }
    },
    {
        "status": "BUG",
        "bugId": [
            "Bug-268"
        ],
        "testClass": "org.apache.hadoop.hbase.io.TestFileLink",
        "testMethod": "testHDFSLinkReadDuringDelete",
        "failure": "java.lang.OutOfMemoryError",
        "errorMessage": "Java heap space",
        "stackTrace": [
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:270)",
            "java.base/java.util.concurrent.ArrayBlockingQueue.<init>(ArrayBlockingQueue.java:254)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$BlockReportProcessingThread.<init>(BlockManager.java:5089)",
            "org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.<init>(BlockManager.java:587)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:831)",
            "org.apache.hadoop.hdfs.server.namenode.FSNamesystem.<init>(FSNamesystem.java:767)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:1209)",
            "org.apache.hadoop.hdfs.server.namenode.NameNode.format(NameNode.java:427)",
            "org.apache.hadoop.hdfs.DFSTestUtil.formatNameNode(DFSTestUtil.java:260)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.configureNameService(MiniDFSCluster.java:1117)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:1001)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:933)",
            "org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:849)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:685)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:665)",
            "org.apache.hadoop.hbase.HBaseTestingUtility.startMiniDFSCluster(HBaseTestingUtility.java:638)",
            "org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete(TestFileLink.java:259)",
            "org.apache.hadoop.hbase.io.TestFileLink.testHDFSLinkReadDuringDelete$$CONFUZZ(TestFileLink.java)",
            "java.base/java.lang.reflect.Method.invoke(Method.java:566)",
            "org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)",
            "org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)",
            "org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59)",
            "org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)",
            "edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65)",
            "edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101)",
            "edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144)",
            "org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)",
            "org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)",
            "org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)"
        ],
        "reproStatus": "REPRODUCIBLE",
        "minConfig": {
            "dfs.namenode.blocks.per.postponedblocks.rescan": "595821979",
            "dfs.namenode.blockreport.queue.size": "1208011039"
        }
    }
]
note	bugId	status	times	testName	failure	failureMessage	stackTrace	reproStatus	replayedFailure	replayedErrorMessage	replayedStackTrace	replayedFile	minConfig	debugFiles
	Bug-52	BUG	1	org.apache.hadoop.io.compress.TestCodec#testSnappyMapFile	java.lang.ArrayIndexOutOfBoundsException		org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(SnappyCompressor.java:86), org.apache.hadoop.io.compress.BlockCompressorStream.write(BlockCompressorStream.java:112), java.base/java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:81), java.base/java.io.BufferedOutputStream.flush(BufferedOutputStream.java:142), java.base/java.io.DataOutputStream.flush(DataOutputStream.java:123), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.writeBuffer(SequenceFile.java:1588), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.sync(SequenceFile.java:1605), org.apache.hadoop.io.SequenceFile$BlockCompressWriter.append(SequenceFile.java:1663), org.apache.hadoop.io.SequenceFile$Writer.append(SequenceFile.java:1425), org.apache.hadoop.io.MapFile$Writer.append(MapFile.java:327), org.apache.hadoop.io.compress.TestCodec.createMapFile(TestCodec.java:638), org.apache.hadoop.io.compress.TestCodec.codecTestMapFile(TestCodec.java:620), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile(TestCodec.java:607), org.apache.hadoop.io.compress.TestCodec.testSnappyMapFile$$CONFUZZ(TestCodec.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.compress.TestCodec/testSnappyMapFile/campaign/failures/debug_000000	{"io.compression.codec.snappy.buffersize": "4", "io.seqfile.compress.blocksize": "767"}	["debug_000000"]
	Bug-213	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testTwoDataEntries	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:612), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testTwoDataEntries(TestTFileByteArrays.java:137), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testTwoDataEntries$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testTwoDataEntries/campaign/failures/debug_000002	{"hadoop.security.dns.log-slow-lookups.threshold.ms": "767", "hadoop.security.groups.cache.secs": "344", "fs.client.resolve.remote.symlinks": "false", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.service.shutdown.timeout": "1000039h", "file.stream-buffer-size": "2095218431", "fs.local.block.size": "767", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "io.file.buffer.size": "1769154518", "tfile.fs.input.buffer.size": "2130640638", "hadoop.kerberos.min.seconds.before.relogin": "30769", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "22701", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "tfile.fs.output.buffer.size": "767", "fs.creation.parallel.count": "456", "file.bytes-per-checksum": "1020", "hadoop.security.groups.cache.warn.after.ms": "27"}	["debug_000002"]
	Bug-3	BUG	1	org.apache.hadoop.ipc.TestRPC#testDecayRpcSchedulerMetrics	java.lang.OutOfMemoryError	Java heap space	java.base/java.util.PriorityQueue.<init>(PriorityQueue.java:172), java.base/java.util.PriorityQueue.<init>(PriorityQueue.java:139), org.apache.hadoop.metrics2.util.Metrics2Util$TopN.<init>(Metrics2Util.java:80), org.apache.hadoop.ipc.DecayRpcScheduler.getTopCallers(DecayRpcScheduler.java:1002), org.apache.hadoop.ipc.DecayRpcScheduler.addTopNCallerSummary(DecayRpcScheduler.java:982), org.apache.hadoop.ipc.DecayRpcScheduler.getMetrics(DecayRpcScheduler.java:935), org.apache.hadoop.ipc.DecayRpcScheduler$MetricsProxy.getMetrics(DecayRpcScheduler.java:893), org.apache.hadoop.test.MetricsAsserts.getMetrics(MetricsAsserts.java:94), org.apache.hadoop.test.MetricsAsserts.getMetrics(MetricsAsserts.java:103), org.apache.hadoop.test.MetricsAsserts.getMetrics(MetricsAsserts.java:99), org.apache.hadoop.ipc.TestRPC.testDecayRpcSchedulerMetrics(TestRPC.java:1426), org.apache.hadoop.ipc.TestRPC.testDecayRpcSchedulerMetrics$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testDecayRpcSchedulerMetrics/campaign/failures/debug_000001	{"decay-scheduler.metrics.top.user.count": "1724464059"}	["debug_000001"]
	Bug-243	BUG	1	org.apache.hadoop.ipc.TestRPC#testClientBackOff	java.lang.ClassCastException	class org.apache.hadoop.ipc.RpcException cannot be cast to class org.apache.hadoop.ipc.RemoteException (org.apache.hadoop.ipc.RpcException and org.apache.hadoop.ipc.RemoteException are in unnamed module of loader 'app')	org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1208), org.apache.hadoop.ipc.TestRPC.testClientBackOff$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testClientBackOff/campaign/failures/debug_000002	{"ipc.maximum.response.length": "40"}	["debug_000002"]
	Bug-175	BUG	1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testSeekBigFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.fs.FSInputChecker.set(FSInputChecker.java:485), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:173), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:124), org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:117), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testSeekBigFile(AbstractContractSeekTest.java:301), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek.testSeekBigFile$$CONFUZZ(TestLocalFSContractSeek.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testSeekBigFile/campaign/failures/debug_000000	{"hadoop.security.groups.cache.warn.after.ms": "2147461118", "file.bytes-per-checksum": "1435584346"}	["debug_000000"]
	Bug-208	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileStreams#testOneEntryMixedLengths1	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(TestTFileByteArrays.java:618), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths1(TestTFileStreams.java:127), org.apache.hadoop.io.file.tfile.TestTFileStreams.testOneEntryMixedLengths1$$CONFUZZ(TestTFileStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileStreams/testOneEntryMixedLengths1/campaign/failures/debug_000002	{"tfile.fs.input.buffer.size": "2130640638", "file.bytes-per-checksum": "2130640638", "tfile.io.chunk.size": "847"}	["debug_000002"]
		FP	1	org.apache.hadoop.ipc.TestRPC#testClientBackOff	org.mockito.exceptions.verification.WantedButNotInvoked	Wanted but not invoked:callQueueManager.addInternal(<any>, false);-> at org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1203)However, there were exactly 2 interactions with this mock:callQueueManager.take();-> at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2942)callQueueManager.size();-> at org.apache.hadoop.ipc.Server$ConnectionManager.register(Server.java:3800)	org.apache.hadoop.ipc.TestRPC.testClientBackOff(TestRPC.java:1203), org.apache.hadoop.ipc.TestRPC.testClientBackOff$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testClientBackOff/campaign/failures/debug_000000	{"ipc.maximum.data.length": "81"}	["debug_000000"]
		FP	1	org.apache.hadoop.ipc.TestMultipleProtocolServer#testPBService	org.apache.hadoop.ipc.RpcException	RPC response exceeds maximum data length	org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936), org.apache.hadoop.security.SaslRpcClient.saslConnect(SaslRpcClient.java:367), org.apache.hadoop.ipc.Client$Connection.setupSaslConnection(Client.java:623), org.apache.hadoop.ipc.Client$Connection.access$2300(Client.java:414), org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:843), org.apache.hadoop.ipc.Client$Connection$2.run(Client.java:839), java.base/java.security.AccessController.doPrivileged(Native Method), java.base/javax.security.auth.Subject.doAs(Subject.java:423), org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878), org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:839), org.apache.hadoop.ipc.Client$Connection.access$3800(Client.java:414), org.apache.hadoop.ipc.Client.getConnection(Client.java:1677), org.apache.hadoop.ipc.Client.call(Client.java:1502), org.apache.hadoop.ipc.Client.call(Client.java:1455), org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:242), org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:129), com.sun.proxy.$Proxy23.ping(Unknown Source), org.apache.hadoop.ipc.TestProtoBufRpc.testProtoBufRpc(TestProtoBufRpc.java:243), org.apache.hadoop.ipc.TestMultipleProtocolServer.testPBService(TestMultipleProtocolServer.java:66), org.apache.hadoop.ipc.TestMultipleProtocolServer.testPBService$$CONFUZZ(TestMultipleProtocolServer.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestMultipleProtocolServer/testPBService/campaign/failures/debug_000005	{"hadoop.security.authentication": "kerberos", "ipc.maximum.response.length": "6"}	["debug_000005"]
		FP	1	org.apache.hadoop.ipc.TestAsyncIPC#testCallIdAndRetry	org.apache.hadoop.ipc.RpcException	RPC response exceeds maximum data length	org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1936), org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238), org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestAsyncIPC/testCallIdAndRetry/campaign/failures/debug_000003	{"ipc.maximum.response.length": "48", "hadoop.security.authorization": "true"}	["debug_000003"]
		FP	1	org.apache.hadoop.ipc.TestIPCServerResponder#testResponseBuffer	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertFalse(Assert.java:65), org.junit.Assert.assertFalse(Assert.java:75), org.apache.hadoop.ipc.TestIPCServerResponder.checkServerResponder(TestIPCServerResponder.java:174), org.apache.hadoop.ipc.TestIPCServerResponder.testResponseBuffer(TestIPCServerResponder.java:142), org.apache.hadoop.ipc.TestIPCServerResponder.testResponseBuffer$$CONFUZZ(TestIPCServerResponder.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPCServerResponder/testResponseBuffer/campaign/failures/debug_000000	{"ipc.maximum.data.length": "51"}	["debug_000000"]
	Bug-204	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureCompressionNotWorking	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareDataBlock(BCFile.java:431), org.apache.hadoop.io.file.tfile.TFile$Writer.initDataBlock(TFile.java:642), org.apache.hadoop.io.file.tfile.TFile$Writer.prepareAppendKey(TFile.java:533), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:393), org.apache.hadoop.io.file.tfile.TFile$Writer.append(TFile.java:356), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:592), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TestTFileByteArrays.java:579), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureCompressionNotWorking(TestTFileByteArrays.java:550), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureCompressionNotWorking$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureCompressionNotWorking/campaign/failures/debug_000004	{"file.stream-buffer-size": "526", "hadoop.security.groups.negative-cache.secs": "13018", "hadoop.security.group.mapping": "org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback", "fs.local.block.size": "425", "tfile.fs.output.buffer.size": "2130640638", "fs.creation.parallel.count": "61346", "file.bytes-per-checksum": "2130640638", "io.file.buffer.size": "525"}	["debug_000004"]
	Bug-208	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays#testScanRange	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.file.tfile.Compression$Algorithm$2.createDecompressionStream(Compression.java:196), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testScanRange(TestTFileUnsortedByteArrays.java:140), org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testScanRange$$CONFUZZ(TestTFileUnsortedByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays/testScanRange/campaign/failures/debug_000000	{"fs.defaultFS": "file:///", "hadoop.security.auth_to_local.mechanism": "hadoop", "hadoop.security.groups.cache.secs": "361", "fs.client.resolve.remote.symlinks": "false", "hadoop.service.shutdown.timeout": "882545707h", "file.stream-buffer-size": "161", "hadoop.security.auth_to_local": "RULE:[1:$1] RULE:[2:$1]", "hadoop.security.groups.cache.background.reload": "true", "hadoop.user.group.static.mapping.overrides": "dr.who=;", "tfile.fs.input.buffer.size": "1715926512", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "hadoop.security.groups.negative-cache.secs": "1136202683", "fs.creation.parallel.count": "161646293", "file.bytes-per-checksum": "2077505226", "fs.automatic.close": "true", "hadoop.security.dns.log-slow-lookups.threshold.ms": "1162035458", "hadoop.security.authentication": "simple", "hadoop.security.dns.log-slow-lookups.enabled": "false", "hadoop.security.groups.cache.background.reload.threads": "865494616", "fs.local.block.size": "3560", "fs.file.impl.disable.cache": "true", "hadoop.security.token.service.use_ip": "false", "hadoop.kerberos.min.seconds.before.relogin": "469", "tfile.fs.output.buffer.size": "898", "hadoop.security.groups.cache.warn.after.ms": "370613170"}	["debug_000000"]
	Bug-213	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams#testFailureNegativeOffset	java.lang.OutOfMemoryError	Java heap space	java.base/java.io..BufferedInputStream<init>(BufferedInputStream.java:209), org.apache.hadoop.io.file.tfile.Compression$Algorithm$3.createDecompressionStream(Compression.java:237), org.apache.hadoop.io.file.tfile.BCFile$Reader$RBlockState.<init>(BCFile.java:505), org.apache.hadoop.io.file.tfile.BCFile$Reader.createReader(BCFile.java:732), org.apache.hadoop.io.file.tfile.BCFile$Reader.getMetaBlock(BCFile.java:709), org.apache.hadoop.io.file.tfile.BCFile$Reader.<init>(BCFile.java:639), org.apache.hadoop.io.file.tfile.TFile$Reader.<init>(TFile.java:804), org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureNegativeOffset(TestTFileStreams.java:361), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams.testFailureNegativeOffset$$CONFUZZ(TestTFileNoneCodecsStreams.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsStreams/testFailureNegativeOffset/campaign/failures/debug_000001	{"hadoop.security.groups.cache.secs": "24068", "tfile.fs.input.buffer.size": "1834570941", "hadoop.kerberos.keytab.login.autorenewal.enabled": "false", "file.bytes-per-checksum": "1561720557", "fs.file.impl.disable.cache": "true", "io.file.buffer.size": "1324739946"}	["debug_000001"]
		FP	1	org.apache.hadoop.ipc.TestIPC#testAuxiliaryPorts	java.lang.IllegalArgumentException	numLevels must be at least 1	org.apache.hadoop.ipc.CallQueueManager.parseNumLevels(CallQueueManager.java:355), org.apache.hadoop.ipc.CallQueueManager.<init>(CallQueueManager.java:78), org.apache.hadoop.ipc.Server.<init>(Server.java:3115), org.apache.hadoop.ipc.Server.<init>(Server.java:3046), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:226), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:212), org.apache.hadoop.ipc.TestIPC$TestServer.<init>(TestIPC.java:195), org.apache.hadoop.ipc.TestIPC.testAuxiliaryPorts(TestIPC.java:385), org.apache.hadoop.ipc.TestIPC.testAuxiliaryPorts$$CONFUZZ(TestIPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestIPC/testAuxiliaryPorts/campaign/failures/debug_000003	{"ipc.9000.scheduler.priority.levels": "0"}	["debug_000003"]
		FP	1	org.apache.hadoop.ipc.TestRPC#testClientRpcTimeout	java.lang.AssertionError		org.junit.Assert.fail(Assert.java:87), org.junit.Assert.assertTrue(Assert.java:42), org.junit.Assert.assertTrue(Assert.java:53), org.apache.hadoop.ipc.TestRPC.testClientRpcTimeout(TestRPC.java:1562), org.apache.hadoop.ipc.TestRPC.testClientRpcTimeout$$CONFUZZ(TestRPC.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testClientRpcTimeout/campaign/failures/debug_000000	{"ipc.maximum.data.length": "23"}	["debug_000000"]
	Bug-7	BUG	1	org.apache.hadoop.fs.TestFsShellCopy#testCopyCrc	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedOutputStream.<init>(BufferedOutputStream.java:75), org.apache.hadoop.fs.statistics.BufferedIOStatisticsOutputStream.<init>(BufferedIOStatisticsOutputStream.java:78), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:428), org.apache.hadoop.fs.RawLocalFileSystem.create(RawLocalFileSystem.java:459), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSOutputSummer.<init>(ChecksumFileSystem.java:433), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:521), org.apache.hadoop.fs.ChecksumFileSystem.create(ChecksumFileSystem.java:500), org.apache.hadoop.fs.FilterFileSystem.create(FilterFileSystem.java:197), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1195), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1175), org.apache.hadoop.fs.FileSystem.create(FileSystem.java:1064), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.create(CommandWithDestination.java:532), org.apache.hadoop.fs.shell.CommandWithDestination$TargetFileSystem.writeStreamToFile(CommandWithDestination.java:494), org.apache.hadoop.fs.shell.CommandWithDestination.copyStreamToTarget(CommandWithDestination.java:417), org.apache.hadoop.fs.shell.CommandWithDestination.copyFileToTarget(CommandWithDestination.java:352), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.copyFileToTarget(CopyCommandWithMultiThread.java:144), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:287), org.apache.hadoop.fs.shell.CommandWithDestination.processPath(CommandWithDestination.java:272), org.apache.hadoop.fs.shell.Command.processPathInternal(Command.java:370), org.apache.hadoop.fs.shell.Command.processPaths(Command.java:333), org.apache.hadoop.fs.shell.Command.processPathArgument(Command.java:306), org.apache.hadoop.fs.shell.CommandWithDestination.processPathArgument(CommandWithDestination.java:267), org.apache.hadoop.fs.shell.Command.processArgument(Command.java:288), org.apache.hadoop.fs.shell.Command.processArguments(Command.java:272), org.apache.hadoop.fs.shell.CommandWithDestination.processArguments(CommandWithDestination.java:238), org.apache.hadoop.fs.shell.CopyCommandWithMultiThread.processArguments(CopyCommandWithMultiThread.java:89), org.apache.hadoop.fs.shell.FsCommand.processRawArguments(FsCommand.java:121), org.apache.hadoop.fs.shell.Command.run(Command.java:179), org.apache.hadoop.fs.FsShell.run(FsShell.java:327), org.apache.hadoop.fs.TestFsShellCopy.shellRun(TestFsShellCopy.java:81), org.apache.hadoop.fs.TestFsShellCopy.testCopyCrc(TestFsShellCopy.java:98), org.apache.hadoop.fs.TestFsShellCopy.testCopyCrc$$CONFUZZ(TestFsShellCopy.java),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.TestFsShellCopy/testCopyCrc/campaign/failures/debug_000001	{"file.stream-buffer-size": "2109839473", "file.bytes-per-checksum": "590481997", "io.file.buffer.size": "1356378664"}	["debug_000001"]
		FP	1	org.apache.hadoop.ipc.TestRPC#testRpcMetricsInNanos	java.io.EOFException		java.base/java.io.DataInputStream.readInt(DataInputStream.java:397), org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1922), org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1238), org.apache.hadoop.ipc.Client$Connection.run(Client.java:1134),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestRPC/testRpcMetricsInNanos/campaign/failures/debug_000001	{"ipc.server.max.connections": "1"}	["debug_000001"]
	Bug-173	BUG	1	org.apache.hadoop.io.TestArrayFile#testEmptyFile	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:64), org.apache.hadoop.io.compress.DecompressorStream.<init>(DecompressorStream.java:71), org.apache.hadoop.io.compress.DefaultCodec.createInputStream(DefaultCodec.java:92), org.apache.hadoop.io.SequenceFile$Reader.init(SequenceFile.java:2072), org.apache.hadoop.io.SequenceFile$Reader.initialize(SequenceFile.java:1940), org.apache.hadoop.io.SequenceFile$Reader.<init>(SequenceFile.java:1889), org.apache.hadoop.io.MapFile$Reader.open(MapFile.java:447), org.apache.hadoop.io.MapFile$Reader.<init>(MapFile.java:403), org.apache.hadoop.io.ArrayFile$Reader.<init>(ArrayFile.java:75), org.apache.hadoop.io.TestArrayFile.testEmptyFile(TestArrayFile.java:63), org.apache.hadoop.io.TestArrayFile.testEmptyFile$$CONFUZZ(TestArrayFile.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.TestArrayFile/testEmptyFile/campaign/failures/debug_000001	{"file.stream-buffer-size": "947265776", "io.file.buffer.size": "957144961"}	["debug_000001"]
		FP	1	org.apache.hadoop.security.TestGroupsCaching#testExceptionOnBackgroundRefreshHandled	java.lang.AssertionError	Excepted group counter values are not reached in given time, expecting (Queued, Running, Success, Exception) : [0, 0, 0, 1] but actual : [1, 0, 0, 0]	org.junit.Assert.fail(Assert.java:89), org.apache.hadoop.security.TestGroupsCaching.waitForGroupCounters(TestGroupsCaching.java:786), org.apache.hadoop.security.TestGroupsCaching.testExceptionOnBackgroundRefreshHandled(TestGroupsCaching.java:657), org.apache.hadoop.security.TestGroupsCaching.testExceptionOnBackgroundRefreshHandled$$CONFUZZ(TestGroupsCaching.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:41),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.security.TestGroupsCaching/testExceptionOnBackgroundRefreshHandled/campaign/failures/debug_000004	{"hadoop.security.groups.cache.background.reload.threads": "1073741824"}	["debug_000004"]
	Bug-212	BUG	1	org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek#testReadSmallFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:153), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.read(ChecksumFileSystem.java:210), org.apache.hadoop.fs.FSDataInputStream.read(FSDataInputStream.java:98), org.apache.hadoop.fs.contract.AbstractContractSeekTest.testReadSmallFile(AbstractContractSeekTest.java:543), org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek.testReadSmallFile$$CONFUZZ(TestLocalFSContractSeek.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:61), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.fs.contract.localfs.TestLocalFSContractSeek/testReadSmallFile/campaign/failures/debug_000001	{"hadoop.security.groups.cache.background.reload.threads": "29821", "fs.local.block.size": "62202041", "fs.creation.parallel.count": "865", "file.bytes-per-checksum": "2111531054", "fs.automatic.close": "false", "hadoop.security.groups.cache.warn.after.ms": "695"}	["debug_000001"]
	Bug-192	BUG	1	org.apache.hadoop.ha.TestZKFailoverController#testObserverExitGracefulFailover	java.lang.NullPointerException		org.apache.hadoop.ha.ZKFailoverController.doRun(ZKFailoverController.java:258), org.apache.hadoop.ha.ZKFailoverController.access$000(ZKFailoverController.java:63), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:181), org.apache.hadoop.ha.ZKFailoverController$1.run(ZKFailoverController.java:177), org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:503), org.apache.hadoop.ha.ZKFailoverController.run(ZKFailoverController.java:177), org.apache.hadoop.ha.MiniZKFCCluster$DummyZKFCThread.doWork(MiniZKFCCluster.java:301), org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:189),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ha.TestZKFailoverController/testObserverExitGracefulFailover/campaign/failures/debug_000001	{"ipc.0.scheduler.priority.levels": "0"}	["debug_000001"]
		FP	1	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider#testClientRetriesIfMaxAttemptsNotSet	org.mockito.exceptions.verification.TooFewActualInvocations	kMSClientProvider.createKey(    "test3",    <any org.apache.hadoop.crypto.key.KeyProvider.Options>);Wanted 2 times:-> at org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet(TestLoadBalancingKMSClientProvider.java:659)But was 1 time:-> at org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider$15.call(LoadBalancingKMSClientProvider.java:485)	org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet(TestLoadBalancingKMSClientProvider.java:659), org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider.testClientRetriesIfMaxAttemptsNotSet$$CONFUZZ(TestLoadBalancingKMSClientProvider.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:299), org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:293), java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264), java.base/java.lang.Thread.run(Thread.java:829),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.crypto.key.kms.TestLoadBalancingKMSClientProvider/testClientRetriesIfMaxAttemptsNotSet/campaign/failures/debug_000001	{"hadoop.security.kms.client.failover.max.retries": "0"}	["debug_000001"]
	Bug-212	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays#testFailureOpenRandomFile	java.lang.OutOfMemoryError	Java heap space	java.base/java.io.BufferedInputStream.<init>(BufferedInputStream.java:209), org.apache.hadoop.fs.BufferedFSInputStream.<init>(BufferedFSInputStream.java:56), org.apache.hadoop.fs.RawLocalFileSystem.open(RawLocalFileSystem.java:275), org.apache.hadoop.fs.ChecksumFileSystem$ChecksumFSInputChecker.<init>(ChecksumFileSystem.java:166), org.apache.hadoop.fs.ChecksumFileSystem.open(ChecksumFileSystem.java:372), org.apache.hadoop.fs.FileSystem.open(FileSystem.java:976), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOpenRandomFile(TestTFileByteArrays.java:411), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays.testFailureOpenRandomFile$$CONFUZZ(TestTFileNoneCodecsByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsByteArrays/testFailureOpenRandomFile/campaign/failures/debug_000000	{"fs.creation.parallel.count": "24979", "file.bytes-per-checksum": "2130640639"}	["debug_000000"]
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testParseThresholds	java.lang.IllegalArgumentException	Decay Factor must be between 0 and 1	org.apache.hadoop.ipc.DecayRpcScheduler.parseDecayFactor(DecayRpcScheduler.java:311), org.apache.hadoop.ipc.DecayRpcScheduler.<init>(DecayRpcScheduler.java:227), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds(TestDecayRpcScheduler.java:113), org.apache.hadoop.ipc.TestDecayRpcScheduler.testParseThresholds$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:44),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testParseThresholds/campaign/failures/debug_000000	{"ipc.8.faircallqueue.decay-scheduler.decay-factor": "-0.37059444189071655"}	["debug_000000", "debug_000001", "debug_000003", "debug_000002", "debug_000004"]
		FP	1	org.apache.hadoop.ipc.TestDecayRpcScheduler#testUsingWeightedTimeCostProvider	java.lang.AssertionError	expected:<0> but was:<1>	org.junit.Assert.fail(Assert.java:89), org.junit.Assert.failNotEquals(Assert.java:835), org.junit.Assert.assertEquals(Assert.java:647), org.junit.Assert.assertEquals(Assert.java:633), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider(TestDecayRpcScheduler.java:321), org.apache.hadoop.ipc.TestDecayRpcScheduler.testUsingWeightedTimeCostProvider$$CONFUZZ(TestDecayRpcScheduler.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413), org.junit.runner.JUnitCore.run(JUnitCore.java:137), edu.berkeley.cs.jqf.fuzz.junit.GuidedFuzzing.run(GuidedFuzzing.java:208), edu.illinois.confuzz.internal.FuzzForkMain.main(FuzzForkMain.java:44),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.ipc.TestDecayRpcScheduler/testUsingWeightedTimeCostProvider/campaign/failures/debug_000007	{"ipc.15.weighted-cost.lockfree": "455", "ipc.15.decay-scheduler.decay-factor": "4.729628562927246E-4"}	["debug_000007"]
	Bug-204	BUG	1	org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays#testFailureBadCompressionCodec	java.lang.OutOfMemoryError	Java heap space	org.apache.hadoop.io.BytesWritable.setCapacity(BytesWritable.java:146), org.apache.hadoop.io.file.tfile.BCFile$Writer$WBlockState.<init>(BCFile.java:125), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:357), org.apache.hadoop.io.file.tfile.BCFile$Writer.prepareMetaBlock(BCFile.java:383), org.apache.hadoop.io.file.tfile.TFile$Writer.close(TFile.java:319), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.closeOutput(TestTFileByteArrays.java:765), org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureBadCompressionCodec(TestTFileByteArrays.java:366), org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays.testFailureBadCompressionCodec$$CONFUZZ(TestTFileNoneCodecsJClassComparatorByteArrays.java), java.base/java.lang.reflect.Method.invoke(Method.java:566), org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59), org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12), org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner$1.evaluate(TrialRunner.java:59), org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26), org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), edu.berkeley.cs.jqf.fuzz.junit.TrialRunner.run(TrialRunner.java:65), edu.illinois.confuzz.internal.ConfuzzGuidance.run(ConfuzzGuidance.java:101), edu.berkeley.cs.jqf.fuzz.junit.quickcheck.FuzzStatement.evaluate(FuzzStatement.java:144), org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100), org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103), org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63), org.junit.runners.ParentRunner$4.run(ParentRunner.java:331), org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79), org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329), org.junit.runners.ParentRunner.access$100(ParentRunner.java:66), org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293), org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306), org.junit.runners.ParentRunner.run(ParentRunner.java:413),	REPRODUCIBLE				/home/ctestfuzz/fuzz-hadoop/hadoop-common-project/hadoop-common/target/meringue/org.apache.hadoop.io.file.tfile.TestTFileNoneCodecsJClassComparatorByteArrays/testFailureBadCompressionCodec/campaign/failures/debug_000001	{"file.stream-buffer-size": "848", "tfile.fs.output.buffer.size": "2143553551", "file.bytes-per-checksum": "2130640639", "hadoop.security.groups.cache.warn.after.ms": "750"}	["debug_000001"]